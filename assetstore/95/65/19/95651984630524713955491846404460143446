A new AC Unification algorithm with an Algorithm 
for Solving Systems of Diophantine Equations 
Alexandre Boudet * Evelyne Contejean HervC Devie 
LRI, Universitd Paris-Sud, BSt 490 
91405 ORSAY Cedex, France 
Abstract 
This paper presents a new AC-unification algorithm. A new 
combination technique for regular collapse-free theories is 
provided along the line developped in [Bou Jou Sch 881. 
The number of calls to  the diophantine equations solver is 
bounded by the number of AC symbols times the number 
of shared variables. The rest of our algorithm being linear, 
this gives a much better idea of how the complexity of AC 
unification is related to the complexity of solving linear dio- 
phantine equations. The termination proof is surprisingly 
easy, compared to  [Fages 841. 
Finally, systems of constraint linear diophantine equations 
can be solved, rather than one equation at a time, using 
an algorithm which extends Fortenbacher’s algorithm to an 
arbitrary dimension. This allows a much more efficient use 
of the constraints than in the standard case. 
1 Introduction 
Associative-commutative unification [Stickel 751, [Siekmann 
781, [Fages 841, [Kirchner 85,871, [Her Sie 851 is a main issue 
in term rewriting and in automated deduction in general. 
Given F = {+,* ,..., a , b , c  , . . . ,  f , g , h  ,... } where 
+, *, . . . denote AC symbols, a ,  6 ,  c ,  . . . denote free constants 
and f , g ,  h . .  . free function symbols, and a graded set X 
of variables, the problem is to solve equations in T ( F ,  X), 
modulo the axioms of associativity and commutativity. 
A particular case is when F = {+}, that is when the 
signature is reduced to  one AC symbol, or possibly one AC 
symbol plus free constants. The problem is then much eas- 
ier and reduces to combining the minimal positive solutions 
of linear diophantine equations. 
One difficulty is indeed to combine several AC sym- 
bols and some additional free function symbols; it has been 
solved in at least two different ways in the past, by Stickel 
[Stickel 751 and by Kirchner [Kirchner 851. In both cases, 
the completeness proof is difficult [Fages 841 because the 
termination proof is quite involved. 
*This research was partially supported by GRECO Programmation 
and FIRTECH. 
Another difficulty is to solve linear diophantine equa- 
tions, a problem in N P .  Again, there are two main meth- 
ods, by Huet [Huet 781 and Lambert [Lamt.ert 871, on one 
hand, and by Clausen and Fortenbacher [Clau For 871 on 
the other hand. We present an algorithm which extends 
Fortenbacher’s method to  solve directly systems of linear 
Diophantine equations. 
The structure of the paper is as follows: section 2 in- 
troduces our basic assumptions, section 3 gives our set of 
inference rules for combining simple theories and proves its 
completeness, section 4 gives a simple proof of termination 
for any control which postpones replacement to the end, 
and a bound for the number of calls to AC-unification for 
one AC symbol plus variables. 
Section 5 gives a new efficient algorithm for solving sys- 
tems of linear constrained diophantine equations, which is 
needed for solving pure problems. Our notations are con- 
sistent with [Der Jou 891. 
2 Basic Concepts 
Given a set F of function symbols, and a set X of vari- 
ables, given two terms s and t in T ( F ,  S), a substitution U 
is a unifier of s and t if su = tu (we use postfix notation, 
denoting by so the application of substitution U to  a term 
s).  We use the notation t [ s ] ,  to  denote the term t in which 
the subterm at position p has been replaced by the term 
s. Position p may be omitted if clear from the context or 
irrelevant. V ( t )  denotes the set of variables occurring in the 
term t .  
Let E = { l k  = f k } k , K  be a set of equations such that l k  and 
rk are in T ( F ,  X )  for k E K .  Let s and t be two terms in 
T ( F , X ) .  We write s H E  t if there exist an equation 1 = r 
in E ,  a position p in s and a substitution U such that the 
subterm of s at position p is equal to la, and t = ~ [ r u ] , .  
s HE t is a one-step equational proof. The reflexive sym- 
metric transitive closure of H E  is denoted by = E .  A sub- 
stitution U is an E-unifier of s and t if su = E  tu. Given 
V C X ,  a substitution U is said to  be more general modulo 
E over V than substitution t? (denoted U ‘&t?) if there 
exists a substitution U’ such that Vz E V ,  zuu’ = E  26. 
CH2897-7/90/0000/0289$01 .OO 0 1990 IEEE 
289 
Definition 1 Let s and t be two terms, and W a set of 
variables such that ( V ( s )  U V ( t ) )  C W .  A complete set of 
E-unifiers of s and t away from W is a set C of substitutions, 
denoted C S u ~ ( s , t ) ,  such that 
VU E C,Dom(u)  ( V ( s )  U V ( t ) )  and I(u) n W = 0 
(Idempotency and protection of variables) 
0 VU E C, su = E  t u  [correctness), 
ve such that se = E  t e ,  ju E c such that U s v ( s ) u v ( t ) 8  
[completeness). 
Zf i n  addition 
U sv(A)uv(t)e for no u , e  E 
C is called a minimal complete set of E-unifiers of s and t .  
Let Fo = {f ,g ,  h, . . . , a ,  b ,c ,  . . .} be a set of free function 
symbols, AC' = . . , +,}, a set of AC operators, 
and X a set of variables. F, denotes the set {+,}. 
We denote by E,  the AC theory on T ( { + , } , X )  and, for 
ease of notations, by Eo the free theory on T(F0 ,X)  (Eo 
contains no axioms). 
Definition 2 
Let F = U, F,. A term t E T ( F ,  X )  is pure i n  the theory E ,  
if t E T ( F , , X ) .  A non-pure term is called heterogeneous. 
A n  equation s t as said to be pure i n  a theory E if both 
s and t are pure in  E, and heterogeneous otherwise. A n  
equation s : t is proper i f s  and t are not both variables. 
Definition 3 
A unification problem P is of the form: 
P = Pv U PH U Po U PI U P2 U , .  . U P ,  
where 
Pv is the subset of non proper equations z 
PH is the subset of heterogeneous equations s 2 t i n  P .  
P, is the subset of proper equations s 
i n  E,. 
V ( P )  denotes the set of the variables occurring zn P .  
Splitting P in such subproblems is natural since we aim 
at using the known unification algorithms for each theory: 
plain unification for Eo, and ACrunification for E , , i  > 1.  
The combination problem is the following: given two 
consistent equational theories E on T ( F , X )  and E' on 
T ( F ' ,  X )  for which complete unification algorithms are 
known, is it possible to  deduce a complete unification al- 
gorithm modulo E U E' for terms in T ( F  U F',  X)? 
Two kinds of axioms make this problem difficult: a 
collapse-equation is an equation z = t where z E V ( t )  and 
t $ X (if z 4 V ( t ) ,  the theory is inconsistent). A theory 
is collapse-free if it contains no collapse-equation, or equiv- 
alently one of its presentations contains no collapse-axiom. 
Collapse-axioms provide solutions to  equations s t where 
y in P .  
t in P that are pure 
the top function symbols of s and t are in F and F' respec- 
tively. If both E and E' are collapse-free, then equations 
s t where s and t have their top function symbols in F 
and F' respectively have no E U E'-solution. This is easily 
proved by contradiction and induction on the length of the 
alleged proof. 
Another property, regularity, makes unification in a 
combination of theories easy: an equation s = t is regular if 
V ( s )  = V ( t ) .  An equational theory E is said to  be regular 
if it contains only regular equations, or equivalently, if one 
of the presentations of E contains only regular axioms. 
Non-regular axioms yield solutions to unification prob- 
lems which contain compound cycles as defined below: 
Definition 4 
A compound cycle is a set of equations 
{zl 2 SI, ..., z,: s,} 
where z, E V ( S , - ~ )  for i E [2..n] and z1 E V ( s , )  and two of 
sir.. . , s, are non-variable terms pure in  different theories. 
If all the theories involved are regular and collapse-free, 
then compound cycles have no solution [Yelick 851, [TidCn 
A third property makes unification in combination of 
861. 
equational theories even simpler: 
Definition 5 A n  equational theory E is  simple if equations 
s 1 t where t is a proper subterm of s have no E-solution. 
Simple theories are regular and collapse-free, but the 
converse is not true: the theory of which a presentation 
is { a  = f(a)} is regular and collapse-free, but it is not a 
simple theory. 
The combination problem has been treated by, e.g., 
Claude Kirchner [Kirchner 851, who combines mutation 
schemes for E and E' with the requirement that  both E 
and E' are simple theories. Yelick [Yelick 851 gives a com- 
plete unification algorithm for the combination of regular, 
collapse-free theories, and T i d h  [Tidbn 861 extends Yelick's 
result by allowing non-regular axioms. Boudet, Jouannaud 
and Schmidt-SchauD [Bou Jou Sch 881 give an algorithm 
for combining an arbitrary theory and a simple theory, and 
an algorithm for combining arbitrary theories is given by 
Schmidt-Schauil [Schmidt-Schaul3 881. 
It is remarkable that  AC theories are of the simplest 
type with regard to  the combination problem, since they 
are simple, and yet AC unification has a long history. 
3 Combining Regular 
Collapse-Free Theories 
As seen above, AC unification reduces to  unification in a 
combination of simple theories provided that a complete 
290 
unification algorithm is known for the free theory, as well 
as a complete AC unification algorithm for one AC symbol. 
Nevertheless, proving the termination of Stickel’s algorithm 
[Stickel 751 has remained an open problem for nine years un- 
til Fages [Fages 841 found an adequate complexity measure. 
We envision a unification algorithm as given by a set 
of transformation rules S and a control. The proof of the 
algorithm consists of three independent steps: 
1. For each inference rule P k P‘, prove that the rule 
preserves solutions, that is: U is a solution of P iff  it is 
a solution of PI. If the rule is nondeterministic, then it 
must be shown that  every solution of P is accessible by an 
adequate choice, and that no further solution is added. 
2. Prove that the normal forms are unification problems 
in a solved form from which a most general unifier can be 
readily computed. 
3. Prove the termination of S for the given control (or a 
class of controls). 
3.1 The Rules 
Defini t ion 6 
The occur-check relation <OC is defined b y  z <OC y iff there 
ezist some equations 
z s1[z1],z1 L sz[zz], .. . ,z, L s,[y] 
where at least one s; is not a oariable. 
Defini t iop 7 
P‘ = (21 = t l , .  , . , z, 
and P‘ have the same solutions and V i , j  E [l..n] 
t,} is a dag solved form of P if P 
1. z, # z1 f o r i  # j .  
e. z; <OC zj * i < j .  
3. t ,  E X + t , , ~ ,  E V ( P )  and z, occurs nowhere else in 
P’ . 
3 j  < i such that z1 E V ( P )  and zl <OC 5,. 
4. z; E V ( P )  or 
P is i n  a dag solved form if P is a dag solved form of itself. 
For any theory E ,  a most general E-unifier for a dag 
solved form {zl t l , .  . . , z, = t,} of P is o = u10z . . .on  
where oi = {zi ++ t i } .  
Several algorithms are known for unification in combina- 
tions of regular collapse-free theories which basically rely 
(although implicitely for the most part) on the same mech- 
anisms as the rules given below. 
VA (Variable  Abs t rac t ion)  
s 2 t k CjZl,. . . , z,] 2 t , z1  2 S I , .  . . ,z, L s, 
s = C[z,, . . . ,x,]{z1 H S I , .  . . ,x, H s,}. 
if s is heterogeneous, and 
C[zl,. . . , z,] is a maximal pure term such that 
The goal of variable abstraction is to  yield equations 
between pure terms : applying variable abstraction to  
f ( z , g ( y )  + g(z + U ) )  t yields the equations f ( z , o l )  2 t ,  
U 1 2  g b )  + g ( 2  + U). 
P, k P; 
E-Res (E-Resolut ion)  
if PI is not in dag solved form and 
{zl t l , .  . . ,z, A t,} is a dag solved form of P,. 
When P, has no solution, the rule returns “fail” which is a 
particular unification problem with no solution. E-Res is 
known to preserve solutions [Bou Jou Sch 881. A complete 
proof is given in [ Boudet 901. 
If the theory E, is not unitary, the rule becomes nonde- 
terministic. In the case of AC unification, a complete set of 
unifiers of an elementary AC-unification problem (involv- 
ing only one AC operators and variables) can have many 
solutions [Domenjoud 891. 
C l a s h  
s t 1 fail 
if the top function symbols of s and t are constrained by 
two different theories. 
Merge 
z A s,z t k fail 
if the top function symbols of s and t are constrained by 
two different theories. 
Since all considered theories are collapse free, no equation 
can be solved between two terms whose top function symbol 
do not belong to  the same theory. This makes the rules 
Clash  and Merge complete. 
Combined  Occur-Check 
P 1 fail 
if P contains a compound cycle. 
It is shown in [Yelick 851 and [Tidbn 861 that compound 
cycles have no solution in a combination of regular, collapse- 
free theories, which yields the completeness of Combined  
Occur-Check.  
Var-Rep (Variable  Replacement )  
{ z ? y } u P  k { z r y } u P { z H y }  
if both z and y occur in P ,  and 
y occurs in the original problem Po or z does not occur 
inPo. 
Remove  
{ z ’ s } u P  k P 
if z $ V ( P o )  and z V ( s )  U V ( P ) .  
Finally the completeness of Var-Rep and Remove  is 
29 1 
straightforward. Remove removes useless equations that 
do not satisfy the condition 4 of the definition of the dag 
solved form of Po. The use of E-Res and Var-Rep is il- 
lustrated in section 4. 
7 
x - y  
4 Terminat ion 
7 7 
z = a  v = u l + u z  
We use the following measures for proving the termination 
of s: 
Definition 8 TEI,,l(P) denotes the multiset of theory 
heights of the hetcrogeneous terms in P ,  where the theory 
height of a term t is the maximal number of times the theory 
constraining the function symbols changes in a path of t .  
Note that no rule of S can increase TH,,I(P) and that 
TH,,i(P) decreases every time VA is applied: 
Lemma 1 VA decreases strictly TH,,,(P). No rule of S 
increases T H m , ~ ( P ) .  
proof : 
equation s 
VA decreases TH,,l(P) because it replaces an 
t by the equations 
C[Zl , .  . . ,z,] : t , X l  s,, . . . ,z, : s, 
where C[zl , .  . . , xn] t is a pure term and SI,. . . , s ,  have 
all a strictly smaller theory height than s. No rule increase s 
THm,~(P) :  E-Res creates no heterogeneous term and Var- 
Rep replaces a variable by another which does not change 
the theory heights of the terms. 
Shared variables are crucial in our termination proof. 
Intuitively, x and y are shared variables whenever Var- 
Rep, applied to  the equation x y yields a subproblem P, 
unsolved: 
Definition 9 
x -pa y if both x and y occur in PI. 
Let P = Pv U PH U Po u . .  . U P,,. The variables z and y 
are identifiable outside PI, denoted x G Z ~  y af (x ,y)  is in the 
transitive closure of the relation 
=v U -p,, U ' .  . U -p,-, U -p,+, u.. ' U -p, 
where =v is the equivalence on  variables generated b y  the 
equations in  -Pv. 
When z and y are identifiable outside P,, it is possible 
that some application of E-Res to  problems other than PI 
yield the equation x 
Definition 10 
A variable x is shared i n  PI if 3: V(P , )  and x x!' y for 
some variable y E V ( P l ) ,  y # z. 
S V ( P )  is the multiset {mo,ml, ..., m,} where m, is the 
number of variables shared in  PI. 
y. Hence, the following definition: 
Here is an example to illustrate the definition of shared vari- 
ables and how Var-Rep and E-Res work. 
Pv Po I Pl 
The original problem has both Po and P1 solved, but x and 
y are shared in Po and U and v are shared in Po and in PI, 
hence S V ( P )  = {4 ,2} .  Var-Rep applies to x y yielding: 
z = u  
Po unsolved, Pl solved 
I S V ( P )  = {2 ,2}  
After Var-Rep has replaced z by y, Po is not solved 
anymore but z and y are not shared anymore in PO. We 
now have S V ( P )  = (2 ,  a}, the application of Var-Rep has 
decreased S V ( P ) .  E-Res now applies to Po and yields 
U U. The obtained problem is: 
S V ( P )  = {0 ,2}  
Var-Rep applies to U U: 
u 1 v I y L f ( v ) I  u : v v l + u z  
Po solved, Pl unsolved 
1 S V ( P )  = {O,O} J 
This last application of Var-Rep makes PI unsolved, 
and as before, it has removed two shared variables. There 
are no shared variables anymore in Po or PI. This is a 
general property as shown below. 
Lemma 2 E-Res does not increase S V ( P ) .  
proof: 
Assume E,-Res is applied to  
P = Pv U PH U Po U . . . U P, U . . . U P,, yielding 
Note first that  E,-res does not change -p, for j # i. We 
can assume that El-Res first replaces P, by a dag solved 
P' = P; U PH U PO U . . '  UP: U ' . '  U p". 
292 
form, then moves the non proper equations from P,' to P; . 
The new non-proper equations occurring in P; must be of 
the form x1 22 where x1 and x2 are in V (P,),  by definition 
of E-Res. 
We proceed by inspecting all the variables shared in P'. 
1. A new variable x' cannot be is shared in P,', because it 
occurs only in P,'. 
2. Let y be a variable shared in Pi for # 2 .  Then y =f' z 
for some z E V ( P , ) .  
Every step of the proof using a new non-proper equation 
x1 2 x2 E P'v \ PV can be replaced by x1 -ps  x2 because 
xl,x2 E V ( P , ) .  The steps -p; involving a new variable are 
not useful in the proof because new variables occur only in 
P,'. Hence y =: z ,  and y was already shared in P,. 
3. Assume y is shared in P,'. By definition, there exists a 
variable z E V(P,') such that y =f' z. Both y and z are 
shared in P,', hence they both are in V(P, ) .  A proof must 
be of one of the three forms: 
* y x p z  
y %p x1 d x2 xp' 2 
y z' x1 q 52 N 2  1 3  zp' 2 
where x1 and x 2  denote the two first uses of new equations 
in P;. Note that x1 and 22 are both in V ( & )  by definition of 
a dag solved form of P,. In the two first cases, y was already 
shared in P,. In the last case, x1 and x2 were shared in P,. 
By definition of a dag solved form of P,, there is at most 
one variable equal to  x 1  modulo the equations in Pv \ P; 
left in P,'. This variable is y. Hence x 1  is no longer shared 
in 4'. 
We have shown that  if a variable is made shared, it is a 
variable of P,, and that another shared variable associated 
to y disappears from P,, hence E,-res, does not increase 
S V ( P ) .  0 
E-Res 
Var-Rep (2) 
Var-Rep (1) 
Lemma 3 Var-Rep does not increase S V ( P ) .  
proof : Assume Var-Rep applies to  the equation z y 
in Pv and replaces x by y in P \ {x y } .  Note first that 
x cannot be shared anymore because it occurs only once 
in PI. For the other variables, it is enough to  note that 
any proof z F Z ~ '  v can be mapped back to  a proof in P by 
replacing appropriate occurrences of y by occurrences of x. 
0 
=l 1 - 
= =J = 1 -  
= 1 T 1 
Definition 11 U S P ( P )  is the number of subproblems that 
are not in a dag solved fo rm in P .  
Lemma 4 If Var-Rep increases U S P ( P ) ,  then it de-  
creases strictly SV ( P ) .  
proof : For Var-Rep to make a subproblem P, unsolved, 
it must have replaced a variable x by a variable y, both 
occurring in Pi. Hence z and y were shared in P, because 
of the equation x y in Pv, and x has disappeared from 
P,, hence is no longer shared. 0 
Defini t ion 12 P V R ( P )  denotes the number of potential 
applications of Variable Replacement. A potential applica- 
tion of Variable Replacement is an equation x A y E P such 
that both x and y occur elsewhere in  P .  
The weight W ( P )  of a unification problem is 
< TH,,I ( P )  ,SV ( P )  ,U S  P (  P )  , PV R( P )  > 
Let <W be the ordering on weights obtained by comparing 
lexicographically its components from left to  right, using 
the multiset extension of < for the two first, and < for 
the two others, where < denotes the ordinary ordering on 
natural numbers. The ordering <w is well founded, as a 
lexicographic extension of well founded orderings. 
Theorem 1 For any input Po ,  S terminat. s and yields ei- 
ther fail, or a dag solved form of Po. 
proof : First note that if a problem is not in a dag 
solved form, then some rule of S applies necessarily. If there 
is a cycle in the occur-check graph, then E-Res or Com- 
bined Occur-Check apply. If one of the subproblems is 
not solved, then E-Res applies. If a variable x appears in 
two equations x t ,  then one of Var-Rep, E- 
Res, Merge or Clash applies. Finally Remove removes 
useless equations that do not satisfy the condition 4 of the 
definition of a dag solved form of Po.  
The termination proof is summarized in the following table: 
s and x 
I TH,,,,l I SV I U S P  I P V R  
I VA I l l  
4.1 A Bound on the Number of 
E-Resolutions 
Theorem 1 shows that  S terminates for any control, but 
the most natural one is to  apply VA first, as long as pos- 
sible. After VA does not apply anymore, the numbzr of 
293 
shared variables will never increase. Lemma 4 shows that a 
shared variable must disappear every time a subproblem is 
made unsolved. In the worst case, E-Res is applied to  all 
subproblems and then some applications of Var-Rep make 
them all unsolved. In the worst case, this can happen as 
many times as the number of shared variables. Hence the 
number of calls to restricted AC unification (unification for 
one AC symbol) is bounded by the number of different AC 
symbols times the number of shared variables minus one. 
This is so because only Variable Replacement may make a 
solved subproblem unsolved by identifying two shared vari- 
ables. Hence: 
Theorem 2 When VA does not apply anymore, the num- 
ber of applications of E-Res i s  bounded by the number of 
pure subproblems t imes the number of shared variables. 
Note that it is easy to  compute statically the maximal 
number of shared variables. 
4.2 Inside E-Res 
The cost of AC-unification is mainly due to  the solving of 
linear Diophantine equations, and even more to  the com- 
bining of minimal positive non-null solutions. It turns out 
that these computations can sometimes be avoided thanks 
to the following transformations: 
E-Rep 
{ Z L } U P  k { Z ~ S } U P ( Z H S }  
if P is a pure subproblem with no cycle in its occur-check 
graph and z E V ( P ) ,  and s 4 X .  
E-Sancel ~ 
z + s = z + t  k s = t  
if + is an AC operator. 
It may happen that E-Cancel creates a possible appli- 
cation of E-Rep and vice versa. Therefore, these two rules 
should be applied as long as possible before to starting to  
solve Diophantine equations. 
When solving a pure AC unification problem P,, we do 
not need to  consider the solved forms containing an equa- 
tion z s with s 6 X when there exists an equation 
z = t E P3 for j # i, because Merge would apply yielding 
“fail“. This allows to solve sets of constrained Diophantine 
equations (i.e. look for the solutions such that some vari- 
ables get a value not greater than 1) which may decrease 
drastically the number of solutions. 
7 
5 Solving Linear Systems of Dio- 
phant ine Equations 
How solving a pure AC unification subproblem is related 
to  the solving of systems of linear Diophantine equations is 
shown in, e.g., [Kirchner 851. The case where the system 
reduces to  a single equation is well-known. Two main ap- 
proaches may be distinghished. The first one is represented 
by, e.g., Huet [Huet 781 and Lambert [Lambert 871, the sec- 
ond one by Clausen and Fortenbacher [Clau For 871. The 
algorithms of Huet and Fortenbacher are compared and ex- 
tended to non homogeneous equations in [Gluck Her 851. 
Unfortunately these algorithms are not well-suited to  solve 
simultaneously several equations. In this section, we first 
give a geometric interpretation of Fortenbacher’s algorithm 
and show how it can be generalized and yield an algorithm 
for solving systems. We give the proof of the algorithm, as 
well as some refinements. Finally we show how the algo- 
rithm can be used to  solve constrained equations. 
5.1 Notations 
In the whole section, e, 
vector in Nq : 
e, = (0,.  . , O , l , O , .  . . ,O), 
The standard scalar product and the euclidian norm are 
respectively denoted by . and 11 1 1 .  
S denotes the following homogeneous linear diophantine 
system: 
denotes the j t h  canonical 
- 
3 - 1  time3 
where d,3 (lst<p,lsJ<q) is a natural number. S is also written 
d ( z )  = 0. Let S be the set of non-negative solutions of S: S 
is an additive monoid. What we actually need is a basis B of 
S, i.e. a minimal subset of S such that every solution in S 
can be written as a linear combination of the solutions in B 
where the coefficients are natural numbers. It can be easily 
shown that B is also the set of minimal elements of S \ (0) 
w.r.t. the following ordering >> on tuples of non-negative 
integers : 
(al,...,an) >> ( h , . . . , b n )  if 
V i  E [ l . .n ] ,a ,  2 b, 
and 3i E ( I . . n ] , a ,  # b, 
B is called the set of minimal solutions of S .  
5.2 A Geometric Interpretation of 
Fortenbacher’s Algorithm 
Consider one equation d l z l +  . . . + dqzq = 0. The idea is to 
search the space starting from the vectors in the canonical 
basis of Nq. Assume that we have a q-tuple (zl,. . ,zq)  
which is not yet a solution. It can be non-deterministically 
incremented component by component until it becomes a 
solution or greater than a solution. A constraint may be 
added without loosing completeness, which can drastically 
decrease the search space, namely : 
294 
if dlxl -t . . . + d,z, < 0, 
then increment some x1 such that d, > 0 ; 
if d l z l  + . . . + d,z, > 0,  
then increment some z, such that d, < 0 . 
This constraint can be expressed by the condition: 
(C,) increment z1 only if d ( z )  x d(e,) < 0 
whose geometric interpretation is displayed below: 
This method consists in choosing between different pos- 
sibilities the vectors d(e j )  heading to  the ”right direction”, 
that is, the origin. It is easy in the case of one equation 
because all vectors are in Z. But, for a system of several 
equations, the image of a tuple by d is in Z P  and the notion 
of “right direction” must be adapted. 
5.3 Generalization of Fortenbacher’s 
algorithm 
At each step, the idea is to  forbid the half-space which 
does not contain the origin, as shown in the figure below. 
Formally, a current tuple x (such that d(x) # 0) can be 
incremented on its j t h  component if and only if d ( z  + e,) 
lies in the half-space containing the origin and delimited 
by the affin hyperplan orthogonal to  the vector d ( x )  and 
containing M ,  the extremity of d ( x ) .  
0 
Mathematically, this constraint can be expressed by the 
following simple condition: 
(C,) increment zj only if d ( x )  . d ( e j )  < 0 
Note that for a single equation ( p  = I), the scalar prod- 
uct . is reduced to  the standard product x on integers, so 
that the condition (C,) is actually a particular case of the 
condition (Cp). 
Let us now give a simple algorithm which computes the 
basis 8. We are not interested in the trivial null solution. 
Hence, we start with the q distinct tuples e l , .  . . , ev. They 
can be seen as the roots of a directed acyclic graph whose 
nodes are labelled by tuples. This dag is searched breadth- 
first. If a node is labelled by the tuple ( X I , .  . . , xp), its i-th 
potential successor is labelled by 
(xl,...>zi-l,zi + 1,zi+1,...,zq) 
A leaf of the dag is subjected to  one of the following prop- 
erties: either it is a solution of the system, or it is greater 
(w.r.t. the ordering >) than a solution already found, or 
none of its potential successors satisfies the condition (C,). 
If a node does not satisfy any of these properties its poten- 
tial successors satisfying the constraint (C,) must be com- 
puted: they are the actual successors of the node. 
Example 1 Consider the system: 
5 2  - 2x3 = 0 
According to  the description oj  the algorithm, we obtain the 
dag: 
The value d(z)  is on the left of each 
tuple z if it IS not a leaf. >> s 
Here, we obtain the basis E {(1,2,1)}. 
Let P, be the set of nodes a t  depth n - 1 in the dag, and 
E ,  the subset of P, whose elements are minimal solutions. 
For sake of clarity, let us call Q, the set of nodes at depth 
n - 1 whose successors have to  be computed. Hence : 
= I j E [ l ’ . q ] )  ;
vfl 2 1,  
P,,+l = {U + e, 1 v E Q, ,d (v )  .d(e,) < O} ; 
En = {U E P, 1 d ( v )  = 0} ; 
Q n  = { V  E Pn\& I v.9 E U k < n  B k j V  $ s} . 
The algorithm stops as soon as P, is empty. U L < ,  B k  is the 
basis E that we look for. This last claim is proved in the 
next section. 
295 
5.4 Proof of the Algorithm 
Proposition 1 (Completeness) Every minimal solution oj  
S i s  computed i.e. B C 
sketch of the proof : The key of the proof is the 
following remark: once a point is reached in the space, all 
paths returning to  the origin contain a vector heading to 
the "right" direction. Since addition of vectors is associative 
and commutative, such a vector can always be applied first, 
as done by our algorithm. 
8,. 
by choosing d(e3 when M is reached, and so 
on yielding the f)Dllowing path: 
(l,b,O) ( 1 , O J )  ( 1 J J )  ( 2 , l J )  (2,1,2) (3,1,2) 
Proposition 2 (Soundness) 
minimal i.e. Untl B,  C_ B .  
Proposition 3 (Termination) 
i n  the dag i . e .  3n 2 1 ,  P, = 0. 
Every computed solution is 
There i s  no infinite branch 
Termination is the hard part of the proof. It is based upon 
the following lemma which is due to  the constraint (C,) : 
proof : The proof is by induction on n .  It is obvious 
for n = 1. Let us assume it is true for n 2 1 and let vntl 
be in P,+l. v,+~ can be written v, + e3 with U,, E P, and 
j E [ l . . q ]  such that d(v,) . d ( e , )  < 0. We get : 
IId(vn+l)I12 = !Id(?)II:+ !Id(?)II:+?d(vn?. d(e,l, 
5 ,  CZ <cz <O 
~ ~ ~ ( ~ n + 1 ) ~ ~ 2  5 (n + 1 )  Cz.  
proof : of proposition 3 
Termination is now proved by contradiction. Assume that 
there is an infinite branch in the dag, labelling an infinite 
sequence (u,),>~. As usual, for all n 2 1 ,  v, belongs to  P,, 
and v,+~ = v, + e, for some j in [ l . .q] .  The tuple v, can 
be written ( v l n , .  . . ,vqn) ;  for all j in [ l . . q ] ,  U,, is a natural 
number, and E:=, u3, = n .  
The first step of the proof ensures the existence of a 
solution in strictly positive real numbers, For this purpose, 
let us consider the sequence (u,,),>~ defined by : 
vn V n  2 1, U,, = - 
n 
We get from the previous lemma that V n  2 1 
which allows to  conclude that 
On the other hand, for all n 2 1, U, takes its values in [O,  1Iq 
(where [O, 11 is the real interval). Since [O, l ] q  is a compact 
subset in Rq, the sequence ( 2 ~ ~ ) ~ ~ ~  has an adherence value 
1 = ( 1 1 , .  . . , l q ) ,  limit of a subsequence ( u ~ ( , ) ) , > ~  (where 1p 
is an increasing mapping on N).  
From these two results and using the continuity of the map- 
ping v H lld(v) 11, we obtain 
Hence d(1) = 0, i.e. I is a tuple in [ O , 1 ] 9  solution of S in 
Rq. Note that C~,113 = 1 ,  so that 1 is not the null tuple. 
This ends up the first step. 
Starting from the solution 1 the goal is now to construct 
a solution in Nq smaller than U ,  for all n greater than some 
no. Using continuity arguments, we first construct a solu- 
tion 1' in Qq. Using standard techniques in arithmetics, 1' is 
then transformed into a solution 1" E Nq. Let us now pro- 
ceed with the first of these two steps. We have established 
that every component 1, in 1 is positive and that at least 
one of them is non-null. Let k be the number of non-null 
components in 1. Then 1 5 k 5 q and by reindexing the 
components ( 1 3 ) 1 < J < q  of 1 if necessary, we can assume that 
these k components are I 1 , .  . . , lk. Let us furthermore note 
that, since 1, (where 1 5 j 5 k) is non null, the sequence 
(vJn),>1 takes infinitely large values. 
The reals 11,. . . ,Ik generate a vector space on Q whose di- 
mension is m (1  5 m 5 k). Let ( l 1 , .  . . , l m )  be a basis of 
this space (after reindexing again the components ( 1 3 ) 1 < 3 < q  
if necessary). Then the vectors l m + l r . .  . , l k  can be expressed 
w.r.t. this basis : 
V r  E [m+ l . . k ] ,  VJ E [ l . . m ] ,  3a,, E Q, s.t. 1, = Xlml aJ, 
Hence we obtain: 
2% 
' 
5.5 Improvement of the algorithm 
5.5.1 
The simple version of the algorithm given previously deals 
with sets P, of tuples such that E;=, v3 = n. But such a 
tuple U in P, may be the successor of several different tuples 
in Pn-l, hence the underlying structure is a dag. 
In order to avoid such a redundancy, we need for each node 
x in the dag a total ordering + z  of [ l . . q ] .  Assume now that 
a node x has two successors x + e,, and x + e,* such that 
jl >= j 2 ,  then we forbid to add the vector eJ1 in the subdag 
rooted at  the node labelled by 5 + e,?. We say that the j i h  
component is frozen. Using such an ordering, the particular 
dags we get are actually forests. Several orderings may 
be chosen. The simplest one is arbitrary ordering of [ l . . q ]  
which does not depend on the node x, see [Clau Fort 871. 
A better ordering is based on the idea of a minimal norm : 
From a dag to a fores t  
j l  > Z  j2 iff + e J ~ ) / l  > l i d ( .  f ' j 2 ) I l  
Or + ' 3 i ) I l  = l i d ( .  + e3?)11 
and jl > j2). 
 CY=^ 1, (d l j  + CLm+1 a i r  d1r) = 0 
ET=llj ( d X J  + E,"=,+, 47) = 
, Elmi 1, (dpj + C,"=,+i dpr) = 0 
Example 2 For the previous example, the modified algo- 
rithm computes the forest: 
S \ 
Frozen components are in  italics. Nodes without successors 
are in  bold. 
5.5.2 
The forests provided by the new version of the algorithm, 
have an interesting property, if all the successors of a node 
are written from left to right according to  the ordering >. 
Propos i t ion  4 If a tuple U i n  the forest is greater than a 
solution, then this solution appears o n  its right side. 
From a forest  to a s tack  
It follows that it is sufficient to check whether a tuple 
is greater than a solution lying on its right side. Compare 
example 1 with example 2 .  The ordering 1 t 2 t 3 has 
eliminated two leaves in the dag in adddition t o  the redun- 
dancy expressed by the shared nodes. 
There is indeed a way for enumerating solutions from right 
to  left, using a stack. Such a stack searches the forest 
291 
depth first, but from right to  left. The initial stack con- 
tains e l , .  . . , e,, the roots of the forest (el  at  the bottom, eq 
at the top). The top is popped and its successors are pushed 
in the stack with respect to  the ordering +, the largest first. 
The forest has been completely searched once the stack is 
empty. This is examplified in the figure displayed below: it 
shows the different states of t h  ’ -’; during the computa- 
tion of B for the system of ex? ‘6z L. 
U mo mo mi 021 022 
Components written in italics are frozen 
Note also that the size of the stack is bounded by q. 
This follows from the following straightforward property : 
a tuple a t  level j (1 5 j 5 q )  in the stack has exactly j - 1 
frozen components. 
5.6 A useful restriction for AC unification 
For solving an AC unification subproblem, we don’t always 
need all minimal solutions of the system: if a diophantine 
unknown U is associated with an  A C  variable z appearing 
in a proper equation z s of another subproblem, the solu- 
tions where U is a t  least 2 will lead to  a theory clash. Hence 
the value of U can be bounded by 1. Our algorithm can be 
modified very easily in order to compute only these solu- 
tions: the corresponding component of the current tuple in 
the stack is frozen as soon as it reaches the value 1. 
6 Conclusion 
We have given a new combination technique for AC unifi- 
cation. The termination proof is easier than Fage’s which 
results from our approach to the problem: rather than de- 
signing an algorithm, give a set of transformation rules and 
separately, give the control. We have shown why Fages’ 
termination proof was difficult: because Stickel’s control, 
using eager replacement, was the most difficult to prove! 
On the other hand, proving any control without using term 
replacement was a easier task. 
Another advantage of avoiding replacement is efficiency. 
It allows to  solve sets of linear diophantine equations, rather 
than one equation a t  a time. This decreases drastically 
the number of calls to the diophantine equation solver, for 
which we have given an  upper bound; at the same time it 
allows an optimal use of the constraints. 
Finally, we have an  efficient and easy to  implement algo- 
rithm for solving linear systems of Diophantine equations. 
The main interests of this new algorithm come from it solves 
a system as a whole and not equation by equation. Hence 
the number of variables is steady. By solving a system equa- 
tion by equation, one gets as many variables as the number 
of solutions of some single equation built from the system 
and this number can become very huge! 
The algorithm extends trivially to  the case of constrained 
equations by bounding the values of some variables. 
Acknowledgements: we thank Jean-Pierre Jouannaud 
for his help on this work, and Jieh Hsiang for numerous 
fruitful discussions on Diophantine equations. 
References 
[Bou Jou Sch 88 ] Boudet, A., Jouannaud, J.-P., and Schmidt- 
SchauO, M. “Unification in Boolean Rings and Abelian Groups 
” JSC, 8:5, p p .  449-477, nov. 1989 
[boudet90 ] Boudet, A. “Unification dans les Mklanges de 
Theories Equationnelles ” Ph. U .  thesis, UniversitC Paris XI,  Or- 
say, Feb 1990. 
[Clau For 87 ] Clausen, M. and Fortenbacher, A. “Efficient Sw 
lution of Linear Diophantine Equations ” Universitit Karlsruhe 
Facultat fur informatik, Interner Bericht Nr 92, (1987) 
[Der Jou 89 ] Dershowitz, N and Jouannaud J.-P. “Term Rewrit- 
ing Systems ”Handbook of  Theoretical Computer Science, North- 
Holland, to appear. 
[Domenjoud89 ] Domenjoud, E. “Number of Minimal Unifiers of 
the Equation az1 + . . . + axp  py1 + . . . + pyq ”Research 
report n.89-R-2, CRIN, Nancy, 1989 
[Fages 84 ] Fages, F. “Associative Commutative Unification 
” Proc. 7th Int. Conf. on Automated Deduction. Springer- Verlag 
[Fortenbacher 87 Fortenbacher, A. “An Algebraic Approach to 
Unification under Associativity and Commutativity ”Journal of 
Symbolic Computation, uol 3, p p  217-229 (1987) 
[Gluck Her 85 ] Guckenbiehl, T. and Herold, A. “Solving Linear 
Diophantine Equations ” Technical Report SEKI-85-IV-KL, 1985 
[Her Sie 85 ] Herold, H. and Siekmann, J .  “Unification in Abelian 
Semigroups ”Memo SEKI-8.5-III-KL, Universitat Kaisershutern 
[Huet 78 ] Iluet, G. “An Algorithm to Generate the Basis of Solu- 
tions to Homogeneous Linear Diophantine Equations ” I n .  Proc. 
[Kirchner 85 ] Kirchner, C. “Methodes et outils de concep- 
tion systematique d’algorithmes d’unification dans les theories 
equationnelles ” Thhe  de Doctorat d’Etat en Informatique. Uni- 
versite‘ d e  Nancy l(1985). 
[Kirchner 87 ] Kirchher, C. “From Unification in a Combination 
of Equational Theories to a new AC-unification algorithm I’ Proc. 
CREAS, Austin, to a p p e a r .  
[Lambert 87 ] Lambert, J.-L. “Une borne pour les gknerateurs des 
solutions entibres positives d’une equation diophantienne lineaire. 
’I Comptes Rendus d e  1’Acade‘mie des Sciences d e  Paris, t.305, 
Se‘rie I, 39-40, 1987. 
(1 984). 
Let., 7 P ) ,  PP144-147 
298 
[Lin Chris 88 ] Lincoln, P. and Christian ,J. "Adventures in 
Associative-Commutative Unification (A Summary) " In Proc. 
9th Int. Conf. on Automated Deduction, pp.358-367, Springer- 
Verlag (1988). 
[Mar Mon 82 ] Martelli, A. and Montanari, U. "An Efficient Uni- 
fication Algorithm ACM Transactions On Programming Lan- 
guages And Systems, ~ 0 1 . 4 ,  n 2 
[Schmidt-Schaufi 88 ] Schmidt-Schaufi, M. "Unification in a Com- 
bination of Arbitrary Disjoint Equational Theories "In Proc. 
9th lnt. Conf. on Automated Deduction, pp.978-396, Springer- 
Verlag (1 988). 
[Siekmann 78 ] Siekmann G. "Unification and Matching Prob- 
lems 
[Stickel 81 ] Stickel, M.E. "A complete unification Algorithm for 
Associative-Commutative functions *Journal of the ACM, 001.28, 
[Tiden 86 ] Tiden, E. "Unification in combinations of collapse- 
free theories with disjoint sets of function symbols "Proc. 8th 
Int. Conf. on Automated deduction. Springer- Verlag (1986). 
[Tiden 87 ] Tiden, E. "First Order Unification in Combinations 
of Equational Theories. " Ph. D. Thesis, Stockholm (1987) 
[Yelick 85 ] Yelick, K. "Combining unification algorithms for con- 
fined equational theories ,, Proc. First Int. Conf. on Rewriting 
Techniques and Applications. Springer- Verlag (1985). 
Memo CSM-4-78. University of Essez (1978). 
PP4 23-4 34 
299 
