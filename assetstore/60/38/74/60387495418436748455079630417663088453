TERM REWRITING SYSTEMS 
FROM CHURCH-ROSSER TO KNUTH-BENDIX AND BEYOND 
Jan Willem Klop 
Centre for Mathematics and Computer Sci nce, Kruislaan 413,1098 SJ Amsterdam; 
Department ofMathematics and Computer Science, Free University, 
de Boelelaan 1081, 1081 HV Amsterdam; jwk@cwi.nl 
Term rewriting systems are important for computability theory of abstract data types, for automatic theo- 
rem proving, and for the foundations offunctional programming. In this short survey we present, starting 
from first principles, several of the basic notions a d facts in the area of term rewriting. Our treatment, 
which often will be informal, covers abst act rewriting, Combinatory Logic, orthogonal systems, trate- 
gies, critical pair completion, and some xtended rewriting formats. 
Note: Research partially supported by ESPRIT projects 3020: Integration a d 3074: Semagraph. 
Introduction 
The intention of this paper is to present to a general audience of theoretical computer scientists ome of the 
basic concepts, facts and evelopments in the area of Term Rewriting Systems. We do not aim at a com- 
plete historical account, even though the title may hint in that direction. Our aim would be fulfilled if some 
interest is raised, which subsequently may lead to consulting more extensive surveys uch as Huet & 
Oppen [80], Klop [90], Dershowitz & Jouarmaud [90]. Especially the last survey pays much attention to 
the more recent developments in Term Rewriting Systems. 
The concept of a Term Rewriting System (TRS) is paradigmatic for the study of computational proce- 
dures. Already half a century ago, the ~-calculus, probably the most well-known Term Rewriting System, 
played a crucial role in mathematical logic with respect to formalizing the notion of computability; much 
later the same TRS figured in the fundamental work of Scott, Plotldn and others leading to a break- 
through in the denotational semantics of programming languages. More recently, the related system of 
Combinatory Logic was shown to be a very fruitful tool for the implementation f functional languages. 
(Turner [79], Barendregt [89]). Even more recently another elated family of TRSs, that of Categorical 
Combinatory Logic, has emerged, yielding a remarkable connection between concepts from category the- 
ory and elementary steps in machine computations (Curien [86], Hardin [89]). 
Term Rewriting Systems are attractive because of their simple syntax and semantics--at least those 
TRSs that do not involve bound variables uch as g-calculus, but involve the rewriting of terms from a 
first order language. This simplicity facilitates a satisfactory mathematical nalysis. On the other hand 
TRSs provide a natural medium for implementing computations, and in principle even for parallel compu- 
tations. This feature makes TRSs interesting for the design of parallel reduction machines. 
Another field where TRSs play a fundamental role is the analysis and implementation f abstract data 
type specifications, with respect o consistency properties, computability theory (Goguen & Meseguer 
[85]), decidability of word problems (Knuth & Bendix [70]), theorem proving (Hsiang [85]). 
In recent years, a strong impulse for the study of Term Rewriting Systems (including extensions f 
the usual rewriting format) is given by the design of functional programming languages such as Miranda 
(Turner [85]). Another strong impulse is given by efforts of many researchers tocombine and integrate 
logic programming with functional programming (Dershowitz & Plaister [87], H0lidobler [89]). 
Contents 
1. CHURCH-ROSSER 
1.1. Combinatory Logic 
1.2. Repeated variables 
1.3. Newman's Lemma nd 
Abstract Reduction Systems 
1.4. Disjoint unions of TRSs " 
1.5. Decidability 
2. KNUTH-BENDIX 
2.1. Equational Logic 
2.2. Critical pair completion 
2.3. Termination 
2.4. Narrowing 
3. BEYOND 
3.1. Orthogonality 
3.2. Strategies and sequentiality 
3.3. Conditional rewriting 
3 A. Other rewriting formats 
References 
351 
1.  CHURCH-ROSSER 
1.1. Combinatory Logic 
A good starting point is the Term Rewriting System, or TRS for short, called Combinatory Logic (CL). 
Originally devised by Sch/3nfinkel [24] in an attempt to eliminate bound variables from Predicate Logic, 
the system was rediscovered by H. Curry and played the central role in his foundational program of 
'lllative Combinatory Logic'. Here we will not pay attention to the foundational spects of CL, and merely 
consider the system of the following three equations in the first order language with binary function sym- 
bol Ap (application), constant symbols S, K, I and variables x, y, z .... as in Table l(a): 
Ap(Ap(Ap(S, x), y), z) = Ap(Ap(x, z), Ap(y, z)) 
Ap(Ap(K, x), y) = x 
Ap(t x) =x  
Sxyz = xz(yz) 
Kxy =x  
Ix =x 
b 
((S'x)'y)'z = (x'z)'(y'z) 
(K'x)'y = x 
I ' x  = X 
d 
Sxyz -> xz(yz) 
Kxy -> x 
Ix --> x 
Table 1 
For better eadability we write instead of the binary prefix operator Ap an infix dot (Table l(b)). To en- 
hance readability even more we leave away the dot and save several pairs of brackets under the convention 
of association to the left: restore missing bracket pairs as leftmost as possible (Table l(c)). This is the form 
in which the equations of CL usually are presented. Actually, the equations have a direction, from left to 
right; applications of the equations consisting of replacing an instantiated left-hand side (in some context) 
by the corresponding instantiated right-hand side tend to simplify the term in some sense. For the K- and I- 
equation this is clear, for the S-equation it is less clear but may be clear after subsequent elaborations. 
Notationally the direction is represented asin Table l(d); and this is our first example of a Term Rewriting 
System. Henceforth CL will denote this TRS. 
So, in general, a TRS is a pair (~:, R) where Y. is some signature, listing the function symbols (with 
their 'arities') and constant symbols, and R is a set of reduction rules (or rewrite rules) of the form t --* s. 
Here t, s e Ter(E), the set of terms over E. Two restrictions are imposed on the form of reduction rules: t 
must not be a variable, and S does not contain occurrences of variables that do not already occur in t. (It is 
not hard to think of an intuitive motivation for these restrictions; also, there are several points in the subse- 
quent development of the theory where they are required.) The reduction rules are used as one expects 
from familiarity with equational logic: they induce reduction steps (rewrite steps) C[t o] --~ C[s o] for arbi- 
trary contexts C[ ] and substitutions a. A substitution o is a map from Var, the set of variables, to Ter(Y.); 
it is extended to a map from Ter(E) to Ter(E) in a homomorphic way. A context is a term with a 'hole' n; 
e.g. SK(n I)x is a CL-context. The instantiated left-hand side t Â° of a reduction rule t ---) s is called a redex 
(reducible xpression) with contractum s o. Often we will write just R instead of (Y-, R) and Ter(R) instead 
of Ter(E). 
We have now defined the one step reduction relation --> on Ter(R). The transitive reflexive closure of 
--~ is written as ~;  also the notation --4" is often used. The reflexive closure of ~ is --->-=. The equivalence 
relation generated by ---> is '=', called convertibility. It should not be confused with ---, denoting syntactical 
identity. 
Let us return to CL and play with some xamples in order to appreciate the great expressive power of 
this TRS and to illustrate the concepts and notations introduced thus far. As CL was originally devised by 
Curry as a theory about functions, it is to be expected that function composition o can be det'med: indeed, 
abbreviating S(KS)K as B we have the reduction sequence in Table 2 (1), establishing that Bxyz --~ 
x(yz), and a fortiori that Bxyz = x(yz). So Bxy is x o y in prefix notation. 
352 
(1) Bxyz -= S(KS)Kxyz -~ KSX(Kx)yz -~ S(Kx)yz -~ Kxz(yz) -~ x(yz) 
(2) ~x ~ SIIX -~ Ix(Ix) -~ IXX -~ xx 
(3) ox~-= SII(SII) -~ I(SII)(I(SII)) -~ I(SII)(SII) -~ SII(SII) 
(4) P --- m(BFo)) -~ BFm(BF(o) -~ F(m(BFm)) -= FP 
(5) Cxyz ~ S(BBS)(KK)xyz -~ xzy 
(6) Wxy =- SS(KI)xy -~ xyy 
(7) Yx~ WS(BWB)x-~ BWBx(BWBx) -~ x(BWBx(BWBx)<~- x(Yx) 
Table 2 
Another aspect of C L is that it admits elf-application. Abbreviating S 11 as co, we have a '  self-applicator': 
0)x --~ xx as in Table 2 (2). This leads to the term ox~ admitting acyclic reduction as in Table 2 (3). 
CL-terms without variables (so, only built from S, K, I) are also called combinators. As observed 
earlier (Scott [75]), combinators are fun. Much of the fun derives from the fact that every CL-term F has a 
fixed point P: for, consider P = 0~(BF(o), then we have FP = P, in fact P ~ FP (Table 2 (4)). This fea- 
ture embodies the possibility of recursive definitions and is exploited to implement functional program- 
ming languages as in the TRS called SKIM (S-K-I-Machine) described in Turner [79] (see Table 3). 
Sxyz -~ xz(yz) Uz(Pxy) - *  zxy 
Kxy -~ x cond T xy - *  x 
Ix ~ x cond F xy -~ y 
Cxyz -~ xzy A B m -~ n+m 
Bxyz -~ x(yz) Mnm -~ n.m 
Yx -~ x(Yx) E ~1 n ~ T 
Po(Pxy) -~ x Enm -~ F / fn~m 
PI(PXy) -~ y 
Table 3 
This TRS has infinitely many constants: apart from the constants S, K ...... E there is a constant n for 
each natural number n ~ N. There are also infinitely many reduction rules, because the last four ules (for 
A, M, E) are actually rule schemes; e.g. A n m ~ n+m stands for all reduction rules A 0 0 ~ 0 ,  A (3 1 
1 ...... A 37 63 ---) 100 . . . . .  (Historically, such reduction rules were called 5-rules by Church.) In 
fact, the extra constants in SKIM are introduced for reasons of efficient implementation; they can all be 
defined using only S and K, in such a way that 'reduction is respected'. Definitions of B, C are in Table 
2. (To define the fixed point operator Y of SKIM, we should take a definition different from the one in 
Table 2 (7): note that there a conversion is established which is not a reduction.) For the other definitions 
one may consult Barendregt [84] or Hindley & Seldin [86]. 
CL derives its expressive power from the property of combinatory completeness: for every CL-term 
N containing no other variables than Xl . . . .  , Xn, there is a combinator M such that MXl ...Xn --* N. 
Combinatory completeness implies the existence of a fixed point combinator, yielding the following 're- 
cursive definition principle': for every 'reduction equation' ~Xl...Xn ~ C[~], where C[ ] contains no other 
variables than xl ..... Xn, one can find a combinator as a solution for ~. (It is not hard to extend this prin- 
ciple to multiple recursion.) In fact, combinatory completeness, and hence the recursive definition princi- 
ple, holds for every applicative xtension of GL, like SKIM; somewhat remarkably it does not hold as 
soon as a function symbol is added to CL with arity _> 1. 
The salient fact about reduction in CL and its extension SKIM is: 
1.1.1. THEOREM. (i) CL and SKIM have the Church-Rosserproperty (or:are confluent). 
This means that Vt, s, r 3u (t --~ s & t ~ r ~ s ~ u & r --~ u). 
Or, equivalently, Vr, s 3u (r = s ~ s ~) u & r -,7 u). (See Figure 1.) 
(ii) Both TRSs have the unique normal form property. 
353 
We have to explain the statement in (ii). A term is a 
normal form, or in normal form, if it does not con- 
tain redexes as subterms. Equivalently: t is in nor- 
mal form if there does not exist an s such that t --* 
s. A TRS has the unique normal form property, ab- 
breviated UN, if whenever two normal forms are 
convertible, they must be identical: Vt, s (t = s & 
t, s are normal forms ~ t - s). 
Statement (i) of 1.1.1, the Church-Rosser theo- 
rem for CL and SKIM, requires anontrivial proof. 
i i iii iiii iiiiiiiiiiiiii!i i iiii iiiiiiiiiiii iiiiii iiii iiiii! iiiiiiiiiii iiii !i ii iii ii!iiiii!iii iiiii iiii iiiiiii i i: ii iiiiii i ii i ! !i iii 
:iiiiiiiiiiiii::iiiiiii::~ i ~ i i ~ ~ l i  .......... ~%iiiiiii iiiii::ii::!iii~iii . . . . . iii!iiiiiiii!i!=J:::::::ii::ii::i':iiiiiiiii~* %iiii !ii::iii::~i 
Figure 1 
Later on we will mention aconfluence criterion by means of which the Church-Rosser p operty (or CR for 
short) can be derived very quickly from an inspection of only the left-hand sides of the reduction rules. 
(This confluence criterion is the property of 'orthogonality' enjoyed by both TRSs.) Statement (ii) follows 
almost rivially from (i), the confluence (CR) property. Indeed, we have in general: CR ~ UN. 
1.2. Repeated variables 
Above, in the system SKIM, we encountered the rules E 1212 --* T for all 'numerals' 12. One may ask why 
we do not simply replace this infinity of reduction rules by the single rule Exx ---> T. This reduction rule is 
called 'non-left-linear'. A term is linear when it contains no repeated variables; a rule is left-linear when its 
left-hand side is linear. 
Rather surprisingly, SKIM with the rule scheme E n n --> T replaced ........................................................................ 
by the single rule Exx --> T would no longer be confluent---even though iliii iiiiiii~iiiiiiiiiiii!iiii!iiiiiiiiliiiiiii~iiiiiiiiiiiiiliiiii 
the resulting TRS is weakly confluent (has the weak CR property, iiiiiiiiiii ~ ~  
WCR). g TRS is weakly confluent if Vt, s, r 3u (t --> s & t ~ r ~ iiiiiiiii~ 
s --* u & r --, u). (See Figure 2.) 
In fact, the same state of affairs holds also for CL extended with the 
non-left-linear rule Dxx ---> T (we use D to avoid confusion with the E of 
SKIM; D can be read as 'discriminator'). 
Figure 2 
1.2.1. THEOREM. Let R be CL extended with the rule Dxx ---> T. Then R 
is weakly confluent, but not confluent. Yet, R has the unique normal form property. Further- 
more, the equational theory of CL u { Dxx ---> T} is conservative over that of C L. 
The weak confluence iseasily established by simple casuistics. The essence of the proof of non-confluen- 
ce is as follows. Consider the 'ad hoc' TRS (ad hoc in contrast with the general purpose character of C/ )  
with rules: Dxx ~ T, Fx --> Dx(Fx), P ~ FP. (So the signature consists of the application operator Ap, 
not visible due to the 'applicative notation' explained above, and of constants D, T, F, P, and nothing 
else.) Now we have P --, FP ~ DP(FP) --~ D(FP)(FP)) --~ T, hence FP -~ T and FP --* FT. For the 
confluence property, the terms T and FT should have a common reduct. However, T is a normal form, 
and FT admits as only reductions: FT ---, DT(FT) ~ DT(DT(FT) ~ DT(DT(DT(FT))) ~ .. . .  
Therefore confluence fails--for the ad hoc TRS. Now, using fixed point constructions a hinted at in 
Section 1.1, one can define the ad hoc TRS in CL ~) {Dxx --4 T}, thereby respecting the reduction rela- 
tion, and obtain the non-confluence of CL w {Dxx ~ T}. 
For a more precise account of theorem 1.2.1 and its proof, see Klop [80] and Klop & de Vdjer [89]. 
1.3. Newman's Lemma and Abstract Reduction Systems 
As we have seen in 1.2, weak confluence does not neces- 
sarily imply confluence. This fact is already apparent by ii ili 
considering the TRS with only the constants A, B, C, D 
and reduction rules B ~ A, 13 ~ C, 0 ~ B, C ~ D. 
This TRS does also not have the property UN. Figure 3 
An obvious thought is to use WCR in a tiling procedure to find common reducts. If the tiling suc- 
ceeds, we get a successfully completed reduction diagram as in Figure 4(a). Here we may have to use 
354 
some 'empty steps' to keep matters in a rectangular shape (these are the shaded steps). Some experiments 
show that if the reduction diagram, constructed by tiling on the basis of the WCR property, grows into an 
infinite reduction diagram, there always arise infinite reductions. (See Figure 4(b) for the simplest infinite 
reduction diagram, and Figure 4(c) for an infinite diagram with a curious fractal-like border.) 
Figure 4 
Indeed, the following lemma states that if there are no infinite reductions, then the tiling procedure must 
succeed. We use the abbreviation SN (Strong Normalization) to indicate that there are no infinite reduc- 
tions. A TRS with the property SN is also said to be terminating or (Huet [80]) noetherian. 
1.3.1. NEWMAN'S LEMMA. SN & WCR ~ CR. 
Various proofs have been given of this fundamental lemma. The (too) complicated proof in Newman [42] 
(Theorem 3) uses numerical estimations. Another proof can be given using a version of KGnig's Lemma 
for infinite, finitely branching "dag's" (directed acyclic graphs). Klop [90] contains a proof by means of 
'proof orderings', using multisets. Huet [80] contains an elegant proof using noetherian i duction. A 
rather similar proof, equally elegant, is in Barendregt [84]: assuming SN, we need only to prove for 
confluence that no point is 'bad', where a point is bad if it reduces to different normal forms. From WCR 
it follows that if t is bad, then t --> t' for some bad t'. Hence, by SN, no bad points exist. 
Just like the implication CR ~ UN that we noted above, Newman's Lemma is a proposition about 
Abstract Reduction Systems; the term structure of a TRS does not play a role. An Abstract Reduction 
System or ARS for short, is a set equipped with one or more binary relations, that are called reduction re- 
lations in view of the applications to TRSs or other rewriting systems. So an ARS has the form ~ = (A, 
--->) in case it has only one reduction relation --->, o r~ = (A, (-">i)ie I) in the general case. The notions CR, 
WCR, SN apply already to ARSs. For a collection of facts (mostly criteria for confluence) holding for 
ARSs, we refer to Staples [75] and Klop [90]. Here we mention a few of the most important of them. 
1.3.2. LEMMA. Let.~ = (A, ('-->ct)ctE I) be an ARS such that for all or, ~ E I we have that -'~c~ commutes 
with --~13. (This means: Va, b, c ~ A 3dE A (a ~ ct b & a --,> 13 c =, b --* 13 d & c -* ct d; see Figure 5(a).) 
Then.~ (i.e. the union ---> = ['-Jot~ I '-%t) is confluent. 
This lemma is known as the Lemma of Hindley-Rosen. The proof is trivial, but the lemma is very useful. 
Figure 5 
355 
Another simple but useful emma is: 
1.3.3. LEMMA (Huet [80]). Let (A, --->) be an ARS. Suppose that Va, b, c â¢ A 3de A (a --> b & a ---> c 
b --~ d & c - -~ d). (A reduction relation --~ with thisproperty is called 'strongly confluent'; see Figure 
5(b).) Then --~ is confluent (see Figure 5(c)). 
The next lemma strengthens Newman's Lemma (see Figure 5(d)): 
1.3.4. LEMMA (Winlder & Buchberger [83]). Let (A, --->, > ) be an ARS where the 'reduction' relation > 
is a partial order and SN. (So > is well-founded.) Suppose a ~ b implies a > b. Then the following are 
equivalent: (a) --~ is confluent, (b) whenever a --~ b and a ---> c, there is a --->-conversion b = d 1 ~ d 2 e-> 
... e-> d n - c (for some n > 1) between b, c such that a > d i (i = 1,...,n). Here each e-> is ---> or e-. 
To conclude this sample of confluence criteria for ARSs we mention an unpublished result of N.G. de 
Bruijn that recently was brought o our attention and which is a considerable strengthening of Huet's 
strong confluence lemma 1.3.3. In contrast with the previous 1emma's, this one is not easy to prove. We 
use the following notation: 
Let ..eL = <A, (-">n)ne I) be an ARS with I a par- 
tial order. Then, for a, b e A, a "-~<n b means 
that there is a sequence of reduction steps from 
a to b, each reduction step having index < n. 
Analogously a"--~ <_.n b is defined. Furthermore, 
â¢ ->n -= is the reflexive closure of ->n" 
1.3.5. LEMMA (De Bruijn [78]). 
iii i iiiiii ! !i!iii!iii! iiii ii iii !!i iiii ii i! iiii iiiiiii 1iiii!iiiiiiii !iiiii!ii iiiiiiiiiii!ii ! ii ii 1iiiii iiii iiii i!ii!iii iiiiiiiiii!iiiiiii 
ili~i!i ~iiiiiiiiiiiii!iiiiii ~i::i;:;:: 
Figure 6 
Let ..q = (A, (--*n)n~ I) be an ARS with I a well-founded linear order. Suppose that 
(i) ~/a,b,c, n3d,  e,f(a---~nb&a--->nc ~ b---,~,<_nf&C--~<nd--~n-=e--*<nf),and 
(ii) Va, b ,c ,n ,  k3d, e , f (k<n&a- ->nb&a- ->kc  ~ b---~<nf&c---~<kd-->n---e--~<nf). 
Then A is confluent. 
1.4. Disjoint unions of Term Rewrit ing Systems 
After the intermezzo about Abstract Reduction Systems we return to Term Rewriting Systems. Often a 
TRS can be partitioned in some parts that have a disjoint alphabet (or signature). Let us denote for TRSs 
R 1 , R 2 having disjoint alphabets with R 1 @ R 2 the TRS that results by taking the union of R 1 , R 2, both 
with respect to the alphabets and the sets of reduction rules. (If it is not required that the alphabets are dis- 
joint we denote the union just by R1u R 2 .) If for a property Pwe have: R 1 â¢ R 2 ~ T Â¢~ R 1 ~ P& R 2 
P, we call Pa  modular property. (Here ~ is informally used as abbreviation for 'satisfies'.) A pleasant 
state of affairs is that we have: 
1.4.1. THEOREM (Toyama [87b]). Confluence is a modular property of  TRSs. 
This theorem has useful applications. For instance, consider the extension of CL with a binary discrimina- 
tor: 
Sxyz --.', XZ(yz), Kxy ~ x,  Ix --r x, D(x, x) --~ T. 
This extension CL â¢ {D(x, x) --~ T} is confluent, because CL is and because the one rule TRS {D(x, x) 
---> T} also is confluent, asis easily seen by an application of Newman's Lemma. This should be con- 
trasted with our earlier observation that the extension C I  u {Dxx --> T} is not confluent. Indeed, the latter 
is not a disjoint union since Dxx ~ T is in fact Ap(Ap(D, x), x) ~ T, revealing that there is an overlap in 
alphabets between CL and Dxx --~ T. 
Is termination (SN) also modular? No: Toyama [87a] gives the following simple counterexample. 
Take R 1 = {F(0, 1, x) ---> F(x, x, x)} and R 2 = {or(x, y) ~ x, or(x, y) ~ y}; both TRSs are terminating. 
They am also disjoint. However R 1 @ R 2 has an infinite reduction: 
F(or(O, 1), or(O, 1), or(O,1)) --~ F(O, or(O, 1), or(O, 1)) ~ F(O, 1, or(O, 1)) ~ F(or(O, 1), or(O, 1), or(O,1)). 
356 
In view of the fact that R 2 is not confluent, one may conjecture that 'confluent & terminating' (usually 
called 'complete', sometimes also 'canonical') is a modular property, but this also fails as a more compli- 
cated counterexample shows (Toyama [87a]). However: 
1.4.2. THEOREM (Toyama, Klop & Barendregt [89]). 
Let R 1 , R 2 be left-linear TRSs. Then RI@ R 2 is complete i f f  R 1 and R 2 are complete. 
~eminder: A TRS is left-linear if no rule contains repeated variables in its left-hand side.) 
Some useful information conceming the inference of SN for R a @ I:12 from the SN property for R 1 
and R 2 separately is given in Theorem 1.4.4, 
1.4.3. DEFINITION. (i) A rewrite rule t ---> S is a collapsing rule (c-rule) i f s  is a variable. (ii) A rewrite rule 
t ---> s is a duplicating rule (d-rule) if some variable has more occurrences in s than it has in t. 
Example: F(x, x) ---> G(x, x) is not a d-rule, but F(x, x) ---> H(x, x, x) is. Also P(x) --~ G(x, x) is a d-n~e. 
1.4.4. THEOREM. Let R 1 and R 2 be TRSs both with the property SN. 
(i) If neither R a nor [:12 contain c-rules, R 1 @ R 2 is SN. 
(ii) If neither R 1 nor R 2 contain d-rules, R 1 @ R 2 is SN. 
(iii) If one of the TRSs R t , R 2 contains neither c- nor d-rules, R 1 @ R 2 is SN. 
Statements (i) and (ii) are proved in Rusinowitch [87]; statement (iii) is proved in Middeldorp [89b]. 
Another useful fact, proved in Middeldorp [89a], is that UN is a modular property. More on the theme of 
modular properties can be found in recent work of Kurihara & Kaji [88] and Kurihara & Ohuchi [89]. 
1.5. Decidabi l i ty 
As is to be expected, most properties of TRSs are undecidable. Consider only TRSs with finite signature 
and finitely many reduction rules. Then it is undecidable whether confluence holds, and also whether ter- 
mination holds (Huet & Lankford [78], Klop [90]). (Even tor TRSs with only one rule termination is un- 
decidable.) However, for ground TRSs (where all rules are between ground terms, i.e. no rule contains 
variables), confluence is decidable (Dauchet et al. [87], Oyamagnchi [87]). Also termination is decidable 
for ground TRSs (Huet & Lankford [78]). 
For particular TRSs it may also be undecidable whether two terms are convertible, whether aterm has 
a normal form, whether a term has an infinite reduction. A TRS where all these properties of terms are un- 
decidable is Ck (Barendregt [84]). 
2. KNUTH-BENDIX 
2.1. Equational Logic 
We will now explain two important applications that TRSs, and especially complete TRSs, have in Equa- 
tional Logic: to decide word problems, and to solve equations in some equational theory. Equational Logic 
is concerned with equational theories (or equational specifications) of the form (E, E) where Y. is a signa- 
ture as before and E is a set of equations over Y.. 
We suppose familiarity with the semantics of Equational Logic, that is, with the concept of a Z-algebra 
A and the notion A ~ t = s, expressing validity of the equation t = s between Z-terms in .~ If all equa- 
tions of E are valid in the algebra :R we write A Â¢ E. The variety of E-algebras defined by an equational 
specification (E, E), notation Alg(E, E), is the class of all >:-algebras A such that A ~ E. 
Instead of VA ~ AIg(Y., E) A ~ t = s, we write (E, E) ~ t = s. 
A simple inference system for Equational Logic is given in Table 4. If an equation l = s between Z- 
terms is derivable by means of this inference system, using the equations f (Z, E) as axioms, we write 
(Y., E) ~- t --- s. We then have the well-known completeness theorem 2.1.1. 
2.1.1. THEOREM (Birkhoff [35]). Let (Z, E) be an equational specification. Then for all t, S ~ Ter(Z): 
(Y, E ) t -  t = s Â¢~(Z,, E) i= t = s. 
357 
Axioms (in addition to the equations in E):
t=t  
Inference rules: 
from t 1 = t 2 infer t 2 = t 1 
from t l=t  2, t 2=t  3 infer t l=t  3 
from t I ffi t 2 infer t I Ix:= t] = t2[x:= t] 
from t 1 = t 2 infer t[x:= t l ]  = t[X:= t2] 
(reflexivity) 
(symmetry) 
(transitivity) 
(substitution (1)) 
(substitution (2)) 
Table 4 
The validity problem or uniform word problem for (Y., E) is: given an equation t = s between E-terms, 
decide whether or not (Z, E) ~ t = s. According to Birkhoff's completeness theorem this amounts to de- 
ciding (y., E) ~- t = s. Now we can state why complete TRSs (i.e. TRSs which are SN and CR, termina- 
ting and confluent) are importantÂ° Suppose for the specification (E, E) we can find a complete TRS (Z, R) 
such that for all terms t, S e Ter(T~): t =R S Â¢=~ (Z, E) t-- t = s. (Here =R is the convertibility relation of 
R.) Then, provided R has only finitely many rewrite rules, we have a positive solution for the validity 
problem, obtained by this simple algorithm: reduce s and t to their respective normal forms s', t' and com- 
pare; t =R S iff t' - s'. 
2.1.2. Groups, L-R algebras and R-L algebras: an example 
To illustrate the use of complete TRSs for equational specifications we turn to the classical example given 
in Knuth & Bendix [70]. Apart from the three axioms for group theory as in the first column of Table 5, 
one may consider two closely related theories: the three axioms for L-R theory, and three axioms for R-L 
theory. At first sight i  is not clear whether these different theories determine different varieties. Let us call 
an algebra satisfying L-R theory an L-R algebra, and likewise for a R-L algebra. Now Knuth & Bendix 
[70] find complete TRSs for these theories as in the table. 
group theory: L-R theory: R-L theory: 
e 'x=x o .x=x x 'o=x 
I(x).x = e x.l(x) = e I(x)-x = e 
(x-y)-z = x.(y.z) (x.y).z = x.(y.z) (x.y)-z = x.(y.z) 
completion: completion: completion: 
O'X --> X O'X --) x 
x 'o  --~ X x 'e  --~ x 
I (x).x -~  e I(x)-x --, e 
x'l(x) --> e x.l(x) --> e 
(x.y).z -~ x'(y.z) (x.y) 'z --* x.(y.z) (x'y)-z ~ x.(y.z) 
I(o) --~ e I(e) --~ e l(e) --~ e 
t(x.y) --~ I(y).l(x) t(x'y) --* t(y).l(x) I(x.y) ~ I(y)q(x) 
x.( l(x).y) --~ y x.( l(x)-y) --~ y 
e.x ~ I(l(x)) 
I(x).(x.y) -o  y I(x).(x.y) --~ y 
x.l(l(y)) -~ x.y 
I(l(x)) --~ x 
x 'e ~ lO(x) )  
IO0(x))) -* l (x)  
I ( t (x ) ) 'y -~x 'y  
Table 5 
IO0(x))) - *  I(x) 
x.(y.l(y)) - )  x 
x-(l(l(y))-z) -~ x-(y.z) 
x.(y.(l(y).z)) -~ x.z 
I(x)'(x.y) - *  I(l(y)) 
From these completions it is immediately clear that the three varieties indeed are different. Clearly, it fol- 
lows that each group is also an L-R algebra nd a R-L algebra. Furthermore, the equation x'o = x is not 
derivable in L-R theory, because the normal forms of left-hand side and right-hand side of this equation, 
358 
with respect to the L-R completion, are I(l(x)) and x, so syntactically different. Hence (by Birkhoff's 
completeness theorem) there is an L-R algebra which is not a R-L algebra. Also, there is a R-L algebra 
which is not an L-R algebra because in R-L theory the equations e'x = x and x'l(x) = e are not derivable. 
Finally, it is clear that the variety of groups is the intersection of the other two varieties. The strategy of 
deciding validity problems in a positive way by providing acomplete TRS does not work always; even for 
very simple (IC, E) with solvable validity problem it may be impossible to find a complete TRS R with the 
same equality. A typical obstacle is the presence in E of equations expressing commutativity of some 
operator. E.g., consider the specification with signature: a constant 0, and a binary function A, and sup- 
pose E = {A(x, y) = A(y, x)}. Then there is no complete TRS 'for' E with the same signature ]L 
Discovering the one-line proof is left to the reader. 
2.2. Critical pair  completion 
So, in spite of the drawback that we just mentioned, it is important to be able to find complete TRSs for 
equational specifications. The seminal paper Knuth & Bendix [70] demonstrated a method, Knuth-Bendix 
completion or criticalpair completion, that does the job---at least fairly often. The best way to get an un- 
derstanding of the method is to complete by hand the specification of groups as in Table 5, which amounts 
to two pages of computation. Here we will consider a simpler example, which is less spectacular than the 
group completion, but shorter. 
Consider the following equational specification (or theory) E of the integers (Z) with 0, +, successor 
S and predecessor P (left column, (a)): 
(a) 0+x=x (b) (1) 0 + x--->x 
x+O=x (2) x+O->x 
S(x) + y = S(x + y) (3) S(x) + y ~ S(x + y) 
x + S(y) = S(x + y) (4) x + S(y) --~ S(x + y) 
x+ P(y) = P(x + y) (5) x + P(y) --~ P(x + y) 
P(S(x)) = x (6) P(S(x)) --) x 
(Since this specification is intended to be symmetrical with respect to permuting S and P one might expect 
also the equations S(P(x) = x and P(x) + y = P(x + y) to be included in E. Actually these equations are 
derivable.) 
We will now perform an 'intuition 
guided' completion of E. First let us adopt 
as rewrite rules all equations from E, ori- 
ented from left to right. This yields rules (1 - 
6) as above in column (b). This is not yet a 
complete TRS; though it is terminating (as 
will be seen later), it is not confluent. The 
reason is that there is an overlap between the 
left-hand sides of (3), (5) that is harmful: 
S(x) + P(y) reduces with (3) to S(x + P(y)) 
and with (5) to P(S(x) + y). These two 
terms form what is called a criticalpair. The 
terms can be reduced further: S(x + P(y)) 
S(P(x + y)) and P(S(x) + y) ~ P(S(x 
+ y)) ---> x + y, but then we are stuck since 
S(P(x + y)) and x + y are normal forms 
with respect to (1 - 6). So confluence falls. 
)i ))i  i I iiiiiiii )i i )! !!ii)ii )ii)iiii))ii)iiii)) i)i i)iii))ii))ii)iiiii)i Ii!ii)iiiiii i)i ))   iii) , 
!i))! (~) o + x- - ,  x ~i)i) ) ~  
))))))i (2) X + 0 --) X )));~)))i 
)I))))) (3) s(~) + y-, ~x  + y) j)))))))) 
);)i(i)))i;::)))) ) (4) X + S(y) --> S(x + y) )i~i;;)))) 
::::::::::::::):::::::: (5) x + P(y) ~ P(x + y) ::::i::i!i::i::i 
i~ii); (6) P(S(x))-, x i)~)ii)i ~o 
,, 
; i ; ix ; ;2x ........... iiiiiiiiiiiiii 
  iiiii iii i i   iii   i i1iiiiiii  !N i  !:    iNiii i i  iiiiiii!i ?i!) ii)  i?i 
(I0) P(x)+y -* P(x+y) )i)i))i ftom~ 9 cancel9 
Figure 7 
Actually, this is not the only critical pair generated by (1 - 6); there are also overlaps between (1), (2), 
between (1), (4), between (1), (5), between (2), (3), between (3), (4), between (5), (6). But these critical 
pairs are harmless. For instance, (5), (6) yield the critical pair P(x + S(y)), x + y. These terms have a 
common reduct: P(x + S(y)) ~ P(S(x + y)) ~ x + y. 
359 
We try to solve the problem of non-confluence posed by the terms S(P(x + y)) and x + y in a drastic 
way: we simply add as a new rule (7) S(P(x + y)) ~ x + y. Now the critical pair given by (3), (5) is 
harmless too. However, new critical pairs arise: overlap between (1), (7) yields S(P(0 + y)) with as 
reducts 0 + y, S(P(y)). This causes us to adopt a new rule: (8) S(P(y)) -~ y. We can cancel (7) now, as 
it is a consequence of (8). We consider the possible overlaps: the overlap between (8), (6) is harmless; 
likewise between (8), (4). But not the one between (8), (3), which causes the introduction of rule (9): 
S(P(x) + y) --~ x + y. In this way we continue, and luckily after a few more steps as in Figure 7 we reach 
a successful conclusion: a TRS R where all critical pairs are harmless. Moreover, R is terminating; this can 
be seen by noting that all our rules were chosen such that they respected the recursive path ordering (to be 
explained in the next section) obtained by putting + > S and + > P. 
Let us give a precise definition f critical pairs: 
2.2.1. DEFINITION. Let the TRS R contain the rewrite rules r: t --~ s and r': t' ---) s'. Suppose r, r' are 
'standardized apart', i.e. renamed such that they have no variables in common. Suppose furthermore that t 
= C[u], u not a variable, and that u and t' can be unified with most general unifier o. Then to --- Co[u o] = 
Co[t 'o] is subject o an r'-reduction as well as an r-reduction, with result: Co[s 'o] respectively s o. Now 
(CÂ°[s'Â°], s Â°) is called a criticalpair of R. 
If r, r' are (renamed versions f) the same rewrite rule, we moreover require that the context C[ ] is not 
the trivial context. 
Note that if C[ ] in the above situation is trivial (so that t, t' unify 'at the root') two critical pairs are 
obtained which are mirror-images: (S 'o, S o) and (s o, s'O). Such critical pairs are sometimes called 
'overlays'. (See the chess-board-like table in Figure 7, where it is mentioned which pairs of rules of our 
example above give rise to critical pairs. The grey squares denote overlays.) 
A critical pair (S, t) is convergent if s, t have a common reduct ~r  s --~ r & t --* r), notation: s $ t. 
The significance of the fact that all critical pairs (S, t) are 'harmless', i.e. convergent, is expressed by the 
following lemma. 
2.2.1. CRITICAL PAIR LEMMA (Huet [80]). A TRS is weakly confluent iff all its critical pairs are 
convergent. 
Convergence of all critical pairs is not sufficient for confluence; a counterexample is the ABCD-TRS in 
Figure 3 (Section 1.3), with critical pairs (overlays) (A, C), (C, A), (B, D), (D, B). However, in addi- 
tion to termination, it is sufficient for confluence, according to Newman's Lemma, and we have: 
2.2.2. THEOREM (Knuth & Bendix [70]). A terminating TRS is confluent iff all its critical pairs are 
convergent. 
As we noted above, convergence of all critical pairs is sufficient for weak confluence, but not for conflu- 
ence. Huet [80] gave a criterion for critical pairs, stronger than convergence, which does imply confluence 
while not requiring termination as in the Knuth-Bendix theorem. First define parallel reduction as follows: 
t -")11 s i f t  reduces to s via a reduction sequence consisting of contracting a set of disjoint redexes in t. 
Thus, i f  ti (~i ~ $i (~i (i = 1 ..... n) are contractions, i.e. instances of reduction rules t i ~ si (i = 1 ..... n), 
then C[tlOl ..... tn Â°hI -'-~11 C[Sl Â°l  ..... SnCn] â¢ 
2.2.3. THEOREM (Huet [80]). Let R be a left-linear TRS such that we have $ "")11 tfor every critical pair 
(s, t). Then R is confluent. 
Note the direction i volved here. As far as we know, it is an open problem whether the reverse condition 
also implies confluence: for  all critical pairs (S, t) we have t "~11 s. Also open seems to be the problem 
whether confluence is implied by the property:for all criticalpairs ($, t) we have s ----~-= t or t ---~=- s. 
The example of a completion above merely intended to give the flavour of a critical pair completion. 
Actual completion algorithms (for some simple versions ee Klop [90]) would not start with adopting ori- 
ented versions of all equations that are initially given, as we did above. Rather, there will be a step by step 
conversion of E into a complete TRS R (if possible; the aIgorithm may fail), with as intermediate stages 
pairs (E', R'), where E' contains ome equations and R' contains ome rewrite rules. 
360 
An important aspect in critical pair completion algorithms i that we need to have an ordering of terms 
at our disposal, guiding us (or the algorithm) how to choose orientations. Thus, at the start of a comple- 
tion procedure, one must provide the algorithm with a so-called reduction ordering onterms; this is a well- 
founded partial order among terms which is closed under substitutions and contexts, i.e. if s > t then 
C[S a] > C[t a] for all substitutions a and contexts C[ ]. 
The original specification E does not prove x + y = y + x (this follows immediately from the fact that x 
+ y and y + x are different normal forms of R); yet for all ground terms t, s we have E ~ t + s = s + t. 
That is: x + y = y + x is valid in the initial algebra of E. Such an equation is called an inductive theorem 
(since its validity is usually proved with induction to the structure of ground terms). Completion tech- 
niques provide the means to prove inductive theorems without using induction Cinductionless induction"); 
another phrase in this respect is "proof by consistency". For an account of proof by consistency applica- 
tions, see Dershowitz & Jouannaud [90] and Bachmair [88]. 
To conclude this section about completion, we mention an important recent development in proving 
correctness of completion algorithms. This is the method of proof orderings, introduced by B achmair, 
Dershowitz & Hsiang [86]; for details we refer also to Dershowitz & Jouarmaud [90], Klop [90], 
2.3. Terminat ion 
Clearly, termination is an important property of TRSs (see Newman's Lemma), and therefore it is impor- 
tant to have methods to prove termination. In general, it is undecidable whether aTRS is terminating, but 
some quite sophisticated methods have been devised to prove termination for many TRSs. We present the 
most powerful of these methods (in a simplified version), known as the method of recursive path order- 
ings. (Actually, there are some refinements of the method which are even stronger; they are not discussed 
here.) The method is based on a powerful theorem of Kruskal [60], which is too beautiful not to mention 
even in a short survey. 
Let t, s ~ Ter(E). We say that t is embeddabte in s, notation t << s, if s --* S t with respect to the TRS 
(E, S) consisting of the rules F(t 1 .... , tn) --> t i for all 1 < i < n and all n-ary F ~ ~'.. (S stands for simplifi- 
cation.) Example: F(H(A), B) << F(G(H(A), A), H(B)). Note that not F(A, B) << F(G(A, B), A). 
2.3.1. KRUSKAL'S TREE THEOREM. Let t 1 , t 2 .... be a a sequence of terms, such that in the sequence 
only finitely many symbols (function symbols, constants, variables) appear. Then for some i, j with i < j 
we have t i << tj. 
Let us now define the recursive path ordering. We will define it using some auxiliary terms using 
markers. Let Y.* = E u {F* 1F ~ ~} (F a function or constant symbol from y.; F* has the same arity as 
F). Example: if F(H(A), B) ~ Ter(Y.), then F*(H*(A), B) a Ter(E*). Note that Ter(E) ~ Ter(Y-*). Now 
suppose E finite and suppose that function and constant symbols of E are partially ordered by >. We de- 
fine a reduction relation ~ on Ter(E*), with the following reduction rules. 
(1) F(t) ~ F*(t) 
(2) F*(t) ,# G(F*(t) ..... F*(t)) i fF > G 
(3) F*(t) ,~, t i ( i= 1 ..... n) 
(4) F*(p, G(s), q) ~ F(p, G*(s), q) 
Table 6 
Here t = t 1 ..... t n and $ = Sl ..... S m with ti, s] e Ter(E*). Furthermore, F, G ~ ~. are function symbols 
with arities n, m > 0 respectively (so in rule (2) there are in the right-hand side m copies of F*(t)). In rule 
(1), (2) the arity of F may be 0; in rule (3), (4) it is clear that [he arity of F has to be at least 1. In (4), p, 
G(s), q is a sequence of n elements from Ter(Y-*), where p, q may be empty sequences. Since ~ is a re- 
duction relation, it is understood that reduction steps according to (1-4) may be performed within a T.*- 
context. With W* we denote the transitive reflexive closure of W, with ,~+ the transitive closure. Note 
that the simplification reduction .-,> S is contained in ,~*, i.e. if s --, S t then s ~*  t. 
361 
Intuitively, attaching a marker as in rule (1) signifies a command to make the term smaller. The other 
rules express one step of the execution of this command, which is fully executed if all markers have dis- 
appeared. Clearly, O on Ter(E*) is not terminating; see the reduction rule (2). However, the restriction of 
~+ to Ter(E), the set of unmarked terms, is terminating (SN). This is proved by first showing that ~+ is 
a strict partial order. (The difficult part here is to show the acyclicity.) Now termination follows at once 
from Kruskal's Tree Theorem: suppose there is an i finite sequence t 1 ~+ t 2 ~+ ... of E-terms. Then for 
some i < j we have t~ << t i, i.e. t i ~,  S t i, and therefore tj ~*  t i. But then we have a cycle: t i ~+ t i ~*  t i. 
So ~+ is a well-founded ordering on Ter(E). This ordering is called the recursive path ordering. 
(Usually, the ordering is defined such that it is preserved under permutations of the arguments t of a term 
F(t); we will not do so here.) The recursive path ordering can be used for termination proofs of TRSs as 
follows. Let (E, R) be a TRS with finite E. (The method can be extended to deal with infinite signatures, 
however.) Suppose the function and constant symbols of E can be partially ordered in such a way that for 
the corresponding recursive path order fO+ we have, for every reduction rule s --~ I of R, that s ,O+ t. 
Then (since S ~+ t implies C[s ~] ~+ C[t o] for every context G[ ] and instantiation a) it Iollows immedi- 
ately that --~ must be terminating too. It is instructive to see the method at work in the following example 
of Dershowitz: 
--(-aX) ~ X 
--,(x v y) --~ (--~x) A (~y) 
-~(X ^  y) ~ (--~) V (-~y) 
X^(y VZ) ~ (x^y) V (X^Z) 
(y v Z)^ X ---~ (y A X) V (ZA X) 
Table 7 
Order the operators as follows: ~ > A > V. NOW we have e.g. for the second rule ~(x v y) C~+ (~x) A 
(~y), since: 
m(x v y) ~ ~*(x v y) ~ (-~*(x v y)) A ('~*(X V y)) ~ (~(X V* y)) A (--~*(X V y)) t~ 
('--~X) ^ (~*(X V y)) '~ (~X) A (--,(X V* y)) ~ (~X) A (~y). 
Likewise for the other rules. Hence the reduction relation -% computing disjunctive normal forms, is 
terminating. 
Just as we encountered the presence of commutativity axioms x + y = y + x in E as an obstacle for 
finding a complete TRS R for E, we encounter problems in proving termination via the recursive path 
ordering (rpo) method of a TRS containg a rewrite rule expressing associativity of an operator: (x + y) + z 
--~ x + (y + z). In fact, the rpo method will not work in this case as is easily seen. However, in contrast 
with the obstacle of commutativity axioms, this time the problem is surmountable: an extension of the rpo 
method with a lexicographic component will do the job of proving termination. For details we refer to 
Dershowitz [87], an extensive survey of termination proof methods. 
An interesting fact is proved in Kurihara & Ohuchi [89]: 'simple termination' is a modular property (in 
contrast with the general case, see section 1.4). A TRS is simply terminating f the termination can be 
proved by the rpo method (or by some other termination proof methods, like polynomial orderings, not 
discussed here). 
2.4 .  Nar rowing  
After our discussion of one major application of complete TRSs, viz. deciding validity of equations in an 
equational theory, we will now briefly discuss another major application: solving equations i  an equa- 
tional theory. If (E, E) is an equational theory, we write ~t = S~E for the set of solutions of the equation t 
-- S in E, i.e. {~ I E ~- t ~ = s~}. A solution o is a substitution as defined earlier, i.e. a map from Var, the 
set of variables, to Ter(E). Let SUB be the set of all substitutions, and if X ~ SUB, let o~ denote {on t x 
X}.  (Here o~ is the composition of o, x written in the usual logic programming notation; in ordinary 
mathematical notation it would be x o o.) Now noting that for every substitution c~ we have ~t -- S~E 
o ~t a = SO~E, there is in principle the possibility of a stepwise determination f ~t = S~E. 
362 
This stepwise determination consists of 
two kinds of steps. The first is as just 
described: guess a component a of a 
solution and narrow It = S~E to c ~ta= 
SO~E . The second is: apply an equation 
of E in one of the sides of the equation 
t = s at hand. Clearly, a step of  the 
second kind preserves equality of the 
solution set. By an iteration of  such 
steps, alternating between steps of the 
first kind and steps of the second kind, 
we may reach the solution set of a triv- 
ial equation r = r (that is SUB): 
[~t = S~E ~ a [~tc= SO~E = 
o ~r = SÂ°~E ~ aa' ~ra'= saa'~E = 
.,. ~ ,.. ~ aa ' . . .a (n )  ~r = r~ E. 
The last solution set of this 'narrowing' 
chain has as a most general element the 
substitution oo'...o(n). The word nat- 
narrowing step on terms 
Figttre 8 
rowing has been given a formal content: it denotes acertain method, based on term rewriting, to perform a 
stepwise determination of It = $~E as described. A narrowing step combines a step of the first kind and 
one of the second. Actually, the narrowing relation is defined on terms, as in the following definition. 
Suppose E is given as (or equivalent to) a TRS R. 
2.4.1. DEFINITION. Let term t contain the subterm U, so t - C[U] for some context C[ ]. We say that t is 
narrowable into t', at the (nonvariable) subterm u ~ t, using rewrite rule r: t 1 ---~t 2of R, via o=mgu(u, tl), 
i f t '  3 (C[t2])o. Notation: t mus.o 1'. Sometimes we will drop mention of u, r; but not ofo .  
(Here 'mgu' abbreviates 'most general unifier'.) 
We now extend the narrowing transformation, which was defined on terms, to equations: if t "~o r, 
then t=s "*a t '=sÂ° and likewise s=t "*a sa=t' are said to be narrowing steps on equations. As we have 
seen, the word narrowing actually refers to the solution sets: if t=s "*o t '=sÂ° then ~t=s~R m o~t'=SO~R . 
Note how narrowing cuts down the search space for determining the solution set, first by using the direc- 
tional aspect of a TRS, and second by performing substitutions which are as 'small' (as general) as pos- 
sible. However, there is a price to be paid: to ensure completeness of the narrowing method for solving 
equations, we must require that the underlying TRS is ... complete. For more precise information on the 
subject of completeness of narrowing, we refer to H611dobler [89] or one of the extensive surveys men- 
tioned before. We conclude this subsection by drawing attention to the fact that the narrowing relation on 
terms is actually a generalization ofreduction: i f t  --> s then t "~'a $ for some o that leaves the variables 
occurring in t unaffected. 
3. BEYOND 
3.1. Orthogonality 
From the previous chapters it is clear that the two main obstacles to obtain confluence of a TRS are: the 
presence of repeated variables (non-left-linear reduction rules), and the presence of critical pairs (overlap- 
ping reduction rules). Both obstacles need to be fatal for confluence. In the presence of non-left-linear 
rules we may have confluence, provided the TRS in question is not 'too strong'. For example, R1 = CL u 
{D(x, x)--> 1"} is confluent, but the stronger system R2 = OL u {Dxx---> T} is not. The former TRS can be 
viewed as a sub-TRS of the latter, namely, by restricting term formation in R2 such that each D has to have 
two 'arguments' (i.e. each D appears in a subterm (Dst)) we have a sub-TRS which is 'isomorphic' to 
R1. There is a more precise sense in which R2 can be said to be stronger: R2 is still combinatory complete 
but R1 is not. (It is not hard to show that R1 does not possess a ground term F, built from S, K, I, D, 
363 
satisfying Fx -~ D(x, 1).) Also the other potential obstacle, the presence of critical pairs, does not per se 
prohibit confluence as the Knuth-Bendix theorem 2.2.2 shows. Nevertheless, the presence of one or two 
of these obstacles requires extra conditions i  order to ensure confluence. 
A particularly attractive class of TRSs arises if we forbid both obstacles, repeated variables as well as 
critical pairs. This is the class oforthogonal TRSs, characterized by the definition that all reduction rules 
are left-linear and non-overlapping. A comment on the terminology is in order. Instead of orthogonal, in 
the literature also the phrases 'consistent', 'left-linear and non-ambiguous' and 'regular' are used. The last 
term was introduced in Klop [80] and subsequently adopted by some authors, but is deemed objectionable 
by other authors. Dershowitz proposed in private communication to employ the term 'orthogonai' and 
since this term has in the present context exactly the right intuitive connotations, we adopt his term. 
The orthogonality requirement allows the development of a sizeable amount of theory, of which the 
basic fact is the following. 
3.1.1. THEOREM. All orthogonal term rewriting systems are confluent. 
Various proofs have been given of this theorem, e.g. the one in Rosen [73]. Note that the theorem is also 
an immediate consequence of Huet's theorem 2.2.3: since there are no critical pairs, the condition of that 
theorem is trivially satisfied. Intuitively, the theorem can be understood very well by realizing that in an 
orthogonal TRS the reduction steps in a reduction diagram, constructed in order to find a common reduct, 
move in an orthogonal way 'through each other' (see Figure 9), thereby retaining their identity. The 
orthogonality, in the sense of independence, of reductions in an orthogonal TRS can be understood by the 
following reformulation of the absence of critical pairs. Let a redex pattern be a left-hand side of a reduc- 
tion rule where the variables have been replaced by [3, the symbol denoting an empty place. As an exam- 
ple, consider the three redex patterns of the TRS CL, in the notation with explicit application operator: 
Ap(Ap(Ap(S, u), u), u), Ap(gp(K, a), a), Ap0, U). 
Now in a CL-term, even though it may contain nested redexes, it is easily seen not to be possible that the 
patterns of these redexes overlap (example: Figure 10(b)). So, reduction of some redex R does not disturb 
(the pattern of) a super-redex S containing R, nor does it disturb a sub-redex S' contained by R (though 
the reduction of R may multiply S' into a number n > 0 of copies). In general, in an orthogonal TRS, re- 
rex patterns do not overlap, which is just a rephrasing of the statement that there are no critical pairs. 
(Note, for contrast, the heavy overlapping into a term from the TRS R in section 2.2 as in Figure 10(a).) 
! 
Figure 9 Figure I0 
So OL is an orthogonal TRS. Also its extension SKIM is orthogonal, hence confluent. 
Many interesting theorems can be proven for orthogonal TRSs. We mention two fundamental ones. 
Let WN (Weak Normalization) be the property of a TRS that every term has a normal form (though infi- 
nite reductions may exist). Let NE (non-erasing) be the syntactical property of a TRS which holds if in 
every rewrite rule t ~ s, both sides t, s contain the same variables (so OL is not NE). Let WIN (Weak 
Innermost Normalization) be the property of a TRS stating that every term has a normal form which can be 
reached by an innermost reduction, i.e. a reduction in which only redexes are contracted that do not prop- 
erly contain other redexes. The properties SN, WN, WIN can also be specialized to individual terms: 
364 
SN(t) states that t has no infinite reductions, WN(t) means that t has a normal form, WIN(t) that t has a 
normal form reachable by innermost reduction. Now we have the following facts. 
3.1.2. THEOREM (O'DonneU [77]). (i) For orthogonal TRSs: NE ~ (WN Â¢e~ SN). 
(ii) For orthogonal TRSs: WIN Â¢Â¢. SN. 
(iii) For every term t in an orthogonal TRS: WIN(t) Â¢~ SN(t). 
3.2. Strategies and sequential ity 
Since terms may have a normal form as well as an infinite reduction, one is interested in formulating 
'strategies' that as much as possible avoid the infinite reductions and are heading for the normal form. 
Formally, we define: 
3.2.1. DEFINITION. (i) Let R be a TRS. A one step or sequential reduction strategy IF for R is a map from 
Ter(R) to Ter(R) such that t ~ IF(t), if t is not in normal form, and t -- IF(t) i f  t is a normal form. 
(ii) Likewise, IF is a many step orparatlel reduction strategy for R, if t --~+ IF(t) if t is not in normal form, 
and t - ~(t) if t is a normal form. 
(iii) A reduction strategy is normalizing when it finds the normal form whenever it exists, i.e. if t has a 
normal form t', then 9n IFn(t) - t'. 
We consider five of the main strategies. First, two sequential strategies: (1) the leftmost outermost (or 
normal order) strategy; (2) the leftmost innermost strategy. In the first, each time the leftmost outermost 
redex is contracted; in the second, the leftmost of the innermost redexes. Next, there are these three paral- 
lel strategies: (3) the parallel outermost rategy; (4) the parallel innermost rategy; and (5) the 'full substi- 
tution' (or Gross-Knuth) strategy. In the third, all outermost redexes are contracted in one parallel 'step'; 
in the fourth, all innermost redexes. Of course, outermost redexes are pairwise disjoint, so performing this 
parallel step is unproblematic, and likewise for the innermost redexes. Actually, the definition of strategies 
(1-4) makes sense for arbitrary TRSs; this is not so for the full substitution strategy, where each time a 
'parallel' step is performed consisting of contracting all redexes present at that time. For general TRSs, 
this notion is not well-defined, but for orthogonal TRSs there can be shown to be an unequivocal result of 
contracting all redexes that are already present at once. We restrict our consideration f strategies in the se- 
quel to orthogonal TRSs; not much can be said for the general case. 
The two innermost strategies are not interesting from the point of view of normalization; in fact, they 
are 'anti-normalizing', finding infinite reductions whenever possible. 
Although finding normal forms is important, we are often interested in terms that do not have a nor- 
real form, but rather an 'infinite normal form'. (We will not attempt a formal definition of infinite normal 
form here.) For example, in SKIM one can define, using combinatory completeness and the fixed point 
combinator, terms (p, A* such that: 
Â¢p-. PI(A*~o(P0~o)) 
A*xy -.. P(A(Pox)(Poy))(A*(Plx)(ply)). 
Here P, P0, P1 are the pairing, respectively unpalring constants from SKIM, and A is addition (see Table 
3). Using pairing, we may have infinite sequences of natural numbers, or rather potentially infinite s - 
quences, i.e. terms t such that t --- tO, tk --~ P n_k tk+l (so t represents he sequence no, n l ,  n9 .... ). Now 
A* represents pointwise addition of such infinite sequences, and as one may check, ep represents he se- 
quence of Fibonacci numbers. A closer analysis of cp will reveal that this term has no normal form. Yet we 
need a strategy to compute the 'infinite normal form' of ~0, since there are also reductions of q~ that make 
no progress towards the infinite normal form. A normalizing strategy will not do now. Here we need a 
stronger version: a 'cofmal' reduction strategy. 
3.2.2. DEFINITION. F is a cofinal reduction strategy if for every reduction t --~ s there is an n such that 
s--* W~(t). 
Clearly, a cofmal strategy is normalizing; but the reverse need not be the case. 
365 
3.2.3. THEOREM. For all orthogonal TRSs: 
O) The parallel outermost reduction strategy is normalizing, although not necessarily cofinal. 
(it) The "full substitution' reduction strategy is cofinal, hence normalizing. 
('hi) The leftrnost outermost reduction strategy is normalizing for "left-normar TRSs. 
In (iii), a TRS is left-normal if for every reduction rule t --~ s, in t the variables are to the right of the func- 
tion and constant symbols (in the linear term notation). E.g. GL is left-normal, SKIM is not due to the rule 
for U. Proofs of (i-tit) can be found e.g. in O'Donnell [77] or Klop [80]. 
A paradigm example in considerations of sequential versus parallel reduction isBerry's TRS, with the 
three rules: 
F(A, B, x) -.> 0,  F(x,A, B) .-) 1, F(B,x,A) --," 2.  
When added to, say, CL, the resulting TRS seems to require a parallel reduction strategy for normaliza- 
tion. For, in a term F(p, q, r) there seems at first sight to be no co_m__putab!e way of detecting the 'right" re- 
dex; selecting a redex in say r, we might find ourselves in the case that p, q, reduce to A, R respectively, 
and then our selection of a redex in r was useless. Likewise, by symmetry, for selections of a redex in one 
of the other two arguments. Note that i is undecidable whether indeed p, q reduce to A, B respectively. 
(The same problem occurs with the rules {or(x, true) ~ true. or(true, x) ~ true}; however, in contrast 
with the present example, these are not orthogonal .) Actually, it has been claimed in some papers that CL 
together with Berry's TRS does not admit a computable sequential normalizing strategy. However, there 
is the following remarkable fact. 
3.2.4. THEOREM (Kennaway [89]). Every orthogonal TRS possesses a computable, sequential, 
normalizing reduction strategy. 
In general, the algorithm involved in Kennaway's theorem is, however, too complicated to be of more 
than theoretical interest. So, the task remains to isolate a (decidable) class of orthogonal TRSs for which 
'feasibly computable' sequential normalizing strategies exist. This complicated problem was successfully 
tackled by Huet & l_~vy [79]. Moreover, the sequential strategy that they established has the virtue of not 
only being normalizing, but also of being efficient: no wasteful reductions are performed, 
They defined a property of orthogonal 
TRSs called 'strong sequentiality'; a 
strongly sequential TRS admits the se- 
lection (by a simple algorithm) of a so- 
called 'needed' redex, needed for 
reaching the normal form, in the sense 
that every reduction to normal form 
must contract one of the descendants of 
that redex. Since, as proved in Huet & 
LEvy [79], repeated contraction of a 
needed redex inevitably finds the nor- 
mat form if it exists, we have therefore 
!i iiiiiiiiiiiiiiii !i!iiiiiiiiiiiiiiiiiiiii!iiiii!iiiiiii   "" i i iil 
iiiiiii iii!i!! iiiiiiil iiiiiiiiii iii!iiiiiii 
ii!ii i i!i i i !iii!i ! ii i i iii iiii!iii! i!ii i!!i! iiiiii i i iii iiiiiii i i i ii i iiiii!iiiii ii i ii i ii!ii!i
iii~iii~ii~iiit~i"g~ri~icesiiii~i~iiiiiii!i!~iiiii~i~iii~iii!iiii~i~iii~i~!~iiiii~!~iiiii!~i~i~i~ii i iiiii 
Figure 11 
a normalizing sequential strategy that is computable by a simple algorithm. 
One may ask why we are interested insequential strategies when parallel strategies (parallel outermost 
and full substitution) are available that are normalizing for all orthogonal TRSs. The reason is that we do 
not want to be forced to evaluate in parallel; maybe we have only a reduction machine at our disposal that 
operates in a sequential way. 
Let us describe now the algorithm in Huet & LEvy [79] detecting needed redexes. In general, it is 
undecidable whether a redex in a term is needed. However, for strongly sequential TRSs the algorithm 
will always point to at least one needed redex. 
First, the signature T. is extended with a constant f~ (playing the same role as the symbol D). Terms 
M, N .... are henceforth over the alphabet E u {~} and are also called t~-terms. M is aprefix of N if M 
366 
results from N by replacing some subterms of N by ~. A redex compatible term is a prefix of a redex. A 
new reduction ---*o~ is defined: if P is a redex compatible term, P ~ f2, then C[P] --~coC[D] for arbitrary fl- 
contexts C[ ]. The reduction ---%~ is confluent and terminating; the ---~o~-normal form of M, notation (o(M), 
is called the flxed part of M. 
Now suppose that a term M, without f l ' s  and not in normal form, is given and that we want to 
determine among the outermost redexes of M one that is needed. To that end, all outermost redexes of M 
are replaced by E2, result C[f2 ..... Â£2] where all f2's are displayed. An fl-occurrence in C[f2 .... , f2] is called 
an index, when the following "i-test" is positive. Replace the f~-occurrence under investigation by a fresh 
symbol i (see Figure 11). Now determine the fixed part. If and only if the test-symbol i is preserved in the 
fixed part, it indicates an index-f2. The redex present in the original M at the place of this f2, is a needed 
one. As remarked earlier, repeated contraction of a needed redex is a normalizing sequential strategy. 
Not for all orthogonal TRSs we will find an index-f2 when running the i-test on all fl-occurrences in
C[f2 ..... f~]. But for strongly sequential orthogonal TRSs the i-test will find at least one index-f2 in every 
C[f~ ..... ~q] as defined above. This fact can even be taken as a definition of strongly sequential TRSs. 
Moreover, strong sequentiality is a decidable property of TRSs; the proof is rather intricate. It is important 
to realize that all concepts involved in the definition of index and of strong sequentiality are independent of
the right-hand sides of the reduction rules; this is what makes trong sequentiality decidable. 
3.3. Condit ional rewrit ing 
A very prominent place in investigations of term rewriting in the last years is taken by the theme of 
conditional rewriting. Conditional Equational Logic originated in Universal Algebra, from the need to deal 
with conditional equations for algebraic structures, as for instance a left-cancellation law xy = xz --~ y = z. 
Conditional equations were also studied in the field of Abstract Data Types, not only because they provide 
easier specifications, but also because they can be shown to have a greater expressive power. Further- 
more, conditional equations turn out to be an essential ingredient in Equational Logic Programming (H611- 
dobler [89]), an attempt to integrate logic programming and functional programming. 
We will write conditional equations in the form e ~ el ..... On where o, Ol ..... en are equations 
between first order terms. The reversed implication is used in accordance with the usual logic 
programming notation; its right-hand side Ol .. . . .  en is the conjunction of these equations. Much of 
Equational Logic (section 2.1) generalizes easily to Conditional Equational Logic, such as initial algebra 
semantics and a completeness theorem analogous to Birkhoff's completeness theorem 2. I. 1; a simple 
version of a complete inference system can be found in Klop [90]. 
After orientation of the head equation e, we have a conditional rewrite rule: 
t -~  s ~ t l  = Sl . . . . .  In = Sn. (*) 
Here we require that t --* s is an ordinary rewrite rule, i.e. t must not be a variable and s contains no more 
variables than t (although this condition is less natural now). A Conditional Term Rewriting System 
(CTRS) consists of (a signature Z and) a set R of conditional rewrite rules. Actually, there is some 
ambiguity in the definition of a CTRS, due to the possible interpretations of the equality signs in the 
conditional part tl = Sl ..... tn = Sn. We will consider the three main interpretations. The terminology 
stems from Dershowitz, Okada & Sivakumar [87, 88]. 
(1) Semi-equational CTRSs. Here the '=' in (.) is convertibility of the rewrite relation -~ (the definition 
of '=' and '--)' thus depend on each other, but this is no problem since the conditions are positive). 
(2) Join CTRSs. Here '=' is interpreted asjoinability or convergence(S, see 2.2.1), i.e. having a com- 
mon reduct. 
(3) Normal CTRSs. Here '=' is interpreted as -,7 !, defined as: t --*> !s i f t  --~ s and s is a normal form. 
The definition of critical pairs in a CTRS (of one of the above types) is lightly more complicated than for 
the unconditional case. It will now have a conditional form too. If t ~ s ~ E and t' --* s' ~ E' are 
conditional rewrite rules, then by a definition analogous to 2.2.1 we find in case of overlap of t and t' the 
critical pair (CG[s'Â°], S ~) ~ E ~, E '~, also written as a conditional equation Cc[s 'Â¢J] = s ~ ~ E c, E 'c. The 
critical pair t = s ~ E is called feasible in Dershowitz, Okada & Sivakumar [87, 88], if there is a 
367 
substitution c~such that E o is true. Critical pair t = s ~ E is called joinable if for all a such that Ea is true, 
s a $ t a. The following theorem is the conditional nalogue of the Knuth-Bendix theorem 2.2.2. 
3.3.1. THEOREM (Dershowitz, Okada & Sivakumar [87, 88]). (i) Let R be a semi-equational CTRS. 
Then: if R is terminating and all critical pairs are joinable, R is confluent. 
(ii) Let R be a join CTRS. Then: if R is decreasing and all critical pairs are joinable, R is confluent. 
Here R is decreasing (a property stronger than termination) if it has a decreasing ordering, i.e. an ordering 
> on Ter(R) satisfying: (I) > is well-founded; (2) t c s ~ t < s (c is the proper subterm ordering); (3) t 
---> s ~ t > s; (4) for each rewrite rule t --~ s ~ tl Et sl ..... tn [] Sn and each o we have tÂ° > ti Â°, si Â° (i 
= 1 ..... n). Here 13 is =, $, --~ !. 
In general, the property of being a normal form is not decidable in a CTRS. (This is not surprising, 
since being a normal form depends on some conditions that refer to convertibility or reduction and hence 
may be undecidable.) However, for decreasing CFRSs being a normal form is decidable. 
For more about conditional rewriting, we refer to Kaplan [84, 85], Dershowitz &Plaisted [87]. For 
conditional critical pair completion see Ganzinger [87]. Recently, Middeldorp [89c] generalized Toyama's 
theorem 1.4.1 to the case of CTRSs, showing that also in the conditional case (for all three types above 
mentioned) confluence is a modular property. We conclude this section by mentioning a confluence the- 
orem for orthogonal CTRSs; a CTRS is called orthogonal if its unconditional part, that is the TRS arising 
after emoving all conditions from the conditional rewrite rules, is an orthogonal TRS as defined in 3.1. 
3.3.2. THEOREM (Bergstra & Klop [86]). Orthogonal semi-equational and orthogonal normal CTRSs are 
confluent. Orthogonal join CTRSs are in general not even weakly confluent. 
3.4. Other rewrite formats 
We conclude by mentioning some important other rewriting formats that could not be discussed in this 
paper. An useful extension of the 'pure' rewrite format is equational term rewriting, where one rewrites 
not terms but equivalence classes of terms. For instance, it s sometimes convenient to work modulo 
commutativity and/or associativity of some operators; recall the problems, discussed in section 2 above, 
that commutativity and associativity axioms present to pure term rewriting. For a treatment of this subject 
we refer to Dershowitz & Jouannaud [90]. Another ewrite format is that of graph rewriting, introduced to 
avoid duplications of subterms in reductions. For implementations this is of crucial importance. For an 
introduction and further eferences we refer to Barendregt et. al. [87]. Also not covered here are term 
rewriting systems with bound variables, or Combinatory Reduction Systems as they are called in Klop 
[80, 90]. For instance, X-calculus is a TRS with bound variables. 
As said in the Introduction, the design of functional programming languages poses many stimulating 
questions to the study of TRSs. E.g. Peyton Jones [87] introduces A-calculus with patterns, with (instead 
of the usual [3-reduction rule of the ordinary ~-calculus) the reduction rule (~.P. M)N --> M o, if o = mgu(P, 
N) exists. Here P is a linear term built from 'constructors' and free variables (a 'pattern'). (Without he 
linearity, i.e. if P may contain repeated variables, the system is not Church-Rosser.) With P --- x we get 
the ~-reduction rule. (We have not defined the concept of 'constructors'. An interesting calculus, without 
referring to constructors, and in the syntax of pure ~.-calcutus, arises if P above is taken to be a linear ~.- 
calculus term in normal form.) How much of the well-known theory of the ~.-calculus can be generalized 
to this extension? 
Another feature, common in the practice of functional programming, is the use of reduction rules with 
priorities assigned to them: 
fao0~l  
fac x --, mult x (f.E~ (ored x)) 
Here the first rule should be 'tried' first; only if it is not applicable, the second one may be used. Without 
this priority assignment, the specification would of course be erroneous. The mechanism of rule priorities 
is not without some nasty problems; it is studied in Baeten et.al. [88]. 
368 
As a third example, we mention the question how to translate (or interpret) rewrite systems into each 
other. Peyton Jones [87] contains a translation of  a subset of  Miranda into the pure 7~-calculus. In general, 
it is known that not every TRS can, in a direct sense, be translated into L-calculus, not even every ortho- 
gonal TRS with the constructor discipline (an example is Berry's  TRS), As far as we know, at present it is 
not r igorously established what subclasses of  TRSs (say of  orthogonal constructor TRSs) can be 'directly 
defined' into ~,-calculus, by f inding k-terms for the operators of  the TRS such that reductions are respec- 
ted, (This is a vague definition, but part of  the question is to find the right notions here. For some propo- 
sals in this direction see O'Donnel l  [85].) 
Acknowledgements 
I am much obliged to Roel de Vrijer for many detailed criticisms and in general for his help in getting my efforts to write this 
paper confluent and terminating. (Yet, the paper is not complete, but that is solely due to the author.) 
Thanks are also due to the Computer Science Department of the Universit~t degli Smdi di Milano, where a part of this 
paper was written in a stimulating and hospitable environment created by, among others, Giovanni Degii Antoni and Nice- 
letta Sabadini. 
References 
BACHMAIR, L. (1988). Proof by consistency inequational theories. In: Proc. 3rd Symp. on Logic in Computer Science, 
Edinburgh. 228-233. 
BACHMAIR, L., DERSHOWITZ, N. & HSIANG, J. (1986). Orderingsfor equationalproofs. In: Proc. of the IEEE Syrup, 
on Logic in Computer Science, Cambridge, Massachusetts, 346-357. 
BAETEN, J.C.M., BERGSTRA, J.A., KLOP, J.W. & W.P. Weijland. (1988). Term rewriting systems with rule priorities. 
TCS 67 (1989) 283-30t. 
BARENDREGT, H.P. (1984). The Lambda Calculus, its Syntax and Semantics. 2rid ed. North-Holland t984. 
BARENDREGT, H.P. (1989). Functionalprogramming and lambda calculus. In: Handbook of Theoretical Computer Science 
(ed. J. van Leeuwen), North-Holland, Amsterdam. 
BARENDREGT, H.P., VAN EEKELEN, M.C.J.D., GLAUERT, J,R,W,, KENNAWAY, J,R,, PLASMEIJER, M.J. & 
SLEEP, M.R. (1987). Term graph rewriting. In: Proc. PARLE Conf., Springer LNCS 259, 141-158. 
BERGSTRA, J.A. & KLOP, J.W. (1986). Conditional rewrite rules: confluence and t rmination. JCSS 32 (3), 323-362. 
BIRKHOFF, G. (1935). On the structure of abstract algebras. In: Proc. of the Cambridge Philosophical Society 31,433-454. 
DE BRUIJN, N.G. (1978). A note on weak diamond properties. Memorandum 78-08, Eindhoven Univ. of Technology, 1978. 
CURIEN, P.-L. (1986). Categorical combinators, sequential algorithms and functional programming. Research Notes in 
Theoretical Computer Science, Pitman, London 1986. 
DAUCHET, M., TISON, S., HEUILLARD, T. & LESCANNE, P. (1987). Decidability of the confluence of ground term 
rewriting systems. In: Proc. of the 2nd Symp. on Logic in Computer Science, Ithaca, NY, 1987, 353-359. 
DERSHOWITZ, N. (1987). Termination of rewriting. J. of Symbolic Computation 3 (l&2), 69-115, 1987. Corrigendum: 
Vol.4, No.3, 409-410. 
DERSHOWITZ, N. & JOUANNAUD, J.-P. (1989). Rewrite systems. To appear as Chapter 15 of VoI.B of "Handbook of 
Theoretical Computer Science", North-Holland, 1989. (Rapport de R6cherche no.478, Unit6 Associ6e au CNRS UA 410: AL 
KHOWARIZMI, Avril 1989.) 
DERSHOWITZ, N., OKADA, M. & SIVAKUMAR, G. (1987). Confluence of Conditional Rewrite Systems. In: Proc. of 
the 1st International Workshop on Conditional Term Rewrite Systems, Orsay, Springer LNCS 308, 31-44. 
DERSHOWITZ, N., OKADA, M. & SIVAKUMAR, G. (1988). Canonical Conditional Rewrite Systems. In: Prec. of 9th 
Conf. on Automated Deduction, Argonne, Springer LNCS 310, 538-549, 
DERSHOWITZ, N. & PLAISTED, D,A. (1987). Equational Programming. I : Machine Intelligence 11 (eds. J.E. 
Hayes, D. Michie and L Richards), Oxford University Press, 21-56. 
GANZINGER, H. (1987). A completionprocedurefor conditional equations. In: Pr c of the 1st Intern. Workshop on 
Conditional Term Rewriting Systems, Orsay 1987, Springer LNCS 308, 1988, 62-83. 
GOGUEN, J.A. & MESEGUER, J. (1985). Initiality, induction, and computability. In: Algebraic methods in semantics 
(eds. M. Nivat and J.C. Reynolds), Cambridge University Press1985, 459-542. 
HARDIN, T. (1989). Confluence results for the pure Strong Categorical Logic CCL. )'-calculi as subsystems ofCCL. 
Theor. Comput Sci. Fundamental Studies, Vol.65, Nr.3, 1989, 291-342, 
HINDLEY, LR. & SELDIN, J.P. (1986). Introduction to Combinators and ).-Calculus. London Mathematical Society 
Student Texts, Nr.1, Cambridge University Press 1986. 
HOLLDOBLER, S. (1989). Foundations of Equational Logic Programming. Springer Lecture Notes in A.I. 353. 
HSIANG, J. (1985). Refutational Theorem Proving using Term-Rewriting Systems. Artificial Intelligence, 25, Vol.3, 1985. 
369 
HUET, G. (1980)~ Confluent reductions: Abstract properties and applications to term rewriting systems. JACM, Vol.27, 
No.4 (1980), 797-821. 
I~IUET, G. & LANKFORD, D.S. (1978). On the uniform halting problem for term rewriting systems. Rep. 283, IRIA. 
HUET, G. & Lt~VY, J.-J. (1979). Call-by-need computations in non-ambiguous linear term rewriting systems. Rapport 
INRIA rtr.359. 
HUET, G. & OPPEN, D.C. (1980). Equations and rewrite rules: A survey. In: Formal Language Theory: Perspectives and 
Open Problems (ed. R. Book), Academic Press, 1980, 349-405. 
KAPLAN, S. (1984). Conditional Rewrite Rules. TCS 33(2,3), 1984. 
KAPLAN, S. (1985). Fair conditional term rewriting systems: Unification, termination a d c fluence, Recent Trends in 
Data Type Specification (ed. H.-J. Kreowski), Informatik-Fachberichte 116, Sprigtger-Verlag, Berlin, 1985. 
KENNAW AY, J.R. (1989). Sequential evaluation strategies for parallel-or and related reduction systems. Annals of Pure and 
Applied Logic 43 (1989) 31-56. 
KLOP, J.W. (1980). Combinatory Reduction Systems. Mathematical Centre Tracts btr.127, CWI, Amsterdam. 
KLOP, J.W. (1990). Term Rewriting Systems, in: Handbook of Logic in Computer Science (eds. S. Abramsky, D. Gabbay 
and T. Maibaurn) Vol.1, Chapter 6, Oxford University Press, to appear. 
KLOP, J.W. & DE VRIJER, R.C. (1989). Unique Normal Forms for Lambda Calculus with Surjective Pairing. Information 
and Computation 80 (2), 97-113. 
KNUTH, D.E. & BENDIX, P.B. (1970). Simple word problems in universal algebras. In: Computational Problems in 
Abstract Algebra (ed. J. Leech), Pergamon Press, 1970, 263-297. 
KRUSKAL, J.B. (1960). Well-Quasi-Ordering, the Tree Theorem, and Vazsonyi' s Conjecture. Trans. AMS 95,210-225. 
KURIHARA, M. & KAJI, I. (1988). Modular Term Rewriting Systems: Termination, Confluence argl Strategies. Report, 
Hokkaido University. 
KURIHARA, M. & OHUCHI, A. (1989). Modularity of Simple Termination of Term Rewriting Systems.Report 89-SF-31, 
Hokkaido University, Sapporo, 1989. 
MIDDELDORP, A. (1989a). Modular aspects of properties of term rewriting systems related to normal forms. In: Prec. of 
3rd Intern. Conf. on Rewriting Techniques and Applications, Chapel Hill, Springer LNCS 355,263-277. 
MIDDELDORP, A. (1989b). A sufl'tcient condition for the termination of the direct sum of term rewriting systems. In: Prec. 
of 4th IEEE Symposium on Logic in Computer Science, Pacific Grove, 396-401, 
MIDDELDORP, A. (1989c). Confluence of the Disjoint Union of Conditional Term Rewriting Systems. Report CS-R8944, 
Centre for Mathematics and Computer Science, Amsterdam 1989. 
NEWMAN, M.H.A. (1942). On theories with a combinatorial definition of "equivalence". Annals of Math. 43 (2), 223-243. 
O'DONNELL, M.J. (1977). Computing in systems described by equations. Springer LNCS 58. 
O'DONNELL, M.J. (1985). Equational ogic as aprogramming language. The MIT Press, Cambridge MA, 1985. 
OYAMAGUCHI, M. (1987). The Church-Rosser property for ground term rewriting systems i decidable. Theoretical 
Computer Science 49 (1). 
PEYTON JONES, S.L (1987). The Implementation f Functional Programming Languages. Prentice-Hall 1987. 
ROSEN, B.K. (1973). Tree-manipulating systems and Church-Rasser theorems. JACM, Vol.20 (1973), 160-187. 
RUSINOWITCH, M. (1987). On termination of the direct sum of term rewriting systems IPL 26, 65-70. 
SCHONFINKEL, M. (1924). Uber die Bausteine der mathematischen Logik. Math. Annalen 92, 305-316. Translated as: On 
the building blocks of mathematical logic, in From Frege to Gfdel, ed. J. van Heyenoort, Harvard Un. Press, 1967, 355-366, 
SCOTT, D,S. (1975). Some philosophical issues concerning theories ofcombinators. In: Prec. of Symposium 'X-calculus 
and Computer Science Theory', (ed. C. B6hm), Rome 1975/, Springer LNCS 37, 346-366. 
STAPLES, J. (1975). Church-Rosser theorems for replacement systems. In: Algebra nd Logic (ed. J. Crosley), Springer 
Lecture Notes in Mathematics 450, 291-307. 
TOYAMA, Y. (1987a). Counterexamples to termination for the direct sum of Term Rewriting Systems. Information 
Processing Letters 25, 141-143. 
TOYAMA, Y. (1987b). On the Church-Rosser p operty for the direct sum of term rewriting systems. JACM, Voi.34, No.l, 
1987, 128-t43. 
TOYAMA, Y., KLDP, LW. & BARENDREGT, H.P. (1989). Termination for the direct sum of left-linear term rewriting 
systems. In: Prec. of 3rd Intern. Conf. on Rewriting Techniques and Applications, Springer LNCS 355,477-491. 
TURNER, D.A. (1979). A new implementation technique for applicative languages. Software Practice and Experience, 
Vet.9, 1979, 31-49. 
TURNER, D.A.. (1985). Miranda: a non-strict functional language with polymorphic types. In: Prec. of the IFIP Intern. 
Conf. on Functional Programming Languages and Computer Architecture, Nancy. Springer LNCS 201, 1985. 
WINKLER, F. & BUCHBERGER, B. (1983). A criterion for eliminating unnecessary reductions in the Knuth-Bendix algo- 
rithm. In: Prec. of the Coll. on Algebra, Combinaturics and Logic in Computer Science, GyOr, Hungary, Sept. 1983. 
