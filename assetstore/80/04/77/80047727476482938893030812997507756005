Term Rewriting Systems
J. W. Klop
1
Contents
1 Abstract Reduction Systems : : : : : : : : : : : : : : : : : : : : : 3
1.1 Basic notions : : : : : : : : : : : : : : : : : : : : : : : : : : 11
1.2 Disjoint sums of Term Rewriting Systems : : : : : : : : : : 18
1.3 A termination proof technique : : : : : : : : : : : : : : : : 28
1.4 Completion of equational specications : : : : : : : : : : : : 39
1.5 An abstract formulation of completion : : : : : : : : : : : : 54
1.6 Unication : : : : : : : : : : : : : : : : : : : : : : : : : : : 61
2 Orthogonal Term Rewriting Systems : : : : : : : : : : : : : : : : 68
2.1 Basic theory of orthogonal TRS's : : : : : : : : : : : : : : : 69
2.2 Reduction strategies for orthogonal TRS's : : : : : : : : : : 76
2.3 Sequential orthogonal Term Rewriting Systems : : : : : : : 84
3 Conditional Term Rewriting Systems : : : : : : : : : : : : : : : : 98
4 References : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 107
Abstract
Term Rewriting Systems play an important role in various areas, such as
abstract data type specications, implementations of functional program-
ming languages and automated deduction. In this chapter we introduce
several of the basic concepts and facts for TRS's. Specically, we discuss
Abstract Reduction Systems; general Term Rewriting Systems including
an account of Knuth-Bendix completion and (E-)unication; orthogonal
TRS's and reduction strategies; strongly sequential orthogonal TRS's. The
paper concludes with a discussion of conditional term rewriting systems.
The emphasis throughout the chapter is on providing information of a syn-
tactic nature.
1
Research partially supported by ESPRIT project 432: Meteor (until Sept. 1989)
and ESPRIT BRA projects 3020: Integration and 3074: Semagraph (since July 1989).
1
2 J. W. Klop
Introduction
The concept of a Term Rewriting System (TRS) is paradigmatic for the
study of computational procedures. Already half a century ago, the -
calculus, probably the most well-known Term Rewriting System, played a
crucial role in mathematical logic with respect to formalizing the notion of
computability; much later the same TRS gured in the fundamental work
of Scott, Plotkin and others leading to a break-through in the denotational
semantics of programming languages. More recently, the related system of
Combinatory Logic was shown to be a very fruitful tool for the implemen-
tation of functional languages. Even more recently another related family
of TRS's, that of Categorical Combinatory Logic, has emerged, yielding a
remarkable connection between concepts from category theory and elemen-
tary steps in machine computations.
Term rewriting systems are attractive because of their simple syntax
and semantics|at least those TRS's that do not involve bound variables
such as -calculus, but involve the rewriting of terms from a rst order
language. This simplicity facilitates a satisfactory mathematical analysis.
On the other hand they provide a natural medium for implementing com-
putations, and in principle even for parallel computations. This feature
makes TRS's interesting for the design of parallel reduction machines.
Another eld where TRS's play a fundamental role concerns the anal-
ysis and implementation of abstract data type specications (consistency
properties, computability theory, decidability of word problems, theorem
proving).
The aim of the present paper is to give an introduction to several key
concepts in the theory of term rewriting, providing where possible some
of the details. At various places some `exercises' are included. These con-
tain additional information for which proofs are relatively easy; they are
not primarily meant to have an educational purpose, if only because the
distribution of the exercises is not very uniform.
The present introduction starts at a level of `rewriting' which is as
abstract as possible and proceeds by considering term rewriting systems
which have ever more `structure'. Thus we start with Abstract Reduction
Systems, which are no more than sets equipped with some binary (`rewrite')
relations. A number of basic properties and facts can already be stated on
this level.
Subsequently, the abstract reductions are specialized to reductions (re-
writings) of terms. For such general Term Rewriting Systems a key issue is
to prove the termination property; we present one of the major and most
powerful termination proof methods, recursive path orderings, in a new for-
mulation designed to facilitate human understanding (rather than practical
Term Rewriting Systems 3
implementation). Proving termination is of great importance in the area
of Knuth-Bendix completions. Here one is concerned, given an equational
specication, to construct a TRS which is both conuent and terminat-
ing and which proves the same equations as the original specication. If
the construction is successful, it yields a positive solution to the validity
problem of the original equational specication. (Nowadays there are also
several other applications of Knuth-Bendix-like completion methods, such
as `inductionless induction' and `computing with equations'. For a survey
of such applications we refer to Dershowitz & Jouannaud [90].)
Also in Chapter 1, we explain the basic ideas of Knuth-Bendix comple-
tion together with an interesting recent `abstract' approach of Bachmair,
Dershowitz & Hsiang [86] to prove the correctness of Knuth-Bendix com-
pletion algorithms. We also present an elegant unication algorithm, and
likewise for `E-unication'.
In Chapter 2 we impose more `structure' on TRS's, in the form of an
`orthogonality' requirement (non-ambiguity and left-linearity). For such
orthogonal TRS's a sizeable amount of theory has been developed, both
syntactically and semantically. Here we will almost exclusively be con-
cerned with the syntactical aspects; for semantical aspects we refer to
Boudol [85], Berry & Levy [79], Guessarian [81]. Basic theorems (conu-
ence, the Parallel Moves Lemma, Church's theorem, O'Donnell's theorem)
are presented, where possible with some proof sketch. Also in this sec-
tion we survey the most important facts concerning reduction strategies
for orthogonal TRS's, strategies aiming at nding normal forms whenever
possible. Chapter 2 concludes with an explanation of the beautiful theory
of Huet & Levy [79] of (strongly) sequential TRS's. Such TRS's possess a
`good' reduction strategy.
In the nal chapter (3) we consider TRS's with conditional rewrite rules.
Some important topics have not found their way into this introduction.
Most notable are: rewriting modulo a set of equations, proof-by-consistency
procedures, and graph rewriting. For information about the rst two we re-
fer to Bachmair [88] and Dershowitz & Jouannaud [90], for graph rewriting
one may consult Barendregt e.a. [87].
This chapter is an extension of the short survey/tutorial Klop [87]; also
most of the material in Klop [85] is included here.
1 Abstract Reduction Systems
Many of the basic denitions for and properties of TRS's (Term Rewriting
Systems) can be stated more abstractly, viz. for sets equipped with one
or more binary relations. As it is instructive to see which denitions and
properties depend on the term structure and which are more basic, we start
4 J. W. Klop
with a section about Abstract Reduction Systems. Moreover, the concepts
and properties of Abstract Reduction Systems also apply to other rewrite
systems than TRS's, such as string rewrite systems (Thue systems), tree
rewrite systems, graph grammars. First we present a sequence of simple
denitions.
Denition 1.0.1.
1. An Abstract Reduction System (ARS) is a structure A = hA; (!

)
2I
i
consisting of a set A and a sequence of binary relations !

on A,
also called reduction or rewrite relations. Sometimes we will refer to
!

as . In the case of just one reduction relation, we also use !
without more. (An ARS with just one reduction relation is called
`replacement system' in Staples [75], and a `transformation system'
in Jantzen [88].) If for a; b 2 A we have (a; b) 2!

, we write a!

b
and call b a one-step (-)reduct of a.
2. The transitive reexive closure of !

is written as 

. (More cus-
tomary is the notation!


, but we prefer the double arrow notation
as we nd it more convenient in diagrams.) So a 

b if there is a
possibly empty, nite sequence of `reduction steps' a  a
0
!

a
1
!

   !

a
n
 b. Here  denotes identity of elements of A. The
element b is called an (-)reduct of a. The equivalence relation gen-
erated by !

is =

, also called the convertibility relation generated
by !

. The reexive closure of !

is !


. The transitive closure of
!

is !
+

. The converse relation of !

is  

or !
 1

. The union
!

[ !

is denoted by !

: The composition!

 !

is dened
by: a!

 !

b if a!

c!

b for some c 2 A:
3. If ;  are reduction relations on A, we say that  commutes weakly
with  if the diagram of Figure 1.1a holds, i.e. if 8a; b; c 2 A 9d 2
A (c  

a !

b ) c 

d 

b), or in a shorter notation:  

 !

 

 

: Further,  commutes with  if 

and 

commute weakly. (This terminology diers from that of Bachmair &
Dershowitz [86], where  commutes with  if 
 1
   
 1
 :)
4. The reduction relation! is called weakly conuent or weakly Church-
Rosser (WCR) if it is weakly self-commuting (see Figure 1.1b), i.e. if
8a; b; c 2 A 9d 2 A (c  a ! b ) c  d  b): (The property WCR
is also often called `local conuence', e.g. in Jantzen [88].)
5. ! is subcommutative (notation WCR
1
) if the diagram in Figure 1.1c
holds, i.e. if 8a; b; c 2 A 9d 2 A (c a! b) c!

d 

b):
6. ! is conuent or is Church-Rosser, has the Church-Rosser property
(CR) if it is self-commuting (see Figure 1.1d), i.e. 8a; b; c 2 A 9d 2
A (c a b) c d b): Sometimes (6) is called `conuent' and
the situation as in Proposition 1.0.2(6) `Church-Rosser'.
Term Rewriting Systems 5
Proposition 1.0.2. The following are equivalent:
1. ! is conuent
2.  is weakly conuent
3.  is self-commuting
4.  is subcommutative
5. the diagram in Figure 1.1e holds, i.e.
8a; b; c 2 A 9d 2 A (c a b) c d b)
6. 8a; b 2 A 9c 2 A (a = b) a  c b) (Here `=' is the convertibility
relation generated by !. See diagram in Figure 1.1f.)
Figure 1.1
Denition 1.0.3. Let A = hA;!i be an ARS.
1. We say that a 2 A is a normal form if there is no b 2 A such that
a ! b. Further, b 2 A has a normal form if b  a for some normal
form a 2 A:
2. The reduction relation! is weakly normalizing (WN) if every a 2 A
has a normal form. In this case we also say that A is WN.
6 J. W. Klop
3. A (or !) is strongly normalizing (SN) if every reduction sequence
a
0
! a
1
!    eventually must terminate. (Other terminology: ! is
terminating, or noetherian.) If the converse reduction relation  is
SN, we say that A (or !) is SN
 1
.
4. A (or!) has the unique normal form property (UN) if 8a; b 2 A(a = b
& a; b are normal forms ) a  b).
5. A (or !) has the normal form property (NF) if 8a; b 2 A(a is normal
form & a = b) b a):
6. A (or !) is inductive (Ind) if for every reduction sequence (possibly
innite) a
0
! a
1
!    there is an a 2 A such that a
n
 a for all n.
7. A (or !) is increasing (Inc) if there is a map j j: A ! N such that
8a; b 2 A (a! b ) j a j< j b j). Here N is the set of natural numbers
with the usual ordering < :
8. A (or !) is nitely branching (FB) if for all a 2 A the set of one
step reducts of a, fb 2 A j a! bg, is nite. If the converse reduction
relation  is FB, we say that A (or !) is FB
 1
. (In Huet [80], FB
is called `locally nite'.)
Exercise 1.0.4. Dene: A (or !) has the unique normal form property with
respect to reduction (UN
!
) if 8a; b; c 2 A(a b & a c & b; c are normal forms
) b  c). Show that UN ) UN
!
, but not conversely.
An ARS which is conuent and terminating (CR & SN) is also called
complete (other terminology: `canonical' or `uniquely terminating').
Before exhibiting several facts about all these notions, let us rst intro-
duce some more concepts.
Denition 1.0.5. Let A = hA;!

i and B = hB;!

i be two ARS's.
Then A is a sub-ARS of B, notation A  B, if:
1. A  B
2.  is the restriction of  to A, i.e. 8a; a
0
2 A (a!

a
0
, a!

a
0
)
3. A is closed under , i.e. 8a 2 A (a!

b) b 2 A):
The ARS B is also called an extension of A.
Note that all properties introduced so far (CR, WCR, WCR
1
, WN,
SN, UN, NF, Ind, Inc, FB) are preserved downwards: e.g. if A  B and B
is CR, then also A is so.
Of particular interest is the sub-ARS determined by an element a in an
ARS.
Denition 1.0.6. Let A = hA;!i be an ARS, and a 2 A. Then G(a),
the reduction graph of a, is the smallest sub-ARS of A containing a. So
G(a) has as elements all reducts of a (including a itself) and is structured
Term Rewriting Systems 7
by the relation ! restricted to this set of reducts.
We will now collect in one theorem several implications between the var-
ious properties of ARS's. The rst part (1) is actually the main motivation
for the concept of conuence: it guarantees unique normal forms, which
is of course a desirable state of aairs in (implementations of) algebraic
data type specications. Apart from the fundamental implication CR )
UN, the most important fact is (2), also known as Newman's Lemma. The
property CP (`conality property') is dened in Exercise 1.0.8(13) below.
Theorem 1.0.7.
1. CR ) NF ) UN
2. SN & WCR ) CR (Newman's Lemma)
3. UN & WN ) CR
4. UN & WN ) Ind
5. Ind & Inc ) SN
6. WCR & WN & Inc ) SN
7. CR , CP for countable ARS's.
Most of the proofs of (1)-(7) are easy. For Newman's Lemma a short
proof is given in Huet [80]; an alternative proof, illustrating the notion of
`proof ordering', is given in Section 1.5 (Exercise 1.5.4). Proposition (5)
is from Nederpelt [73]; (6) is proved in Klop [80a]; for (7) see Exercise
1.0.8(13) below. The propositions in the statement of the theorem (and
some more|for these see Exercises 1.0.8) are displayed also in Figure 1.2;
here it is important whether an implication arrow points to the conjunction
sign &, or to one of the conjuncts. Likewise for the tail of an implication
arrow. (E.g. UN & WN ) Ind, SN & WCR ) UN & WN, Inc ) SN
 1
,
FB
 1
& SN
 1
) Inc, CR ) UN but not CR ) UN & WN.)
It does not seem possible to reverse any of the arrows in this diagram
of implications. An instructive counterexample to WCR) CR is the TRS
in Figure 1.3 (given by R. Hindley, see also Huet [80]).
There are several other facts about ARS's which often are very helpful
e.g. in proving properties of algebraic data type specications. We present
them in the form of the following series of Exercises 1.0.8. For an under-
standing of the sequel these additional facts are not necessary. Some proofs
require the notion of `multiset ordering', explained in Exercise 1.3.15.
Exercises 1.0.8.
1. (Rosen [73]) If hA;!
1
;!
2
i is an ARS such that 
1
=
2
and !
1
is sub-
commutative, then !
2
is conuent.
2. (Hindley [64]) Let hA; (!

)
2I
i be an ARS such that for all ; 2 I;!

commutes with !

. (In particular, !

commutes with itself.) Then the
8 J. W. Klop
Figure 1.2
Figure 1.3
union != U
2I
!

is conuent. (This proposition is sometimes referred
to as the Lemma of Hindley-Rosen; see e.g. Barendregt [81], Proposition
3.3.5.)
3. (Hindley [64]) Let hA;!
1
;!
2
i be an ARS. Suppose: 8a; b; c 2 A 9d 2
A (a !
1
b & a !
2
c ) b 
2
d & c !

1
d). (See Figure 1.4a.) Then
!
1
;!
2
commute.
4. (Staples [75]) Let hA;!
1
;!
2
i be an ARS. Suppose: 8a; b; c 2 A 9d 2
A (a !
1
b & a 
2
c ) b 
2
d & c 
1
d). (See Figure 1.4b.) Then
!
1
;!
2
commute.
Term Rewriting Systems 9
5. (Rosen [73]) Let hA;!
1
;!
2
i be an ARS. DEFINITION: !
1
requests!
2
if 8a; b; c 2 A 9d; e 2 A (a
1
b & a
2
c) b
2
d & c
1
e
2
d): (See
Figure 1.4c.) To prove: if !
1
;!
2
are conuent and if !
1
requests !
2
,
then !
12
is conuent.
6. (Rosen [73]) Let hA;!
1
;!
2
i be an ARS such that !
2
is conuent and
8a; b; c 2 A 9d; e 2 A (a 
1
b & a !
2
c ) b 
2
d & c 
1
e 
2
d). (See
Figure 1.4d.) Then !
1
requests !
2
:
7. (Staples [75]) Let hA;!
1
;!
2
i be an ARS such that !
1
requests !
2
and
!
2
is conuent. Let !
3
be the composition of 
1
and 
2
, i.e. a !
3
b
i 9c a 
1
c
2
b. Suppose moreover that 8a; b; c 2 A 9d 2 A (a 
1
b &
a
1
c) b!
3
d & c!
3
d). Then !
12
is conuent.
8. (Staples [75]) DEFINITION: In the ARS hA;!
1
;!
2
i the reduction re-
lation !
2
is called a renement of !
1
if !
1

2
. If moreover 8a; b 2
A 9c 2 A (a 
2
b ) a 
1
c & b 
1
c), then !
2
is a compatible rene-
ment of !
1
: Let in the ARS hA;!
1
;!
2
i the reduction relation !
2
be
a renement of !
1
. Prove that !
2
is a compatible renement of !
1
i
8a; b; c 2 A 9d 2 A (a!
2
b & b
1
c) c
1
d & a
1
d):
9. (Staples [75]) Let hA;!
1
;!
2
i be an ARS where !
2
is a compatible re-
nement of !
1
. Then: !
1
is conuent i !
2
is conuent.
10. (Huet [80]) DEFINITION: Let hA;!i be an ARS. Then! is called strongly
conuent (see Figure 1.4e) if 8a; b; c 2 A 9d 2 A (a ! b & a! c) b  d
& c!

d). Prove that strong conuence implies conuence.
11. Let hA; (!

)
2I
i be an ARS such that for all ; 2 I;!

commutes
weakly with !

. DEFINITION: (a) !

is relatively terminating if no
reduction a
0
! a
1
! a
2
! : : : (where != U
2I
!

) contains innitely
many ?steps. (b)!

has splitting eect if there are a; b; c;2 A such that
for every d 2 A and every  2 I with a !

b; a !

c; c 

d; b 

d,
the reduction b 

d consists of more than one step. To prove: if every
!

( 2 I) which has splitting eect is relatively terminating, then ! is
conuent. (Note that this is equivalent to Newman's Lemma.)
12. (Winkler & Buchberger [83]) Let hA;!;>i be an ARS where the `reduc-
tion' relation > is a partial order and SN. (So > is well-founded.) Sup-
pose a ! b implies a > b. Then the following are equivalent: (a) !
is conuent, (b) whenever a ! b and a ! c, there is a !-conversion
b  d
1
$ d
2
$ : : : $ d
n
 c (for some n  1) between b; c such that
a > d
i
(i = 1; : : : ; n). Here each $ is ! or  . (See Figure 1.4f.) (Note
that this strengthens Newman's Lemma.)
13. (Klop [80a]) Let A = hA;!i be an ARS. Let B  A. Then B is conal in
A if 8a 2 A 9b 2 B a  b. Furthermore, A is said to have the conality
property (CP) if in every reduction graph G(a); a 2 A, there is a (possibly
innite) reduction sequence a  a
0
! a
1
! : : : such that fa
n
j n  0g is
conal in G(a). Then, for countable ARS's: A is CR , A has CP.
14. Let A = hA;!i be an ARS. Dene: A is consistent if not every pair
of elements in A is convertible. Note that if A is conuent and has two
dierent normal forms, A is consistent. Further, let A = hA;!

i;B =
10 J. W. Klop
Figure 1.4
hB;!

i be ARS's such that A  B. Then we dene: B is a conservative
extension of A if 8a; a
0
2 A (a =

a
0
, a =

a
0
). Note that a conservative
extension of a consistent ARS is again consistent. Further, note that a
conuent extension B of A is conservative.
15. (Newman [42]) Let WCR
1
be the following property of ARS's hA;!i :
8a; b; c 2 A 9d 2 A (c  a ! b & b 6 c ) c ! d  b). (See Figure
1.5a.) Prove that WCR
1
& WN ) SN, and give a counterexample to the
implication WCR
1
& WN ) SN.
16. (Bachmair & Dershowitz [86]) Let hA;!

;!

i be an ARS such that
8a; b; c 2 A 9d 2 A (a !

b !

c ) a !

d 

c). (In the termi-
nology of Bachmair & Dershowitz [86]:  quasi-commutes over .) (See
Figure 1.5b.) Prove that = is SN i  is SN. (For the denition of =,
see Exercise 1.0.8(19) below.)
17. (Klop [80a]) Let A = hA;!

i and B = hB;!

i be ARS's. Let  : A! B
and  : B ! A be maps such that
(a) ((a)) = a for all a 2 A;
(b) 8a; a
0
2 A8b 2 B 9b
0
2 B (b !

a !

a
0
) b !

b
0
!

a
0
)
(Reductions in A can be `lifted' to B.) See Figure 1.5c.
Prove that B is SN implies that A is SN.
18. (Geser [90]) Let hA;!

;!

i be an ARS with two reduction relations ;
such that  [  is transitive. Then:  [  is SN ,  is SN and  is SN.
(Hint: use the following innite version of Ramsey's Theorem, in which
for a set S the notation [S]
2
is used to denote the set ffa; bg j a; b 2 S &
a 6= bg of two-element subsets of S. Furthermore, N is the set of natural
numbers. THEOREM: Let [N ]
2
be partitioned into subsets X and Y. Then
Term Rewriting Systems 11
Figure 1.5
there is an innite A  N such that either [A]
2
 X or [A]
2
 Y .)
19. (Geser [90]) This exercise reformulates and slightly generalizes Exercise
1.0.8(11). Let hA;!

;!

i be an ARS. DEFINITION: = (\ modulo
") is the reduction relation 



. So a!
=
b i there are c; d such that
a 

c !

d 

b: Note that  is relatively terminating (in the sense
of Exercise 1.0.8(11)) i = is SN. DEFINITION:  is called nonsplitting
(with respect to [) if 8a; b; c 2 A9d 2 A(a!

b & a!
[
c) c
[
d & b (!
[
)

d): Prove: If = is SN,  is WCR, and  is non-splitting,
then  [  is conuent.
1.1 Basic notions
Syntax of Term Rewriting Systems
A Term Rewriting System (TRS) is a pair (; R) of an alphabet or signature
 and a set of reduction rules (rewrite rules) R. The alphabet  consists
of:
1. a countably innite set of variables x
1
; x
2
; x
3
; : : : also denoted as
x; y; z; x
0
; y
0
; : : :
2. a non-empty set of function symbols or operator symbols F;G; : : : ;
each equipped with an `arity' (a natural number), i.e. the number of
`arguments' it is supposed to have. We not only (may) have unary,
binary, ternary, etc., function symbols, but also 0-ary: these are also
called constant symbols.
The set of terms (or expressions) `over'  is Ter() and is dened induc-
tively:
1. x; y; z; : : : 2 Ter();
2. if F is an n-ary function symbol and t
1
; : : : ; t
n
2 Ter() (n  0),
then F (t
1
; : : : ; t
n
) 2 Ter(). The t
i
(i = 1; : : : ; n) are the arguments
of the last term.
Terms not containing a variable are called ground terms (also: closed
terms), and Ter
0
() is the set of ground terms. Terms in which no variable
occurs twice or more, are called linear.
12 J. W. Klop
Contexts are `terms' containing one occurrence of a special symbol 2,
denoting an empty place. A context is generally denoted by C[ ]. If t 2
Ter() and t is substituted in 2 , the result is C[t] 2 Ter(); t is said to be
a subterm of C[t], notation t  C[t]. Since 2 is itself a context, the trivial
context, we also have t  t. Often this notion of subterm is not precise
enough, and we have to distinguish occurrences of subterms (or symbols) in
a term; it is easy to dene the notion of occurrence formally, using sequence
numbers denoting a `position' in the term, but here we will be satised with
a more informal treatment.
Example 1.1.1. Let  = fA;M; S; 0g where the arities are 2,2,1,0 re-
spectively. Then A(M (x; y); y) is a (non-linear) term, A(M (x; y); z) is a
linear term, A(M (S(0); 0); S(0)) is a ground term, A(M (2; 0); S(0)) is a
context, S(0) is a subterm of A(M (S(0); 0); S(0)) having two occurrences:
A(M (S(0); 0);S(0)).
A substitution  is a map from Ter() to Ter() which satises
(F (t
1
; : : : ; t
n
)) = F ((t
1
); : : : ; (t
n
)) for every n-ary function symbol F
(here n  0). So,  is determined by its restriction to the set of variables.
We also write t

instead of (t):
A reduction rule (or rewrite rule) is a pair (t; s) of terms 2 Ter(). It
will be written as t ! s. Often a reduction rule will get a name, e.g. r,
and we write r : t! s. Two conditions will be imposed:
1. the LHS (left-hand side) t is not a variable,
2. the variables in the right-hand side s are already contained in t.
A reduction rule r : t ! s determines a set of rewrites t

!
r
s

for all
substitutions . The LHS t

is called a redex (from `reducible expression'),
more precisely an r-redex. A redex t

may be replaced by its `contractum'
s

inside a context C[ ]; this gives rise to reduction steps (or one-step
rewritings)
C[t

]!
r
C[s

]:
We call !
r
the one-step reduction relation generated by r. Concatenating
reduction steps we have (possibly innite) reduction sequences t
0
! t
1
!
t
2
!    or reductions for short. If t
0
!    ! t
n
we also write t
0
 t
n
,
and t
n
is a reduct of t
0
, in accordance with the notations and concepts
introduced in Section 1.0.
Example 1.1.2. Consider  as in Example 1.1.1. Let (; R) be the TRS
(specifying the natural numbers with addition, multiplication, successor
and zero) with reduction rules R given in Table 1.1.
Now M (S(S(0)); S(S(0)))  S(S(S(S(0)))), since we have the following
reduction:
Term Rewriting Systems 13
r
1
A(x; 0) ! x
r
2
A(x; S(y)) ! S(A(x; y))
r
3
M (x; 0) ! 0
r
4
M (x; S(y)) ! A(M (x; y); x)
Table 1.1
M(S(S(0));S(S(0))) ! A(M(S(S(0));S(0));S(S(0)))
! S(A(M(S(S(0));S(0));S(0)))
! S(S(A(M(S(S(0));S(0));0)))
! S(S(M(S(S(0));S(0))))
! S(S(A(M(S(S(0));0); S(S(0)))))
! S(S(A(0;S(S(0)))))
! S(S(S(A(0;S(0)))))
! S(S(S(S(A(0;0)))))
! S(S(S(S(0)))):
Here in each step the bold-face redex is rewritten. Note that this is not the
only reduction from M (S(S(0)); S(S(0))) to S(S(S(S(0)))).
Obviously, for each TRS (; R) there is a corresponding ARS, namely
(Ter(); (!
r
)
r2R
). Here we have to be careful: it maymake a big dierence
whether one discusses the TRS (; R) consisting of all terms, or the TRS
restricted to the ground terms (see the next example). We will adopt
the convention that (; R) has as corresponding ARS the one mentioned
already, and we write (; R)
0
if the ARS (Ter
0
(); (!
r
)
r2R
) is meant. Via
the associated ARS, all notions considered in Section 1.0 (CR, UN, SN,
. . . ) carry over to TRS's.
Example 1.1.3. Let (; R) be the TRS of Example 1.1.2 and consider
(; R
0
) where R
0
= R [ fA(x; y) ! A(y; x)g; so the extra rule expresses
commutativity of addition. Now (; R
0
) is not WN: the term A(x; y) has no
normal form. However, (; R
0
)
0
(the restriction to ground terms) is WN.
Whereas (; R)
0
is SN, (; R
0
)
0
is no longer so, as witnessed by the innite
reductions possible in the reduction graph in Figure 1.6. The `bottom'
term in that reduction graph is a normal form.
Many-sorted Term Rewriting Systems
TRS's (; R) as we just have dened are sometimes called homogeneous
(Ganzinger & Giegerich [87]), as they correspond to algebraic data type
specications (by replacing `!' by `=' in R) where the signature  has
14 J. W. Klop
Figure 1.6
just one sort (which therefore was not mentioned).
It is straightforward to extend our previous denitions to the hetero-
geneous or many-sorted case. The denition of term formation is as usual
in many-sorted abstract data type specications, and is left to the reader.
We will stick to the homogeneous case, but note that `everything' extends
at once to the heterogeneous case, at least with respect to the theory in
this chapter; of course, the extension to the heterogeneous case presents
a whole area of new features and problems (see e.g. Ehrig & Mahr [85],
Drosten [89] for a treatment of many-sorted specications and rewriting).
Semi-Thue systems
Semi-Thue Systems (STS's), as dened in Jantzen [88], can be `viewed' in
two ways as TRS's. We demonstrate this by the following:
1. Let T = f(aba; bab)g be a one-rule STS. Then T corresponds to the
TRS R with unary function symbols a; b and a constant o, and the
reduction rule a(b(a(x))) ! b(a(b(x))). Now a reduction step in
T , e.g.: bbabaaa ! bbbabaa, translates in R to the reduction step
b(b(a(b(a(a(a(o))))))) ! b(b(b(a(b(a(a(o))))))). It is easy to see that
this translation gives an `isomorphism' between T and R (or more
precisely (R)
0
, the restriction to ground terms).
2. The second way to let a STS correspond to a TRS is by introducing
an associative concatenation operator, and letting the symbols of the
STS correspond to constant symbols in the TRS. In fact, a `natu-
ral' correspondence in this way requires that we introduce equational
TRS's, which we will not do here. (See e.g. Bachmair & Plaisted [85]
or Plaisted [85].)
Term Rewriting Systems 15
Applicative Term Rewriting Systems
In some important TRS's there is a very special binary operator, called
application (Ap). E.g. Combinatory Logic (CL), based on S;K; I, has the
rewrite rules as in Table 1.2. Here S;K; I are constants. Often one uses
Ap(Ap(Ap(S; x); y); z) ! Ap(Ap(x; z); Ap(y; z))
Ap(Ap(K;x); y) ! x
Ap(I; x) ! x
Table 1.2
the inx notation (t  s) instead of Ap(t; s), in which case the rewrite rules
of CL read as follows:
((S  x)  y)  z ! (x  z)  (y  z)
(K  x)  y ! x
I  x ! x
Table 1.3
As in ordinary algebra, the dot is mostly suppressed; and a further no-
tational simplication is that many pairs of brackets are dropped in the
convention of association to the left. That is, one restores the missing
brackets choosing in each step of the restoration the leftmost possibility.
Thus the three rules become:
Sxyz ! xz(yz)
Kxy ! x
Ix ! x
Table 1.4
Note that xz(yz) restores to (xz)(yz), not to x(z(yz)). Likewise Kxy
restores to (Kx)y, not K(xy). Of course not all bracket pairs can be
dropped: xzyz is when restored ((xz)y)z, which is quite dierent from
xz(yz). Note that e.g. SIx does not contain a redex Ix.
It is a convenient ction to view the S;K; I in the last three equations
as \operators with variable arity" or varyadic operators, since they may
be followed by an arbitrary number of arguments t
1
; : : : ; t
n
(n  0). But it
needs, in the case of S, at least three arguments to use the rewrite rule for
16 J. W. Klop
S; e.g.: St
1
t
2
t
3
t
4
t
5
t
6
! t
1
t
3
(t
2
t
3
)t
4
t
5
t
6
:
Example 1.1.4. We have SII(SII) ! I(SII)(I(SII)) ! SII(I(SII)) !
SII(SII). The term SII(SII) has manymore reductions, which constitute
an interesting reduction graph (see Figure 1.7).
Figure 1.7
The TRS CL has `universal computational power': every (partial) re-
cursive function on the natural numbers can be expressed in CL. This
feature is used in Turner [79], where CL is used to implement functional
programming languages. Actually, an extension of CL is used there, called
SKIM (for S,K,I-Machine); it is also an applicative TRS (see Table 1.5).
Note that this TRS has innitely many constants: apart from the constants
S;K; : : : ; eq there is a constant n for each n 2 N. There are also innitely
many reduction rules, because the last four rules are actually rule schemes;
e.g. plus n m ! n+ m stands for all reduction rules like plus 0 0 ! 0,
plus 0 1 ! 1 ; : : : ; plus 37 63 ! 100 ; : : : . In fact, the extra constants
in SKIM are there for reasons of ecient implementation; they can all be
dened using only S and K. E.g. dening B as S(KS)K we have:
Bxyz  S(KS)Kxyz ! KSx(Kx)yz
! S(Kx)yz
! Kxz(yz)
! x(yz)
Term Rewriting Systems 17
Sxyz ! xz(yz)
Kxy ! x
Ix ! x
Cxyz ! xzy
Bxyz ! x(yz)
Y x ! x(Y x)
Uz(Pxy) ! zxy
cond true xy ! x
cond false xy ! y
plus n m ! n+m
times n m ! n m
eq n n ! true
eq n m ! false if n 6= m
Table 1.5
as we should have. Likewise, dening C as S(BBS)(KK), we have Cxyz 
xzy as the reader may check. For the other denitions one may consult
Barendregt [81] or Hindley & Seldin [86].
It is harmless to mix the applicative notation with the usual one, as in
CL with test for syntactical equality in Table 1.6.
Sxyz ! xz(yz)
Kxy ! x
Ix ! x
D(x; x) ! E
Table 1.6
However, some care should be taken: consider the TRS in Table 1.7.
Sxyz ! xz(yz)
Kxy ! x
Ix ! x
Dxx ! E
Table 1.7
where D is now a constant (instead of a binary operator) subject to the
rewrite rule, in full notation, Ap(Ap(D;x); x)! E. These two TRS's have
18 J. W. Klop
very dierent properties, as we shall see later (the rst TRS is conuent,
the second is not).
Another interesting example of a TRS in such a mixed notation is Weak
Categorical Combinatory Logic, which plays an important role in imple-
mentations of functional languages (see Curien [86] and Hardin [89]):
Id x ! x
(x  y)z ! x(yz)
Fst (x; y) ! x
Snd (x; y) ! y
hx; yiz ! (xz; yz)
App (x; y) ! xy
(x)yz ! x(y; z)
Table 1.8
Here Id, Fst, Snd, App are constants, ; h; i and ( , ) are binary function
symbols and  is a unary function symbol. Note that Fst, Snd are not
binary symbols and that App is not the `underlying' application operator
which was called in CL above Ap.
1.2 Disjoint sums of Term Rewriting Systems
In view of the need for modularisation of abstract data type specications,
it would be very helpful if some properties of a TRS could be inferred from
their validity for `parts' of that TRS. The simplest possible denition of
`parts' is that obtained by the concept of `disjoint sum' of TRS's:
Denition 1.2.1. Let R
1
; R
2
be TRS's. Then the disjoint sum R
1
 R
2
of R
1
; R
2
is the TRS obtained by taking the disjoint union of R
1
and R
2
.
That is, if the alphabets of R
1
; R
2
are disjoint (R
1
; R
2
have no function or
constant symbols in common), then the disjoint sum is the ordinary union;
otherwise we take renamed copies R
0
1
; R
0
2
of R
1
; R
2
such that these copies
have disjoint alphabets and dene R
1
R
2
to be the union of these copies.
We have the following useful fact from Toyama [87b]:
Theorem 1.2.2. R
1
R
2
is conuent i R
1
and R
2
are conuent.
So, conuence is a `modular' property. One might think that the same is
true for termination (SN), but Toyama [87a] gives a simple counterexample:
take
R
1
= ff(0; 1; x)! f(x; x; x)g
R
2
= for(x; y)! x; or(x; y)! yg
Term Rewriting Systems 19
then R
1
; R
2
are both SN, but R
1
 R
2
is not, since there is the innite
reduction:
f(or(0; 1); or(0; 1); or(0; 1)) ! f(0; or(0; 1); or(0; 1))
! f(0; 1; or(0; 1))
! f(or(0; 1); or(0; 1); or(0; 1))
!   
In this counterexample R
2
is not conuent and thus one may conjecture
that `conuent and terminating' (or CR & SN, or complete) is a modular
property (i.e. R
1
 R
2
is complete i R
1
; R
2
are so). Again this is not
the case, as a counterexample given by Barendregt and Klop (adapted by
Toyama, see Toyama [87a]) shows: R
1
has the eleven rules
F (4; 5; 6; x) ! F (x; x; x; x)
F (x; y; z; w) ! 7
and R
2
has the three rules
G(x; x; y) ! x
G(x; y; x) ! x
G(y; x; x) ! x:
(Similar counterexamples with the additional property of being `reduced' or
`irreducible'|meaning that both sides of every rule are normal forms with
respect to the other rules (see Denition 1.4.18 below for a more accurate
denition)|are given in Toyama [87a] and Ganzinger & Giegerich [87].)
Now R
1
and R
2
are both complete, but R
1
 R
2
is not:
F (G(1; 2; 3); G(1; 2; 3); G(1; 2; 3); G(1; 2; 3)) 
F (G(4; 4; 3); G(5; 2; 5); G(1; 6; 6); G(1; 2; 3)) 
F ( 4; 5; 6; G(1; 2; 3)) !
F (G(1; 2; 3); G(1; 2; 3); G(1; 2; 3); G(1; 2; 3)):
Exercise 1.2.3. A simpler counterexample is given in Drosten [89]. Slightly
adapted it reads:
20 J. W. Klop
R
1
F (0; 1; x) ! F (x;x; x)
F (x;y; z) ! 2
0 ! 2
1 ! 2
and
R
2
D(x;y; y) ! x
D(x;x; y) ! y:
Now R
1
;R
2
are complete; however, their disjoint sum is not. To see this, consider
the term F (M;M;M) where M  D(0; 1; 1) and show that F (M;M;M) has a
cyclic reduction.
The last counterexamples involve a non-leftlinear TRS. This is essential,
as the following theorem indicates. First we dene this concept:
Denition 1.2.4.
1. A reduction rule t! s is left-linear if t is a linear term.
2. A TRS is left-linear if all its reduction rules are left-linear.
Theorem 1.2.5. (Toyama, Klop & Barendregt [89]) Let R
1
; R
2
be left-
linear TRS's. Then: R
1
 R
2
is complete i R
1
and R
2
are complete.
Some useful information concerning the inference of SN for R
1
R
2
from
the SN property for R
1
and R
2
separately is given in Rusinowitch [87a] and
Middeldorp [89b], in terms of `collapsing' and `duplicating' rewrite rules.
Denition 1.2.6.
1. A rewrite rule t! s is a collapsing rule (c-rule) if s is a variable.
2. A rewrite rule t! s is a duplicating rule (d-rule) if some variable has
more occurrences in s than it has in t.
Example 1.2.7. F (x; x)! G(x; x) is not a d-rule, but F (x; x)! H(x; x; x)
is. Also P (x)! G(x; x) is a d-rule.
Theorem 1.2.8. Let R
1
and R
2
be TRS's both with the property SN.
1. If neither R
1
nor R
2
contain c-rules, R
1
 R
2
is SN.
2. If neither R
1
nor R
2
contain d-rules, R
1
 R
2
is SN.
3. If one of the TRS's R
1
; R
2
contains neither c- nor d-rules, R
1
R
2
is
SN.
Statements (1) and (2) are proved in Rusinowitch [87a]; statement (3)
is proved in Middeldorp [89b].
Exercise 1.2.9. Prove that WN is a modular property.
Another useful fact, proved in Middeldorp [89a], is that UN is a modular
Term Rewriting Systems 21
property.
Theorem 1.2.10. R
1
R
2
is UN i R
1
and R
2
are so.
The proof of this theorem employs a lemma of independent interest; see
the proof sketch in the following exercises.
Exercises 1.2.11. (Middeldorp [90])
1. Let R be a TRS. For t 2 Ter(R), [t] denotes the equivalence class of t with
respect to convertibility in R: [t] = ft
0
j t =
R
t
0
g. Further, V (t) is the
set of variables occurring in t. EV (t) is the set of essential variables of t,
dened as: \
t
0
2[t]
V (t
0
):
2. Now let t(~x; ~y ) be a term with essential variables ~x = x
1
; : : : ; x
n
and
non-essential variables ~y = y
1
; : : : ; y
m
. Prove that for arbitrary terms
~s = s
1
; : : : ; s
m
we have t(~x;~s ) =
R
t(~x; ~y ).
3. Let R have the property UN (unique normal forms). Show that a normal
form has only essential variables.
4. Let R contain a ground term (i.e., R contains a constant symbol). Show
that every convertibility class [t] contains a term s having only essential
variables.
5. Let R have the property UN and contain a ground term. Show that there
is a choice function ' from f[t] j t 2 Ter(R)g to Ter(R), selecting from each
equivalence class [t] a term such that
(a) '([t]) 2 [t];
(b) if [t] contains a normal form t
0
, then ([t])  t
0
;
(c) '([t]) contains only essential variables.
6. LEMMA. Let R be a TRS with property UN and containing a ground term.
Then R can be extended to a conuent TRS R
0
with the same alphabet, the
same convertibility and the same normal forms.
Prove the lemma by considering R
0
, originating from R by adding the set
of reduction rules ft ! '([t]) j t 2 Ter(R) & t 6 '([t])g. (Note that the
t! '([t]) are added as reduction rules, not merely as reduction steps.)
7. LEMMA. Let R be a TRS with property UN. Then R can be extended to a
conuent TRS R
0
with the same convertibility and the same normal forms.
Prove the lemma as follows: in case R contains a constant, (6) applies; if
not, we add a constant C and a rule C ! C to yield R
00
. Now apply (6)
on R
00
.
Exercise 1.2.12. (Middeldorp [90]) Let R
1
;R
2
be disjoint TRS's, both
having the property UN. Show that R
1
 R
2
has property UN. (Proof sketch:
Use the previous exercise to extend R
i
to R
0
i
such that R
0
i
is conuent and has
the same convertibility and the same normal forms as R
i
(i = 1; 2). Moreover,
R
0
1
and R
0
2
can be taken disjoint from each other. By Toyama's theorem (1.2.2)
R
0
1
R
0
2
is conuent, and hence also UN. Now consider t; t
0
2 Ter(R
1
R
2
) such
that t; t
0
are normal forms and convertible in R
1
 R
2
. Obviously t; t
0
are also
convertible in R
0
1
 R
0
2
. The proof is concluded by showing that t; t
0
are also
22 J. W. Klop
normal forms in R
0
1
 R
0
2
. Hence t  t
0
, and R
1
R
2
is UN.)
Examples 1.2.13.
1. Consider CL  fD(x; x)! Eg, Combinatory Logic with binary test
for syntactic equality as in Table 1.6. Note that this is indeed a
disjoint sum. As we shall see in Section 2.1, CL is conuent. Trivially,
the one rule TRS fD(x; x) ! Eg is conuent. Hence, by Toyama's
theorem (1.2.2) the disjoint sum is conuent.
2. By contrast, the union CL [ fDxx ! Eg, Combinatory Logic with
`varyadic' test for syntactic equality as in Table 1.7, is not conuent.
(See Klop [80a].) Note that this combined TRS is merely a union
and not a disjoint sum, since CL and fDxx ! Eg have the func-
tion symbol Ap in common, even though hidden by the applicative
notation.
3. Another application of Toyama's theorem (1.2.2): let R consist of the
rules
if true then x else y ! x
if false then x else y ! y
if z then x else x ! x
(Here true; false are constants and if   then   else is a ternary
function symbol.) Then CL  R is conuent. Analogous to the
situation in (2), it is essential here that the if   then else construct
is a ternary operator. For the corresponding varyadic operator, the
resulting TRS would not be conuent.
Remark 1.2.14. A dierent approach to modularity is taken by Kurihara
& Kaji [88]. If R
1
and R
2
are disjoint TRS's, it is not allowed in that
approach to perform arbitrary interleaving of R
1
-steps and R
2
-steps; there
is the obligation to use as long as possible the rules of the same TRS.
Thus, if a rule of say R
1
is applied to term t, we must rst normalize t with
respect to R
1
, before applying rules of R
2
, and vice versa. Formally: dene
relations I
i
(i = 1; 2) for terms s; t 2 Ter(R
1
R
2
) by s I
i
t if s!
+
i
t and
t is a normal form of R
i
: Furthermore, I is the union of I
1
and I
2
. Now
Kurihara & Kaji [88] prove the following theorem:
1. Let R
1
; R
2
be disjoint TRS's. Then the relation I is terminating
(SN).
2. Let R
1
; R
2
be disjoint complete TRS's. Then the relation I is com-
plete.
Note that in (1) R
1
; R
2
need not be SN. We will sketch a proof of (2).
Assuming (1), part (2) of the theorem follows in some easy steps: First
observe that for I we have UN , CR, using UN & SN ) CR, a general
fact for ARS's. So to prove UN for I. Consider reductions s I    I t
1
Term Rewriting Systems 23
and s I    I t
2
, where t
1
; t
2
are I-normal forms. Because the original
reductions !
i
(i = 1; 2) in R
i
are SN, the terms t
1
; t
2
are normal forms
with respect to!, the union of!
i
(i = 1; 2). Hence by Toyama's theorem
1.2.2: t
1
 t
2
.
Exercises 1.2.15. (Middeldorp)
1. Show that the modularity of WN (Exercise 1.2.9) is a corollary of the
theorem in Remark 1.2.14.
2. Give an example of disjoint conuent TRS's such that I is not conuent.
(Solution by A. Middeldorp of this question in Kurihara & Kaji [88]: R
1
=
fF (x; x) ! F (x; x);A ! Bg; R
2
= fe(x) ! xg. Now F (e(A);A) I
1
F (e(B);B) I
2
F (B;B) and F (e(A);A) I
2
F (A;A): The terms F (A;A)
and F (B;B) are dierent I-normal forms.)
In this introduction to TRS's we will not consider termination proper-
ties of combined TRS's R
1
[ R
2
which are not disjoint sums. For results
in that area see Dershowitz [81, 87], Bachmair & Dershowitz [86], Toyama
[88] and, for heterogeneous TRS's, Ganzinger & Giegerich [87]. As to con-
uence properties of combined TRS's R
1
[R
2
which are not disjoint sums,
we include two facts in the following exercises, which require some concepts
from the sequel (namely, the notion of overlapping reduction rules, critical
pairs, and -calculus).
Exercise 1.2.16. (Raoult & Vuillemin [80], Toyama [88]) Let R
1
;R
2
be
TRS's. Dene: R
1
?R
2
(R
1
and R
2
are orthogonal to each other) if there is no
overlap between a rule of R
1
and one of R
2
. (There may be critical pairs due to
overlap between R
1
-rules, or between R
2
-rules.) Prove:
Theorem. Let R
1
;R
2
be left-linear and conuent TRS's such that R
1
?R
2
. Then
R
1
[R
2
is conuent.
(Proof sketch. Prove that in R
1
[ R
2
we have: (1) R
1
-reductions commute;
(2) R
2
-reductions commute; (3) R
1
-reductions commute with R
2
-reductions. In
order to prove (3), it is sucient to prove (4) as in Figure 1.8. To prove (4),
we need the left-linearity and the orthogonality requirements. The result now
follows by an application of the Hindley-Rosen lemma in Exercise 1.0.17(3). The
orthogonality is obviously necessary. Note that also the left-linearity cannot be
dropped|see Example 1.2.13(2).)
Figure 1.8
24 J. W. Klop
Exercises 1.2.17. Prove:
Theorem. Let R be a left-linear, conuent TRS. Let the signature of R be dis-
joint from that of -calculus, i.e. R does not contain the application operator.
Then  R, the disjoint sum of -calculus and R, is conuent.
Proof sketch: by the same strategy as used for Exercise 1.2.16.
Semantics of Term Rewriting Systems
Although we do not enter the subject of semantics of TRS's (see e.g. Boudol
[85], Guessarian [81]), there is one simple remark that should be made. It
concerns a semantical consideration that can be of great help in a proof of
UN or CR:
Theorem 1.2.18. Let A be an algebra `for' the TRS R such that for all
normal forms t; t
0
of R:
A  t = t
0
) t  t
0
:
Then R has the property UN (uniqueness of normal forms).
Here the phrase `A is an algebra for the TRS R' means that A has the
same signature as R, and that reduction in R is sound with respect to A,
i.e. t
R
s implies A  t = s. The terms t; s need not be ground terms.
More `semantic conuence tests' can be found in Plaisted [85], in the
setting of equational TRS's (not treated here).
Decidability of properties in Term Rewriting Systems
We adopt the restriction in this subsection to TRS's R with nite alphabet
and nitely many reduction rules. It is undecidable whether for such TRS's
the property conuence (CR) holds. (This is so both for R, the TRS of all
terms, and (R)
0
, the TRS restricted to ground terms.)
For ground TRS's, i.e. TRS's where in every rule t ! s the terms
t; s are ground terms (not to be confused with (R)
0
above), conuence is
decidable (Dauchet & Tison [84], Dauchet et al. [87], Oyamaguchi [87]).
For the termination property (SN) the situation is the same. It is
undecidable for general TRS's, even for TRS's with only one rule (see for
a proof Dauchet [89]). For ground TRS's termination is decidable (Huet &
Lankford [78]).
For particular TRS's it may also be undecidable whether two terms
are convertible, whether a term has a normal form, whether a term has
an innite reduction. A TRS where all these properties are undecidable is
Combinatory Logic (CL), in Table 1.4.
Exercise 1.2.19. If t 2 Ter(R), we say \t is SN" if t admits no innite
reduction t ! t
0
! t
00
!    . Prove: If R is not SN, then there is a redex of R
Term Rewriting Systems 25
which is not SN. In fact, then there is a redex whose contractum is not SN.
Exercises 1.2.20. (Huet & Lankford [78])
1. Let R be a ground TRS with nitely many rules, R = ft
i
! s
i
j i =
1; : : : ; ng. Prove: If R is not SN, then for some i 2 f1; : : : ; ng and some
context C[ ] we have t
i
!
+
C[t
i
]: (Hint: Use the previous exercise and use
induction on n.)
2. Conclude: SN is decidable for nite ground TRS's.
Exercise 1.2.21. (Undecidability of SN) In this exercise we will outline a
proof that SN is an undecidable property for (nite) TRS's, via a translation of
the problem to the (uniform) halting problem for Turing machines. The proof is
a slight simplication of the one in Huet & Lankford [78]. (However, that proof
employs only constants and unary function symbols; below we use also binary
function symbols.) We will not be concerned with the number of reduction rules
employed in the translation of a Turing machine to a TRS; for an undecidability
proof using a TRS of only two reduction rules, thus establishing that SN is
undecidable even for TRS's with only two rules, see Dershowitz [87]. For a
(complicated) proof that even for one rule TRS's the property SN is undecidable,
see Dauchet [89]. (Even more, for orthogonal one rule TRS's SN is undecidable,
as shown in Dauchet [89]. The property `orthogonal' is dened in Chapter 2.)
A (deterministic) Turing machine M consists of a triple hQ;S; i where Q is a
set fq
0
; : : : ; q
n
g of states, S = f2; s
1
; : : : ; s
m
g is the set of tape symbols (2 being
the empty symbol or `blank'), and  is a partial function (the transition function)
from Q  S to Q S  fL;Rg. Here L represents a move to the left, R to the
right.
An instantaneous description or conguration is an element of S

QS

(in
the well-known notation of regular expressions). E.g. in Figure 1.9(a) the con-
guration 2aqba2a is pictured; the understanding is that in the conguration
w
1
qw
2
the head is in state q and scans the rst symbol to the right of it, i.e. of
w
2
. Furthermore, the innite portions of tape which are to the left of w
1
and
to the right of w
2
, are supposed to be blank. Equivalent congurations arise by
appending to the left or to the right of the conguration nite portions of empty
tape, i.e. elements of f2g

:
The transition function  determines transition rules, of the form
qst s
0
q
0
t (for all t 2 S) whenever (q; s) = (q
0
; s
0
;R)
and
tqs q
0
ts
0
for all t 2 S) whenever (q; s) = (q
0
; s
0
; L):
A transition rule of the rst type (`R-type') is a move to the right (see Figure
1.9(b)), and of the second type (`L-type') a move to the left. A rule of the rst
type can also be rendered as
qs s
0
q
0
whenever (q; s) = (q
0
; s
0
;R):
Transition rules may be applied in a `context', giving rise to transitions between
congurations, by appending words w
1
; w
2
2 S

to the left and the right. Thus
26 J. W. Klop
Figure 1.9
the transition rule qst  s
0
q
0
tR generates transitions w
1
qstw
2
 w
1
s
0
q
0
tw
2
for
all w
1
; w
2
2 S

. Note that transitions operate in fact on equivalence classes of
congurations.
We will now translate all this in the terminology of TRS's. That is, we
associate to the Turing machine M = hQ;S; i a TRS R
M
as follows. For each
q 2 Q there is a binary function symbol which we will denote with the same
letter. Each s 2 S corresponds to a unary function symbol, also denoted with
the same letter. Furthermore, the alphabet of R
m
contains a constant symbol .
A word w 2 S

is translated into the term (w) as follows:
(") =  (" is the empty word)
(sw) = s((w)) for s 2 S;w 2 S

:
E.g. the translation of baa is b(a((a()))). In the sequel of this exer-
cise we will suppress parentheses by association to the right, thus rendering
b(a((a()))) as baa.
Term Rewriting Systems 27
A conguration w
1
qw
2
will be translated to q((w
 1
1
); (w
2
)). Here w
 1
1
is w
1
reversed. The reason for this reversal will be clear later. E.g. the conguration
aqbaa is translated to q(a; baa).
We will now dene the translation of the transition rules of M into reduction
rules of R
M
. To transition rules of R-type, qs  s
0
q
0
, we let correspond the
reduction rule
q(x; sy)! q
0
(s
0
x; y):
In the case that s is , so that the rule reads q  s
0
q
0
, we add moreover the
reduction rule
q(x;)! q
0
(s
0
x;):
In some sense, the second rule is a degenerate case of the rst one; conceiving 
as a potentially innite portion of tape, satisfying the equation  = , it is
clear how this rule arises from the rst one.
To a rule of L-type, tqs q
0
ts
0
, we let correspond the reduction rule
q(tx; sy)! q
0
(x; ts
0
y):
Again we have some extra rules for the `degenerate' cases. If tqs  q
0
ts
0
is in
fact qs q
0
ts
0
we add moreover
q(; sy)! q
0
(;s
0
y):
If tqs q
0
ts
0
is in fact tq q
0
ts
0
we add moreover
q(tx;)! q
0
(x; ts
0
):
If tqs q
0
ts
0
is q  q
0
s
0
we add moreover
q(;)! q
0
(;s
0
):
(So the transition rule q  q
0
s
0
corresponds to four reduction rules.)
1. Now it is not hard to prove that for congurations ; we have:
  , ()! ():
2. Prove that, given a TRS R and a term t in R, the problem to determine
whether t has an innite reduction in R, is undecidable. This means: there
is no algorithm that accepts as inputs pairs (R; t) of a TRS R (given by a
nite set of rewrite rules) and a term t 2 Ter(R), and that yields as output
the answer `yes' if t has an innite reduction in R, and `no' otherwise.
(Using (1), reduce this problem to the well-known undecidable halting
problem for Turing machines with empty tape as initial conguration.)
3. To each ground term in R
M
of the form q(t
1
; t
2
) where t
1
; t
2
are terms in
which no q
0
2 Q occurs (call such a term `restricted'), there corresponds a
28 J. W. Klop
conguration of M ; but this is not so without that restriction. Prove that
if some term t in R
M
has an innite reduction in R
M
, then there is also
a restricted ground term t
0
in R
M
having an innite reduction, and thus
yielding a corresponding innite run of the Turing machine M .
4. Prove, using (3) and referring to the well-known undecidable uniform halt-
ing problem for Turing machines, that the problem to determine whether
a given TRS is SN (strongly normalizing) is undecidable. The uniform
halting problem for Turing machines is the problem to decide whether a
given Turing machine halts on every input as initial conguration.
1.3 A termination proof technique
As Newman's Lemma (WCR & SN ) CR) shows, termination (SN) is a
useful property. In general, as noted in Exercise 1.2.21, it is undecidable
whether a TRS is SN; but in many instances SN can be proved and various
techniques have been developed to do so. (See Huet & Oppen [80], Der-
showitz [87].) We will present in this section one of the most powerful of
such termination proof techniques: the method of recursive path orderings,
as developed by Dershowitz on the basis of a beautiful theorem of Kruskal.
(See also the similar concept of `path of subterm ordering' in Plaisted [78],
discussed in Rusinowitch [87b].) In fact we will use the presentation of
Bergstra & Klop [85], where the rather complicated inductive denitions
of the usual presentation are replaced by a reduction procedure which is to
our taste easier to grasp.
Denition 1.3.1.
1. Let T be the set of commutative nite trees with nodes labeled by
natural numbers. Example: see Figure 1.10(a). This tree will also
be denoted by: 3(5; 7(9); 8(0(1; 5))). Commutativity means that the
`arguments' may be permuted; thus 3(8(0(5; 1)); 5; 7(9)) denotes the
same commutative tree.
2. Let T

be the set of such trees where some of the nodes may be
marked with (a single)

. So T T

. Example: see Figure 1.10(b);
this tree will be denoted by 3

(5; 7(9

); 8

(0(1; 5))):
Notation 1.3.2. n(t
1
; : : : ; t
k
) will be written as n(
~
t ). The t
i
(i = 1; : : : ; k)
are elements of T

. Further, if t  n(t
1
; : : : ; t
k
) then t

stands for
n

(t
1
; : : : ; t
k
):
Denition 1.3.3. On T

we dene a reduction relation ) as follows.
1. place marker at the top:
n(
~
t )) n

(
~
t ) (
~
t = t
1
; : : : ; t
k
; k  0)
Term Rewriting Systems 29
Figure 1.10
2. make copies below lesser top:
if n > m, then n

(
~
t )) m(n

(
~
t ); : : : ; n

(
~
t )) (j  0 copies of n

(
~
t ))
3. push marker down:
n

(s;
~
t )) n(s

; : : : ; s

;
~
t ) (j  0 copies of s

)
4. select argument:
n

(t
1
; : : : ; t
k
)) t
i
(i 2 f1; : : : ; kg; k  1)
It is understood that these reductions may take place in a context, i.e. if
t) s, then n(|; t;|)) n(|; s;|)
We write )
+
for the transitive (but not reexive) closure of ).
Example 1.3.4. Figure 1.11 displays a reduction in T

.
Clearly, the reduction ) is not SN in T

; for, consider the second step
in Figure 1.11: there the right hand side contains a copy of the left-hand
side. However:
Theorem 1.3.5. The relation )
+
, restricted to T, is a well-founded par-
tial ordering. Or, rephrased, the relation )
+
, restricted to T, is SN.
So there is no innite sequence t
0
)
+
t
1
)
+
t
2
)
+
   of terms t
i
(i  0) without markers. The proof of Theorem 1.3.5 is based on Kruskal's
Tree Theorem; we will give the main argument.
In order to introduce the next notion of `embedding', we must make
the denition of trees t 2 Tsomewhat more precise. An element t 2Tis a
pair (hD;; 
0
i;L) where D is a nite set f
0
; ; ; : : :g with distinguished
element 
0
, called the root or the top of t, and partially ordered by . We
require that:
1. 
0
  for all  2 D,
2.    and    )    or   , for all ; ;  2 D.
30 J. W. Klop
Figure 1.11
The set D is also called Nodes(t). Furthermore, L: D ! N is a map
assigning labels (natural numbers) to the nodes of t. Finally, we use the
notation  ^  for the supremum (least upper bound) of ;  2 D. (The
actual names ; ; : : : of the nodes are not important, which is why they
were suppressed in the pictorial representation of t 2Tabove.)
Denition 1.3.6. Let t; t
0
2 T. We say that t is (homeomorphically)
embedded in t
0
, notation t  t
0
, if there is a map ': Nodes(t)! Nodes(t
0
)
such that:
1. ' is injective,
2. ' is monotonic (   ) '()  '()),
3. ' is sup preserving ('( ^ ) = '() ^ '()),
4. ' is label increasing (L()  L
0
('()), where L;L
0
are the labeling
maps of t; t
0
respectively;  is the ordering on natural numbers).
Actually, (2) is superuous as it follows from (3).
Example 1.3.7.
1. 2(9; 7(0; 4))  1(3(8(0(5; 1)); 9; 5(9)); 2) as the embedding in Figure
1.12 shows.
2. Note that we do not have 1(0; 0)  1(0(0; 0)).
Term Rewriting Systems 31
Figure 1.12
Clearly,  is a partial order on T: Moreover it satises the following
remarkable property:
Theorem 1.3.8. (Kruskal's Tree Theorem) Let t
0
; t
1
; t
2
; : : : be a sequence
of trees in T. Then for some i < j: t
i
 t
j
.
The proof of this theorem, as given in Kruskal [60], is extremely com-
plicated. Proofs are given in Dershowitz [79] and Dershowitz & Jouannaud
[90]. See also Exercise 1.3.12 for a detailed proof sketch of a restricted case
which is sucient for the present purpose.
Now we have the following proposition (of which (1) is nontrivial to
prove):
Proposition 1.3.9.
1. )
+
is a strict partial order on T,
2. if s  t, then t)

s:
(Here )

is the transitive-reexive closure of ).) Combining 1.3.8 and
1.3.9, we have Theorem 1.3.5. For, suppose there is an innite sequence
t
0
)
+
t
1
)
+
t
2
)
+
   )
+
t
i
)
+
   )
+
t
j
)
+
  
then for some i < j we have t
i
 t
j
, hence t
j
)

t
i
, so t
i
)
+
t
i
, which is
impossible as )
+
is a strict partial order.
Application 1.3.10 (Dershowitz [87]). Let a TRS R as in Table 1.9 be
given. To prove that R is SN. Choose a `weight' assignment _ 7! 1, ^ 7! 2,
32 J. W. Klop
::x ! x
:(x _ y) ! (:x ^ :y)
:(x ^ y) ! (:x _ :y)
x ^ (y _ z) ! (x ^ y) _ (x ^ z)
(y _ z) ^ x ! (y ^ x) _ (z ^ x)
Table 1.9
: 7! 3. Now a reduction in R corresponds to a )
+
reduction in T (and
hence it is also SN) as follows:
3(3(t)) )
+
t
3(1(t; s)) )
+
2(3(t); 3(s))
3(2(t; s)) )
+
1(3(t); 3(s))
2(t; 1(s; r)) )
+
1(2(t; s); 2(t; r))
2(1(s; r); t) )
+
1(2(s; t); 2(r; t))
E.g. the second rule:
3(1(t; s)) ) 3

(1(t; s))
) 2(3

(1(t; s)); 3

(1(t; s)))
)
+
2(3(1

(t; s)); 3(1

(t; s)))
)
+
2(3(t); 3(s)):
Remark 1.3.11.
1. The termination proof method above does not work when a rule is
present of which the left-hand side is embedded (in the sense of Deni-
tion 1.3.6) in the right-hand side, as in f(s(x)) ! g(s(x); f(p(s(x)))).
For an extension of Kruskal's Theorem, leading to a method which
also can deal with this case, see Kamin & Levy [80] and Puel [86].
2. Another example where the method above does not work directly, is
found in the TRS's corresponding to process algebra axiomatizations
as in Bergstra & Klop [84, 85]. For instance in the axiom system PA
there are the rewrite rules
xky ! (x k y) + (y k x)
(x+ y) k z ! (x k z) + (y k z)
(a  x) k y ! a  (xky):
Here one wants to order the operators as follows: k > k > ;+,
but then we get stuck at the third rule with the re-emergence of the
`heavy' operator k. In Bergstra & Klop [85] the solution was adopted
Term Rewriting Systems 33
to introduce innitely many operators k
n
and k
n
, where n refers to
some complexity measure of the actual arguments of the operators
in a reduction. In fact, the operator + does not contribute to the
problem, and forgetting about it and writing xky as g(x; y); x k y as
h(x; y); ax as f(x), we have Example 16 in Dershowitz [87] where this
problem takes the following form and is solved by a lexicographical
combination of recursive path orderings:
g(x; y) ! h(x; y)
h(f(x); y) ! f(g(x; y)):
The termination proof as in Bergstra & Klop [85] amounts to the
following for the present example. Dene a norm j j on terms by: j t j
is the length of t in symbols; then introduce normed operators g
n
and
h
n
(n  2); order the operators thus: g
n
> h
n
> f; h
n+1
> g
n
. Then
replace in a term t every subterm h(s; r) by h
jsj+jrj
(s; r) and likewise
for g(s; r). Now the recursive path ordering as before is applicable.
Caution is required here: the norm must be chosen such that the
norm of a term t is not increased by reduction of a subterm of t. (For
this reason, taking j t j as the length of t in symbols would not work
for the process algebra example above.)
3. A third example were the proof method above does not work, is when
an associativity rule
(x  y)  z ! x  (y  z)
is present. The same problem occurs in the TRS for Ackermann's
function:
A(0; x) ! S(x)
A(S(x); 0) ! A(x; S(0))
A(S(x); S(y)) ! A(x;A(S(x); y))
What we need here is the lexicographic path ordering of Kamin &
Levy [80], see Dershowitz [87]. Essentially this says that a reduc-
tion in complexity in the rst argument of A outweighs an increase
(strictly bounded by the complexity of the original term) in the sec-
ond argument. In fact, an ordering with the same eect can easily be
described in the framework of reduction with markers

as explained
above: all one has to do is give up the commutativity of the trees in
Tand T

and require that an embedding (Denition 1.3.6) respects
also the left-right ordering; Kruskal's Tree Theorem works also for
this case of noncommutative trees.
Next, the rules in Denition 1.3.3 are restricted such that the ari-
ties of the operators are respected; in Denition 1.3.3 the operators
were treated `varyadic'. So rule (3) becomes: n

(t
1
; : : : ; t
i
; : : : ; t
k
))
34 J. W. Klop
n(t
1
; : : : ; t

i
; : : : ; t
k
) (1  i  k). Further, we add to the rules in
Denition 1.3.3 (with (3) amended) the rule
5. simplify left argument:
n

(
~
t )) n(t

1
; n

(
~
t ); : : : ; n

(
~
t ))
(
~
t = t
1
; : : : ; t
k
(k  1); k   1 copies of n

(
~
t ))
Example:
A(S(x); S(y)) ) A

(S(x); S(y))
) A(S

(x); A

(S(x); S(y)))
) A(x;A

(S(x); S(y)))
) A(x;A(S(x); S

(y)))
) A(x;A(S(x); y)):
Exercise 1.3.12. In this exercise we outline a short proof of a restricted
version of Kruskal's Tree Theorem 1.3.8, which is sucient for termination proofs
of TRS's where the function symbols have arities uniformly bounded by some
natural number N . (There may be innitely many function symbols, as e.g. the
g
n
; h
n
in the preceding Remark 1.3.11.) A fortiori this is the case for TRS's with
nite alphabet.
The proof below is similar to that in Dershowitz [79]; the proof in Dershowitz
& Jouannaud [90] is similar but for a short-cut there appealing to a special case
of the Tree Theorem known as Higman's Lemma. These proofs are originally due
to Nash-Williams [63]. First we dene:
1. The branching degree of a node s in t 2 T is the number of immediate
successor nodes of s.
2. T
N
is the subset of Tconsisting of trees where all nodes have branching
degree  N . Likewise we dene T

N
:
We will now outline a proof of Kruskal's Tree Theorem 1.3.8 where Tis restricted
to T
N
:
1. CLAIM. Each innite sequence of natural numbers n
0
; n
1
; n
2
; : : : has a
weakly ascending innite subsequence.
This means that there is a subsequence n
f(0)
; n
f(1)
; n
f(2)
; : : : with f(0) <
f(1) < f(2) < : : : such that n
f(0)
 n
f(1)
 n
f(2)
 : : : . The proof is
simple.
2. DEFINITION.
(a) Let t 2T
N
. Then j t j is the number of nodes of t.
(b) Notation: an innite sequence of trees t
0
; t
1
; : : : will be written as t.
The initial segment t
0
; : : : ; t
n 1
is (t)
n
. The set of innite sequences
of trees from T
N
is T
!
N
:
(c) Let D  T
!
N
. Then the sequence t 2 D is minimal in D if 8s 2
D (s)
n
= (t)
n
)j s
n
j  j t
n
j :
(d) Furthermore, we say that s, t 2T
!
N
have distance 2
 n
if (s)
n
= (t)
n
but (s)
n+1
6= (t)
n+1
. This induces a metric on T
!
N
.
Term Rewriting Systems 35
3. CLAIM. LetD T
!
N
be non-empty and closed w.r.t. the metric just dened.
Then D contains a minimal element (with respect to D).
The proof of Claim 3 is easy.
4. NOTATION.
(a) Let s; t 2T
!
N
. Then s  t means that s is a subsequence of t.
(b) Let t = t
0
; t
1
; : : : and let s = s
f(0)
; s
f(1)
; : : : be a subsequence of t,
such that for all i; s
f(i)
is a proper subtree of t
f(i)
. Then we write
s  t and call s a subsubsequence of t. (See Figure 1.13.)
Figure 1.13
5. DEFINITION. s = s
0
; s
1
; s
2
; : : : is a chain if s
0
 s
1
 s
2
 : : : , where 
is the embedding relation as in Kruskal's Tree Theorem.
We will now suppose, for a proof by contradiction, that there is a counterexample
sequence to the restricted version of Kruskal's Tree Theorem that we want to
prove. That is, the set C  T
!
N
of sequences s such that for no i < j we have
s
i
 s
j
, is supposed to be non-empty. Note that C is closed in the sense of
Denition 2(d).
6. CLAIM. Let t be a minimal element from C. Suppose s  t.
(a) Then for some i < j: s
i
 s
j
:
(b) Even stronger, s contains a subsequence which is a chain.
PROOF of Claim 6(a). (Note that a minimal element t exists by the assumption
C 6= ? and by Claim 3.) Let s, t be as in Claim 6. Let s
0
be a proper subtree of
t
f(0)
= t
k
. Consider the sequence t
0
; : : : ; t
k 1
; s
0
; s
1
; s
2
; : : : ; that is, (t)
k
followed
by s. By minimality of t, this sequence is not in C. Hence it contains an embedded
pair of elements (the earlier one embedded in the later one). The embedded pair
cannot occur in the prex (t)
k
because t 2 C. It can also not be of the form
t
i
 s
j
, since then t would contain the embedded pair t
i
 t
f(j)
. So, the
embedded pair must occur in the postx s.
As to part (b) of the claim, suppose s does not contain an innite chain as
subsequence. Then s contains an innite number of nite chains, each starting
to the right of the end of the previous nite chain and each maximal in the sense
36 J. W. Klop
that it cannot be prolonged by an element occurring to the right of it in s. Now
consider the last elements of these nite chains. These last elements constitute
an innite subsubsequence of t, containing by (a) of the claim an embedded
pair. But that means that one of the maximal nite chains can be prolonged, a
contradiction.
7. CLAIM. Let t be minimal in C and suppose s  r  t. Then s contains
an innite chain as subsequence.
The proof of Claim 7 is trivial. We will now apply a sieve procedure to the mini-
mal counterexample sequence t 2 C. By Claim 1 we can take a subsequence t
0
of
t such that the root labels are weakly ascending. Of t
0
we take a subsequence t

with the property that the branching degrees of the roots are a weakly ascend-
ing sequence. By Claim 6 every subsubsequence of t

still contains an innite
embedding chain.
Let us `freeze' the elements in t
0
, that is, we impose an ordering of the suc-
cessors of each node in some arbitrary way. So the frozen trees in t
0
are no longer
commutative trees, and we can speak of the rst, second etc. `arguments' of a
node. (An argument of a node  is the subtree with as root a successor node 
of .)
The next step in the sieve procedure is done by considering the sequence of
rst arguments of (the roots of) the elements in t

. As this is a subsubsequence,
it contains an innite chain. Accordingly, we thin t

out, to the subsequence
t

. This sequence has the property that its rst arguments form a chain. Next,
t

is thinned out by considering the sequence of the second arguments of t

.
Again, this sequence contains a chain, and thinning t

accordingly yields the
subsequence t

.
Figure 1.14
After at most N steps of the last kind, we are through. The result is then a chain,
since the roots already satised the embedding condition (they form a weakly
ascending chain), and the arguments are also related as chains. (See Figure
1.14.) However, this contradicts the assumption that t contains no embedded
pair. Hence C is empty, and the restricted version of Kruskal's Tree Theorem is
proved.
Exercise 1.3.13. (Kruskal [60]) In this exercise we introduce the terminol-
ogy of well-quasi-orderswhich is often used to formulate Kruskal's Tree Theorem.
Term Rewriting Systems 37
1. DEFINITION. The binary relation  is a quasi-order (qo) if it is reexive
and transitive. (So the relation  in a TRS is a qo.) If in addition  is
anti-symmetric (i.e. x  y & y  x) x = y for all x; y) then  is a partial
order (po).
2. DEFINITION. Let hX;i be a qo. A subset Y  X is called a cone if
x 2 Y & x  y ) y 2 Y for all x;y 2 X. The cone generated by Y  X,
notation Y ", is the set fx 2 X j 9y 2 Y y  xg. (It is the intersection of
all cones containing Y .) A cone Z is nitely generated if Z = Y " for some
nite Y .
3. DEFINITION. Let hX;i be a qo (po, respectively). Then hX;i is a well-
quasi-order (wqo) or well-partial-order (wpo) respectively, if every cone of
X is nitely generated.
4. DEFINITION. Let hX;i be a qo. A subset Y  X is an anti-chain if
the elements of Y are pairwise incomparable, i.e. for all x; y 2 Y such that
x 6= y we have neither x  y nor y  x:
Prove the following lemma:
5. LEMMA. Let hX;i be a qo. Then the following conditions are equivalent:
(a) hX;i is a wqo;
(b) X contains no innite descending chains x
0
> x
1
> x
2
>    and all
anti-chains of X are nite;
(c) for every innite sequence of elements x
0
; x
1
; x
2
; : : : in X there are
i; j such that i < j and x
i
 x
j
:
So, Kruskal's Tree Theorem as stated in 1.3.8 can be reformulated as follows:
hT;i is a well-quasi-order. Prove that hT;i is in fact a partial order; so
Kruskal's theorem states that hT;i is even a well-partial-order.
Exercise 1.3.14.
1. Show that the well-partial-order hT;i is not a linear order.
2. Show that )
+
is a linear order. As it is well-founded (Theorem 1.3.5),
it corresponds to an ordinal. For connections with the ordinal ?
0
, the
rst impredicative ordinal, see Dershowitz [87]. For more about Kruskal's
Tree Theorem and the connection with large ordinals, as well as a version
of the Tree Theorem which is independent from Peano's Arithmetic, see
Smorynski [82] and Gallier [87].
Exercise 1.3.15. (Multiset orderings) Very useful for termination proofs
(used in some of the Exercises 1.0.8) are the multiset orderings; these are par-
ticular cases of the well-founded ordering hT;)
+
i discussed above, namely by
restricting the domain T:
1. Multisets. Let hX;<i be a strict partial order. Then the p.o. of multisets
over X, or the multiset extension of X, notation hX

; <

i, is obtained as
follows. The elements of X

are nite \sets" of elements from X with the
understanding that multiplicity of occurrences is taken into account, other
than in ordinary sets. A multiset will be denoted by square brackets [ ].
38 J. W. Klop
E.g. if a; b 2 X then [a; a; b] and [a; b] are dierent multisets; but [a; a; b]
and [a; b; a] denote the same multiset. Stated dierently, a multiset is a
nite sequence of elements where the order of occurrences in the sequence
is disregarded. Giving a more formal denition is left to the reader. A
multiset is also known as a bag. We use in this exercise ;; : : : as variables
for multisets.
Now we dene the following relation >
1
between elements of X

by the
two clauses:
(a) [a] >
1
[b
1
; : : : ; b
n
] for all a; b
1
; : : : ; b
n
2 X (n  0) such that a > b
i
(i = 1; : : : ; n);
(b)  >
1
 )  [  >
1
 [ . Here [ denotes multiset union, dened in
the obvious way as a union where the multiplicities of the elements
are respected. E.g. [a; a; b][ [a; b; c] = [a; a; a; b; b; c]. Thus, a multiset
gets smaller by replacing an element in it by arbitrarily many (possi-
bly 0) elements which are less in the original ordering. The converse
of >
1
is <
1
.
Furthermore, we dene:
(c) <

is the transitive closure of <
1
.
Now prove the following statements:
(a) If hX;<i is a strict partial order, then so is its multiset extension
hX

;<

i. If hX;<i is moreover a linear order, then so is hX

;<

i:
(b) (Dershowitz & Manna [79]) hX;<i is a well-founded p.o. , hX

;<

i
is a well-founded p.o. (The p.o. hX;<i is well-founded if there are
no innite descending chains x
0
> x
1
> : : : .)
(c) Let hX;<i be a well-founded linear order with order type . Then
hX

;<

i has order type !

:
2. Nested multisets. Let hX;<i be a p.o. Then the p.o. of nested multisets
over X, notation: hX


;<


i, is dened as follows. The domain X


is
the least set Y such that X  Y and Y

= Y . Or, inductively:
(a) X
0
= X;
(b) X
n+1
= (X
0
[    [X
n
)

;
(c) X


= [
n0
X
n
.
Note that the elements of X


can be represented as nite commutative
trees, with terminal nodes labeled by elements from X, and non-terminal
nodes with a label representing the multiset-operator. The depth of  2
X


is the stage of the inductive denition in which it is generated, or in
the tree representation, the maximum of the lengths of the branches of the
tree corresponding to :
Furthermore, the ordering <


is the least relation R extending < and
satisfying:
(a) xR for all x 2 X and multisets  2 X


?X;
(b) []R [
1
; : : : ; 
n
] for all ;
1
; : : : ; 
n
2 X


(n  0) such that 
i
R
i
(i = 1; : : : ; n);
(c) R )  [  R  [  for all multisets ;;  2 X


?X.
Now:
Term Rewriting Systems 39
(a) Let hX;<i be a p.o. Prove that hX


;<


i is a p.o. If moreover
hX;<i is a linear order, then so is hX


;<


i.
(b) Let ; 2 hX


;<


i. Prove that if the depth of  is greater than
the depth of , we have  <


.
(c) (Dershowitz & Manna [79])
hX;<i is well-founded , hX


;<


i is well-founded.
(d) Let hN;<i be the natural numbers with the usual ordering. Prove
that hN


;>


i, the nested multisets over the natural numbers, is in
fact a restriction of the recursive path ordering hT;)
+
i if the non-
terminal nodes of the tree representation of  2 N


are taken to be
0. That is, for ; 2 N


Twe then have:  >


 , )
+
:
(e) Show that the order type of the well-founded linear ordering hN


;<


i
is 
0
. Note that hN


;<


i is isomorphic to hf0g


;<


i. Here `<'
in the last occurrence of <


is the restriction of < to f0g (which
in fact is the empty relation). Figure 1.15 gives an example of two
multisets ; over f0g, such that  >


; or equivalently,
 )
+
. All labels at the nodes can be taken 0, and are omitted in
the gure. Note that the procedure using the markers may employ
all clauses in Denition 1.3.3 except clause (2).
Figure 1.15
1.4 Completion of equational specications
In this section we will give an introduction to Knuth-Bendix completion of
equational specications. First we will introduce the latter concept.
Equational specications: syntax and semantics
We can be short about introducing the syntax of equational specications:
an equational specication is just a TRS \without orientation". More
precisely, an equational specication is a pair (; E) where the signature
40 J. W. Klop
(or alphabet)  is as in Section 1.1 for TRS's (; R), and where E is a set
of equations s = t between terms s; t 2 Ter():
If an equation s = t is derivable from the equations in E, we write
(; E) ` s = t or s =
E
t. Formally, derivability is dened by means of the
inference system of Table 1.10.
(; E) ` s = t if s = t 2 E
(; E) ` s = t
(; E) ` s

= t

for every substitution 
(; E) ` s
1
= t
1
; : : : ; (; E) ` s
n
= t
n
(; E) ` F (s
1
; : : : ; s
n
) = F (t
1
; : : : ; t
n
)
for every n-ary F 2 
(; E) ` t = t
(; E) ` t
1
= t
2
; (; E) ` t
2
= t
3
(; E) ` t
1
= t
3
(; E) ` s = t
(; E) ` t = s
Table 1.10
Exercise 1.4.1. (Equational deduction systems) Often the inference sys-
tem in Table 1.10 is presented slightly dierent, as follows. Prove the equivalence
of the two versions below with the system above. Axioms (in addition to the
equations in E):
t = t reexivity
Rules:
t
1
= t
2
t
2
= t
2
symmetry
t
1
= t
2
; t
2
= t
3
t
1
= t
3
transitivity
t
1
= t
2
t
1
[x := t] = t
2
[x := t]
substitution(1)
t
1
= t
2
t[x := t
1
] = t[x := t
2
]
substitution(2)
Term Rewriting Systems 41
Here [x := t] denotes substitution of t for all occurrences of x. (The assignment
notation is chosen to avoid the usual confusion between [x=t]; [t=x]; [xnt]; [tnx].)
An equivalent formulation is to combine the two substitution rules in one:
t
1
= t
2
; t = t
0
t
1
[x := t] = t
2
[x := t
0
]
substitution
If  is a signature, a -algebra A is a set A together with functions
F
A
: A
n
! A for every n-ary function symbol F 2 . (If F is 0-ary,
i.e. F is a constant, then F
A
2 A.) An equation s = t (s; t 2 Ter()) is
assigned a meaning in A by interpreting the function symbols in s; t via the
corresponding functions in A. Variables in s = t are (implicitly) universally
quantied. If the universally quantied statement corresponding to s = t
(s; t 2 Ter()) is true in A, we write A j= s = t and say that s = t is valid
in A. A is called a model of a set of equations E if every equation in E
is valid in A. Abbreviation: A j= E. The variety of -algebras dened
by an equational specication (; E); notation Alg(; E), is the class of all
-algebras A such that A j= E. Instead of 8A 2Alg(; E) A j= F , where
F is a set of equations between -terms, we will write (; E) j= F . There is
the well-known completeness theorem for equational logic of Birkho [35]:
Theorem 1.4.2. Let (; E) be an equational specication. Then for all
s; t 2 Ter() :
(; E) ` s = t , (; E) j= s = t:
Now the validity problem or uniform word problem for (; E) is:
Given an equation s = t between -terms, decide whether or
not (; E) j= s = t:
According to Birkho's completeness theorem for equational logic this
amounts to deciding (; E) ` s = t. Now we can state why complete
TRS's (i.e. TRS's which are SN and CR) are important. Suppose for the
equational specication (; E) we can nd a complete TRS (; R) such
that for all terms s; t 2 Ter() :
t =
R
s , E ` t = s ()
Then (if R has nitely many rewrite rules only) we have a positive solution
of the validity problem. The decision algorithm is simple:
1. Reduce s and t to their respective normal forms s
0
; t
0
2. Compare s
0
and t
0
: s =
R
t i s
0
 t
0
:
We are now faced with the question how to nd a complete TRS R for a
given set of equations E such that () holds. In general this is not possible,
42 J. W. Klop
since not every E (even if nite) has a solvable validity problem. The most
famous example of such an E with unsolvable validity problem is the set of
equations obtained from CL, Combinatory Logic, in Tables 1.3, 1.4 above
after replacing `!' by `=': see Table 1.11.
Sxyz = xz(yz)
Kxy = x
Ix = x
Table 1.11
(For a proof of the unsolvability see Barendregt [81].) So the validity prob-
lem of (; E) can be solved by providing a complete TRS (; R) for (; E).
Note however, that there are equational specications (; E) with decid-
able validity problem but without a complete TRS (; R) satisfying ():
see the following Exercise.
Exercise 1.4.3. Let (;E) be the specication given by the equations
x+ 0 = x
x+ S(y) = S(x + y)
x+ y = y + x
Prove that there is no complete TRS R `for' E, i.e. such that for all terms s; t 2
Ter() : s =
R
t, s =
E
t. (Consider in a supposed complete TRS R, the normal
forms of the open terms x+ y and y + x.)
It is important to realize that we have considered up to now equations
s = t between possibly open -terms (i.e. possibly containing variables). If
we restrict attention to equations s = t between ground terms s; t, we are
considering the word problem for (; E), which is the following decidability
problem:
Given an equation s = t between ground terms s; t 2 Ter(),
decide whether or not (; E) j= s = t (or equivalently, (; E) `
s = t).
Also for the word problem, complete TRS's provide a positive solution. In
fact, we require less than completeness (SN and CR) for all terms, but only
for ground terms. (See Example 1.1.3 for an example where this makes a
dierence.) It may be (as in Exercise 1.4.3) that a complete TRS for E
cannot be found with respect to all terms, while there does exist a TRS
which is complete for the restriction to ground terms.
Exercise 1.4.4. Consider the specication as in the previous exercise and
nd a TRS (;R) such that (;R)
0
(i.e. the restriction of (;R) to ground
terms) is complete.
Term Rewriting Systems 43
Remark 1.4.5. Note that there are nite equational specications (; E)
which have a decidable word problem (so for ground terms) for which no
complete TRS R (complete with respect to ground terms) exists. This
strengthens the observation in Exercise 1.4.3. The simplest such (; E) is
the specication consisting of a single binary commutative operator + and
a constant 0, and equations E = fx + y = y + xg. According to Exercise
1.4.3 (which also works for the present simpler specication) no complete
TRS R can be found such that for all (open) s; t we have s =
R
t, s =
E
t.
According to the next exercise, we also have the stronger result that no
TRS R exists which is complete for ground terms and such that for ground
terms s; t we have s =
R
t, s =
E
t:
Exercise 1.4.6. (Bergstra & Klop) Prove the following fact:
THEOREM. Let (; E) be the specication with  = f0;+g and E = fx + y =
y + xg. Then there is no nite TRS R such that the restriction to ground terms,
(R)
0
, is complete and such that =
R
and =
E
coincide on ground terms.
PROOF SKETCH. Dene terms t
0
 0, t
n+1
 t
n
+ t
n
(n  0). Suppose R is a
TRS with nitely many rewrite rules such that =
R
and =
E
coincide on ground
terms. Let N be the maximum of the depths of the LHS's of the rewrite rules in
R. (Here `depth' refers to the height of the corresponding term formation tree.)
Consider the terms t

 t
N
+ t
2N
and t

 t
2N
+ t
N
. Clearly, t

=
E
t

.
In fact, ft

; t

g is an E-equivalence class, hence also an R-convertibility class.
Therefore there must be a rewrite rule r such that t

is an r-redex or t

is an r-
redex (since there are only two elements in the convertibility class) and such that
t

!
r
t

. Say t

is an r-redex. Now one can easily show that t

!
r
t

!
r
t

.
Hence R is not even SN on ground terms.
Term rewriting and initial algebra semantics
We will now make more explicit the connection between term rewriting and
initial algebra semantics. We suppose familiarity with the concept of an
initial algebra in the class of models of an equational specication (; E),
i.e. the variety Alg(; E), as dened by universal properties in terms of
homomorphisms. (See e.g. Meinke & Tucker [91], Goguen & Meseguer
[85].) Although the initial algebra is only determined up to isomorphism,
we will speak of `the' initial algebra and use the notation I(; E) for it. It
is well-known that I(; E) can be obtained from the set of ground terms
Ter
0
() by dividing out the congruence relation =
E
. Thus we can equate
the initial algebra I(; E) with the quotient algebra Ter
0
()==
E
.
Now suppose that (; R) is a TRS `for' (; E), that is, =
R
coincides with
=
E
. (So the initial algebra of (; E) van also be written as Ter
0
()==
R
.)
If R is a complete TRS, then I(; E) is in fact a computable algebra. This
is merely a rephrasing of: the word problem (for ground terms) for (; E)
is solvable. As noted in Exercise 1.4.6, the reverse is not necessarily the
case; for some (; E) with computable initial algebra there does not exist a
44 J. W. Klop
complete TRS|at least not in the same signature. However, a remarkable
theorem of Bergstra and Tucker states that if we allow an extension of
the signature with some functions and constants (no new sorts), then a
complete TRS can always be found. (This result also follows from the
simulation of Turing Machines by a TRS|consisting of two rules|as in
Dershowitz [87].) More precisely:
Denition 1.4.7.
1. The algebra A 2 Alg(; E) is minimal, if it is (isomorphic to) a
quotient algebra Ter()= for some congruence . In particular,
I(; E) is a minimal algebra. In other words, an algebra is minimal if
its elements are generated by functions and constants in the signature.
2. A minimal algebra A is computable, if its equality is decidable, i.e. if
the relation A j= t = s for ground terms t; s 2 Ter() is decidable.
Theorem 1.4.8. (Bergstra & Tucker [80]) Let A be a minimal-algebra,
 a nite signature. Then the following are equivalent:
1. A is a computable algebra;
2. there is an extension of  to a nite 
0
, obtained by adding some
function and constant symbols, and there is a complete TRS (
0
; R)
such that
A  I(
0
; R
=
) j

:
Here R
=
is the equational specication obtained by viewing the reduc-
tion rules in R as equations, and j

is the restriction to the signature .
So A is a `reduct ' (see Meinke & Tucker [91]) of an initial algebra given by
a complete TRS. (The TRS R as in the theorem is not only ground com-
plete, but complete with respect to all terms. Actually, it is an orthogonal
TRS as dened in the next chapter; and for orthogonal TRS's possessing
at least one ground term, ground completeness implies completeness.) The
functions (including the constants as 0-ary functions) to be added to 
are sometimes referred to as `hidden functions'. Note that according to
the statement in the theorem no new sorts are needed, thus the present
theorem has also a bearing on the homogeneous (i.e. one-sorted) case that
we are considering in this chapter.
For more information concerning the connection between term rewriting
and computability aspects of initial algebra semantics (and `nal' algebra
semantics), also for the heterogeneous (many-sorted) case, we refer to the
very complete survey Goguen & Meseguer [85].
Critical pair completion
We resume the question how to nd a complete TRS (for the case of open
terms, henceforth) for an equational specication (; E). This is in fact
Term Rewriting Systems 45
what the Knuth-Bendix completion algorithm is trying to do. We will
now explain the essential features of the completion algorithm rst by an
informal, \intuition-guided" completion of the equational specication E
of groups:
e  x = x
I(x)  x = e
(x  y)  z = x  (y  z)
Table 1.12
First we give these equations a `sensible' orientation:
1. e  x! x
2. I(x)  x! e
3. (x  y)  z ! x  (y  z)
(Note that the orientation in rules 1, 2 is forced, by the restrictions on
rewrite rules in Section 1.1. As to the orientation of rule 3, the other
direction is just as `sensible'.) These rules are not conuent, as can be seen
by superposition of e.g. 2 and 3. Redex I(x) x can be unied with a non-
variable subterm of redex (x  y)z (the underlined subterm), with result
(I(x)x)z. This term is subject to two possible reductions: (I(x)x)z !
2
e z and (I(x) x) z !
3
I(x) (x z). The pair of reducts he z; I(x) (x z)i is
called a critical pair, since the conuence property depends on the reduction
possibilities of the terms in this pair. Formally, we have the following
denition which at a rst reading is not easily digested. For the concept of
a `most general unier' we refer to Section 1.6 below.
Denition 1.4.9. Let !  and  !  be two rewrite rules such that 
is uniable (after renaming of variables) with a subterm of  which is not a
variable (a non-variable subterm). This means that there is a context C[ ],
a non-variable term t and a `most general unier'  such that   C[t]
and t

 

. The term 

 C[t]

can be reduced in two possible ways:
C[t]

! C[]

and 

! 

: Now the pair of reducts hC[]

; 

i is called
a critical pair obtained by the superposition of !  on  ! : If ! 
and  !  are the same rewrite rule, we furthermore require that  is
uniable with a proper (i.e. 6 ) non-variable subterm of   :
Denition 1.4.10. A critical pair hs; ti is called convergent if s and t have
a common reduct.
Our last critical pair he  z; I(x)  (x  z)i is not convergent: I(x)  (x  z) is
46 J. W. Klop
a normal form and e  z only reduces to the normal form z. So we have the
problematic pair of terms z; I(x)  (x z); problematic because their equality
is derivable from E, but they have no common reduct with respect to the
reduction available so far. Therefore we adopt a new rule
4. I(x)  (x  z)! z
Now we have a superposition of rule 2 and 4: I(I(y))  (I(y)  y) !
4
y and
I(I(y))  (I(y) y) !
2
I(I(y))  e. This yields the critical pair hy; I(I(y))  ei
which cannot further be reduced. Adopt new rule:
5. I(I(y))  e! y cancelled later
As it will turn out, in a later stage this last rule will become superuous.
We go on searching for critical pairs. Superposition of 4,1: I(e) (e z)!
4
z
and I(e)  (e  z)!
1
I(e)  z: Adopt new rule:
6. I(e)  z ! z cancelled later
Superposition of 3, 5: (I(Iy)) e) x !
3
I(I(y)) (e x) and (I(Iy)) e) x !
5
y  x: Adopt new rule:
7. I(Iy))  x! y  x cancelled later
Superposition of 5, 7: I(I(y))  e !
7
y:e and I(I(y))  e !
5
y: Adopt new
rule:
8. y  e! y
Superposition of 5, 8: I(I(y))  e !
5
y and I(I(y))  e !
8
I(I(y)): Adopt
new rule
9. I(I(y)) ! y cancel 5 and 7
(Rule 5 is now no longer necessary to ensure that the critical pair hy; I(I(y))
ei has a common reduct, because: I(I(y))  e !
9
y  e !
8
y. Likewise for
rule 7.) Superposition of 6, 8: I(e)  e !
6
e and I(e)  e !
8
I(e): Adopt
new rule
10. I(e) ! e cancel 6
Superposition of 2, 9: I(I(y))  I(y) !
2
eand I(I(y))  I(y) !
9
y  I(y):
Adopt new rule
11. y  I(y) ! e
Superposition of 3, 11: (y I(y)) x!
3
y (I(y) x) and (y I(y)) x !
11
e x:
Adopt new rule
12. y  (I(y)  x)! x
Superposition (again) of 3, 11: (x y)  I(x y) !
11
e and (x y)  I(x y) !
3
x  (y  I(x  y)): Adopt new rule
13. x  (y  (y  I(x  y)) ! e cancelled later
Superposition of 13, 4: I(x)  (x  (y  I(x  y))) !
4
y  I(x  y) and I(x)  (x 
(y  I(x  y)))!
13
I(x)  e: Adopt new rule
Term Rewriting Systems 47
14. y  I(x  y) ! I(x) cancelled later cancel 13
Superposition of 4, 14: I(y)(y I(xy)) !
4
I(xy) and I(y)(y I(xy)) !
14
I(y)  I(x): Adopt new rule
15. I(x  y) ! I(y)  I(x) cancel 14
At this moment the TRS has only convergent critical pairs. The signicance
of this fact is stated in the following lemma.
Lemma 1.4.11. (Critical Pair Lemma; Knuth & Bendix [70], Huet [80])
A TRS R is WCR i all critical pairs are convergent.
Exercise 1.4.12. Prove the Critical Pair Lemma. (The proof is not hard,
after distinguishing cases as in Figure 1.16, after Le Chenadec [86] where the proof
also can be found. Some care has to be taken to deal with repeated variables in
left-hand sides of reduction rules.)
Exercise 1.4.13. Prove, using the Critical Pair Lemma: if the TRS R has
nitely many rules and is SN, then WCR and CR are decidable.
So the TRS R
c
with rewrite rules as in Table 1.13 is WCR.
1: e  x ! x
2: I(x)  x ! e
3: (x  y)  z ! x  (y  z)
4: I(x)  (x  z) ! z
8: y  e ! y
9: I(I(y)) ! y
10: I(e) ! e
11: y  I(y) ! e
12: y  (I(y)  x) ! x
15: I(x  y) ! I(y)  I(x)
Table 1.13
Furthermore, one can prove SN for R
c
by a `Knuth-Bendix ordering' (not
treated here) or by the recursive path ordering explained in Section 1.3. (In
fact we need the extended lexicographic version of Remark 1.3.11(3), due
to the presence of the associativity rule.) According to Newman's Lemma
(1.0.7(2)) R
c
is therefore CR and hence complete. We conclude that the
validity problem for the equational specication of groups is solvable.
The following theorem of Knuth and Bendix is an immediate corollary
of the Critical Pair Lemma 1.4.11 and Newman's Lemma:
Corollary 1.4.14. (Knuth & Bendix [70]) Let R be a TRS which is SN.
Then R is CR i all critical pairs of R are convergent.
48 J. W. Klop
Figure 1.16
The completion procedure above by hand was naive, since we were
not very systematic in searching for critical pairs, and especially since we
were guided by an intuitive sense only of what direction to adopt when
generating a new rule. In most cases there was no other possibility (e.g. at
4: z ! I(x)  (x  z) is not a reduction rule due to the restriction that the
LHS is not a single variable), but in case 15 the other direction was at least
as plausible, as it is even length-decreasing. However, the other direction
I(y)  I(x) ! I(x y) would have led to disastrous complications (described
in Knuth & Bendix [70]).
The problem of what direction to choose is solved in the actual Knuth-
Bendix algorithm and its variants by preordaining a `reduction ordering'
on the terms.
Term Rewriting Systems 49
Denition 1.4.15. A reduction ordering > is a well-founded partial or-
dering on terms, which is closed under substitutions and contexts, i.e. if
s > t then s

> t

for all substitutions ; and if s > t then C[s] > C[t] for
all contexts C[ ].
We now have immediately the following fact (noting that if R is SN,
then !
+
R
satises the requirements of Denition 1.4.15):
Proposition 1.4.16. A TRS R is SN i there is a reduction ordering >
such that  >  for every rewrite rule !  of R.
Simple version of the Knuth-Bendix completion algorithm
Input: { an equational specication (; E)
{ a reduction ordering > on Ter()
(i.e. a program which computes >)
Output: - a complete TRS R such that for all
s; t 2 Ter() : s =
R
t , (;E) ` s = t
R := ?;
while E 6= ? do
choose an equation s = t 2 E;
reduce s and t to respective normal forms s
0
and t
0
with respect to R;
if s
0
 t
0
then
E := E ? fs = tg
else
if s
0
> t
0
then
 := s
0
;  := t
0
else if t
0
> s
0
then
 := t
0
;  := s
0
else
failure
;
CP := fP = Q j hP;Qi is a critical pair between
the rules in R and ! g;
R := R [ f! g;
E := E [CP ? fs = tg

od;
success
Figure 1.17
50 J. W. Klop
In Figure 1.17 a simple version of the Knuth-Bendix completion algo-
rithm is presented. As to the reduction ordering > on Ter() which is an
input to the algorithm: nding this is a matter of ingenuity, or experimen-
tation. (Also without reduction ordering, computer systems for Knuth-
Bendix completion equipped with an interactive question for orientation of
equations into rewrite rules are of great help.)
The program of Figure 1.17 has three possibilities: it may (1) termi-
nate successfully, (2) loop innitely, or (3) fail because a pair of terms s; t
cannot be oriented (i.e. neither s > t nor t > s). The third case gives
the most important restriction of the Knuth-Bendix algorithm: equational
specications with commutative operators cannot be completed.
Exercise 1.4.17. Show that there exists no complete TRS for the specica-
tion of abelian groups as in Table 1.14. (Consider in a supposed complete TRS
the normal forms of the open terms x + y and y + x.)
0 + x = x
(?x) + x = 0
(x+ y) + z = x + (y + z)
x+ y = y + x
Table 1.14
If one still wants to deal with equational specications having commu-
tative/associative operators as in Exercise 1.4.17, one has to work modulo
the equations of associativity and commutativity. For completion mod-
ulo such equations we refer to Peterson & Stickel [81] and Jouannaud &
Kirchner [86].
In case (1) the resulting TRS is complete. To show this requires a
non-trivial proof, see e.g. Huet [81]. In the next section we will give
an abstract formulation of Knuth-Bendix completion, following Bachmair,
Dershowitz & Hsiang [86], which streamlines considerably this kind of cor-
rectness proofs.
The completion program of Figure 1.17 does not `simplify' the rewrite
rules themselves. Such an optimization can be performed after termination
of the program, as follows.
Denition 1.4.18. A TRS R is called irreducible if for every rewrite rule
!  of R the following holds:
1.  is a normal form with respect to R,
2.  is a normal form with respect to R  f! g:
Exercise 1.4.19. Prove that every irreducible ground TRS is complete.
(Hint: use Exercise 1.2.19 and Corollary 1.4.14.)
Term Rewriting Systems 51
Theorem 1.4.20. (Metivier [83]) Let R be a complete TRS. Then we
can nd an irreducible complete TRS R
0
such that the convertibilities =
R
and =
R
0
coincide.
Exercise 1.4.21. A proof of Theorem 1.4.20 can be given along the following
line. Let R
1
be the TRS f ! 
0
j  !  2 R and 
0
is the normal form of 
with respect to Rg. We may assume that R
1
does not contain rewrite rules that
are a renaming of another rewrite rule. Further, dene R
0
= f!  2 R
1
j  is a
normal form with respect to R
1
?f! gg. Now the proof that s =
R
t, s =
R
0
t
follows from the (easy) proofs of the sequence of statements:
1. if s!
R
1
t then s!
+
R
t;
2. R and R
1
dene the same set of normal forms;
3. R
1
is SN;
4. if s
R
t and t is a normal form then s
R
1
t;
5. s =
R
t , s =
R
1
t;
6. R
1
is CR;
7. if s!
R
0
t then s!
R
1
t;
8. R
1
and R
0
dene the same set of normal forms;
9. R
0
is SN;
10. if s
R
1
t and t is a normal form then s
R
0
t;
11. s =
R
1
t , s =
R
0
t;
12. R
0
is CR;
13. R
0
is irreducible.
Instead of optimizing the TRS which is the output of the above simple
completion algorithm after the completion, it is more ecient to do this
during the completion. Figure 1.18 contains a more ecient Knuth-Bendix
completion algorithm, which upon successful termination yields irreducible
TRS's as output.
We conclude this section with a theorem stating that the Knuth-Bendix
completion algorithm, given an equational specication and a reduction or-
dering, cannot generate two dierent complete irreducible TRS's. Accord-
ing to Dershowitz, Marcus & Tarlecki [88] the theorem is originally due to
M. Ballantyne, but rst proved in Metivier [83].
Denition 1.4.22. Let > be a reduction ordering. We call a TRS R
compatible with > if for every rewrite rule !  of R we have  > :
52 J. W. Klop
More ecient version of the Knuth-Bendix completion algorithm
Input: { an equational specication (;E)
{ a reduction ordering > on Ter()
Output: - a complete irreducible TRS R such that for all
s; t 2 Ter() : s =
R
t , (;E) ` s = t
R := ?;
while E 6= ? do
choose an equation s = t 2 E;
reduce s and t to respective normal forms
while E 6= ? do
choose an equation s = t 2 E;
reduce s and t to respective normal forms s
0
and t
0
with respect to R;
if s
0
 t
0
then
E := E ? fs = tg
else
if s
0
> t
0
then
 := s
0
;  := t
0
else if t
0
> s
0
then
 := t
0
;  := s
0
else
failure
;
R := f ! 
0
j  !  2 R and ' is a normal form of 
with respect to R [ f! gg;
CP := fP = Q j hP;Qi is a critical pair between
the rules in R and ! g;
E := E [CP [ f =  j  !  2 R and  is reducible by
! g ? fs = tg;
R := R [ f! g ? f !  j  is reducible by ! g

od;
success
Figure 1.18
Theorem 1.4.23. (Metivier [83]) Let R
1
and R
2
be two complete irre-
ducible TRS's compatible with a given reduction ordering >. Suppose R
1
and R
2
dene the same convertibility. Then R
1
and R
2
are equal (modulo
a renaming of variables).
Exercise 1.4.24. (Huet [80]) In this exercise we collect some criteria for
conuence in terms of properties of critical pairs, as well as some counterexamples,
Term Rewriting Systems 53
from Huet [80]. Also some questions are listed which are, as far as we know, open.
See Table 1.15.
Table 1.15
1. In row 1 of the table the Critical Pair Lemma 1.4.11 is stated: if every
critical pair ht; si is convergent (notation: t # s), then WCR holds. How-
ever, CR need not to hold; a counterexample is given by the TRS with four
constants a; b; c; d and rules as in Figure 1.3.
2. Row 2 of the table is Theorem 1.4.14 of Knuth and Bendix.
3. In row 3, LL means that the TRS is left-linear, RL right-linear (i.e. no
right-hand side of a reduction rule contains repetitions of a variable).
Strongly conuent is dened in Exercise 1.0.8(10).
We furthermore dene:
DEFINITION. A TRS is strongly closed if for every every critical pair ht; si there
are t
0
, t
00
such that t  t
0
 

s and s  t
00
 

t. Prove that `strongly
closed' is not sucient to guarantee CR, by considering the non-left-linear TRS
fF (x; x)! A; F (x;G(x))! B; C ! G(C)g. However, if the TRS is left-linear,
right-linear and strongly closed, then CR holds (for a proof see Huet [80]); in
fact, we then have strong conuence.
4. In 3, RL cannot be dropped. A nice counterexample is in Huet [80], given
by J.-J. Levy: it contains the following eight left-linear rules. See also
Figure 1.19.
F (A;A) ! G(B;B) G(B;B) ! F (A;A)
A ! A
0
B ! B
0
F (A
0
; x) ! F (x; x) G(B
0
; x) ! G(x;x)
F (x;A
0
) ! F (x; x) G(x;B
0
) ! G(x;x)
Check that CR does not hold, and that the TRS is strongly closed.
54 J. W. Klop
Figure 1.19
5. This is a remarkable fact: if the TRS is left-linear, and for every critical
pair ht; si we have t !
jj
s, then WCR
1
holds, and hence CR. Here !
k
(parallel reduction) denotes a sequence of redex contractions at disjoint
occurrences.
6,7,8. If in 5 we replace t !
k
s by s !
k
t, then the CR question is open.
Likewise (7) if t !
k
s is replaced by s !

t, or (8) replaced by: \t !

s
or s!

t".
Exercise 1.4.25. Knuth & Bendix [70] contains completions of two speci-
cations which closely resemble the specication of groups (see Table 1.16), called
`L-R theory' and `R-L theory'. Prove, using the completions, that x  e = x is
not derivable in L-R theory and that in R-L theory the equations e  x = x and
x  I(x) = e are not derivable. Furthermore, in L-R theory the equation x  e = x
is not derivable. Hence the three theories are dierent, i.e. determine dierent
varieties of algebras. In fact, note that the variety of groups is a proper subset
of both the variety of L-R algebras and that of R-L algebras, and that the latter
two varieties are incomparable with respect to set inclusion.
1.5 An abstract formulation of completion
(This section is taken from Klop & Middeldorp [88].)
There are many completion algorithms such as the two above (in Figures
1.17 and 1.18), diering in order of execution or ways of optimization. The
question is, how to prove that these algorithms are correct, i.e. deliver
upon successful termination indeed a TRS R with the same equality as the
one generated by the original set of equations E. As there is a whole family
of completion algorithms, one needs to extract the `abstract principles' of
such algorithms; and this is done indeed by Bachmair, Dershowitz & Hsiang
[86]. Their method for proving correctness of completion algorithms starts
with the introduction of a derivation system where the objects are pairs
Term Rewriting Systems 55
group theory L-R theory: R-L theory:
e  x = x e  x = x x  e = x
I(x)  x = e x  I(x) = e I(x)  x = e
(x  y)  z = x  (y  z) (x  y)  z = x  (y  z) (x  y)  z = x  (y  z)
completion: completion: completion:
e  x! x e  x! x
x  e! x x  e! x
I(x)  x! e I(x)  x! e
x  I(x)! e x  I(x)! e
(x  y)  z ! x  (y  z) (x  y)  z ! x  (y  z) (x  y)  z ! x  (y  z)
I(e) ! e I(e) ! e I(e) ! e
I(x  y) ! I(y)  I(x) I(x  y) ! I(y)  I(x) I(x  y) ! I(y)  I(x)
x  (I(x)  y) ! y x  (I(x)  y) ! y
e  x! I(I(x))
I(x)  (x  y) ! y I(x)  (x  y) ! y
x  I(I(y)) ! x  y
I(I(x)) ! x
x  e! I(I(x))
I(I(I(x))) ! I(x) I(I(I(x))) ! I(x)
x  (y  I(y)) ! x
I(I(x))  y ! x  y
x  (I(I(y))  z)! x  (y  z)
x  (y  (I(y)  z))! x  z
I(x)  (x  y) ! I(I(y))
Table 1.16
(E;R); each derivation step from (E;R) to (E
0
; R
0
) preserves equality:
=
E[R
coincides with =
E
0
[R
0
; and moreover, along a sequence of derivations
the actual proofs of equations s = t will be getting `better and better', with
as optimal proof format that of a \rewrite proof". See Figure 1.20, where
it is shown how E (that is the pair (E;?)) is gradually transformed via
pairs (E
0
; R
0
) to a TRS R (that is the pair (?; R)); along the way the two
example proofs in Figure 1.20 get more and more oriented until they are
in rewrite form. (Here direction is downward; horizontal steps are without
direction.)
There are two crucial ideas in this recent approach. One is the concept
of a derivation system on pairs (E;R) as discussed above. The other is the
concept of ordering the proofs of equations s = t according to their degree
of orientation. We will now proceed to a more formal explanation.
56 J. W. Klop
Figure 1.20
Denition 1.5.1. Let (; E) be an equational specication. If s =
E
t by
application of exactly one equation in E we write s $
E
t. So s $
E
t i
there exists a context C[ ], a substitution  and an equation u = v (or
v = u) in E such that s  C[u

] and t  C[v

]:
Denition 1.5.2. Let (; E) be an equational specication and R a TRS
with signature :
1. A proof in E [R of an equation s = t between terms s; t 2 Ter() is
a sequence of terms (s
0
; : : : ; s
n
) such that s
0
 s; s
n
 t, and for all
0 < i  n we have s
i 1
$
E
s
i
, s
i 1
!
R
s
i
or s
i 1
 
R
s
i
:
2. A subproof of P  (s
0
; : : : ; s
n
) is a proof P
0
 (s
i
; : : : ; s
j
) with 0 
i  j  n: The notation P [P
0
] means that P
0
is a subproof of P .
(Actually, as occurrence of a subproof of P .)
3. A proof of the form s
0

R
s
k

R
s
n
is called a rewrite proof.
By denition, P  (s) is a proof of s = s. Figure 1.21 contains an
example of a proof.
Knuth-Bendix completion aims at transforming every proof (s
0
; : : : ; s
n
)
Term Rewriting Systems 57
Figure 1.21
into a rewrite proof s
0
 t  s
n
. We now present an inference system
for Knuth-Bendix completion. The objects of this system are pairs (E;R).
The inference system BC (basic completion) has the following rules (see
Table 1.17); > is a reduction ordering.
(C
1
) orienting an equation
(E [
0
fs =
0
tg; R) ) (E;R [ fs! tg) if s > t
(C
2
) adding an equation
(E;R) ) (E [ fs = tg; R) if s 
R
u!
R
t
(C
3
) simplifying an equation
(E [
0
fs =
0
tg; R) ) (E [ fu = tg; R) if s!
R
u
(C
4
) deleting a trivial equation
(E [
0
fs = sg; R) ) (E;R)
Table 1.17
The notation s =
0
t means s = t or t = s; the symbol [
0
denotes
disjoint union. A BC-derivation is a nite or innite sequence (E
0
; R
0
) )
(E
1
; R
1
)) (E
2
; R
2
))    . We write )
+
for the transitive closure of ).
It is easily seen that, given a derivation step (E;R)) (E
0
; R
0
), if R is
SN then so is R
0
and furthermore =
E[R
coincides with =
E
0
[R
0
. However,
proofs in E
0
[R
0
are in general `simpler' than in E [R. For example, by
adding equations to E by inference rule C
2
some subproofs s  
R
u !
R
t
can be replaced by s $
E
0
t. To formalize this reduction in complexity we
introduce orderings on proofs.
Denition 1.5.3. A binary relation  on proofs is monotonic if Q Q
0
implies P [Q] P [Q
0
] for all proofs P;Q and Q
0
. The relation  is stable
if
P  (s; : : : ; u
i
; : : : ; t)  (s; : : : ; v
j
; : : : ; t)  Q
implies that
58 J. W. Klop
(C[s

]; : : : ; C[u

i
]; : : : ; C[t

]) (C[s

]; : : : ; C[v

j
]; : : : ; C[t

])
for all proofs P and Q, contexts C[ ] and substitutions . A proof ordering
is a stable, monotonic, well-founded partial ordering on proofs.
Exercise 1.5.4. To illustrate the concept of proof ordering we will give an
alternative proof of Newman's Lemma 1.0.7(2) using this notion. (`Alternative'
with respect to the proofs that we have seen in the literature. The present proof
is nevertheless well-known.) See also Exercise 1.3.15 for our multiset notations.
Let R be a TRS which is SN and WCR. Let P  (s
0
; : : : ; s
n
) be a proof
of the conversion s
0
= s
n
. We dene the complexity j P j of the proof P as
the multiset [s
0
; : : : ; s
n
]. The ordering  which we will use is induced by the
multiset extension of !
+
R
, notation: (!
+
R
)

. So
P  P
0
i j P j (!
+
R
)

j P
0
j :
(This means that P  P
0
if the multiset j P
0
j arises from the multiset j P j
by repeatedly replacing an element of the multiset by arbitrarily many elements
which are less in the sense of the well-founded ordering !
+
R
. I.e. by repeatedly
replacing a term t in the multiset of terms by a number ( 0) of proper reducts
of t.)
1. Prove that  is a proof ordering.
2. If P  (s
0
; : : : ; s
n
) is not a rewrite proof, then there is a proof P
0
of the
equation s
0
= s
n
such that P  P
0
. (Hint: consider a `peak' in the
conversion P , and replace it by a `valley', using WCR. See Figure 1.22.)
3. Conclude that R is CR.
Figure 1.22
The proof ordering which we use for completion is based on the given
reduction ordering and on the elementary steps (!
R
; 
R
or $
E
) in a
proof.
Term Rewriting Systems 59
Denition 1.5.5.
1. The complexity j P j of a proof P  (s
0
; : : : ; s
n
) is the multiset
[c(s
0
; s
1
); : : : ; c(s
n 1
; s
n
)] where c(s
i 1
; s
i
), the complexity of an ele-
mentary proof step, is dened by
c(s
i 1
; s
i
) =
8
<
:
[s
i 1
] if s
i 1
!
R
s
i
[s
i
] if s
i 1
 
R
s
i
[s
i 1
; s
i
] if s
i 1
$
E
s
i
2. To compare the complexities of the elementary proof steps we use
the multiset extension >

of the reduction ordering >. (See Exercise
1.3.15.) To compare proof complexities we use the multiset extension
of >

; notation: >

: Now we dene:
P 
BC
P
0
, jP j>

jP
0
j :
Denition 1.5.6. A proof ordering is compatible with BC if (E;R))
+
(E
0
; R
0
) implies that for every proof P in E [R of an equation s = t there
exists a proof P
0
of s = t in E
0
[R
0
such that P  P
0
or P  P
0
:
The following proposition has a straightforward proof, which follows
from considering Figure 1.23 and applying stability and monotonicity of

BC
. Figure 1.23 suggests how proofs are reduced in complexity by appli-
cation of a transformation step according to C
1
; : : : ; C
4
: For instance, in the
case of C
2
(see Figure 1.23) the complexity of the subproof t 
R
s!
R
u is
[[s]; [s]] which decreases to the complexity of the subproof t$
R
u, namely
[[t; u]]. This is indeed a decrease since [s] >

[t; u].
Proposition 1.5.7. The ordering !
BC
is a proof ordering, which more-
over is compatible with BC.
So in a BC-derivation (E
0
; R
0
)) (E
1
; R
1
)) (E
2
; R
2
))    the proofs
in E
j
[R
j
are no more dicult than corresponding proofs in E
i
[R
i
; for
all j > i. The following fairness property of BC-derivations implies that
moreover every proof in E
i
[ R
i
of an equation s = t which is not yet a
rewrite proof, can be simplied to a rewrite proof of s = t in E
j
[R
j
for
some j > i:
Denition1.5.8. A BC-derivation (E
0
; R
0
)) (E
1
; R
1
)) (E
2
; R
2
))   
is called fair if
1.
T
j>i
E
j
= ? for all i  0, and
2. if hc; di 2
T
ji
CP
j
for some i  0 then c = d 2 E
k
for some k  0.
(CP
j
is the set of all critical pairs between the rewrite rules of R
j
.)
So, according to (2) every critical pair which arises will be (or was)
an equation at some time, and by (1) every equation will be `considered'
60 J. W. Klop
Figure 1.23
eventually, that is, oriented in a rewrite rule, simplied, or deleted. The
following fact can now be proved routinely.
Proposition 1.5.9. Let (E
0
; R
0
) ) (E
1
; R
1
) ) (E
2
; R
2
) )    be a fair
BC-derivation and let P be a proof of s = t in E
i
[ R
i
. If P is not yet a
rewrite proof then for some j  i there exists a proof P
0
in E
j
[R
j
of s = t
such that P 
BC
P
0
.
By a completion procedure we mean a strategy for applying the inference
rules of BC to inputs (; E) and reduction ordering >, in order to generate
a BC-derivation (E
0
; R
0
) ) (E
1
; R
1
) )    with (E
0
; R
0
) = (E;?). Be-
cause for some inputs a fair derivation may not be possible, we allow for a
completion procedure to fail. We say that a completion procedure is fair if
it generates only fair derivations unless it fails. We now have:
Theorem 1.5.10. (Bachmair, Dershowitz & Hsiang [86]) Let C be a fair
completion procedure that does not fail on input (; E) and > :
1. If s =
E
t then C will generate a pair (E
i
; R
i
) such that s and t have
Term Rewriting Systems 61
a common reduct in R
i
:
2. R
1
(=
S
n
R
n
) is a complete TRS.
1.6 Unication
In the preceding sections about completion algorithms, we have used as a
`subroutine' the determination of a most general unier of two terms. In
the present section we will describe a version of a unication algorithm, due
to Martelli & Montanari [82]; this nondeterministic algorithm to compute
mgu's is itself phrased in the terminology of rewriting. We start with pre-
senting the rewrite rules for `syntactic unication', and afterwards extend
these rules to include `semantic unication' or `E-unication'.
Syntactic unication
Before presenting the syntactic unication algorithm, we introduce some
more concepts about substitutions, which were dened in Section 1.1 as
homomorphisms (with respect to term formation) from the set of terms
Ter(R) of the TRS R to Ter(R). The composition of substitutions ;  is
the usual one for functions: (  )(t) =  ((t)) for t 2 Ter(R); however,
   will be written as  , and in accordance with our earlier notation
convention, (t) as t

. Note that this notation is unambiguous: (t

)

=
t
()
:
The support of substitution  is the restriction of  to the set of those
variables x
i
for which x
i
6 x

i
. Usually, the support will be nite, and in
this case we write  (by some `abus de langage') as its support, which is a
nite list of `bindings' of terms to variables:
fx
i
1
:= t
i
; : : : ; x
i
n
:= t
n
g:
A renaming substitution is a bijective substitution. This implies that a
renaming, restricted to the set of variables V ar = fx
i
j i  0g, is a permu-
tation of V ar. Note that the composition  of renamings ;  is again a
renaming, and that the inverse 
 1
of a renaming  exists and is again a
renaming. Terms s; t diering a renaming, i.e. t

 s for some renaming
; are called variants (of each other).
If t; s are terms such that t

 s for some substitution ; we write
t  s. The relation  is not yet a partial ordering; it is a quasi-ordering,
also called the subsumption relation. One easily proves for all s; t 2 Ter(R):
s  t & t  s , s; t are variants. For substitutions ;  we write    if
 =  for some substitution . In this case  is called more general than
 . (The `overloading' of the symbol  will cause no confusion.) Analogous
to the case of terms, one easily proves:    &    , ;  dier a
renaming ( =  for some renaming ).
62 J. W. Klop
We call  a unier of a set of terms T = ft
1
; : : : ; t
n
g if t

1
 t

n
. It is a
most general unier (mgu) of T if for every unier  of T we have    .
Each nite set of terms which can be unied (has a unier) has a mgu; it
is unique modulo renamings.
The task of nding a most general unier of two terms F (t
1
; : : : ; t
n
) and
F (s
1
; : : : ; s
n
) can be viewed as the task of solving the set of equations ft
1
=
s
1
; : : : ; t
n
= s
n
g. A very elegant algorithm exploiting this representation
was given by Martelli-Montanari [82]. It consists of rules which transform
one set of equations into another one. To conform with the notation in
`equational logic programming' as in Holldobler [89], we write instead of
ft
1
= s
1
; : : : ; t
n
= s
n
g :
( t
1
= s
1
; : : : ; t
n
= s
n
;
called also an equational goal. The empty goal (empty set of equations)
will be denoted as . The algorithm to be presented transforms, nonde-
terministically, goals into goals; just as in logic programming we intend to
end a sequence of transformations in the empty goal:
G
0
 G
1
    :
Here  denotes an elementary `derivation' step; G
0
; G
1
; : : : are equa-
tional goals. Actually, at some of the -steps we may obtain as a `side-
eect' a substitution ; it will be denoted as a subscript, so that such a
step has the form G

G
0
. So a derivation may have the form, e.g.:
G
0
 G
1


1
G
2


2
G
3
 G
4
 G
5


5
G
6
    :
Derivation sequences ending in  are successful; it will also be possible
that a derivation is stuck and cannot be prolonged to reach , because no
transformation rule applies. In that case we conclude the sequence after
the goal where the sequence got stuck, with the symbol  (for `failure'):
G
0
 G
1
    :
In the case of a successful derivation, we can obtain the `harvest' by com-
posing all the substitutions that are found, in their order of appearance; in
the example above: 
1

2

5
   . This substitution is the computed answer
substitution of the successful derivation that we are considering.
We will now present the four derivation rules for equational goals that
together constitute a unication algorithm. With some adaptations, these
`Martelli-Montanari rules' (MM-rules) are as follows. Here ( t = s; E
stands for an equational goal containing the equation t = s; with E we
denote the remaining equations in the goal.
Term Rewriting Systems 63
1. Term decomposition
( F (t
1
; : : : ; t
n
) = F (s
1
; : : : ; s
n
); E

( t
1
= s
1
; : : : ; t
n
= s
n
; E
2. Removal of trivial equations
( x = x; E  ( E
3. Swap
( t = x; E  ( x = t; E
if t is not a variable
4. Variable elimination
( x = t; E 
fx:=tg
( E
fx:=tg
if x 62 t
(If E is t
1
= s
1
; : : : ; t
n
= s
n
; then E

is t

1
= s

1
; : : : ; t

n
= s

n
. With
`2' we abbreviate `occurs in'. Note that only in transformation rule (4) a
substitution is delivered.)
We have the following well-known `completeness' theorem:
Theorem 1.6.1. (Unication Theorem) Let G be an equational goal
( t
1
= s
1
; : : : ; t
n
= s
n
. Then the following are equivalent:
1. the equations in G can be unied;
2. there is a mgu  such that t

1
 s

1
; : : : ; t

n
 s

n
;
3. the derivation tree with root G and constructed with the MM rules
is nite and has only success branches, all yielding an mgu of the
equations in G as computed answer substitution.
Furthermore, if the equations in G cannot be unied, the MM-derivation
tree with root G is also nite, but now with all branches ending unsuccess-
fully.
(It will be clear what is meant in the statement of the theorem above
with derivation tree; it arises because the rules can be applied nondeter-
ministically.) In the original presentation of Martelli and Montanari, the
following two rules are also included; they enhance eciency, by pruning
the MM-derivation tree of some unsuccessful subtrees. But we don't need
them for the completeness of this (nondeterministic) unication algorithm.
(Also, when extending the set of rules to deal with E-unication, as we will
do below, (5) and (6) must be omitted.)
64 J. W. Klop
5. Failure rule
( F (t
1
; : : : ; t
n
) = G(s
1
; : : : ; s
m
); E  
6. Occur check
( x = t; E  
if x 6 t and x 2 t
It is not hard to prove that the MM rules are indeed terminating, as
stated by the Unication Theorem. (See Martelli-Montanari [82], Apt [90],
or Dershowitz & Jouannaud [90].)
If t; s are uniable terms we will denote with mgu(s; t) a particular
mgu of fs; tg, obtained by performing the MM transformations according
to some xed strategy.
Example 1.6.2.
1. We want to determine `the' mgu of the terms F (G(x);H(x; u)) and
F (z;H(F (y; y); z)). The MM rules yield the following successful
derivation:
( F (G(x);H(x; u)) = F (z;H(F (y; y); z)) 
(1)
( G(x) = z; H(x; u) = H(F (y; y); z) 
(3)
( z = G(x); H(x; u) = H(F (y; y); z) 
(4);fz:=G(x)g
( H(x; u) = H(F (y; y); G(x)) 
(1)
( x = F (y; y); u = G(x) 
(4);fx:=F (y;y)g
( u = G(F (y; y)) 
(4);fu:=G(F (y;y))g

with computed answer substitution fz := G(x)gfx := F (y; y)gfu :=
G(F (y; y))g = fz := G(F (y; y)); x := F (y; y); u := G(F (y; y))g. In-
deed this is a mgu of the original pair of terms.
2. A failing unication attempt:
( F (x; y) = F (y;G(x)) 
(1)
( x = y; y = G(x) 
(2);fx:=yg
( y = G(y) 
(6)

Semantic unication
In the previous section we have presented an algorithm to solve equations
t
1
= t
2
`syntactically'; this is a particular case of the important problem
to solve equations `semantically', i.e. modulo some equational theory E
(for this reason semantic unication is also called E-unication). More
Term Rewriting Systems 65
precisely, in the presence of an equational theory E, and given an equa-
tion t
1
= t
2
, we want to nd substitutions  such that E  t

1
= t

2
or
equivalently (see Theorem 1.4.2) E ` t

1
= t

2
. So syntactic unication is
E-unication with empty E.
The situation is now much more complicated than for the case of syn-
tactic unication, since in general there will not be a most general unier
 for t
1
; t
2
. We will not really enter the vast area of unication theory (see
Siekmann [84]), but will mention two algorithms for E-unication which
are pertinent to term rewriting. Both algorithms operate under the as-
sumption that E, the underlying equational theory, is a complete TRS (or
rather corresponds to one after orienting the equality axioms of E into
rewrite rules). So here we have another important application of Knuth-
Bendix completion: it prepares the way for equation solving over E, by
delivering a complete TRS for E (if possible).
Narrowing
A well-known technique to solve equations t
1
= t
2
in the presence of an
equational theory E uses the `narrowing' transformation on terms. We will
give an `intuitive' explanation rst, which also explains why narrowing is
called `narrowing'.
If (; E) is an equational theory, we write [t = s]
E
for the set of solutions
of the equation t = s in E, i.e. f j E ` t

= s

g. A solution  is a
substitution as dened earlier, i.e. a map from V ar, the set of variables,
to Ter(). Let Sub be the set of all substitutions, and if X  Sub, let
X denote f j  2 Xg. Now noting that for every  we have [t = s]
E

[t

= s

]
E
, there is in principle the possibility of a stepwise determination
of [t = s]
E
. This stepwise determination consists of two kind of steps. The
rst is as just described: guess a component  of a solution and narrow
[t = s]
E
to [t

= s

]
E
. The second is: apply an equation of E in one of
the sides of the equation t = s under consideration. Clearly, a step of the
second kind preserves equality of the solution set. By an iteration of such
steps, alternating between steps of the rst kind and steps of the second
kind, we may reach the solution set of a trivial equation r = r (which is
Sub):
[t = s]
E
 [t

= s

]
E
= [r = s

]
E
 
1
[r

1
= s

1
]
E
=   
   
 
1
  
n
[r = r]
E
:
The last solution set 
1
  
n
[r = r]
E
of this `narrowing' chain has as
a most general element the substitution 
1
  
n
. The word `narrowing'
has been given a formal content: it denotes a certain method, based on
66 J. W. Klop
term rewriting, to perform a stepwise determination of [t = s]
E
as de-
scribed. A narrowing step combines a step of the rst kind and one of the
second. Actually, the narrowing relation is rst dened on terms rather
than equations, as in the following denition, where we suppose that R is
a TRS equivalent to E (i.e. =
R
coincides with =
E
). Note that narrowing
is a generalization of reduction: any reductions step in a TRS is also a
narrowing step. Formally:
Denition 1.6.3. Let term t contain the subterm u, so t  C[u] for some
context C[ ]. In the presence of a TRS R we say that t is narrowable to t
0
at the (nonvariable) subterm u  t using rewrite rule r : t
1
! t
2
2 R, via
 = mgu(u; t
1
), if t
0
 C[t
2
]

. Notation: t ;
u;r;
t
0
. (Sometimes we will
drop mention of u; r; but not of .)
Figure 1.24
We now extend the narrowing transformation, which was dened on
terms, to equations: if t;

t
0
, then t = s;

t
0
= s and likewise s = t;

s = t
0
are said to be narrowing steps (on equations). As we have seen, the
word narrowing actually refers to the solution sets: if t = s;

t
0
= s

then
[t = s]
R
 [t

= s

]
R
. Note how narrowing cuts down the search space for
determining the solution set, rst by using the directional aspect of a TRS,
and second by performing substitutions which are as `small' (as general)
as possible. However, there is a price to be paid: to ensure completeness
Term Rewriting Systems 67
of the narrowing method for solving equations, we must require that the
underlying TRS is . . . complete. More precisely (as stated in Hullot [80]): in
order to solve an equation t
1
= t
0
1
in an equational theory E, corresponding
to a complete TRS R, we can construct all possible narrowing derivations
starting from the given equation until an equation t
n
= t
0
n
is obtained such
that t
n
and t
0
n
are syntactically uniable. In fact, we are sure to nd all
possible solutions of the equation. We will make this more precise, via the
following denition.
Denition 1.6.4. Let ;  be substitutions and E an equational theory.
Then  
E
 if for some  we have  =
E
. (Here  =
E
 means:
E ` x

= x

for all x.)
Now we have the following completeness theorem for narrowing plus
syntactic unication. (See Martelli, Moiso & Rossi [86], Theorem 2. See
also Holldobler [89] for a proof of this theorem and many related facts.) The
formulation of the theorem refers to a slightly more general setting than in
our discussion of narrowing above: the narrowing procedure may be applied
not only to single equations, but to equational goals( t
1
= s
1
; : : : ; t
n
= s
n
.
Theorem 1.6.5. Let R be a complete TRS. Suppose t

1
=
R
t

2
(i.e.  is
a solution of the equation t
1
= t
2
). Then there is a successful derivation
sequence starting with ( t
1
= t
2
and using narrowing steps and MM
steps (1{4), such that the computed answer substitution  of this sequence
`improves' , i.e.  
R
:
Remark 1.6.6.
1. Note that the subscript R in  
R
 is necessary. (Example: R =
ff(b) ! g(b); a ! bg. Now  = fx=ag is a solution for ( f(x) =
g(x), but as computed answer substitution we only nd  = fx=bg:)
2. Also completeness of R is necessary.
(a) To see that conuence of R is necessary, consider the TRS R =
fa! b; a! cg (so R is not conuent). Now the equation( b =
c cannot be solved, i.e. we do not nd the expected computed
answer substitution  (the identity substitution). However, if
we turn R into a conuent system, e.g. by adding the rewrite
rules b! d and c! d, then narrowing (together with syntactic
unication) gives a refutation of ( b = c:
( b = c ;

( d = c ;

( d = d 
1
:
(b) To see that termination of R is necessary, consider the conu-
ent but nonterminating TRS with one rule: c ! f(c). Now
narrowing plus syntactic unication is not complete: the equa-
tion x = f(x) has a solution, fx := cg, but cannot be resolved,
68 J. W. Klop
because the only subterm where narrowing may be applied is
f(x) (narrowing may not be performed on a variable) and this
does not unify with c. (Also syntactic unication does not help,
since x occurs in f(x).) So we do not nd a computed answer
substitution.
3. Theorem 1.6.5 can be improved in the following sense: we can drop
the termination requirement on R, thus only requiring R to be conu-
ent, if we consider only normalizable solutions  (as in the statement
of the theorem above). Here  is called normalizable if all terms x

(x a variable) have a normal form. (Note that the solution fx := cg
in 2(b) was not normalizable.) If moreover we consider not only nor-
malizable solutions ; but normal  (meaning that every x

is in
normal form), then we can even drop the subscript R in  
R
, in
the statement of the theorem above.
Lazy term rewriting as a complete E-unication algorithm
An interesting complete E-unication algorithm is given by Martelli, Moiso
& Rossi [86], also for the case where E corresponds after orienting the
equations to a complete TRS R. The nondeterministic algorithm consists
of the four derivation rules (1){(4) for syntactic unication as given above
together with a single rule called `term rewriting' in Martelli e.a. [86]. Of
course derivation rules 5 (failure rule) and 6 (occur check) are not included
now. Actually, this rule does not resemble what is usually called term
rewriting. Here we will call the present rule `lazy term rewriting'.
7. Lazy term rewriting
( C[F (t
1
; : : : ; t
n
)] = s; E

( C[t] = s; t
1
= s
1
; : : : ; t
n
= s
n
; E
if F (s
1
; : : : ; s
n
)! t
and likewise with the reverse of the equations C[F (t
1
; : : : ; t
n
)] = s and
C[t] = s. Here C[ ] is some context, and F (s
1
; : : : ; s
n
)! t is a rewrite rule
from the complete TRS R.
Note how amazingly little is `done' in a lazy term rewriting step, as
compared to the rather complicated narrowing procedure.
2 Orthogonal Term Rewriting Systems
In the preceding sections we have considered general properties of TRS's
and how these properties are related; among them the most important
property, conuence, with its consequence of uniqueness of normal forms.
Term Rewriting Systems 69
We will now consider a special class of TRS's, the orthogonal ones (in the
literature mostly known as non-ambiguous and left-linear TRS's), which all
have the conuence property as well as various other desirable properties
concerned with reduction strategies.
A remark concerning the choice of the word `orthogonal': to avoid the
cumbersome phrase `non-ambiguous and left-linear', Klop [80a] introduced
the abbreviation `regular'. This terminology is also used in e.g. O'Donnell
[85], Kennaway [89], Klop [87], and in early versions of Dershowitz & Jouan-
naud [90]. On a proposal of Dershowitz and Jouannaud the word `regular'
has been replaced in the present paper by `orthogonal'; this in view of
the fact that many authors found the terminology `regular' objectionable.
Indeed, the word `orthogonal' has the right intuitive connotations.
2.1 Basic theory of orthogonal TRS's
Denition 2.1.1.
1. A TRS R is orthogonal if the reduction rules of R are left-linear (R
is left-linear) and there are no critical pairs.
2. R is weakly orthogonal if R is left-linear and R contains only trivial
critical pairs, i.e. ht; si is a critical pair then t  s.
We recall that a reduction rule t ! s is left-linear if t is linear, i.e.
no variable occurs twice or more in t. E.g. the rule D(x; x) ! E is not
left-linear; nor is the rule if x then y else y ! y. A TRS R without critical
pairs is also called non-ambiguous or non-overlapping. One problem with
non-left-linear rules is that their application requires a test for syntactic
equality of the arguments substituted for the variables occurring more than
once. As terms may be very large, this may be very laborious. Another
problem is that the presence of non-left-linear rules may destroy the CR
property.
Exercise 2.1.2. Let R consist of the rules D(x; x)! E, C(x)! D(x;C(x)),
A! C(A). To show: R is WCR, but not CR; for, we have reductions C(A) E
and C(A)  C(E) but C(E), E have no common reduct. There are no critical
pairs in R. Hence, in view of our later theorem stating that orthogonal TRS's are
conuent, the non-conuence of R is caused by the non-left-linear rule D(x; x)!
E.
In the preceding section (Denition 1.4.9) we have already dened the
notion of `critical pair'. Since that denition is often found dicult, we
will now explain the absence of critical pairs in a more `intuitive' way. Let
R be the TRS as in Table 2.1:
70 J. W. Klop
r
1
F (G(x; S(0)); y;H(z)) ! x
r
2
G(x; S(S(0))) ! 0
r
3
P (G(x; S(0))) ! S(0)
Table 2.1
Call the context F (G(; S(0));;H()) the pattern of rule r
1
. (Earlier,
we dened a context as a term with exactly one hole , but it is clear what
a context with more holes is.) In tree form the pattern is the shaded area
as in Figure 2.1. For a left-linear rule it is only its pattern that `counts'.
Figure 2.1
Figure 2.2
The TRS R in Table 2.1 has the property that in no term patterns can
overlap, i.e. R has the non-overlapping or non-ambiguity property. Figure
2.2 shows a term in R with all patterns indicated, and indeed they do not
overlap.
Term Rewriting Systems 71
Overlap can already occur in one rule, e.g. in the rule L(L(x)) ! 0;
see Figure 2.3(a). An overlap at the root (of the tree corresponding to a
term), arising from the rules F (0; x; y) ! 0, F (x; 1; y) ! 1, is shown in
Figure 2.3(b). Another overlap at the root, arising from the rules for the
non-deterministic or: or(x; y)! x, or(x; y)! y, is shown in Figure 2.3(c).
Figure 2.3
We will now formulate and sketch the proofs of the basic theorems for
orthogonal TRS's. To that end, we need the notion of `descendant ' in a
reduction. Somewhat informally, this notion can be introduced as follows:
Let t be a term in a orthogonal TRS R, and let s  t be a redex whose head
symbol we will give a marking, say by underlining it, to be able to `trace' it
during a sequence of reduction (rewrite) steps. Thus if s  F (t
1
; : : : ; t
n
), it
is marked as F (t
1
; : : : ; t
n
). First consider the rewrite step t!
s
0
t
0
, obtained
by contraction of redex s
0
in t. We wish to know what has happened in
this step to the marked redex s. The following cases can be distinguished,
depending on the relative positions of s and s
0
in t:
Case 1. The occurrences of s
0
and s in t are disjoint. Then we nd back
the marked redex s, unaltered, in t
0
.
Case 2. The occurrences of s and s
0
coincide. Then the marked redex has
disappeared in t
0
; t
0
does not contain an underlined symbol.
Case 3. s
0
is a proper subterm of the marked redex s (so s
0
is a subterm of
one of the arguments of s). Then we nd back the marked redex, with some
possible change in one of the arguments. (Here we need the orthogonality
of R; otherwise the marked redex could have stopped being a redex in t
0
after the `internal' contraction of s
0
.)
Case 4. s is a proper subterm of s
0
. Then the marked redex s is n times
multiplied for some n  0; if n = 0, s is erased in t
0
. The reduct t
0
now
contains n copies of the marked redex, all of them still marked.
Now the marked redexes in t
0
are called the descendants of s  t in
the reduction step t !
s
0
t
0
. It is obvious how to extend this denition
72 J. W. Klop
by transitivity to sequences of rewrite steps t !
s
0
t
0
!
s
00
t
00
!    !
t
(n 1)
!
s
(n)
t
(n)
:
Proposition 2.1.3. Let R be a orthogonal TRS, t 2 Ter(R). Let t con-
tain, possibly among others, the mutually disjoint redexes s
1
; : : : ; s
n
. Let
these redexes be marked by underlining their head symbol. Furthermore,
suppose that t t
0
is the sequence of n rewrite steps obtained by contrac-
tion of all redexes s
i
(in some order), and let t !
s
t
00
be a rewrite step
obtained from contracting redex s. (See Figure 2.4(a).) Then a common
reduct t
000
of t
0
; t
00
can be found by contracting in t
00
all marked redexes
(which still are mutually disjoint). The reduction t
0
 t
000
consists of the
contraction of all descendants of s in t
0
after the reduction t t
0
.
Figure 2.4
The proof is a matter of easy casuistics, left to the reader. An immediate
corollary is the `Parallel Moves Lemma':
Lemma 2.1.4. (Parallel Moves Lemma) We consider reductions in an
orthogonal TRS. Let t  t
00
, and let t !
s
t
0
be a one step reduction by
contraction of redex s. Then a common reduct t
000
of t
0
; t
00
can be found by
contraction in t
00
of all descendants of redex s, which are mutually disjoint.
(See Figure 2.4(b).)
By repeated application of the Parallel Moves Lemma we now have:
Theorem 2.1.5. Every orthogonal TRS is conuent.
Theorem 2.1.5 also holds for weakly orthogonal TRS's. The earliest
proof of Theorem 2.1.5 is probably that of Rosen [73]; but earlier proofs of
the conuence of CL (Combinatory Logic), work just as well for orthogonal
TRS's in general. The conuence theorem for (weakly) orthogonal TRS's
is also a special case of a theorem of Huet (mentioned already in Exercise
1.4.24), stated here without proof. We need a denition rst:
Denition 2.1.6. (Parallel reduction) t !
k
s if t  s via a reduction of
disjoint redexes.
Term Rewriting Systems 73
Theorem 2.1.7. (Huet [80]) Let R be a left-linear TRS. Suppose for
every critical pair ht; si we have t !
k
s. Then !
k
is strongly conuent,
hence R is conuent.
(For the denition of `strongly conuent' see Exercise 1.0.8(10). In
fact, the proof in Huet [80] yields more: !
k
is even subcommutative|see
Denition 1.0.1(5).)
Exercises 2.1.8.
1. Combinatory Logic (Table 1.4) has rule patterns as in Figure 2.5; they
cannot overlap. As CL is left-linear, it is therefore orthogonal and hence
conuent.
Figure 2.5
2. SKIM, in Table 1.5, is orthogonal. Likewise for the TRS's CL with test for
equality, binary or applicative, in Tables 1.6, 1.7 respectively. Also Weak
Categorical Combinatory Logic in Table 1.8 is orthogonal.
3. A Recursive Program Scheme (RPS) is a TRS with
(a) a nite set of function symbols F = fF
1
; : : : ; F
n
g (the `unknown'
functions), where F
i
has arity m
i
 0 (i = 1; : : : ; n), and
(b) a nite set G = fG
1
; : : : ;G
k
g (the `known' or `basic' functions), dis-
joint from F , where G
j
has arity p
j
 0 (j = 1; : : : ; k),
(c) reduction rules of the form
F
i
(x
1
: : : ; x
m
i
)! t
i
(i = 1; : : : ; n)
where all the displayed variables are pairwise dierent and where t
i
is an arbitrary term built from operators in F ;G and the displayed
variables. For each F
i
(i = 1; : : : ; n) there is exactly one rule.
Every RPS is orthogonal, hence conuent. For an extensive treatise on
semantical aspects of Recursive Program Schemes, see Courcelle [90].
Exercise 2.1.9. For a deterministic Turing machine M , the TRS R
M
as
dened in Exercise 1.2.21 is orthogonal.
Apart from conuence, many interesting facts can be proved for orthog-
onal TRS's.
74 J. W. Klop
Denition 2.1.10.
1. A TRS is non-erasing if in every rule t! s the same variables occur
in t and in s. (E.g. CL is not non-erasing, due to the rule Kxy ! x.)
2. A TRS is weakly innermost normalizing (WIN) if every term has a
normal form which can be reached by an innermost reduction. (In an
innermost reduction a redex may only be `contracted' if it contains
no proper subredexes.)
The next theorem was proved in Church [41] for the case of the non-
erasing version of -calculus, the I-calculus, where the restriction on term
formation is adopted saying that in every abstraction term x:M the vari-
able x must have a free occurrence in M .
Theorem 2.1.11. Let R be orthogonal and non-erasing. Then: R is WN
i R is SN.
Another useful theorem, which also reduces the burden of a termination
(SN) proof for orthogonal TRS's, is:
Theorem 2.1.12. (O'Donnell [77]) Let R be an orthogonal TRS. Then:
R is WIN i R is SN.
The last two theorems can be rened to terms: call a termWN if it has a
normal form, SN if it has no innite reductions, WIN if it has a normal form
reachable by an innermost reduction. The `local' version of Theorem 2.1.11
then says that for a term in an orthogonal, non-erasing TRS the properties
WN and SN coincide. Likewise there is a local version of Theorem 2.1.12.
Thus, if in CL a term can be normalized via an innermost reduction, all
its reductions are nite.
Exercise 2.1.13. In this exercise we sketch a proof of Theorem 2.1.11 and
O'Donnell's Theorem 2.1.12.
1. The following proposition has an easy proof:
PROPOSITION. Let t be a term in an orthogonal TRS, containing mu-
tually disjoint redexes s
1
; : : : ; s
n
, and a redex s. Let t  t
0
be the n-step
reduction obtained by contraction, in some order, of the redexes s
1
; : : : ; s
n
.
Suppose s has after the reduction t  t
0
no descendants in t
0
. Then for
some i 2 f1; : : : ; ng: s  s
i
. This means that either s coincides with some
s
i
, or is contained in an argument of some s
i
.
2. We write `1(t)' if the term t has an innite reduction t!!    . So 1(t)
i t is not SN. Using the proposition in (1) one can now prove (the proof
is non-trivial):
LEMMA. Let t be a term in an orthogonal TRS such that1(t). Let t!
s
t
0
be a reduction step such that :1(t
0
). Then the redex s must contain a
proper subterm p with 1(p) that is erased in the step t !
s
t
0
(i.e. has no
Term Rewriting Systems 75
descendants in t
0
).
3. Using the Lemma it is now easy to prove Theorem 2.1.11: `critical' steps
t! t
0
in which 1(t) but :1(t
0
), cannot occur in a non-erasing TRS.
4. Theorem 2.1.12 follows from the Lemma in (2) by observing that an inner-
most contraction cannot erase a proper subterm which admits an innite
reduction, since otherwise the contracted redex would not have been in-
nermost.
Exercise 2.1.14. STS's (Semi-Thue Systems), viewed as TRS's as explained
in Section 1.1, are always non-erasing (since left-hand side and right-hand side
of every rule end in x, in their TRS version). Also, if there are no critical pairs
in the STS, it is orthogonal. So if a STS has no critical pairs, the properties SN
and WN coincide.
This rather trivial observation could have been more easily made by noting
that for a STS without critical pairs the property WCR
1
holds, as dened in
Exercise 1.0.8(15), whence WN , SN.
Exercise 2.1.15. (Klop [80a]) Let t
0
be a term in an orthogonal TRS.
Suppose t
0
has a normal form, but has also an innite reduction t
0
! t
1
! t
2
!
   . Show that t
0
has also an innite `expansion' (the reverse of a reduction)
   ! t
 2
! t
 1
! t
0
: (Hint: use the lemma in Exercise 2.1.13, and note that
an `erasing redex' can be used to `pump' an innite expansion.)
Exercise 2.1.16. (Klop [85])
1. Let R be orthogonal, and suppose R is WN (i.e. every term has a normal
form), but not SN. Let t 2 Ter(R) be a term with an innite reduction.
Then G(t), the reduction graph of t, contains an innite expansion (by
conuence, there must then also be an innite expansion of the normal
form t
0
of t inside G(t)). In fact, G(t) contains reductions as follows:
t t
1
 t
2
    and t
0
 t
0
1
 t
0
2
   
such that t
n
! t
0
n
for all n  1 and such that the t
i
(n  1) are pairwise
distinct, and likewise the t
0
j
(n  1) are pairwise distinct.
2. Let t be a term in an orthogonal TRS. Prove: if G(t) contains an innite
reduction but contains no innite acyclic expansion, then t reduces to a
context C[ ] of a term s without normal form. (The set of s such that
t  C[s] for some C[ ], is called in Barendregt [81] the family of t.) (In
particular the conclusion holds if G(t) is nite but contains a reduction cy-
cle. Curiously, in CL as in Table 1.4 this is impossible, i.e. nite reduction
graphs in CL based on S;K;I are acyclic; see Klop [80b].)
3. The following gure displays the reduction graph of a term t in an orthog-
onal TRS R. Give an example of such t, R. Conclude, using (2), that t
must have a term without normal form in its family. A fortiori, such a
reduction graph cannot occur in an orthogonal TRS which is WN.
76 J. W. Klop
Figure 2.6
Exercise 2.1.17. (Klop [80a]) Prove for all orthogonal TRS's R with nite
alphabet and nitely many rules:
1. R is non-erasing , R has the property FB
 1
. (See Denition 1.0.3(8) for
FB
 1
.)
2. R has the property SN
 1
, R has the property Inc. (See Denition 1.0.3.)
(Hint: Prove SN
 1
) non-erasing, use (1) and use the implication FB
 1
& SN
 1
) Inc; see Figure 1.2.)
2.2 Reduction strategies for orthogonal TRS's
Terms in a TRS may have a normal form as well as admitting innite
reductions. So, if we are interested in nding normal forms, we should have
some strategy at our disposal telling us what redex to contract in order to
achieve that desired result. We will in this section present some strategies
which are guaranteed to nd the normal form of a term whenever such a
normal form exists. We will adopt the restriction to orthogonal TRS's; for
general TRS's there does not seem to be any result about the existence of
`good' reduction strategies.
The strategies below will be of two kinds: one step or sequential strate-
gies (which point in each reduction step to just one redex as the one to
contract) and many step strategies (in which a set of redexes is contracted
simultaneously). Of course all strategies must be computable.
Apart from the objective of nding a normal form, we will consider the
objective of nding a `best possible' reduction even if the term at hand
does not have a normal form.
Term Rewriting Systems 77
Denition 2.2.1. Let R be a TRS.
1. A one step reduction strategy F for R is a map F: Ter(R) ! Ter(R)
such that
(a) t  F(t) if t is a normal form,
(b) t! F(t) otherwise.
2. A many step reduction strategy F for R is a map F: Ter(R)! Ter(R)
such that
(a) t  F(t) if t is a normal form,
(b) t!
+
F(t) otherwise.
Here !
+
is the transitive (but not reexive) closure of !. Instead of `one
step strategy' we will also say `sequential strategy'.
Denition 2.2.2.
1. A reduction strategy (one step or many step) F for R is normalizing
if for each term t in R having a normal form, the sequence fF
n
(t) j
n  0g contains a normal form.
2. F is conal if for each t the sequence fF
n
(t) j n  0g is conal in
G(t), the reduction graph of t. (See Exercise 1.0.8(13) for `conal'
and see Figure 2.7.)
Figure 2.7
A normalizing reduction strategy is good, but a conal one is even bet-
ter: it nds, when applied on term t, the best possible reduction sequence
starting from t (or rather, a best possible) in the following sense. Consider
a reduction t ! s as a gain in information; thus normal forms have max-
imum information. In case there is no normal form in G(t), one can still
consider innite reductions as developing more and more information. Now
the conal reductions t  t
0
! t
1
! t
2
!    are optimal since for every t
0
78 J. W. Klop
in G(t) they contain a t
n
with information content no less than that of t
0
(since t
0
 t
n
for some t
n
; by denition of `conal'). In a sense, a conal
reduction plays the role of a kind of `innite normal form'. See e.g. Berry
& Levy [79] and Boudol [85], where spaces of nite and innite reductions
modulo the so-called permutation equivalence are studied; this give rise
to cpo's or even complete lattices where the bottom point corresponds to
the empty reduction of t, i.e. to t itself, and the top point corresponds
to the normal form (or rather the equivalence class of reductions to the
normal form), if it exists, and otherwise to the equivalence class of conal
reductions.
We now present some well-known reduction strategies.
Denition 2.2.3.
1. The leftmost-innermost (one step) strategy is the strategy in which
in each step the leftmost of the minimal or innermost redexes is con-
tracted (reduced).
2. The parallel-innermost (many step) strategy reduces simultaneously
all innermost redexes. Since these are pairwise disjoint, this is no
problem.
3. The leftmost-outermost (one step) strategy: in each step the leftmost
redex of the maximal (or outermost) redexes is reduced. Notation:
F
lm
.
4. The parallel-outermost (many step) strategy reduces simultaneously
all maximal redexes; since these are pairwise disjoint, this is no prob-
lem. Notation: F
po
.
5. The full substitution rule (or Kleene reduction, or Gross-Knuth re-
duction): this is a many step strategy in which all redexes are simul-
taneously reduced. Notation: F
GK
.
Strategies (1){(4) are well-dened for general TRS's. Strategy (5) is
only dened for orthogonal TRS's, since for a general TRS it is not possible
to dene an unequivocal result of simultaneous reduction of a set of possibly
nested redexes. The ve strategies are illustrated in Figure 2.8 (taken from
Bergstra, Heering & Klint [89]), for the following TRS:
and(true; x) ! x
and(false; x) ! false
or(true; x) ! true
or(false; x) ! true
We will be mainly interested here in the strategies (3){(5), for a reason
that will be clear by inspection of Table 2.2 below. We have the following
facts (for proofs see O'Donnell [77] or Klop [80a]):
Term Rewriting Systems 79
Figure 2.8 (after Bergstra, Heering & Klint [89])
Theorem 2.2.4. For orthogonal TRS's:
1. F
GK
is a conal reduction strategy.
2. F
po
is a normalizing reduction strategy.
Remark 2.2.5. For -calculus this theorem also holds. Moreover, F
lm
is there also a normalizing strategy, just as it is for the orthogonal TRS
CL (Combinatory Logic). However, in general F
lm
is not a normalizing
strategy for orthogonal TRS's (see Exercise 2.2.6).
Exercise 2.2.6.
1. An example showing that the leftmost-outermost strategy is not normal-
izing in general, is given in Huet & Levy [79]: take the orthogonal TRS
fF (x;B) ! D; A ! B; C ! Cg and consider the term F (C;A). Check
that this term has a normal form which is not found by the leftmost-
outermost strategy.
80 J. W. Klop
2. An example (by N. Dershowitz) showing that parallel-outermost reduction
need not be conal can be found in the TRS fA! F (A); G(x)! G(x)g.
Even though F
lm
is in general for orthogonal TRS's not normalizing,
there is a large class of orthogonal TRS's for which it is:
Denition 2.2.7. (O'Donnell [77]) An orthogonal TRS is left-normal if
in every reduction rule t ! s the constant and function symbols in the
left-hand side t precede (in the linear term notation) the variables.
Example 2.2.8.
1. CL (Combinatory Logic) is left-normal.
2. RPS's (Recursive Program Schemes) as dened in Exercise 2.1.8(3)
are all left-normal.
3. F (x;B)! D is not left-normal; F (B; x)! D is left-normal.
Exercise 2.2.9. (Primitive Recursive Functions) The primitive recursive
functions fromN toN are dened by the following inductive denition (Shoeneld
[67]):
1. The constant functions C
n;k
, the projection functions P
n;i
and the suc-
cessor function S are primitive recursive. (Here C
n;k
(x
1
; : : : ; x
n
) = k,
P
n;i
(x
1
; : : : ; x
n
) = x
i
, S(x) = x+ 1.)
2. If G;H
1
; : : : ;H
k
are primitive recursive, then F dened by
F (~x ) = G(H
1
(~x ); : : : ;H
k
(~x ))
(where ~x = x
1
; : : : ; x
n
) is primitive recursive.
3. If G and H are primitive recursive, then F dened by
F (0; ~x ) = G(~x )
F (S(y); ~x ) = H(F (y; ~x ); y; ~x )
is primitive recursive.
Show that, by replacing every `=' by `!' in the dening equations, every primitive
recursive function is dened by a terminating, left-normal, orthogonal constructor
TRS. (For the denition of `constructor TRS', see the end of Section 2.3.)
Theorem 2.2.10. (O'Donnell [77], Klop [80a]) Let R be a left-normal
orthogonal TRS. Then F
lm
is a normalizing reduction strategy for R.
Exercise 2.2.11. (Hindley)
1. Consider CL extended with Recursor, where Recursor = fRxy0 ! x,
Rxy(Sz)! yz(Rxyz)g. Note that this applicative TRS is not left-normal,
and show that F
lm
is not normalizing.
2. However, for the TRS CL [ Recursor

where Recursor

= fR

0xy !
x; R

(Sz)xy ! yz(Rzxy)g the strategy F
lm
is normalizing.
Term Rewriting Systems 81
In the reduction strategy F
GK
(full substitution) every redex is `killed'
as soon as it arises, and this repeatedly. Suppose we relax this requirement,
and allow ourselves some time (i.e. some number of reduction steps) before
getting rid of a particular redex|but with the obligation to deal with it
eventually. The reductions arising in this way are all conal.
Denition 2.2.12.
1. Let R = t
0
! t
1
!    be a nite or innite reduction sequence.
Consider some redex s in some term t
n
of R. We say that s is secured
in R if eventually there are no descendants of s left, i.e.
9m > n (t
m
contains no descendants s
0
; s
00
; : : : of s  t
n
):
2. R is fair if every redex in R is secured.
Theorem 2.2.13. For reductions R in orthogonal TRS's: R is fair ) R
is conal.
Note that Theorem 2.2.4(1) is a corollary of the present theorem, since
evidently reductions obtained by applying F
GK
are fair. A similar relax-
ation of constraints applies to the other two strategies F
po
and F
lm
:
Denition 2.2.14.
1. A reduction R is leftmost-fair ifR ends in a normal form or innitely
many times the leftmost outermost redex is contracted in R.
2. R = t
0
! t
1
!    is outermost-fair if R does not contain a term
t
n
with an outermost redex which innitely long stays an outermost
redex but which is never contracted.
Theorem 2.2.15. Let R be an orthogonal TRS. Then:
1. Outermost-fair reductions are normalizing.
2. If R is moreover left-normal, then leftmost-fair reductions are nor-
malizing.
We will now summarize some of the main properties of the various
reduction strategies (and their `relaxed' versions) in Table 2.2. Before doing
so, we introduce one more property of strategies:
Denition 2.2.16. A reduction strategy F for R is perpetual, if for all t:
1(t))1(F(t)):
Here 1(t) means that t has an innite reduction, i.e. not SN(t). So
a perpetual strategy is the opposite of a normalizing one; it tries to avoid
normal forms whenever possible, and could therefore also be called `anti-
normalizing'.
82 J. W. Klop
In Table 2.2 p; n; c stand for perpetual, normalizing, conal respectively.
In case a property is not mentioned, it does not hold generally. Note that
for the leftmost-outermost strategy, when applied to orthogonal TRS's in
general, none of the three properties holds generally. Proofs that leftmost-
outermost reduction is normalizing for left-normal orthogonal TRS's and
that parallel-outermost reduction is normalizing for all orthogonal TRS's
can be found in O'Donnell [77]. The latter fact is also proved in Bergstra
& Klop [86] (Appendix).
Table 2.2
Computable reduction strategies
A strategy is recursive or computable if it is, after a coding of the terms
into natural numbers, a recursive function. Obviously we are primarily
interested in computable strategies; and indeed all ve strategies in De-
nition 2.2.3 are computable. We may now ask whether there is always for
an orthogonal TRS a computable one-step normalizing reduction strategy.
A priori this is not at all clear, in view of TRS's such as the one given by
G. Berry: CL extended with rules
FABx ! C
FBxA ! C
FxAB ! C
which is an orthogonal TRS. This TRS seems to require a parallel reduction
strategy (so, not a one-step or sequential strategy), because in a term of the
form FMNL we have no way to see the `right' argument for computation:
a step in the third argument may be unnecessary, namely if the rst and
second argument evaluate to A and B respectively (which is undecidable
due to the presence of CL); likewise a step in the other arguments may be
unnecessary. In the next section about sequential TRS's this problem will
be analyzed extensively.
When we want to be more liberal, we can consider the same problem
for the weakly orthogonal TRS obtained by extending CL with Parallel-or:
Term Rewriting Systems 83
or(true; x) ! true
or(x; true) ! true
It has been claimed by some authors that such TRS's require a parallel
evaluation. However, there is the following surprising fact.
Theorem 2.2.17. (Kennaway [89]) For every weakly orthogonal TRS
there exists a computable sequential normalizing reduction strategy.
The algorithm involved is however too complicated to be of more than
theoretical interest.
Standard reductions in orthogonal TRS's
For -calculus and CL there is a very convenient tool: the Standardization
Theorem (see Barendregt [81], Klop [80a]). For orthogonal TRS's there is
unfortunately not a straightforward generalization of this theorem (how-
ever, see Huet & Levy [79] for a generalization). The obstacle is the same as
for the normalizing property of the leftmost reduction strategy, discussed
in the previous section. When we restrict ourselves again to left-normal
orthogonal TRS's, there is a straightforward generalization.
Denition 2.2.18. (Standard Reductions) Let R be a TRS and R =
t
0
! t
1
!    be a reduction in R. Mark in every step of R all redex head
symbols to the left of the head symbol of the contracted redex, with `'.
Furthermore, markers are persistent in subsequent steps.
Then R is a standard reduction if in no step a redex is contracted with
a marked head operator.
Exercise 2.2.19. Consider CL [ Pairing, where Pairing = fD
0
(Dxy) !
x; D
1
(Dxy)! yg:
1. Show that the reduction D
0
(D(KII)I)! D
0
(DII)! I is not standard.
2. Show that D
0
(D(KII)I)! KII ! I is standard.
Exercise 2.2.20. (Hindley) Consider in the applicative TRS R = fPxQ!
xx; R! S; Ix! xg the reduction
R = PR(IQ)! PRQ! RR! SR
and show that there is no standard reduction for R (i.e. a reduction PR(IQ)
SR which is standard).
Theorem 2.2.21. (Standardization theorem for left-normal orthogonal
TRS's) Let R be a left-normal orthogonal TRS. Then: if t s there is a
standard reduction in R from t to s.
For a proof see Klop [80a]. A corollary is our earlier theorem stating
that F
lm
is a normalizing strategy for left-normal orthogonal TRS's; this
84 J. W. Klop
fact is in -calculus and CL literature also known as the Normalization
Theorem.
Exercise 2.2.22. Prove the Normalization Theorem for left-normal orthog-
onal TRS's from the Standardization Theorem. (Hint: suppose t has a normal
form t
0
. By the Standardization Theorem, there is a standard reduction from t
to t
0
. This is in fact the reduction as given by F
lm
.)
2.3 Sequential orthogonal Term Rewriting Systems
An important feature of orthogonal TRS's is whether they are `sequential'.
The property of sequentiality is relevant both for the existence of nor-
malizing reduction strategies and for the denability (implementability) in
-calculus or CL.
That a TRS is sequential, does of course not mean that it is impos-
sible to rewrite redexes in a parallel way. It means that there are also
adequate sequential reduction strategies, i.e. it is not necessary to rewrite
in a parallel way in order to nd normal forms. Sequentiality is a desir-
able property, but unfortunately it is an undecidable property. However,
there is a stronger version, `strong sequentiality', which is decidable and
which guarantees the existence of a recursive one-step normalizing reduc-
tion strategy. This was shown in Huet & Levy [79]. In this section we
follow this paper, as well as Klop & Middeldorp [89]. We note that here we
are primarily interested in `mathematical' properties of strong sequential-
ity, and are not concerned with eciency of decision algorithms; for the
latter see Huet & Levy [79].
As remarked in Kennaway [89], one can ask whether `sequential' is the
right terminology, in view of his theorem (2.2.17) stating that every or-
thogonal TRS has a computable, sequential, normalizing strategy. Yet we
feel that the terminology is right, if we are interested in `feasibly sequen-
tial' (admitting a sequential normalizing strategy that is computable in a
`feasible' way).
Denition 2.3.1. Let t 2 TerR), R orthogonal. Let s  t be a redex.
Then s is a needed redex (needed for the computation of the normal form,
if it exists) i in all reductions t!    ! t
0
such that t
0
is a normal form,
some descendant of s is contracted. (So, trivially, any redex in a term
without normal form is needed.)
Exercise 2.3.2. Show that the leftmost outermost redex in t 2 TerR) where
R is a left-normal orthogonal TRS, is a needed redex.
Theorem 2.3.3. (Huet & Levy [79]) Let t be a term in an orthogonal
TRS R.
Term Rewriting Systems 85
1. If t is not in normal form, t contains a needed redex.
2. Repeated contraction of a needed redex leads to the normal form, if
it exists. (So, needed reduction is normalizing.)
The proof involves quite some eort and is not included here. (For a
proof dierent from the one of Huet and Levy, see Kennaway & Sleep [89].)
Exercise 2.3.4.
1. The present theory about needed reductions in orthogonal TRS's trivializes
for non-erasing TRS's: Show that in a non-erasing orthogonal TRS every
redex in a term is needed.
2. (Kennaway [89]) Furthermore the present theory does not have a straight-
forward generalization to weakly orthogonal TRS's: Show that Theorem
2.3.3 does not hold for weakly orthogonal TRS's, by considering for(true; x)
! true, or(x; true) ! trueg. (However, see O'Donnell [85].)
Thus, Theorem 2.3.3 gives us a normalizing reduction strategy: just
contract some needed redex. However, the denition of `needed' refers to
all reductions to normal form, so in order to determine what the needed
redexes are, we have to inspect the normalizing reductions rst, which
is not a very good recipe for a normalizing reduction strategy. In other
words, the determination of needed redexes involves look-ahead, and it is
this necessity for look-ahead that we wish to eliminate. Before we do so,
rst the following observation, which is easy to prove:
Proposition 2.3.5. Let t 2 TerR), R orthogonal. Let s and s
0
be redexes
in t such that s  s
0
. Then: s is needed ) s
0
is needed.
Corollary 2.3.6. Let t be a term not in normal form. Then some outer-
most redex of t is needed.
Now let C[ ; : : : ; ] denote a context with n holes. Denote by  a sub-
stitution of redexes s
1
; : : : ; s
n
in the holes 1; : : : ; n. Then the last corollary
states:
8C[ ; : : : ; ] in normal form 8 9i s
i
is needed in C[s
1
; : : : ; s
n
]:
So, which s
i
is needed, may depend on , i.e. from the other s
j
. A
more pleasant state of aairs would be when the TRS R would satisfy the
following property:
Denition 2.3.7. Let R be an orthogonal TRS. Then R is sequential

if
8C[ ; : : : ; ] in normal form 9i 8; s
i
is needed in C[s
1
; : : : ; s
n
]:
86 J. W. Klop
Exercise 2.3.8. (Middeldorp)
1. Show that the orthogonal TRS (where CL is Combinatory Logic)
CL fF (A;B; x)! C; F (B;x;A)! C; F (x;A;B)! Cg
(due to G. Berry) is not sequential

.
2. Show that the TRS fF (A;B; x) ! C; F (B;x;A) ! C; F (x;A;B) ! Cg
is sequential

.
3. Conclude that `sequential

' is not a modular property.
The concept `sequential

' is only introduced for expository purposes. It
is not a satisfactory property as it is undecidable. As it will turn out, a
more satisfactory property is `strongly sequential

', dened as follows.
Denition 2.3.9.
1. Let R be an orthogonal TRS and C[ ] a context. Then a reduction
relation!
?
(possible reduction) is dened as follows. For every redex
s and every term t:
C[s]!
?
C[t]
As usual, 
?
is the transitive reexive closure. The concept of `de-
scendant' is dened for !
?
in the obvious way.
2. Let s be a redex in t. Then s is strongly needed if in every reduc-
tion t !
?
: : : !
?
t
0
where t
0
is a normal form, a descendant of s is
contracted. Clearly: s is strongly needed ) s is needed.
3. R is strongly sequential

if 8C[ ; : : : ; ] in normal form 9i 8 s
i
is
strongly needed in C[s
1
; : : : ; s
n
].
This property of `strong sequentiality

' may be rather subtle, as the
following example of Huet & Levy [79] in Exercise 2.3.10 shows.
Exercise 2.3.10. Let R have rewrite rules, written in tree notation, as in
Figure 2.9(a) (the RHS's are irrelevant). Show that R is not strongly sequential

,
by considering the context as in Figure 2.9(b).
Now the situation takes a pleasant turn, since as we will prove, it is
decidable whether a orthogonal TRS is strongly sequential

, and moreover,
there is a simple algorithm to compute an i as in the denition. Actually,
Huet & Levy dene concepts `sequential' and `strongly sequential' in a
dierent way; our `sequential

' does not exactly coincide with `sequential'
but `strongly sequential

' is equivalent with `strongly sequential'. We will
dene these concepts now. We need some preliminary denitions:
Denition 2.3.11.
1. Let R be a orthogonal TRS. Then the set Ter


(R) of 
-terms of R
consists of those terms that can be built from function and constant
Term Rewriting Systems 87
Figure 2.9
symbols from R together with a new constant 
. Reduction relations
! and !
?
are extended to Ter


(R) in the obvious way. As before,
we say that t is a normal form if t 2 Ter


(R), t contains no 
 and t
contains no redexes. Further, t is an 
-normal form if t contains no
redexes (but t may contain occurrences of 
).
2. On Ter


(R) we dene a partial order  by:
(a) 
  t for all t 2 Ter


(R),
(b) t
i
 t
0
i
(i = 1; : : : ; n) ) F (t
1
; : : : ; t
n
)  F (t
0
1
; : : : ; t
0
n
).
Clearly, t  s i t  C[
; : : : ;
] and s  C[t
1
; : : : ; t
n
] for some
context C[ ; : : : ; ] not containing 
, and some t
i
2 Ter


(R) (i =
1; : : : ; n; n  0):
3. A predicate P on Ter


(R) is monotone if t  t
0
implies P (t)) P (t
0
):
4. The predicate nf is dened on Ter


(R) as follows:
nf(t) holds if t n where n is a normal form (so without 
):
5. The predicate nf
?
is dened on Ter


(R) as follows:
nf
?
(t) holds if t
?
n where n is a normal form:
6. Let P be a monotone predicate on Ter


(R). Let t  C[
; : : : ;
; : : : ;
]
where all 
's in t are displayed. Then the underlined occurrence of 

is an index with respect to P (or P -index) if for all s such that t  s,
where s  C[t
1
; : : : ; t
i
; : : : ; t
n
]; we have: P (s) ) t
i
6= 
: (Note that
in particular, if t has a P -index, then P (t) does not hold.)
It is easily proved that the predicates nf and nf
?
are monotone. Now
we dene (after Huet & Levy [79]):
88 J. W. Klop
Denition 2.3.12.
1. The orthogonal TRS R is sequential if every t 2 Ter


(R) in 
-normal
form, but not in normal form, has a nf-index.
2. The orthogonal TRS R is strongly sequential if every t 2 Ter


(R) in

-normal form, but not in normal form, has a nf
?
-index.
Exercise 2.3.13. (Middeldorp)
1. Show that: R is sequential ) R is sequential

, but not vice versa. Hint:
consider the TRS as in Exercise 2.3.8(2), with the term F (
;
;
):
2. Show that: R is strongly sequential , R is strongly sequential

.
Exercise 2.3.14. Let t  C[
; : : : ;
; : : : ;
] 2 Ter


(R), R not necessarily
strongly sequential. The i-th occurrence of 
 in t is underlined. Suppose that this
underlined occurrence is a nf
?
-index of t. Show then that in C[s
1
; : : : ; s
i
; : : : ; s
n
],
where s
i
is a redex and the other s
j
are arbitrary terms, the redex s
i
is strongly
needed.
To link the beginning of this section, which used the terminology of
contexts, with the present set-up via 
-terms, we note that a context in
normal form, containing at least one hole, corresponds with an 
-term in

-normal form, but not in normal form. Before devoting the rest of this
section to an exposition of the long proof that strong sequentiality is a
decidable property, we will rst show how to nd a nf
?
-index. First, we
need some denitions.
Denition 2.3.15. Let t 2 Ter


(R):
1. t is a redex compatible 
-term if t can be rened to a redex (i.e. t  t
0
for some redex t
0
).
2. 
-reduction replaces a redex compatible subterm 6 
 by 
, notation:
!


. So, C[t]!


C[
] if t is redex compatible and t 6 
:
3. The xed part !(t) of an 
-term t is the result of maximal application
of 
-reductions. (In other words, the normal form with respect to

-reduction.)
Exercise 2.3.16. Show that !(t) is well-dened, by proving that 
-reduction
is conuent and terminating.
Now let t  C[
; : : : ;
; : : : ;
] be an 
-normal form containing at least
one 
. We wish to test whether the i-th occurrence of 
, the underlined
one, is a nf
?
-index of t. To this end we replace it by a fresh constant
symbol, p. Result: t
0
 C[
; : : : ; p; : : : ;
]:
Claim 2.3.17. 
 is a nf
?
-index in t , p occurs in !(t
0
). (See Figure
2.10.)
Term Rewriting Systems 89
Figure 2.10
The proof of the claim is routine and we omit it. Intuitively, the per-
sistence of the test symbol p in !(t
0
) means that whatever the redexes (or
even general terms, cf. Exercise 2.3.14) in the other places are, and what-
ever their reducts might be, the p does not vanish, is not erasable by the
action of the other redexes (or general terms). So if instead of p an actual
redex s
i
was present, the only way to normalize the term at hand is to
reduce s
i
itself, eventually. Huet & Levy [79] gives an ecient algorithm
for executing the `p-test', i.e. for nding nf
?
-indexes (and hence, strongly
needed redexes, cf. Exercise 2.3.14).
The decision procedure for the strong sequentiality property itself is
much more dicult. We will now present a proof (in a slightly informal
way) which is a simplication of the one in Huet & Levy [79], but where
we do not pay any attention to the eciency of the decision procedure.
In the following we will refer to a nf
?
-index as an `index' for short. An

-occurrence which is not an index, will be called `free'. A term in which
all 
's are free, is called free.
The main `problem' is that we do not have the following transitivity
property for indexes, which on rst sight one might expect to hold: if in
the 
-terms C
1
[
]; C
2
[
]; where in both terms the displayed occurrence of

 is an index (there may be other 
's occurring), then the displayed 
 in
C
1
[C
2
[
]] is again an index.
Example 2.3.18. Counterexample to transitivity for indexes. Consider
the TRS as in Exercise 2.3.10, and the term F (G(
;
);
): The under-
lined occurrence is an index, as is easily seen by applying the `p-test':
!(F (G(
;
); p)) = F (
; p): However, substituting the same term in the
index position, with result F (G(
;
); F (G(
;
);
)); we have the `con-
text' in Figure 3.12(b), which is as shown, essentially, in Exercise 2.3.10, a
free term.
However, some `partial' transitivity properties for the propagation of
indexes do hold, notably the one in Proposition 2.3.21 below. We will now
90 J. W. Klop
make explicit some properties of index propagation. To this end we employ
the following notational convention: instead of \the displayed occurrence
of 
 in C[
] is an index "(here the 
-term C[
] may contain other 
's)
we will just write \C[
#]". However, the absence of an arrow as e.g. in
C[
;
#] does not mean that (in this case) the rst 
 is not an index.
Furthermore we stipulate that in C[
; : : : ;
] (or a version with arrow an-
notations) more occurrences of 
 may occur than the ones displayed, unless
specied explicitly otherwise. Finally, the notations s; t; C[
; : : :;
] (pos-
sibly with arrow annotations) will refer to 
-terms, which we sometimes
call just `terms'.
Proposition 2.3.19.
1. C
1
[C
2
[
#]]) C
1
[
#] and C
2
[
#]:
2. The reverse implication does not hold generally.
Figure 2.11
Proof. See Figure 2.11, where an arrow points to an index-
. Part (2) is
the counterexample in 2.3.18. Part (1) follows by an easy argument using
the p-test criterion for indexes.
Proposition 2.3.20.
1. Let !(t) = 
: Then C[t;
#]) [
;
#]:
2. The reverse implication holds for all t: C[t;
#]( C[
;
#]:
Proof. (See Figure 2.12.) Simple applications of the p-test.
The following proposition (from Klop & Middeldorp [89]) states the
`partial transitivity' for index propagation mentioned before. Here  refers
to the maximal height of the trees corresponding to the redex schemes (i.e.,
the left-hand-sides of reduction rules) of R. Furthermore, the depth of an
occurrence in a term is the length of the branch leading from the root
symbol to that occurrence.
Proposition 2.3.21. Let the depth of 
 in C
2
[
] be at least . Then:
C
1
[C
2
[
#]] and C
2
[C
3
[
#]] ) C
1
[C
2
[C
3
[
#]]]:
Term Rewriting Systems 91
Figure 2.12
Figure 2.13
Proof sketch. Suppose contexts C
i
[
] (i = 1; 2; 3) as in the proposition
are given. Consider !(C
1
[C
2
[C
3
[p]]]). We claim that p is still present in
this term. For if not, consider an 
-reduction leading to !(C
1
[C
2
[C
3
[p]]])
and especially the 
-reduction step in which the symbol p is lost. The
redex compatible subterm which is removed in this step, has a root symbol
s. Now s cannot occur in the subterm C
2
[C
3
[p]] of C
1
[C
2
[C
3
[p]]]; for oth-
erwise p would not occur in !(C
2
[C
3
[p]]). But s can also not occur in the
C
1
-part of C
1
[C
2
[C
3
[p]]], for then p would not occur in !(C
1
[C
2
[p]]) due to
the assumption referring to .
In the following propositions, a rigid term t is a term t such that
!(t) = t. Terms t such that !(t) = 
; will be called soft ; they `melt
away' completely by 
-reduction. It is not hard to prove that every term
has a unique decomposition in a top part which is rigid and some subterms
which are soft. (The top context may be trivial, i.e. equal to 
:)
92 J. W. Klop
Proposition 2.3.22. Every term t 2 Ter


(R) can be written, uniquely,
as C[t
1
; : : : ; t
n
] such that C[
; : : : ;
] is rigid and the t
i
(i = 1; : : : ; n) are
soft.
Proposition2.3.23. Suppose C[t
1
; : : : ; t
n
] is a term such thatC[
; : : : ;
]
is rigid and t
k
is soft for k = 1; : : : ; n. Let t
i
 C
0
[
]. Then:
C
0
[
#] ) C[t
1
; : : : ; t
i 1
; C
0
[
#]; t
i+1
; : : : ; t
n
]:
Proof. (See Figure 2.14.) By routine arguments involving the p-test.
Figure 2.14
In an attempt to decide whether the TRS R is strongly sequential, we
will try to construct a term t 2 Ter


(R) in 
-normal form but not in
normal form, which is free, i.e. has no indexes. If such a free term exists,
then and only then R is not strongly sequential. Especially we will look
for a minimal free term, minimal with respect to the length. According
to the last proposition, we may suppose that a minimal free term, if it
exists, is soft. So, such a minimal free term is built from redex compatible
terms (i.e. originates, starting from a redex compatible term, by repeatedly
substituting redex compatible terms for 
's)|this follows at once from
the denition of `soft' and 
-reduction. (See Figure 2.15(a).) However,
this observation is not yet sucient for a sensible attempt to construct a
minimal free term, for there are in general innitely many redex compatible
terms which may be the building blocks of the minimal free term we are
looking for. Fortunately, we may even suppose that a minimal free term
is built from a special kind of redex compatible terms, the preredexes, of
which only nitely many exist if the TRS R has nitely many reduction
rules as was our assumption. (See Figure 2.15(b).)
Denition 2.3.24.
1. A redex scheme (or redex pattern) is a left-hand side of a reduction
rule where all variables are replaced by 
:
2. A preredex is a term which can be rened to a redex scheme. (See
Figure 2.16.)
Term Rewriting Systems 93
Figure 2.15
Figure 2.16
So, a redex scheme itself is a preredex; every preredex is also a redex
compatible term. If the TRS R has nitely many rules, there are only
nitely many preredexes. The 
's in a redex scheme are all free; the 
's
arising by `truncating' a redex scheme and thus forming a preredex, may
be free or an index depending on other redex schemes. The `old' 
's in the
truncation, if there are any, remain free. All this follows immediately from
the denitions and the p-test.
We have already noted that a minimal free term t may be supposed to
be built from redex compatible terms, as in Figure 2.15(a). This `partition'
in redex compatible terms need not be unique, but that does not matter.
94 J. W. Klop
Suppose a certain partition of t is given, corresponding to some 
-reduction
from t to 
: Each redex compatible term from which t is built, and which
is removed in this 
-reduction, consists of a preredex rened with some
`extra' subterms. (The subterms that make the dierence between Figure
2.15(a) and (b).) Now we remove from t all these extra subterms. (See
Figure 2.17.)
Figure 2.17
We claim that the term t
0
, originating after removing all `extra' sub-
terms, is again free. Namely, consider the example in Figure 2.16, and
remove the two extra subterms of the redex compatible subterm s. The

's that arise after this removal are free in s; this follows easily by applying
the p-test and noting that subterm r is soft. But then these 
's are also
free in t; this follows from Proposition 2.3.19(1). Furthermore, the present
removal of the extra subterms of s also does not turn free 
's at other
places into indexes, by Proposition 2.3.20(2).
We will now try to construct a minimal free term t in a tree-like proce-
dure, as suggested in Figure 2.18.
Of course, we want t to be in 
-normalform|cf. Denition 2.3.12(2).
We start, therefore, with the nitely many proper preredexes, where a pre-
redex is `proper' if it is not a redex scheme. Now at every index 
, we
attach in the next construction step, again a proper preredex. This nonde-
terministic procedure is repeated. A branch in the thus originating tree of
construction terminates `successfully' if a free term is reached. In that case
the TRS R is not strongly sequential. However, there may arise innite
branches in the construction tree. But these we may `close', eventually, by
some form of `loop checking' in the following way. First a denition.
Denition 2.3.25.
1. Let C
i
[
] be preredexes (i = 1; : : : ; n). Then the term
  C
1
[C
2
[: : : [C
n
[
]] : : :]]
Term Rewriting Systems 95
Figure 2.18
is called a tower of preredexes. If 1  i < j  n, we say that tower 
contains the subtower 
0
 C
i
[C
i+1
[: : : [C
j
[
]] : : :]]:
2. Let  be the maximal height of redex schemes of R. A tower  
C
1
[: : : [C
n
[
]] : : :] of preredexes is suciently high if the depth of the
displayed 
 in  is at least :
96 J. W. Klop
3. Let t be a term built from preredexes. A main tower in  is a tower
(arising after removing some subterms of t) containing a complete
branch in the tree corresponding to t (so, from root to some `nal'
symbol).
Now if in the construction tree we observe at some construction branch
the arising of a term which has a main tower containing two disjoint suf-
ciently high identical subtowers, that construction branch is stopped un-
successfully.
So every branch of the construction tree terminates, either successfully
in a free term, or unsuccessfully. Because the construction tree is nitely
branching, the result is a nite construction tree. Now if all construc-
tion branches terminate unsuccessfully, the TRS R is strongly sequential;
otherwise the presence of a free term at the end of a successful branch re-
veals that TRS R is not strongly sequential. Hence strong sequentiality is
decidable.
We still have to prove that our decision procedure is correct, in partic-
ular we have to justify the correctness of the `loop check' for unsuccessfully
closing branches at which a repetition of subtowers occurs. To this end,
consider the term s at some point (node) in the construction tree, and
consider a successor s
0
obtained by adjoining a proper preredex  at some
index position of s. In general,  will contain some free 
's as well as
some index 
's (with respect to ). The free 
's remain free with respect
to the whole term s
0
(Proposition 2.3.19(1)). What about the indexes of
? They may become free in s
0
. Now what happens with them is entirely
determined by the main tower of proper preredexes in s
0
leading to the 

in s where  will be adjoined. This follows from Proposition 2.3.20 stating
that removal of soft terms does not aect the index or non-index status of
other 
's.
In fact, what happens with the indexes of  is already determined by
the subtower of height   immediately above the adherence point 
: This
follows from Proposition 2.3.21. But then it is easy to see that in a minimal
free term there will not be a repetition of two identical suciently large
disjoint subtowers (see Figure 2.19). For, if such a repetition occurs in a
minimal free term, we can construct a smaller one by cutting away part
of the term as in Figure 2.19, contradicting the minimality. This ends the
proof of decidability of strong sequentiality.
Many TRS's arising in `practice' are constructor TRS's. For such TRS's
it is easy to decide strong sequentiality. A constructor TRS is a TRS
in which the set of function symbols can be partitioned into a set D of
dened function symbols and a set C of constructors, such that for every
rewrite rule t ! s, the left-hand side t has the form F (t
1
; : : : ; t
n
) with
F 2 D and t
1
; : : : ; t
n
2 Ter(C;V), the set of terms built from variables and
constructors.
Term Rewriting Systems 97
Figure 2.19
The reason that for constructor TRS's deciding strong sequentiality is
easy, is that we do have transitivity of indexes now, in contrast with the
case of general TRS's (cf. Counterexample 2.3.18).
Proposition 2.3.26. Let R be an orthogonal constructor TRS. Let C
2
[
]
start with a dened function symbol. Then: C
1
[
#] and C
2
[
#] implies
C
1
[C
2
[
#]]:
Proof. Straightforward, using the p-test for nding indexes.
Corollary 2.3.27. A constructor TRS is strongly sequential i every
proper preredex has an index.
So, in order to decide whether a constructor TRS R is strongly se-
quential, we only have to compute the indexes of its nitely many proper
preredexes. (R is supposed to have only nitely many rewrite rules.) Also,
the computation of these indexes is very easy: Let C[
; : : : ;
; : : : ;
] be
a preredex of R. Now it is not dicult to see that C[
; : : : ;
#; : : :;
] i
C[
; : : : ; p; : : : ;
] is not redex compatible.
Exercise 2.3.28. Let R be an orthogonal constructor TRS. Show that R is
strongly sequential if every proper preredex P has an 
-occurrence which is inall
98 J. W. Klop
redex schemes S such that P  S, more dened (i.e. replaced by an 
-term
6 
):
Exercise 2.3.29. (Huet & Levy [79]) Let R be a left-normal orthogonal
TRS. Show that R is strongly sequential. Show that, in fact, in C[
; : : : ;
]
(where C[; : : : ; ] is an 
-free context in normal form) the leftmost occurrence of

 is an index.
Exercise 2.3.30. (Klop & Middeldorp [89]) Show that strong sequentiality
is a modular property of orthogonal TRS's, i.e. if R
1
;R
2
are orthogonal TRS's
with disjoint alphabet, then:
R
1
 R
2
is strongly sequential , R
1
and R
2
are strongly sequential.
Exercise 2.3.31. (Thatte [87]) Let R
1
;R
2
be orthogonal TRS's. Dene
R
1
;R
2
to be left-equivalent if the rewrite rules of R
1
;R
2
have identical left-hand
sides. An orthogonal TRS R is called left-sequential if all TRS's which are left-
equivalent with R, are sequential (Denition 2.3.12(1)).
Let R be an orthogonal TRS and C[
; : : : ;
] a context in 
-normal form.
The i-th occurrence of 
 is called an index with respect to left-sequentiality if this

 is an index with respect to sequentiality for all TRS's left-equivalent with R.
1. Let R be the TRS with rules fF (A;B; x)! x; F (x;A;B)! x; F (B;x;A)
! x; G(A)! Ag. Show that the third occurrence of 
 in F (G(
);G(
);
)
is an index with respect to left-sequentiality, but not with respect to strong
sequentiality.
2. Prove that strong sequentiality implies left-sequentiality.

3. (Open problem.) Does the reverse of (2) also hold, i.e. is every left-
sequential TRS strongly sequential?
3 Conditional Term Rewriting Systems
Of growing importance in the eld of term rewriting are the conditional
Term Rewriting Systems (CTRS's). CTRS's have originally arisen from
Universal Algebra (see Meinke & Tucker [91]) and in the theory of Ab-
stract Data Types, as implementations of specications containing positive
conditional equations
t
1
(~x ) = s
1
(~x ) ^ : : :^ t
n
(~x ) = s
n
(~x )) t
0
(~x ) = s
0
(~x ) ()
(If n = 0, the equation is called unconditional.) Here ~x = x
1
; : : : ; x
k
; not
every t
i
; s
i
needs to contain all those variables. In () we implicitly use
universal quantication over ~x, i.e. () is meant to be
8~x (
^
i=1;::;n
t
i
(~x ) = s
i
(~x )) t
0
(~x ) = s
0
(~x )):
Term Rewriting Systems 99
Hence the variables appearing in the conditions t
i
(~x ) = s
i
(~x ), i = 1; : : : ; n,
but not in the consequent t
0
(~x ) = s
0
(~x ) have an `existential' meaning; e.g.
E(x; y) = true ^ E(y; z) = true ) E(x; z) = true
is by elementary predicate logic equivalent to
9y (E(x; y) = true ^ E(y; z) = true) ) E(x; z) = true:
Henceforth we will, conform the notation often used in `equational logic
programming', write instead of ():
t
0
(~x ) = s
0
(~x ) ( t
1
(~x ) = s
1
(~x ); : : : ; t
n
(~x ) = s
n
(~x ):
Example 3.0.1. A specication of gcd on natural numbers with 0 and
successor S, using conditional equations:
0 < 0 = 0 S(x)   S(y) = x  y
0 < S(x) = S(0) 0  x = 0
S(x) < 0 = 0 x  0 = x
S(x) < S(y) = x < y
gcd(x; y) = gcd(x  y; y) ( y < x = S(0)
gcd(x; y) = gcd(x; y   x) ( x < y = S(0)
gcd(x; x) = x
(To keep the specication one-sorted, 0 and S(0) are used as booleans false
and true respectively. Furthermore, ` ' is cut-o subtraction.)
The satisfaction relation A j= ', for an equational implication or as we
will call them henceforth, conditional equation '; is clear; see also Meinke
& Tucker [91], where it is also shown that analogous to the equational
case we can develop initial algebra semantics for conditional equations.
Conditional equations not only facilitate some specications, they also are
a strictly stronger specication mechanism. In Bergstra & Meyer [84] a
conditional specication is given with an initial algebra that cannot be
specied (in the same signature) by means of equations.
Again we can ask whether there exists a deduction system and a corre-
sponding completeness theorem, in analogy with Birkho's theorem 1.4.2
for equational logic.
Conditional equational deduction
Selman [72] presents a sound and complete deduction system for, as they
are called there, equation conjunction implication (ECI) languages, or as
we will say, for conditional equational logic. We state this deduction system
in a considerably simplied way, by considering in a conditional equation
100 J. W. Klop
t = s ( E where E = t
1
= s
1
; : : : ; t
n
= s
n
(n  0), the sequence of
conditions E as a set rather than an ordered tuple as in Selman [72], and
by admitting empty E. (See Table 3.1.) Adapting the inference system to
the case where E is a multiset or even an ordered tuple is straightforward.
axioms
t = s ( t = s; t
0
= s
0
t = t (
t = s ( t = r; s = r
F (t
1
; : : : ; t
n
) = F (s
1
; : : : ; s
n
) ( t
1
= s
1
; : : : ; t
n
= s
n
for every n-ary F
rules
t = s ( t
0
= s
0
; E; t
0
= s
0
( F
t = s ( E; F
t = s ( E
for every substitution 
t

= s

( E

Table 3.1
Here E = ft
1
= s
1
; : : : ; t
n
= s
n
g (n  0), F = ft
0
1
= s
0
1
; : : : ; t
0
m
= s
0
m
g
(m  0); E

= ft

1
= s

1
; : : : ; t

n
= s

n
g.
Operational semantics of conditional equations
In the unconditional case, there is no problem in the transition from equa-
tions to directed equations, i.e. rewrite rules: t
0
(~x ) = s
0
(~x ) is replaced
by t
0
(~x ) ! s
0
(~x ), provided the left-hand side is not a single variable and
variables occurring in the right-hand side do also occur in the left-hand
side. (Of course, choosing the `right' direction may be a problem|see our
discussion of Knuth-Bendix completion.)
In the conditional case the transition from conditional equations to con-
ditional rewrite rules does present a problem, or at least some choices. Der-
showitz, Okada & Sivakumar [88] make the following distinctions, thereby
extending a classication introduced in Bergstra & Klop [86]. First we
introduce some notation.
Term Rewriting Systems 101
Denition 3.0.2. Let ! be a rewrite relation.
1. t # s (t; s are joinable) if t u and s u for some term u. (So ! is
conuent if = (convertibility) and # coincide.)
2. s
!
t if s t and t is a ground normal form.
Now there are several choices for evaluating the conditions of CTRS's.
In the terminology of Dershowitz, Okada & Sivakumar [88] we can distin-
guish (among others) the following types of CTRS's:
1. semi-equational systems
t
0
! s
0
( t
1
= s
1
; : : : ; t
n
= s
n
2. join systems
t
0
! s
0
( t
1
# s
1
; : : : ; t
n
# s
n
3. normal systems
t
0
! s
0
( t
1

!
s
1
; : : : ; t
n

!
s
n
4. generalized systems
t
0
! s
0
( P
1
; : : : ; P
n
:
In the last type of CTRS's, the P
i
(i = 1; : : : ; n) are conditions formulated
in a general mathematical framework, e.g. in some rst order language,
involving the variables occurring in the consequent (and possibly others).
In Bergstra & Klop [86] semi-equational systems were called to be of
Type I, join systems of Type II, and normal systems of Type III
n
: Actually,
Bergstra & Klop [86] dene: t
!
s if s is a ground normal form even with
respect to the unconditional part from the CTRS R (obtained by removing
all conditions). This is necessary since otherwise the reduction relation
may not be well-dened.
Note that in the cases (1){(3), the denition of ! is circular since it
depends from conditions involving in some way or another a reference to!;
but it is not hard to see that in fact ! is well-dened since all conditions
of type (1){(3) are positive. Hence the rewrite rules constitute a positive
induction denition of !. In the case of generalized CTRS's we have to
take care in formulating the conditions, in order to ensure that ! is well-
dened.
Remark 3.0.3. In a rewrite rule t ! s one requires that in s no new
variables appear with respect to t. The same requirement is made for
conditional rewrite rules t ! s ( C. But, as observed in Dershowitz,
Okada & Sivakumar [88], for CTRS's it would make good sense to lift this
102 J. W. Klop
requirement, as e.g. in the following perfectly natural conditional rewrite
specication of the Fibonacci numbers:
Fib(0) ! h0; 1i
Fib(x+ 1) ! hz; y + zi ( Fib(x) # hy; zi:
We will not study this more liberal format here, since it introduces a con-
siderable complication of the theory.
We will now discuss several conuence criteria for CTRS's. The rst
one is a generalization due to Middeldorp [91] (also in Middeldorp [90]) of
Toyama's theorem 1.2.2, stating that conuence is a modular property of
TRS's, to CTRS's:
Theorem 3.0.4. Let R
1
; R
2
be both semi-equational CTRS's or both join
CTRS's or both normal CTRS's with disjoint alphabet. Then:
R
1
; R
2
are conuent , R
1
R
2
is conuent.
(The disjoint sum R
1
R
2
is dened analogously to the unconditional case:
simply join the sets of rewrite rules.) The proof is a nontrivial application
of Toyama's theorem 1.2.2.
Orthogonal Conditional Term Rewriting Systems
We will now state some conuence criteria for orthogonal CTRS's.
Denition 3.0.5.
1. Let R be a CTRS (of any type, semi-equational, join, : : :). Then R
u
;
the unconditional version of R, is the TRS which arises from R by
deleting all conditions.
2. The CTRSR is called (non-)left-linear ifR
u
is so; likewise for (weakly)
orthogonal. (See Section 2.1 for orthogonal TRS's.)
Denition 3.0.6.
1. Let R be a CTRS with rewrite relation !; and let P be an n-ary
predicate on the set of terms of R. Then P is closed with respect to
! if for all terms t
i
; t
0
i
such that t
i
 t
0
i
(i = 1; : : : ; n):
P (t
1
; : : : ; t
n
) ) P (t
0
1
; : : : ; t
0
n
):
2. Let R be a CTRS with rewrite relation !. Then R is closed if all
conditions (appearing in some conditional rewrite rule of R), viewed
Term Rewriting Systems 103
as predicates with the variables ranging over R-terms, are closed with
respect to !.
Theorem 3.0.7. (O'Donnell [77]) Let R be a generalized, weakly orthog-
onal CTRS which is closed. Then R is conuent.
The proof is a rather straightforward generalization of the conuence proof
for weakly orthogonal TRS's.
Obviously, the convertibility conditions t
i
= s
i
(i = 1; : : : ; n) in a
rewrite rule of a semi-equational CTRS are closed. Hence:
Corollary 3.0.8. Weakly orthogonal semi-equational CTRS's are conu-
ent.
Example 3.0.9. Let R be the orthogonal, semi-equational CTRS obtained
by extending Combinatory Logic with a `test for convertibility':
Sxyz ! xz(yz)
Kxy ! x
Ix ! x
Dxy ! E ( x = y:
Then R is conuent.
The question now arises whether analogous facts hold for the other types
of CTRS's. Indeed, this is the case for normal conditions. The following
theorem is a slight generalization of a result in Bergstra & Klop [86]:
Theorem 3.0.10. Weakly orthogonal normal CTRS's are conuent.
Remark 3.0.11.
1. Orthogonal join CTRS's are in general not conuent, and even in
general not weakly conuent. In Bergstra & Klop [86] the following
counterexample is given:
C(x) ! E ( x # C(x)
B ! C(B):
See Figure 3.1. C(E) # E does not hold, since this would require
C(E)! E, i.e. C(E) # E:
2. The counterexample in (1) exhibits an interesting phenomenon, or
rather, makes a pitfall explicit. According to Corollary 3.0.8 above,
the semi-equational CTRS with rules
C(x) ! E ( x = C(x)
B ! C(B)
104 J. W. Klop
Figure 3.1
is conuent. Hence its convertibility, =, coincides with the joinability
relation, #. So x = C(x) i x # C(x). Yet the join CTRS obtained
by replacing the condition x = C(x) by x # C(x), is according to (1)
of this remark not conuent.
The complexity of normal forms
Whereas in the unconditional case, being in `normal form' is an easily
decidable property, this needs no longer to be so in the case of CTRS's.
In fact, there are semi-equational orthogonal CTRS's for which the set of
normal forms is undecidable (and hence not even r.e., since the complement
of the set of normal forms is r.e.). The same holds for normal orthogonal
CTRS's, and for join CTRS's. The proof is short and instructive enough
to be included:
Consider CL (Combinatory Logic); it is well-known (cf. Barendregt
[81]) that there is a representation n, a ground CL-term in normal form, of
the natural number n for each n  0; together with a computable coding #
from the set of ground CL-terms into natural numbers, and an `enumerator'
E (also a ground CL-term in normal form) such that E#(M )  M for
every ground CL-term M . Now let R be the normal CTRS obtained by
extending CL with a new constant symbol F and the rule
Fx! 1 ( Ex 0:
(Note that the reduction relation ! of R satises Fx ! 1 , Ex  0.)
If R had decidable normal forms, then in particular the set fn j Fn 1g
would be decidable, i.e. the set fn j En 0g would be so. However, then
the set
X = fM a ground CL-term jM  0g
is decidable; for, given M we compute #(M ) and decide whether E(#(M ))
 0 or not. (By conuence forR it follows fromE(#(M )) 0 and E#(M )
 M that M  0.) But this contradicts the fact that X is undecidable;
this follows from a theorem of Scott stating that any nonempty proper
subset of the set of ground CL-terms which is closed under convertibility in
CL, must be undecidable.
Term Rewriting Systems 105
For a condition guaranteeing decidability of normal forms, we refer to
the notion `decreasing' below.
Exercise 3.0.12. Adapt the proof above such that it holds for normal
CTRS's, and for join CTRS's.
Exercise 3.0.13. (Bergstra & Klop [86]) In this exercise we give a crite-
rion for decidability of normal forms which does not imply termination (as the
criterion `decreasing' does).
Let R be a normal CTRS. If r: t ! s ( t
1
 n
1
; : : : ; t
k
 n
k
is a rule of
R, then an instance t

( some substitution) is called a candidate r-redex of R.
(Of course it depends on the validity of the instantiated conditions t

i
 n
i
of r
whether t

is an actual r-redex or not.)
We dene inductively the set NF
n
of normal forms of order n for all n  0
as follows: NF
0
is the set of normal forms of R
u
, the unconditional part of
R. Suppose NF
i
(i  n) have been dened. Then M 2 NF
n+1
if for every
candidate r-redex t

M , r as above, the left-hand side of one of the conditions,
t

i
; evaluates to a `wrong' normal form m
i
, i.e. m
i
6 n
i
, such that m
i
is of
order  n. Furthermore, NF is the set of all normal forms of R. We say that
NF?
S
n0
NF
n
contains the normal forms of innite order.
1. Show that if NF is undecidable, then there must be some normal form of
innite order.
2. Suppose for every rule r (as above) of R we have t
i
 t (t
i
is a proper
subterm of t), i = 1; : : : ; k. Then we say that R has subterm conditions.
Show that if R has subterm conditions, there are no normal forms of innite
order. Hence NF is decidable.
Non-orthogonal conditional rewriting
Following Dershowitz, Okada & Sivakumar [88] (see also Dershowitz &
Okada [90]), we will now consider CTRS's which are not orthogonal (i.e.
may have `critical pairs') and formulate some conditions ensuring conu-
ence.
Denition 3.0.14. (Critical Pairs)
1. Let R be a CTRS containing the two conditional rewrite rules
t
i
! s
i
( E
i
(i = 1; 2):
(Suppose these are `standardized apart', i.e. have no variables in
common.) Suppose t
2
can be unied with the nonvariable subterm u
in t
1
 C[u], via  = mgu(t
2
; u). Then the conditional equation(!)
s

1
= C[t
2
]

( (E
1
; E
2
)

is a critical pair of the two rules.
106 J. W. Klop
2. A critical pair is an overlay if in (1), t
1
and t
2
unify at the root, i.e.
t
1
 u:
3. A CTRS is non-overlapping (or non-ambiguous) if it has no critical
pairs.
4. A critical pair s = t ( E is joinable if for all substitutions  such
that E

is true, we have s

# t

:
Theorem 3.0.15. (Dershowitz, Okada & Sivakumar [88])
1. Let R be a semi-equational CTRS. Then: If R is terminating and all
critical pairs are joinable, R is conuent.
2. Let R be a join system. Then: If R is decreasing and all critical pairs
are joinable, R is conuent.
3. Let R be a join system. If R is terminating and all critical pairs are
overlays and joinable, R is conuent.
This theorem contains the unexplained notion of a `decreasing' CTRS:
Denition 3.0.16. (Dershowitz, Okada & Sivakumar [88]) Let R be a
CTRS.
1. > is a decreasing ordering for R if
(a) > is a well-founded ordering on the set of terms of R (i.e. there
are no descending chains t
0
> t
1
> t
2
>   );
(b) t  s ) t < s (here  is the proper subterm ordering);
(c) t! s ) t > s;
(d) for each rewrite rule t ! s ( t
1
# s
1
; : : : ; t
n
# s
n
(n  0)
and each substitution  we have: t

> t

i
; s

i
(i = 1; : : : ; n).
(Likewise for other CTRS's than join CTRS's.)
2. A CTRS is decreasing if it has a decreasing ordering.
A consequence of `decreasing' is termination. Moreover, the notions
!;; #, and normal form are decidable.
Remark 3.0.17. Related notions are fair or simplifying CTRS's (Kaplan
[84, 87]) and reductive CTRS's (Jouannaud & Waldmann [86]). In fact:
reductive ) simplifying) decreasing; see also Dershowitz & Okada [90].
We conclude this section by mentioning a useful fact:
Theorem 3.0.18. (Dershowitz, Okada & Sivakumar [88]) Let R
=
be a
decreasing semi-equational CTRS. Let R
#
be the corresponding join CTRS
(where conditions t
i
= s
i
are changed into t
i
# s
i
). Then:
R
=
is conuent ) R
#
is conuent.
Term Rewriting Systems 107
Acknowledgements
I am grateful to several persons for their support in writing this chapter.
In particular I like to thank Henk Barendregt, Nachum Dershowitz, Ronan
Sleep, Roel de Vrijer, as well as editors and co-authors of this Handbook.
Special thanks to Aart Middeldorp for several contributions, and to Jean-
Jacques Levy for his close scrutiny of a previous version including many
helpful comments. Finally, many thanks to Aart Middeldorp, Vincent van
Oostrom, Jane Spurr and Fer-Jan de Vries for the heroic struggle to trans-
form an early Macintosh version into L
A
T
E
X.
4 References
Apt, K.R. (1990). Logic Programming. In: Formal models and semantics, Hand-
book of Theoretical Computer Science, Vol. B (ed. J. van Leeuwen), 495-574.
Bachmair, L. (1988). Proof by consistency in equational theories. In: Proceedings
of the 3rd IEEE Symposium on Logic in Computer Science, Edinburgh, 228-233.
Bachmair, L. (1989). Canonical Equational Proofs. Birkhauser, Boston, 1991.
Bachmair, L. & Dershowitz, N. (1986). Commutation, transformation, and ter-
mination. Proceedings of the 8th Conference on Automated Deduction (ed. J.H.
Siekmann), Oxford, Springer LNCS 230, 5-20.
Bachmair, L., Dershowitz, N. & Hsiang, J. (1986). Orderings for equational
proofs. In: Proceedings of the 1st IEEE Symposium on Logic in Computer Sci-
ence, Cambridge, Massachusetts, 346-357.
Bachmair, L. & Plaisted, D.A. (1985). Associative path orderings. In: Proceed-
ings of the 1st International Conference on Rewriting Techniques and Applica-
tions (ed. J.-P. Jouannaud), Dijon, Springer LNCS 202, 241-254.
Barendregt, H.P. (1981). The Lambda Calculus, its Syntax and Semantics (1st
edn. 1981, 2nd edn. 1984). North-Holland, Amsterdam.
Barendregt, H.P. (1989). Functional programming and lambda calculus. In:
Handbook of Theoretical Computer Science (ed. J. van Leeuwen), North-Holland,
Amsterdam.
Barendregt, H.P., van Eekelen, M.C.J.D., Glauert, J.R.W., Kennaway, J.R., Plas-
meijer, M.J. & Sleep, M.R. (1987). Term graph rewriting. In: Proceedings of
the 1st Conference on Parallel Architectures and Languages Europe (PARLE),
Eindhoven, Vol. II, Springer LNCS 259, 141-158.
Bergstra, J.A., Heering, J. & Klint, P. (eds.) (1989). Algebraic specication.
Addison-Wesley, Reading, Massachusetts.
Bergstra, J.A. & Klop, J.W. (1984). Process algebra for synchronous communi-
cation. Information and Control 60 (1/3), 109-137.
Bergstra, J.A. & Klop, J.W. (1985). Algebra of communicating processes with
abstraction. TCS 37 (1), 171-199.
Bergstra, J.A. & Klop, J.W. (1986). Conditional rewrite rules: conuence and
termination. JCSS 32 (3), 323-362.
108 J. W. Klop
Bergstra, J.A. & Meyer, J.-J.Ch. (1984). On specifying sets of integers. EIK
(Elektronische Informationsverarbeitung und Kybernetik) 20 (10/11), 531-541.
Bergstra, J.A. & Tucker, J.V. (1980). A characterisation of computable data
types by means of a nite equational specication method. In: Proceedings of of
the 7th International Colloquium on Automata, Languages and Programming,
(eds. J.W. de Bakker & J. van Leeuwen), Amsterdam, Springer LNCS 85, 76-90.
Berry, G. & Levy, J.-J. (1979). Minimal and optimal computations of recursive
programs. JACM 26, 148-175.
Birkho, G. (1935). On the structure of abstract algebras. In: Proceedings of the
Cambridge Philosophical Society 31, 433-454.
Boudol, G. (1985). Computational semantics of term rewriting systems. In: Al-
gebraic methods in semantics (eds. M. Nivat and J.C. Reynolds), Cambridge
University Press, 169-236.
Courcelle, B. (1990). Recursive application schemes. In: Formal models and
semantics, Handbook of Theoretical Computer Science, Vol. B, (ed. J. van
Leeuwen), Elsevier - The MIT Press, Amsterdam, 459-492.
Church, A. (1941). The calculi of lambda conversion. Annals of Mathematics
Studies, Vol. 6, Princeton University Press.
Curien, P.-L. (1986). Categorical combinators, sequential algorithms and func-
tional programming. Research Notes in Theoretical Computer Science, Pitman,
London.
Dauchet, M. (1989). Simulation of Turing machines by a left-linear rewrite rule.
In: Proceedings of the 3rd International Conference on Rewriting Techniques and
Applications, Chapel Hill, Springer LNCS 355, 109-120.
Dauchet, M. & Tison, S. (1984). Decidability of conuence for ground term
rewriting systems. Report, Universite de Lille I.
Dauchet, M., Tison, S., Heuillard, T. & Lescanne, P. (1987). Decidability of the
conuence of ground term rewriting systems. In: Proceedings of the 2nd Sympo-
sium on Logic in Computer Science, Ithaca, NY, 353-359.
Dershowitz, N. (1979). A note on simplication orderings. Information Process-
ing Letters 9 (5), 212-215.
Dershowitz, N. (1981). Termination of linear rewriting systems. Proceedings of
the 8th International Colloquium on Automata, Languages and Programming,
(Eds. S. Even and O. Kariv), Springer LNCS 115, 448-458.
Dershowitz, N. (1985). Computing with rewrite systems. Information and Con-
trol 65, 122-157.
Dershowitz, N. (1987). Termination of rewriting. J. of Symbolic Computation 3
(1), 69-116. Corrigendum: 4 (3), 409-410.
Dershowitz, N. & Jouannaud, J.-P. (1990). Rewrite systems. In: Formal models
and semantics, Handbook of Theoretical Computer Science, Vol. B, (ed. J. van
Leeuwen), Elsevier - The MIT Press, Amsterdam, 243-320.
Dershowitz, N. & Manna, Z. (1979). Proving termination with multiset orderings.
Comm. of the ACM 22 (8), 465-476.
Dershowitz, N., Marcus, L. & Tarlecki, A. (1988). Existence, uniqueness, and
Term Rewriting Systems 109
construction of rewrite systems. SIAM J. Comput. 17 (4), 629-639.
Dershowitz, N. & Okada, M. (1990). A rationale for conditional equational pro-
gramming. TCS 75, 111-138.
Dershowitz, N., Okada, M. & Sivakumar, G. (1987). Conuence of Conditional
Rewrite Systems. In: Proceedings of the 1st International Workshop on Condi-
tional Term Rewrite Systems, Orsay, Springer LNCS 308, 31-44.
Dershowitz, N., Okada, M. & Sivakumar, G. (1988). Canonical Conditional
Rewrite Systems. In: Proceedings of the 9th Conference on Automated Deduc-
tion, Argonne, Springer LNCS 310, 538-549.
Drosten, K. (1989). Termersetzungssysteme. Informatik-Fachberichte 210,
Springer. (In German.)
Ehrig, H. & Mahr, B. (1985). Fundamentals of Algebraic Specication 1. Equa-
tions and Initial Semantics. Springer-Verlag, Berlin.
Gallier, J.H. (1987). What's so special about Kruskal's Theorem and the ordinal
?
0
. Technical report MS-CIS-87-27, University of Pennsylvania, Philadelphia.
Ganzinger, H. & Giegerich, R. (1987). A note on termination in combinations of
heterogeneous term rewriting systems. Bulletin of the EATCS (European Asso-
ciation for Theoretical Computer Science) 31, 22-28.
Geser, A. (1990). Relative Termination. Ph.D. Thesis, University of Passau,
1990.
Goguen, J.A. & Meseguer, J. (1985). Initiality, induction, and computability. In:
Algebraic methods in semantics (eds. M. Nivat & J.C. Reynolds), Cambridge
University Press 1985, 459-542.
Guessarian, I. (1981). Algebraic semantics. Springer LNCS 99.
Hardin, T. (1989). Conuence results for the pure Strong Categorical Logic CCL;
-calculi as subsystems of CCL. TCS, Fundamental Studies 65 (3), 291-342.
Hindley, J.R. (1964). The Church-Rosser property and a result in combinatory
logic. Ph.D. Thesis, University of Newcastle-upon-Tyne.
Hindley, J.R. & Seldin, J.P. (1986). Introduction to Combinators and -Calculus.
London Mathematical Society Student Texts 1, Cambridge University Press.
Holldobler, S. (1989). Foundations of Equational Logic Programming. Springer
LNCS 353.
Huet, G. (1980). Conuent reductions: Abstract properties and applications to
term rewriting systems. JACM 27 (4), 797-821.
Huet, G. (1981). A complete proof of correctness of the Knuth-Bendix completion
algorithm. JCSS 23, 11-21.
Huet, G. & Lankford, D.S. (1978). On the uniform halting problem for term
rewriting systems. Rapport Laboria 283, IRIA, 1978.
Huet, G. & Levy, J.-J. (1979). Call-by-need computations in non-ambiguous lin-
ear term rewriting systems. Rapport INRIA 359. To appear as: Computations
in orthogonal term rewriting systems in: Computational logic, essays in honour
of Alan Robinson (eds. J.-L. Lassez & G. Plotkin), MIT Press, Cambridge, Mas-
sachusetts.
Huet, G. & Oppen, D.C. (1980). Equations and rewrite rules: A survey. In:
110 J. W. Klop
Formal Language Theory: Perspectives and Open Problems (ed. R.V. Book),
Academic Press, London, 349-405.
Hullot, J.M. (1980) Canonical forms and unication. In: Proceedings 5th Con-
ference on Automated Deduction, Les Arcs, France, 318-334.
Jantzen, M. (1988). Conuent string rewriting and congruences. EATCS (Euro-
pean Association for Theoretical Computer Science) Monographs on Theoretical
Computer Science 14, Springer-Verlag, Berlin.
Jouannaud, J.-P. & Kirchner, H. (1986). Completion of a set of rules modulo a
set of equations. SIAM J. Comp. 15 (4), 1155-1194.
Jouannaud, J.-P. & Waldmann, B. (1986). Reductive conditional Term Rewrit-
ing Systems. In: Proceedings of the 3rd IFIP Working Conference on Formal
Description of Programming Concepts, Ebberup, 223-244.
Kamin, S. & Levy, J.-J. (1980). Two generalizations of the recursive path order-
ing. Unpublished manuscript, University of Illinois.
Kaplan, S. (1984). Conditional Rewrite Rules. TCS 33 (2,3).
Kaplan, S. (1987). Simplifying conditional term rewriting systems: Unication,
termination and conuence. J. of Symbolic Computation 4 (3), 295-334.
Kennaway, J.R. (1989). Sequential evaluation strategies for parallel-or and re-
lated reduction systems. Annals of Pure and Applied Logic 43, 31-56.
Kennaway, J.R. & Sleep, M.R. (1989). Neededness is hypernormalizing in regular
combinatory reduction systems. Preprint, School of Information Systems, Uni-
versity of East Anglia, Norwich.
Klop, J.W. (1980a). Combinatory Reduction Systems. Mathematical Centre
Tracts 127, CWI, Amsterdam.
Klop, J.W. (1980b). Reduction cycles in Combinatory Logic. In: Festschrift `To
H.B. Curry, Essays on Combinatory Logic, Lambda Calculus and Formalism'
(eds. J.P. Seldin & J.R. Hindley), Academic Press, London, 193-214.
Klop, J.W. (1985). Term Rewriting Systems. Notes for the Seminar on Reduc-
tion Machines, Ustica. Unpublished.
Klop, J.W. (1987) Term rewriting systems: a tutorial, Bulletin of the EATCS
32, 143-182.
Klop, J.W. & Middeldorp, A. (1988). An Introduction to Knuth-Bendix Com-
pletion. CWI Quarterly 1(3), Centre for Mathematics and Computer Science,
Amsterdam, 31-52.
Klop, J.W. & Middeldorp, A. (1989). Sequentiality in Orthogonal Term Rewrit-
ing Systems. Report CS-R8932, CWI, Centre for Mathematics and Computer
Science, Amsterdam. To appear in J. of Symbolic Computation.
Knuth, D.E. & Bendix, P.B. (1970). Simple word problems in universal algebras.
In: Computational Problems in Abstract Algebra (ed. J. Leech), Pergamon
Press, 263-297.
Kruskal, J.B. (1960). Well-Quasi-Ordering, the Tree Theorem, and Vazsonyi's
Conjecture. Transactions of the AMS 95, 210-225.
Kurihara, M. & Kaji, I. (1988). Modular Term Rewriting Systems: Termina-
tion, Conuence and Strategies. Report, Hokkaido University. Abridged version:
Term Rewriting Systems 111
Modular term rewriting systems and the termination. Information Processing
Letters 34 34, 1-4.
Lankford, D.S. (1979). On proving term rewriting systems are Noetherian. Memo
MTP-3, Mathematical Department, Louisiana Technical University, Ruston,
Louisiana.
Le Chenadec, P. (1986). Canonical forms in nitely presented algebras. Research
Notes in Theoretical Computer Science, Pitman, London.
Martelli, A. & Montanari, U. (1982). An ecient unication algorithm. Trans-
actions on Programming Languages and Systems 4(2), 258-282.
Martelli, A., Moiso, C. & Rossi C.F. (1986). An Algorithm for Unication in
Equational Theories. In: Proceedings Symposium on Logic Programming, 180-
186.
Meinke, K. & Tucker, J.V. (1991). Universal algebra. In: Handbook of Logic
in Computer Science (eds. S. Abramsky, D. Gabbay & T. Maibaum), Oxford
University Press, this volume.
Metivier, Y. (1983). About the rewriting systems produced by the Knuth-Bendix
completion algorithm. Information Processing Letters 16, 31-34.
Middeldorp, A. (1989a). Modular aspects of properties of term rewriting systems
related to normal forms. In: Proceedings of 3rd International Conference on
Rewriting Techniques and Applications, Chapel Hill, Springer LNCS 355, 263-
277.
Middeldorp, A. (1989b). A sucient condition for the termination of the direct
sum of term rewriting systems. In: Proceedings of the 4th IEEE Symposium on
Logic in Computer Science, Pacic Grove, 396-401.
Middeldorp, A. (1990). Modular properties of term rewriting systems. Ph.D.
Thesis, Vrije Universiteit, Amsterdam.
Middeldorp, A. (1991). Modular properties of conditional term rewriting proper-
ties. To appear in Information and Computation.
Nash-Williams, C.St.J.A. (1963). On well-quasi-ordering nite trees. In: Pro-
ceedings of the Cambridge Philosophical Society 59(4), 833-835.
Nederpelt, R.P. (1973). Strong normalization for a typed lambda calculus with
lambda structured types. Ph.D. Thesis, Technische Hogeschool, Eindhoven, the
Netherlands.
Newman, M.H.A. (1942). On theories with a combinatorial denition of \equiv-
alence". Annals of Math. 43(2), 223-243.
O'Donnell, M.J. (1977). Computing in systems described by equations. Springer
LNCS 58.
O'Donnell, M.J. (1985). Equational logic as a programming language. The MIT
Press, Cambridge, Massachusetts.
Oyamaguchi, M. (1987). The Church-Rosser property for ground term rewriting
systems is decidable. TCS 49(1), 43-79.
Peterson, G.E. & Stickel, M.E. (1981). Complete sets of reductions for some
equational theories. J. of the ACM, 28(2), 233-264.
Plaisted, D.A. (1978). A recursively dened ordering for proving termination of
112 J. W. Klop
term rewriting systems. Report R-78-943, University of Illinois, Urbana, Illinois.
Plaisted, D.A. (1985). Semantic conuence tests and completion methods. Infor-
mation and Control, bf 65, 182-215.
Puel, L. (1986). Using unavoidable sets of trees to generalize Kruskal's theorem.
J. of Symbolic Computation 8(4), 335-382.
Raoult, J.-C. & Vuillemin, J. (1980). Operational and semantic equivalence be-
tween recursive programs. Journal of the ACM 27(4),772-796.
Rosen, B.K. (1973). Tree-manipulating systems and Church-Rosser theorems.
Journal of the ACM 20(1), 160-187.
Rusinowitch, M. (1987a). On termination of the direct sum of term rewriting
systems Information Processing Letters 26, 65-70.
Rusinowitch, M. (1987b). Path of subterms ordering and recursive decomposition
ordering revisited. Journal of Symbolic Computation 3, 117-131.
Selman, A. (1972). Completeness of calculii for axiomatically dened classes of
algebras. Algebra Universalis 2, 20-32.
Shoeneld, J.R. (1967). Mathematical Logic. Addison-Wesley, Reading, Mas-
sachusetts.
Siekmann, J. (1984). Universal unication. In: Proceedings of the 7th Interna-
tional Conference on Automated Deduction (ed. R.E. Shostak), Napa, California,
Springer LNCS 170, 1-42.
Smorynski, C. (1982). The variety of arboreal experience. The Mathematical
Intelligencer, 4(4), 182-189.
Staples, J. (1975). Church-Rosser theorems for replacement systems. In: Algebra
and Logic (ed. J. Crosley), Springer Lecture Notes in Mathematics 450, 291-307.
Thatte, S. (1987). A renement of strong sequentiality for term rewriting with
constructors. Information and Computation 72, 46-65.
Toyama, Y. (1987a). Counterexamples to termination for the direct sum of Term
Rewriting Systems. Information Processing Letters 25, 141-143.
Toyama, Y. (1987b). On the Church-Rosser property for the direct sum of term
rewriting systems. Journal of the ACM 34(1), 128-143.
Toyama, Y. (1988). Commutativity of Term Rewriting Systems. In: Program-
ming of Future Generation Computer II (eds. K. Fuchi and L. Kott), North-
Holland, Amsterdam, 393-407.
Toyama, Y., Klop, J.W. & Barendregt, H.P. (1989). Termination for the di-
rect sum of left-linear term rewriting systems. In: Proceedings of the 3rd In-
ternational Conference on Rewriting Techniques and Applications, Chapel Hill,
Springer LNCS 355, 477-491. Extended version: Report CS-R8923, CWI, Ams-
terdam.
Turner, D.A. (1979). A new implementation technique for applicative languages.
Software Practice and Experience, 9, 31-49.
Winkler, F. & Buchberger, B. (1983). A criterion for eliminating unnecessary
reductions in the Knuth-Bendix algorithm. In: Proceedings of the Colloquium on
Algebra, Combinatorics and Logic in Computer Science, Gyor, Hungary.
