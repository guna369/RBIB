Termination of term rewriting using dependency pairs

Thomas Arts a, Jurgen Giesl b
aDepartment of Computer Science, Utrecht University, P.O. Box 80.089, 3508 TB Utrecht, The Netherlands, E-mail: thomas@cs.ruu.nl
bDepartment of Computer Science, Darmstadt University of Technology, Alexanderstra e 10, 64283 Darmstadt, Germany, E-mail:
giesl@informatik.tu-darmstadt.de
Abstract
We present techniques to prove termination and innermost termination of term rewriting systems automatically. In contrast to previous approaches, we do not compare left- and right-hand sides of rewrite rules, but introduce the notion of dependency pairs to compare left-hand sides with special subterms of the righthand sides. This results in a technique which allows to apply existing methods for automated termination proofs to term rewriting systems where they failed up to now. In particular, there are numerous term rewriting systems where a direct termination proof with simpli cation orderings is not possible, but in combination with our technique, well-known simpli cation orderings (such as the recursive path ordering, polynomial orderings, or the Knuth-Bendix ordering) can now be used to prove termination automatically.
Unlike previous methods, our technique for proving innermost termination automatically can also be applied to prove innermost termination of term rewriting systems that are not terminating. Moreover, as innermost termination implies termination for certain classes of term rewriting systems, this technique can also be used for termination proofs of such systems.

1 Introduction

Termination is one of the most fundamental properties of a term rewriting system (TRS), cf. e.g. 18]. While in general this problem is undecidable 29], several methods for proving termination have been developed (e.g. path orderings
To appear in Theoretical Computer Science

Preprint submitted to Elsevier Preprint

27 August 1998

15,17,31,42,45], Knuth-Bendix orderings 19,33], forward closures 17,38], semantic interpretations 11,12,23,37,43,47], transformation orderings 9,10,44], distribution elimination 47], dummy elimination 21], semantic labelling 48], etc. | for surveys see e.g. 16,45]). We present a new approach for the automation of termination proofs. Most well-known techniques for proving termination automatically try to nd a well-founded ordering such that for all rules of the TRS the left-hand sides are greater than the corresponding right-hand sides. In most practical applications the synthesized orderings are total on ground terms 20] and therefore virtually all orderings used are simpli cation orderings 15,16,41,45]. However, numerous TRSs are not simply terminating, i.e. not compatible with a simpli cation ordering. Hence, standard techniques like the recursive path ordering, polynomial interpretations, and the Knuth-Bendix ordering fail in proving termination of these TRSs. In Sect. 2 we introduce a new criterion for termination based on the notion of dependency pairs. The main advantage of our termination criterion is that it is especially well suited for automation. To check the criterion automatically, we have developed a procedure which generates a set of constraints for every TRS. If there exists a well-founded ordering satisfying these constraints, then the TRS is terminating. For the synthesis of suitable orderings existing techniques, such as the recursive path ordering or polynomial interpretations, may be used. It turns out that for many TRSs where a direct application of simpli cation orderings fails, the constraints generated by our technique are nevertheless satis ed by an automatically generated simpli cation ordering. Moreover, all TRSs that can be proved terminating directly by synthesizing a simpli cation ordering automatically, can automatically be proved terminating by this new technique, too. Rewriting under strategies is often used for modelling certain programming paradigms. For example, innermost rewriting, i.e. rewriting where only innermost redexes are contracted, can be used to model call-by-value computation semantics. For that reason, there has been an increasing interest in research on properties of rewriting under strategies. In particular, the study of termination is important when regarding such restricted versions of rewriting 27,28,36]. To prove innermost termination (also called (strong) innermost normalization), one has to show that the length of every innermost reduction is nite. Techniques for proving innermost termination can for example be utilized for termination proofs of functional programs (modelled by TRSs) with eager reduction strategy or of logic programs. (When transforming well-moded logic programs into TRSs, innermost termination of the TRS is su cient for left-termination of the logic program 8].) Up to now, the only way to prove innermost termination automatically was by showing termination of the TRS. Therefore, none of the existing techniques could prove innermost termination
2

of non-terminating systems. However, in Sect. 3 we show that after some modication, the dependency pair technique can be used as the rst speci c method for innermost termination. In Sect. 4 we conclude and give some comments on related work.

2 Proving termination

In this section we present a new approach for automated termination proofs. In Sect. 2.1, we state our termination criterion and prove that it is a necessary and su cient criterion for termination. Sect. 2.2 shows how this criterion can be checked automatically by generating a set of constraints that are satis ed by a well-founded ordering if and only if the criterion is ful lled. The generation of suitable well-founded orderings is described in Sect. 2.3. To increase the power of our method we introduce a re ned approach for its automation in Sect. 2.4 and an additional re nement in Sect. 2.5. In this way we obtain a very powerful technique which performs automated termination proofs for many TRSs where termination could not be proved automatically before. An overview of this technique is given in Sect. 2.6.

2.1 Termination criterion

For constructor systems it is common to split the signature into two disjoint sets, the de ned symbols and the constructors. The following de nition extends
these notions to arbitrary term rewriting systems R(F R) (with the rules R over a signature F). For an introduction to term rewriting and its notations,
we refer to Dershowitz and Jouannaud 18] and Klop 32], for example. Here, the root of a term (f : : :) is the leading function symbol f.

De nition 1 (De ned symbols and constructors) Let R(F R) be a

TRS. The set DR and the set CR of

of de ned symbols of R constructors of R is de

is de ned as f ( )root l ned as F n DR.

j

l

!

r

2

Rg

To refer to the de ned symbols and constructors explicitly, a rewrite system
is written as R(DR CR R) and the subscripts are omitted if R is clear from
the context.

Example 2 The following TRS has two de ned symbols, viz. minus and quot,
and two constructors, viz. 0 and s.

minus(x 0) ! x minus(s(x) s(y)) ! minus(x y)

3

quot(0 s(y)) ! 0 quot(s(x) s(y)) ! s(quot(minus(x y) s(y)))

Most techniques for automated termination proofs are restricted to simpli cation orderings. However, the TRS above is not compatible with a simpli cation ordering, because the left-hand side of the last quot-rule is embedded in its right-hand side if y is instantiated with s(x). Therefore these techniques cannot prove termination of this TRS.

In contrast to previous methods which compare left- and right-hand sides of rules, the central idea of our approach is to compare left-hand sides of rules only with those subterms of the right-hand sides that may possibly start a new reduction.

The motivation for this approach is to regard TRSs as `programs'. Intuitively, such a program is terminating if the arguments are decreasing in each recursive call. For example, to prove termination of quot, instead of comparing both sides of the rules, one only has to compare the input arguments s(x) s(y) with the arguments minus(x y) s(y) of the corresponding recursive call. This way of looking at termination of TRSs motivates that only those subterms of the right-hand sides that have a de ned root symbol are considered for the examination of the termination behaviour.

More precisely, if a term (f s1 : : : sn) rewrites to a term (C g t1 : : : tm)]

(where g is a de ned symbol and C denotes some context), then for proving

termination, the argument order to avoid the handling

tuples s1 of tuples,

:::
the

sn and t1 signature

:
F

::
of

tm are compared. In the TRS is extended

by a set of fresh symbols, i.e., disjoint from the symbols in the signature, such

that there is a one-to-one mapping from the de ned symbols to these fresh

symbols. The fresh symbols are called tuple symbols, and to ease readability,

in this paper we assume that the original signature F consists of lower case

function symbols only, whereas the tuple symbols are denoted by the cor-

responding upper case symbols. Instead of comparing tuples, now the terms

(F s1 : : : sn) and (G t1 : : : tm) are compared, where F and G are the tuple

symbols for f and g, respectively 1 .

De nition 3 (Dependency pair) Let R(D C R) be a TRS. If

( ) ! ( )]nf s1 : : : s

mC g t1 : : : t

1 Intuitively, tuple symbols are used to `measure' the arguments of de ned symbols during the termination proofs. Sometimes the arguments of two de ned function symbols f and g must be measured in a di erent way. Thus, we introduce a di erent tuple symbol for each de ned symbol to distinguish whether a tuple of terms serves as input for f or for g.

4

is a

a rewrite rule of dependency pair

R
of

with
R.

g

2

D,

then

hF

(s1

:::

sn)

(G t1

:::

tm)i is called

The dependency pairs of a TRS are easily determined and if the TRS is nite, then only nitely many dependency pairs exist.

Example 4 The dependency pairs of the TRS in Ex. 2 are

hM(s(x) s(y)) M(x y)i hQ(s(x) s(y)) M(x y)i hQ(s(x) s(y)) Q(minus(x y) s(y))i

(1) (2) (3)

where M and Q denote the tuple symbols for minus and quot, respectively.

The notion of dependency pairs is the basis for our termination criterion. Since every left-hand side has a de ned root symbol, no rule matches a term without de ned symbols, hence such a term is a normal form. Thus, in nite reductions originate from the fact that de ned symbols are introduced by the right-hand sides of rewrite rules. By tracing the introduction of these de ned symbols, information is obtained about the termination behaviour of the TRS. For that purpose we consider special sequences of dependency pairs, so-called chains, such that the right-hand side of every dependency pair in a chain corresponds to the newly introduced redex that should be traced.

De nition 5 (Chain) Let R(D C R) be a TRS. A sequence of dependency

h ipairs s1 t1 !tj R sj+1

h is2 t2
holds

:::
for

is an R-chain if there
every two consecutive

exists pairs

a substitution such that
h i h isj tj and sj+1 tj+1 in

the sequence.

If R is clear from the context we often write `chain' instead of `R-chain'. We
always assume that di erent (occurrences of) dependency pairs have disjoint sets of variables and we always regard substitutions whose domain may be in nite. Hence, in our example we have the chain

hQ(s(x1) s(y1)) Q(minus(x1 )y1 s(y1))i hQ(s(x2) s(y2)) Q(minus(x2 )y2 s(y2))i

betchaautsereQp(lamciensusx(1xb1 yys1()0)s,(yx12))by!0,RaQnd(s(bxo2t)h

s(y2)) y1 and

holds y2 by

for the substitution 0. In fact any nite

sequence of the dependency pair (3) in Ex. 4 is a chain. However, in the next

section we show that the above TRS has no in nite chain. The following

theorem proves that the absence of in nite chains is a su cient and necessary

criterion for termination.

5

Theorem 6 (Termination criterion) A TRS R(D C R) is terminating if and only if no in nite R-chain exists.

PROOF. We rst prove that the above criterion is su cient for termination, i.e., we show that for any in nite reduction we can construct an in nite R-
chain.

Let t be a term that starts an in nite reduction. By a minimality argument, the term t contains a subterm 2 ( )f1 ~u1 that starts an in nite reduction, but none of the terms ~u1 starts an in nite reduction, i.e., the terms ~u1 are strongly normalizing.

Let us consider an in nite reduction starting with f1(~u1). First, the arguments

~u1 are rule f1 ( )f1 ~v1

reduced
!( )w~1 r1
= ( )f1 w~ 1

in zero or is applied
!1 R r1 1

more steps to arguments ~v1 and then to ( ),f1 ~v1 i.e., a substitution 1 exists . Now the in nite reduction continues

a rewrite such that with r1 1,

i.e., the term r1 1 starts an in nite reduction, too.

By assumption there exists no in nite reduction beginning with one of the terms ~v1 = w~1 1. Hence, for all variables x occurring in ( )f1 w~1 the terms 1(x) are strongly normalizing. Thus, since r1 1 starts an in nite reduction, there occurs a subterm ( )f2 ~u2 in ,r1 i.e. r1 = C ( )]f2 ~u2 for some context C, such that

( )f2 ~u2 1 starts an in nite reduction and ~u2 1 are strongly normalizing terms.

The rst dependency pair
i( )F2 ~u2 corresponding to
pendency pairs of the in

nothfitetehreRewi-ncrhitnaeiintreuaRlree-cfdh1e(awt~ien1r)tmh!iantCewdfei2nc(~outn2h)se]t.rsuTacmhteeisowhtFahy1e(:rw~Ld1ee)t-

hFj;1(w~j;1) iFj(~uj) be a dependency pair such that fj(~uj) j;1 starts an in -

nite reduction and the terms ~uj or more steps fj(~uj) j;1 reduces

j;1 are strongly normalizing. Again, in to fj(~vj) to which a rewrite rule fj(w~j)

zero
! rj

can be applied such that rj j starts an in nite reduction for some substitution

j with ~vj = w~j j.

Similar to the observations above, since rj j starts an in nite reduction, there must be a subterm ( )fj+1 ~uj+1 in rj such that

( )fj+1 ~uj+1 j starts an in nite reduction and ~uj+1 j are strongly normalizing terms.

2 Tuples of terms t1 : : : tn are denoted by .~t

6

This results in the j-th dependency pair of the chain, viz. hFj(w~j) i( ) .Fj+1 ~uj+1
In this way, one obtains the in nite sequence

h ( ) ( )i h ( ) ( )i h ( ) ( )iF1 w~1 F2 ~u2

F2 w~ 2 F3 ~u3

F3 w~ 3 F4 ~u4 : : :

It remains to prove that this sequence is really an R-chain.

NofogteentehraatliFtyj,(~uthj ajt;t1h)e!vRarFiaj(b~vlje)s

and ~vj of di

= w~ j erent

j. Since we occurrences

assume, without loss of dependency pairs

are disjoint, we obtain one substitution =

union of 1 2 : fact constructed

): : an

siunchnittheaRt -Fcjh(a~uijn).

!R Fj

1
(w~ j

)

2

: : : (which is the for all j. Thus, we

disjoint have in

Now we show that our criterion is even necessary for termination, i.e., we
prove that any in nite R-chain corresponds to an in nite reduction. Assume there exists an in nite R-chain.

h ( ) ( )i h ( ) ( )i h ( ) ( )iF1 ~s1 F2 ~t2

F2 ~s2 F3 ~t3

F3 ~s3 F4 ~t4 : : :

Hence, there is a substitution such that

( ) ! ( ) ( ) ! ( )F2 ~t2

R F2 ~s2

F3 ~t3

R F3 ~s3

:::

thus also

( ) ! ( ) ( ) ! ( )f2 ~t2

R f2 ~s2

f3 ~t3

R f3 ~s3

:::

as the tuple symbols F2 F3 : : : are no de ned symbols.
Note that every dependency pair h ( )F ~s i( )G ~t corresponds to a rewrite rule f(~s) ! C g(~t)] for some context C. Therefore, this results in the reduction

( )f1 ~s1

! ( )]C1 f2 ~t2 #
( )]C1 f2 ~s2

! ( )]]C1 C2 f3 ~t3 #
( )]]C1 C2 f3 ~s3

! :::

which is in nite.

ut

7

2.2 Checking the termination criterion automatically

The advantage of our termination criterion is that it is particularly well suited for automation. In this section we present a method for proving the absence of in nite chains automatically. For that purpose, we introduce a procedure which, given a TRS, generates a set of inequalities such that the existence of a well-founded ordering satisfying these inequalities is su cient for termination of the TRS. A well-founded ordering satisfying the generated inequalities can often be synthesized by standard techniques, even if a direct termination proof is not possible with these techniques (i.e. even if a well-founded ordering orienting the rules of the TRS cannot be synthesized). For the automation of our method we assume the TRSs to be nite, such that only nitely many dependency pairs have to be considered.

Note that if all chains correspond to a decreasing sequence w.r.t. some well-

founded ordering, then all chains must be nite. Hence, to prove the absence

of in nite chains, we try to synthesize a well-founded ordering > such that all

dependency pairs are decreasing w.r.t. this ordering. More precisely, if for any

sequence with tj

of dependency
!R sj+1 we

pairs have

hs1

iht1 s2

iht2 s3

it3 : : :

and

for

any

substitution

s1 > t1 > s2 > t2 > s3 > t3 > : : :

then no in nite chain exists.

However, for most TRSs, the above inequalities are not satis ed by any wellfounded ordering >, because the terms tj and sj+1 of consecutive dependency pairs in chains are often identical and therefore tj > sj+1 does not hold.

But obviously not all of the inequalities sj > tj and tj > sj+1 have to be strict. For instance, to guarantee the absence of in nite chains it is su cient if there exists a well-founded quasi-ordering 3 such that terms in dependency pairs are strictly decreasing (i.e. sj > tj ) and terms in between dependency pairs are only weakly decreasing (i.e. tj sj+1 ).

So for each sequence of dependency pairs as above we only demand

s1 > t1

s2 > t2

s3 > t3

:::

(4)

Note that we cannot determine automatically for which substitutions we
3 A quasi-ordering is a re exive and transitive relation and is called wellfounded if its strict part > is well founded.

8

have nite

tsjeq!ueRncsejs+1of

and moreover, it is practically impossible to examine independency pairs. Therefore in the following, we restrict

ourselves to weakly monotonic quasi-orderings where both and its strict

part > are closed under substitution. (A quasi-ordering is weakly monotonic

iwrrfuinhlsegesninelv!petorirsmtsjoipbfllt!iyehsieRnfTs(njR:+i:tS1:e.scT:hho:ao:ile)ndnsss,,uwirftee(ids:sj:es:mut>a: n:ct:d)ije.s)ntf>Totrhtoetfnhod,oresmateolaldngdedupepaelrneandndetnerencefycoytrpjpaaailrlisrrsoeshwcsjc+ruit1trie-.

In fact the existence of such a well-founded ordering is not only su cient, but

even necessary to ensure the absence of in nite chains.

Theorem 7 (Proving termination) A TRS R(D C R) is terminating i
there exists a well-founded weakly monotonic quasi-ordering , where both and > are closed under substitution, such that

l r for all rules l ! r in R and s > t for all dependency pairs hs ti.

PROOF. We rst prove that the above conditions are su cient, i.e. that the existence of such a quasi-ordering implies termination of R. Note that as l r holds for all rules l ! r in R and as is weakly monotonic and closed under substitution, we have !R , i.e. if t !R s then t s.

Suppose there is an in substitution such that

nite R-chain !tj R sj+1

h i hs1 t1 s2 t2
holds for all j

i
.

:::
As

Then
!R

there exists a , this implies

.tj sj+1

Since we have sj > tj for all dependency pairs, we obtain the in nite descending sequence

s1 > t1

s2 > t2

s3 > : : :

which is a contradiction to the well-foundedness of >. Therefore, no in nite
R-chain exists and hence by Thm. 6, R is terminating.

Now we prove that the above conditions are even necessary for termination. In
fact, we prove a stronger result, i.e. that termination of R implies termination of the system R0 with the rules

=0
RR

fs ! t j hs ti is a dependency pair of Rg:

Hence, the rewrite ordering of R0 is (even) a well-founded strongly monotonic
ordering > (closed under substitution) satisfying s > t and the strict inequal-

9

ities l > r for all rules of R 4 .

Assume that R0 is not in nite R0-reduction.

terminating.

Hence,

there

exists

a

term

q1

starting

an

! ! ! !R R R k Rq1 0 q2 0 : : :

0q

0 :::

Clearly, q1 must contain tuple symbols, because R is terminating. Without
loss of generality we may assume that q1 is `minimal', i.e. that none of the proper subterms of q1 starts an in nite reduction. We show that this implies that the root of q1 is a tuple symbol.

For any term q, let q] denote the result of replacing all subterms with a root

tuple symbol by one and the same new variable y. Note that tuple symbols do

not occur in rewrite rules of R. Therefore, qj !R0 qj+1 implies qj] !R qj+1],

if the contracted redex in qj is on contracted redex is below a tuple ]qj+1 . If the contracted redex has

a position above all tuple
symbol, then qj !R0 qj+1
a tuple root symbol, then

symbols. If
!implies qj
qj R j0 q +1

the ]= also

implies qj tuple root

] = qj+1]. The reason is that symbol, since all rewrite rules

in of

this case the
R0 that have

reduct a tuple

also has a symbol as

root of the left-hand side also have a tuple symbol as root of the right-hand

side. Hence, as R is terminating, after a nite number of steps (say k) all

contracted redexes in the in nite reduction are below a tuple symbol or have

a tuple root symbol (otherwise ]q1 would start an in nite R-reduction).

Let qk have the symbols and tk

form j are

Ck tk 1
terms

:::
with

ttkunpk]l,e

where Ck is a root symbols.

context without tuple Then one of the tk j

starts an in nite reduction. Now assume that the root symbol of q1 is not a

tuple symbol, i.e., q1 has the form C1 t1 1 : : : context without tuple symbols and t1 1 : : : root positions. By induction on the length k

to1t1fnn1t1hh]e,awrveehdeturuceptCiloe1nsi,ysomanbe(noslohsnoo-wenms ttphhteyai)tr

for each tk j there exists a t1 i such that ! .t1 i R0 tk j Thus, q1 has a proper

subterm t1 i which starts an in nite reduction. This is a contradiction to the

minimality of .q1

Hence, q1 has the form ( )F1 ~u1 where ~u1 are strongly normalizing terms. So

isntetphsetoin~v1n,itaenrdedthuecntioFn1,(~v1r)stisthreedaurcgeudmteontFs2~u(~u12a),rei.er.e,dhuFc1e(d~v1i)n

zero or
i( )F2 ~u2

more is an

instantiation of a dependency pair. Note that ~u2 are again strongly normalizing

terms (this is due to the above observations, because all subterms of ~u2 with

4 The rst intuition to prove this might be to imitate R0-reductions by the union

ortoefdn!uiccRtiifoRnasnidms ntahoyetasslisumobpttelayrkmeteprrmlealaicnetaiowtniintg>h.isnubc.oHntoewxetsv,erw, htehriesaasp!prRoach>fsauibls

b is

ecause R0-
not mono-

10

tuple root symbols already occur in ).~v1 So the in nite reduction has the form

( ) ! ( ) ! ( ) ! ( ) ! ( ) !F1 ~u1

R0 F1 ~v1

R0 F2 ~u2

R0 F2 ~v2

R0 F3 ~u3

R0 : : :

where ~uj !R0
a dependency

~vpjahirooldfsRfo. rLaeltl

j

and

hFj (~vj )

( )iFj+1 ~uj+1

is

an

instantiation

of

h ( ) ( )i h ( ) ( )iF1 ~s1 F2 ~t2

F2 ~s2 F3 ~t3 : : :

be the sequence of 0(x) is de ned to

these be

dependency pairs (x)], then Fj(~tj)

and
0 !R

let ~sj (Fj ~sj

)

=0 h~vojldasndfor~tj

= all j

.~uj If . The

reason is that in dependency pairs, tuple symbols occur on root positions

~otojnf ldy0 e=p(ie.ne~u.d,je]~snjacynadnpdaaigr~tasjinidso~uajnn!ointRc0no~vinjtetiamRinp-cltiheuaspinle~u. jBs]yy!mTbRhoml~vsj).].

Therefore, ~sj 0 = ~vj], . So the above sequence 6, this is a contradiction

to the termination of R. Hence, R0 must also be terminating.

ut

By the above theorem, termination proofs are now reduced to the search for quasi-orderings satisfying certain constraints. Therefore, the technique of Thm. 7 is very useful to apply standard methods like the recursive path ordering or polynomial interpretations to TRSs where they are not directly applicable 5 .
Example 8 For instance, in our example we have to nd a quasi-ordering
satisfying the following inequalities.

minus(x 0) minus(s(x) s(y))
quot(0 s(y)) quot(s(x) s(y))

x
minus(x y) 0 s(quot(minus(x y) s(y)))

5 Using the strict part > of the quasi-ordering in Thm. 7 is sometimes too restrictive. In many standard methods based on semantic interpretations, quasi-orderings are lifted from ground terms to non-ground terms by de ning s it s t for all ground substitutions . However, the strict part of such a quasi-ordering is in general not closed under substitution. On the other hand, the irre exive ordering intuitively associated with such a quasi-ordering is de ned as s >lift t i s > t holds for all ground substitutions , which is indeed closed under substitution. The ordering >lift is compatible with , i.e., >lift >. From the proof of the theorem we easily see that instead of the strict part we in fact only need such a compatible ordering. Therefore in the following, `>' may also be read as this intuitively associated irre exive ordering .>lift

11

M(s(x) s(y)) > M(x y) Q(s(x) s(y)) > M(x y) Q(s(x) s(y)) > Q(minus(x y) s(y))
In the next section we show how quasi-orderings satisfying such sets of inequalities can be synthesized automatically using standard techniques.
2.3 Generating suitable quasi-orderings
A well-founded ordering satisfying the constraints in Ex. 8 can for instance be generated by the well-known techniques of polynomial interpretations 37]. However, when using polynomial interpretations for direct termination proofs of TRSs, the polynomials have to be (strongly) monotonic in all their arguments, i.e. s > t implies f(: : : s : : :) > f(: : : t : : :). But for the approach of this paper, we only need a weakly monotonic quasi-ordering satisfying the inequalities. Thus, s > t only implies f(: : : s : : :) f(: : : t : : :). Hence, when using our method it su ces to nd a polynomial interpretation with weakly monotonic polynomials, which do not necessarily depend on all their arguments. For example, we may map minus(x y) to the polynomial x which does not depend on the second argument y. Then the inequalities in Ex. 8 are satis ed by a polynomial ordering where 0 is mapped to 0, s(x) is mapped to x + 1, and minus(x y), quot(x y), M(x y) and Q(x y) are all mapped to x. Methods for the automated synthesis of polynomial orderings have for instance been developed in 23,43]. In this way, termination of this TRS can be proved fully automatically, although a direct termination proof with simpli cation orderings was not possible. Instead of polynomial orderings one can also use path orderings, which can easily be generated automatically. However, these path orderings are always strongly monotonic, whereas in our method we only need a weakly monotonic ordering. For that reason, before synthesizing a suitable path ordering some of the arguments of function symbols may be eliminated. For instance, one may eliminate the second argument of the function symbol minus. Then every term minus(s t) in the inequalities is replaced by m(s) (where m is a new unary function symbol). By comparing the terms resulting from this replacement (instead of the original terms) we can take advantage of the fact that minus does not have to be strongly monotonic in its second argument.
Example 9 In this way, the inequalities of Ex. 8 are transformed into
m(x) x
12

m(s(x)) m(x) quot(0 s(y)) 0 quot(s(x) s(y)) s(quot(m(x) s(y))) M(s(x) s(y)) > M(x y) Q(s(x) s(y)) > M(x y) Q(s(x) s(y)) > Q(m(x) s(y)):

These inequalities are satis ed by the recursive path ordering using the precedence quot . s . m and Q . M. Apart from eliminating arguments of function symbols, another possibility is to replace functions by one of their arguments. So instead of deleting the second argument of minus one could replace all terms minus(s t) by minus' rst argument s. Then the resulting inequalities are again satis ed by the recursive path ordering. To perform this elimination of arguments resp. of function symbols we introduce the following concept.
De nition 10 (Argument ltering TRS) An argument ltering TRS 6 for the signature F (AFS for short) is a TRS whose rewrite rules are of the
form

( ) ! ( ) ornf x1 : : : x

kg y1 : : : y

( ) !nf x1 : : : x

xi

where x1 : : : ent variables

xn are out of

pairwise di ,nx1 : : : x

erent
g 62 F

variables, , and for

y1 : :
every

: yk are pairwise function symbol

di er-
f 2F

there is at most one f-rule in the AFS.

From a rewriting point of view AFSs are quite simple, because every AFS
is complete. Hence, for any term t the normal form t #A w.r.t. an AFS A is
unique.

The following theorem states that in order to nd a quasi-ordering satisfying a particular set of inequalities, one may rst normalize the terms in the inequalities with respect to an AFS. Subsequently, one only has to nd a quasi-ordering that satis es these modi ed inequalities. Note that for a nite signature there are only nitely many AFSs (up to renaming of the symbols). Hence, by combining the synthesis of a suitable AFS with well-known techniques for the generation of (strongly monotonic) simpli cation orderings, now

6 Argument ltering TRSs are a special form of recursive program schemes 13,32].

13

the search for a weakly monotonic ordering satisfying the constraints can be automated.
Theorem 11 (Preservation under argument ltering) Let A be an
AFS and let IN be a set of inequalities. If the inequalities
fs#A > t#A j s > t 2 INg fs#A t#A j s t 2 INg
are satis ed by a well-founded weakly monotonic quasi-ordering (where both and > are closed under substitution), then there also exists such a quasi-
ordering satisfying the inequalities IN.

PROOF. Assuming that the normalized inequalities are satis ed by a quasi-

ordering , a relation 0 on terms is de ned where the terms are rst nor-

malized w.r.t. A and then compared w.r.t. the quasi-ordering

(i.e. s

0 t

i s #A t #A). It is straightforward to see that 0 is a well-founded quasi-

ordering satisfying the inequalities IN.

For any substitution by normalizing all

, let terms

#A denote
in the range

the of

substitution which results from
w.r.t. A. Then, for all terms t

and all substitutions we have

0
>

are

closed

under

substitution.

(t ) #A= (t
Moreover,

#0Ai)s(

#A).
weakly

Hence, both monotonic,

0 and because

# # # # # #s A

t A implies ( )f : : : x : : : A x=s A]

( ) ] resp.A Af : : : x : : :

x=t

# #( ) Af : : : s : : : ( )f : : : t : : : A ( here, x is a variable occurring just once in

ut( ) ).f : : : x : : :

By the above theorem in combination with Thm. 7 it is now possible to prove termination of the TRS in Ex. 2 automatically using the recursive path ordering. After normalizing all inequalities in Ex. 8 w.r.t. the one-rule AFS
minus(x y) ! m(x)
one obtains the inequalities in Ex. 9 which are satis ed by the recursive path ordering.

2.4 Re nement using dependency graphs

While the method of Thm. 7 can be successfully used for automated termination proofs, in this section we introduce a re nement of this approach, i.e., we show how the constraints obtained can be weakened. By this weakening, the

14

(automatic) search for a suitable quasi-ordering satisfying these constraints can be eased signi cantly.

In order to ensure that every possible in nite chain results in an in nite decreasing sequence of terms, in Thm. 7 we demanded s > t for all dependency
pairs hs ti. However, in many examples several dependency pairs can occur
at most once in any chain and therefore they do not have to be considered at all. Moreover, for the other dependency pairs it is often su cient if just some of them are strictly decreasing, whereas others may be weakly decreasing.

Example 12 The dependency pair hQ(s(x) s(y)) M(x y)i occurs at most

once in any chain: Recall that a dependency pair hv wi may only follow a

pair hs ti in a chain,
the tuple symbol M is

if there exists not a de ned

a substitution symbol, M(x y)

such can

that t !R v . As
only be reduced to

terms with the same root symbol M. Hence, the dependency pair (2) can only

be succeeded by the dependency pair (1) which in turn can only be succeeded by

itself, i.e. (2) can never occur twice in a chain. Therefore, any possible in nite

chain has an in nite tail in which the dependency pair hQ(s(x) s(y)) M(x y)i

does not occur. Therefore it su ces to show that no in nite chain exists con-

sisting of the other dependency pairs.

For the TRS of Ex. 2 it is not necessary to reduce the number of constraints in order to prove termination automatically. However, for the following TRS we have to get rid of a constraint in order to use a simpli cation ordering for satisfying the inequalities.

Example 13 Let us extend the TRS of Ex. 2 by three additional rules. We
now write in x operators for the de ned symbols minus and plus to ease readability.

x;0 ! x s(x) ; s(y) ! x ; y quot(0 s(y)) ! 0 quot(s(x) s(y)) ! s(quot(x ; y s(y)))
!0 + y y s(x) + y ! s(x + y) (x ; y) ; z ! x ; (y + z)

The dependency pairs of this TRS are the dependency pairs as given in Ex. 4 together with the dependency pairs

hP(s(x) y) P(x y)i hM(x ; y z) P(y z)i

(5) (6)

15

hM(x ; y z) M(x y + z)i

(7)

where P is the tuple symbol for the de ned symbol `+'. To prove termination according to Thm. 7 we now obtain the following inequalities.

x;0 s(x) ; s(y)
quot(0 s(y)) quot(s(x) s(y))
0+y s(x) + y
(x ; y) ; z

x
;x y
0
s(quot(x ; y s(y)))
y
s(x + y)
;x (y + z)

M(s(x) s(y)) > M(x y)

Q(s(x) s(y)) > M(x y)

Q(s(x) s(y)) > Q(x ; y s(y))

P(s(x) y) > P(x y)

;M(x ) ( )Py z > y z

;M(x

) ( + )My z >

xy z

Since the inequality Q(s(x) s(y)) > ;Q(x y s(y)) has an instantiation that is
self-embedding, no simpli cation ordering satis es these inequalities directly. In order to apply techniques for the automated generation of simpli cation orderings, therefore Thm. 11 has to be used rst. We have to normalize the
inequalities w.r.t. an AFS A that rewrites x ; y to m(x) or to x (this is forced
by the inequalities). But thereafter, the inequality
;M(x y #z) A> P(y z) #A

in combination with the other remaining inequalities cannot be satis ed by any

well-founded monotonic ordering closed under substitution. (The reason is that

y does not
on y, as A

occur must

in ;M(x y z) #A
not eliminate the

any rst

more, whereas P(y z) #A still depends
argument of P.) Hence, an automatic

termination proof fails at this point.

Recall that one may delete all dependency pairs which occur at most once in any chain. In the example above, this elimination of constraints results in a set of inequalities for which a suitable quasi-ordering can be generated automatically, whereas this is not possible for the original set of constraints.

Example 14 For the TRS of Ex. 13, the constraint M(: : :) > P(: : :) is unnec-
essary to ensure the absence of in nite chains. The reason is that in any chain

16

the dependency pair (6) can occur at most once, since the only dependency pair following (6) can be (5) and (5) can only be followed by itself. To determine those dependency pairs which may occur in nitely often in a chain we de ne a graph of dependency pairs where those dependency pairs that possibly occur consecutive in a chain are connected. In this way, any in nite chain corresponds to a cycle in the graph (as we restricted ourselves to nite TRSs).
De nition 15 (Dependency graph) The dependency graph of a TRS R
is the directed graph whose nodes are the dependency pairs and there is an arc
from hs ti to hv wi if hs tihv wi is an R-chain.
Thus, the dependency graph connects dependency pairs that form a chain, i.e., for some instantiation the right-hand side of one pair reduces to the left-hand side of the other pair. Every chain corresponds to a path in the dependency graph. Note however that the converse does not hold, i.e., a path in this graph does not necessarily correspond to a chain, since instead of using one `global' substitution for all dependency pairs in a chain, here one may use di erent `local' substitutions for consecutive dependency pairs.
Example 16 As an example consider the TRS with the rules

f(x) ! g(x 0) g(1 y) ! f(y):

It has the following dependency pairs.

hF(x) G(x 0)i hG(1 y) F(y)i

(8) (9)

Both (8) (9) and (9) (8) are chains, as can be seen using the `local' substitutions 1(x) = 1 1(y) = 0 and 2(x) = y. Hence, in the dependency graph there are arcs from (8) to (9) and back. However, although (8) (9) (8) is on a path in the dependency graph, it is not a chain, because there exists no `global'
substitution such that G(x 0) !R G(1 y) and F(y) !R F(x) .
Now to prove termination of a TRS it is su cient if s > t holds for at least
one dependency pair hs ti on each cycle of the dependency graph and if s t
holds for all other dependency pairs on cycles. Dependency pairs that do not occur on a cycle can be ignored.
17

h iP(s(x) y) P(x y)

h ; iQ(s(x) s(y)) Q(x y s(y))

h ; iM(x y z) M(x y + z)

h ; iM(x y z) P(y z)

h iQ(s(x) s(y)) M(x y)

h iM(s(x) s(y)) M(x y)

Fig. 1. The dependency graph for the TRS of Ex. 13.

Example 17 For the TRS of Ex. 13 we obtain the dependency graph in Fig.
1. Hence, this results in the following set of inequalities.

x;0 s(x) ; s(y)
quot(0 s(y)) quot(s(x) s(y))
0+y s(x) + y
(x ; y) ; z

x
;x y
0
s(quot(x ; y s(y)))
y
s(x + y)
;x (y + z)

M(s(x) s(y)) > M(x y)

Q(s(x) s(y)) > Q(x ; y s(y))

P(s(x) y) > P(x y)

;M(x

) ( + )My z >

xy z

The inequalities obtained are satis ed by the polynomial ordering where 0 is
mapped to 0, s(x) is mapped to x + 2, x ; y is mapped to x + 1, quot(x y)
is mapped to 2x, M(x y) and Q(x y) are mapped to x, and both + and P are mapped to addition. By normalizing the inequalities with respect to the argument ltering TRS

18

x ; y ! m(x) !M(x y) x
the resulting inequalities are also satis ed by the recursive path ordering. Thus, by the following theorem, termination of the TRS is proved.
Theorem 18 (Dependency graph re nement) A TRS R(D C R) is
terminating i there exists a well-founded weakly monotonic quasi-ordering , where both and > are closed under substitution, such that
l r for all rules l ! r in R, s t for all dependency pairs hs ti on a cycle of the dependency graph, and s > t for at least one dependency pair hs ti on each cycle of the dependency
graph.

PROOF. The proof is similar to the proof of Thm. 7 with the additional observation that any in nite R-chain corresponds to an in nite path in the
dependency graph. This in nite path traverses at least one cycle in nitely many times, since there are only nitely many dependency pairs. At least one dependency pair in this cycle corresponds to a strict inequality. Thus, the chain corresponds to a descending sequence of terms containing in nitely many strict inequalities.

Thm. 7 directly implies that the above conditions are also necessary for the

termination of R.

ut

However, to perform termination proofs according to Thm. 18, we have to construct the dependency graph automatically. Unfortunately, in general this
is not possible, since for two dependency pairs hs ti hv wi it is undecidable
whether they form a chain (i.e. whether there exists a substitution such that
t !R v ).

Therefore, we introduce a technique to approximate the dependency graph,

i.e., the technique computes holds for some substitution

a superset of those . We call terms t v

terms t v suggested

where by our

ttec!hnRiqvue

connectable terms. In this way, (at least) all cycles that occur in the depen-

dency graph and hence all possibly in nite chains can be determined. So by

computing a graph containing the dependency graph we can indeed apply the

method of Thm. 18 for automated termination proofs.

For the computation of connectable terms we use syntactic uni cation. This uni cation is not performed on the terms of the dependency pairs directly, but one of the terms is modi ed rst. If t is a term with a constructor root symbol c, then t can only be reduced to terms which have the same root

19

symbol c. If the root symbol of t is de ned, then this does not give us any direct information about those terms t can be reduced to. For that reason, to determine whether the term t is connectable to v, we replace all subterms in t that have a de ned root symbol by a new variable and check whether this modi cation of t uni es with v. For example, P(: : :) is not connectable to M(: : :). On the other hand, the term
;Q(x y s(y)) is connectable to Q(s(x) s(y)), because before uni cation, the subterm x ; y is replaced by a new variable.
In order to ensure that t is connectable to v whenever there exists a sub-
stitution such that t !R v , before uni cation we also have to rename
multiple occurrences of the same variable x in t. (The reason is that di erent occurrences of x can reduce to di erent terms.)
Example 19 As an example consider the following TRS of Toyama 46].

f(0 1 x) ! f(x x x) !g(x y) x !g(x y) y

The only dependency pair, viz. hF(0 1 x) F(x x x)i, is on a cycle of the de-

pendency graph, because F(x x x)

reduces to

F(0

1

0
x

)

, if

replaces x and

0
x

by

g(0

1).

Note

however

that

F(x

x

x)

does

not

unify

with

F(0

1

x0),

i.e.,

if

we would not rename F(x x x) to F(x1 x2 )x3 before the uni cation, then we

could not determine this cycle of the dependency graph and we would falsely

conclude termination of this (non-terminating) TRS.

To perform the required modi cation on the term t, two functions cap and ren are introduced. For any term t, cap(t) results from replacing all subterms of t that have a de ned root symbol by di erent new variables and ren(t) results from replacing all variables in t by di erent fresh variables. In particular, di erent occurrences of the same variable are also replaced by di erent new variables.

De nition 20 (Connectable terms) Let D be the set of de ned symbols.
The functions cap and ren from terms to terms are inductively de ned as

cap(f (t1

cap(x) ))n: : : t

= =

x8>< >:

y
f (cap(t1)

:::

cap(tn))

for variables x
if f 2 D if f 62 D

20

ren(x) = y

for variables x

ren(f (t1 : : : tn)) = f (ren(t1) : : : ren(tn))

where y is the next variable in an in nite list of fresh variables y1 y2 : : : For any terms t and v, the term t is connectable to v if ren(cap(t)) and v are uni able. Strictly speaking, neither cap nor ren are proper functions, because one time we have ren(x) = y1 and the next time we obtain ren(x) = .y2 Of course, cap and ren can easily be transformed into proper functions by giving cap and ren a second argument which contains the next fresh variable that has not yet been used. However, we omitted this second argument to ease readability. For example, we have
ren(cap(Q(x ; y s(y)))) = ren(Q(y1 s(y))) = Q(y2 s(y3))
and ren(cap(Q(x x))) = ren(Q(x x)) = Q(y4 )y5 :
As ren(t) is always a linear term, to check whether two terms are connectable we can even use a uni cation algorithm without occur check. To approximate the dependency graph, we draw an arc from a dependency
pair hs ti to hv wi whenever t is connectable to v. In this way, for our example
the dependency graph of Fig. 1 is constructed automatically. So termination of the TRS in Ex. 13 can be proved automatically. The following theorem proves the soundness of this approach: by computing connectable terms we in fact obtain a supergraph of the dependency graph. Using this supergraph, we can now prove termination according to Thm. 18.
Theorem 21 (Computing dependency graphs) Let R be a TRS and let hs ti hv wi be dependency pairs. If there is an arc from hs ti to hv wi in the
dependency graph, then t is connectable to v.

PROOF. By induction on the structure of t we prove that if there exists a sSounoblyisntciptounatrtitaoiicnnuslanrew,wiitfvhtatri!a!bRleRvs,ut,hftoihsreinsmorpmleieenst(ectrhamapt(urt,)e)tnhm(ecanatcrphe(etns))(vcaan.pdA(vts)a)rremenua(ntcciahpeasb(tlu)e)..

21

Assume for a de

that ned

stym!bRoluf

for some term u. If , then ren(cap(t))

t is a variable is a variable,

or if = (t f t1 : : : hence it matches

tk) u.

If t = (c t1 : : : tk) for some constructor c, then

ren(cap(t)) = c(ren(cap(t1)) : : : ren(cap(tk))):

In this case, u has to be of the form (c u1 : : : uk) and tj !R uj holds for all j.

By the induction hypothesis we obtain that ren(cap(tj)) matches uj. Since

the for

variables
all i 6= j,

in ren(cap(tj)) are disjoint ren(cap(t)) also matches u.

from

the

variables

in

ren(cap(ti

))
ut

2.5 Re ned termination proofs by narrowing dependency pairs

By the re nement of dependency graphs, Thm. 18 provides us with a powerful technique to prove that there exists no in nite chain of dependency pairs. However, there are still examples where the automation of our method fails.
Example 22 For instance, let us replace the last rule of the TRS in Ex. 13
by a `commutativity' rule (here, s0 abbreviates s(0), etc.).

x;0 ! x s(x) ; s(y) ! x ; y quot(0 s(y)) ! 0 quot(s(x) s(y)) ! s(quot(x ; y s(y)))
!0 + y y s(x) + y ! s(x + y) (x ; s0) + (y ; ssz) ! (y ; ssz) + (x ; s0)

One of the new dependency pairs, viz.
hP(x ; s0 y ; ssz) P(y ; ssz x ; s0)i

(10)

forms a cycle of the dependency graph. Hence, due to Thm. 18 we have to nd an ordering such that the dependency pair (10) is strictly decreasing, i.e.
P(x ; s0 y ; ssz) > P(y ; ssz x ; s0):

In order to apply techniques for the synthesis of simpli cation orderings, we
have to normalize the inequalities w.r.t. an AFS again which rewrites x ; y to

22

m(x) (or to x). However, the resulting constraint P(m(x) m(y)) > P(m(y) m(x))

is not satis ed by any well-founded ordering closed under substitution. Hence, in this way termination of the TRS cannot be proved automatically.

Up to now we demanded constraints which ensure that in any sequence of de-
pendency pairs hs1 i ht1 s2 it2 : : : and for all substitutions !with tj R sj+1
we have 7

s1 > t1

s2 > t2

:::

(4)

So we demanded s > t for the dependency pairs hs ti. But instead of the
requirement that there should be a strict decrease in dependency pairs, it would also be su cient if the ordering is strict between two dependency pairs.
Thus, if hs ti and hv wi are consecutive in a chain, then instead of s >
t v one could demand s t and t > v for all substitutions with
! .Rt v

To achieve this e ect we replace the original dependency pairs by new pairs of terms. Subsequently, we demand that these new pairs of terms are strictly decreasing. Note that if the reduction from t to v is always of the form

! !t

R

0
t

Rv

then instead of s > t

v

we may also require s

0
>t

v . To compute

the

terms

0
t

we use narrowing

(cf. e.g.

30]).

De nition 23 (Narrowing) Let R be a TRS. A term t narrows to a term

0
t

via

the

position p

rule l ! r

substitution

in t, is the

of

R,

and

0
t

=

(denoted by t R most general uni t r ]p. (Here, the

t0), if there exists a non-variable

er of jt p
variables

and of l

l
!

for some rewrite r must have been

renamed to fresh variables.)

If a dependency pair hs ti is followed by another dependency pair hv wi in a chain, and if t is not already uni able with v (i.e. at least one rule of R is
needed to reduce t to v ), then we may perform all possible narrowing steps on t (resulting in new terms t1 : : : tn) in order to examine the reduction from t to v .

7 By taking the dependency graph into account, this requirement has been weakened, i.e., it is su cient if just a certain subset of dependency pairs is strictly decreasing in any possibly in nite chain.

23

However, instead of only narrowing right-hand sides of dependency pairs hs ti,
the substitutions derived from narrowing the term t should also be applied on
the left-hand side s of the pair hs ti. Thus, if t R t1 : : : t R tn are all
possible narrowings of t (via the substitutions 1 : : : n), then instead of

s >t

v

for all with t !R v

it is su cient to demand

s 1 > t1

v ... for all with t1 !R v ,

s n > tn

v

for all with tn !R v .

Hence,
h: : : s

we may replace
n tni. For that

the dependency purpose instead

pair hs ti by the n new
of narrowing terms we

pairs hs 1
introduce

it1
the

concept of narrowing pairs of terms.

De nition 24 (Narrowing pairs) Let R be a TRS. If a term t narrows

to

a

term

0
t

via

the

substitution

, then we say that the pair of terms hs ti

narrows to the pair hs t0i.

Example 25 For Ex. 22, the instantiated right-hand side

P(y ; ssz x ; s0)

of dependency pair (10) can only reduce to an instantiation of a left-hand
side of a dependency pair if one of the minus-rules is applied to (y ; ssz) or (x ; s0) . So instead of the dependency pair (10) we may regard its two
narrowings

hP(x ; s0 sy ; ssz) P(y ; sz x ; s0)i hP(sx ; s0 y ; ssz) P(y ; ssz x ; 0)i:

(11) (12)

Now the constraints that the left-hand sides of the new pairs (11) and (12) should be greater than their right-hand sides (together with the remaining constraints for this system) are again satis ed by the orderings mentioned in Ex. 17. Hence, in this way termination of the TRS can be proved automatically.

If P is the set of all dependency pairs of R, then instead of checking whether

there exists an in nite R-chain of pairs from P now it su ces to show that

there is no in nite R-chain of pairs from P nfhs where hs 1 it1 : : : hs n itn are all narrowings

tig fhs of hs ti.

i1 t1 : : :
(So with

hs
this

n tnig,
re ne-

ment we have to regard chains of pairs of terms which are no dependency

pairs any more.) Note that any pair hs ti can only be narrowed (in one step)

24

to

nitely

many

pairs

hs0

0
t

i

(up

to

variable

renaming)

and

these

pairs

hs0

0
t

i

can easily be computed automatically. In particular, if a dependency pair hs ti

has no narrowings, then it does not have to be considered any more for the

termination proof.

However, the following two examples demonstrate that a pair hs ti in P may
only be replaced by its narrowings, if t does not unify with any left-hand side
of a pair in P and if t is a linear term.

Example 26 The following non-terminating TRS

f(0) ! f(0) 0!1
has one cycle in the dependency graph formed by an arc from the dependency
pair hF(0) F(0)i to itself. Narrowing this pair, although its right-hand side uni es with its left-hand side, results in hF(0) F(1)i. Now the new right-hand
side F(1) is not connectable to F(0) any more. Hence, by ignoring the uni cation condition, the only cycle in the dependency graph would be erroneously removed and therefore termination of this TRS could be falsely concluded. Similarly, the linearity of the right-hand side plays a crucial role, as can be seen from the non-terminating TRS

f(s(x)) ! f(g(x x)) g(0 1) ! s(0)
0!1 where hF(s(x)) F(g(x x))i forms the only cycle of the dependency graph. How-
ever, by ignoring the linearity condition, this dependency pair could be deleted, as the term F(g(x x)) cannot be narrowed. Hence, no cycle exists in the new dependency graph and therefore termination of the TRS would be falsely concluded 8 . The following theorem proves that under the above conditions the replacement of dependency pairs by their narrowings maintains the su ciency and necessity of our termination criterion.
8 The problem is that the rst reduction step from F(g(x x)) to F(s(x0)) takes place `in ' and therefore it cannot be captured by narrowing. For linear terms, this e ect could be simulated by choosing another suitable 0, but in the above example this is not possible, because here two di erent occurrences of x are reduced to di erent terms.

25

Theorem 27 (Narrowing re nement for termination) Let R be a TRS and let P be a set of pairs of terms. Let hs ti 2 P such that t is linear and for all hv wi 2 P the terms t and v are not uni able (after renaming the
variables). Let
P0 = P n fhs tig fhs0 t0i j hs0 t0i is a narrowing of hs tig:
There exists an in nite R-chain of pairs from P i there exists an in nite R-chain of pairs from P0.

PROOF. It su ces to prove that for every hs ti 2 P the sequence h i h i h i: : : v1 w1 s t v2 w2 : : :

(of pairs from P or P0) is an R-chain i there exists a narrowing hs0 t0i of

hs hs0

ti such that

0
t

i

may

also

:::
be

hv1
the

iw1
rst

h i h i0 0 s t v2 w2 : : :
pair in the chain

is an R-chain. Here, hs ti resp. (i.e. hv1 iw1 may be missing).

If this has been proved then all occurrences of hs ti in an in nite chain may be replaced by pairs from P0. In an analogous way, every in nite chain of pairs from P0 can also be transformed into an in nite chain of pairs from P.

For the rst direction, let : : : hv1 iw1 hs ti hv2 iw2 : : : be an R-chain. Hence,
there must be a substitution such that for all pairs, the instantiated right-hand side reduces to the instantiated left-hand side of the next pair in the chain. Let be such a substitution where the length of the reduction

!Rt v2

is minimal. Note that the length of this reduction
do not unify. Hence, we have t ! !R q R v2 for

cannot be some term

zero, q.

as

t

and

v2

Ttfoohchricseusrroreesmdaoeurnecpctteoiwosinointipttoaon(ksaespsis)btpisliluisatccilheiens`tefihoanarr)tta'h.ne(Hdxree)tnd!hcueecRr,teirftoohnraeenrt,edwi!qse a=hRavqvta.errLi]qapeb.t=lTuetshxe0,irvnwsatthraie(asribs.eeul.emt0xjeipsot=htnhalxyet substitution with 0(x) = r and 0(y) = (y) for all y 6= x. As all (occurrences
of) dependency pairs are variable disjoint, 0 behaves like for all pairs except
hs ti. For this pair, we have

! !=0
w1 w1

Rs

R s 0 and

= ! =0
t

q

R v2

0
v2 :

26

Hence, 0 is also a substitution where each instantiated right-hand side reduces to the instantiation of the left-hand side of the following pair in the chain. But as the reduction from t 0 to v2 0 is shorter than the reduction from t to v2 , this is a contradiction to the minimality of .

So the reduction t !R
subterm f(~u) such that a

q cannot take
rule l ! r has

place `in '. Hence, been applied to f(~u)

t
.

contains some In other words,

l matches f(~u) (i.e. l = f(~u) ). Hence, the reduction has the following form:

!t = t ( )f ~u ]p = t l ]p

] =R pt r

q:

Similar to Def. 23 we assume that the variables of l ! r have been renamed
to fresh ones. Therefore we can extend to `behave' like on the variables of l and r (but it still remains the same on the variables of all pairs in the chain). Now is a uni er of l and ( )f ~u and hence, there also exists a most general uni er . By the de nition of most general uni ers, then there must be a substitution such that = .

Let

0
t

be

the

term

we

may

assume

0
s

tr
and

t0]ptoanbde

let

0
s

be

variable

s . Then hs ti narrows to hs0 t0i. As
disjoint from all other pairs, we may

extend

to behave like

on

the

variables

of

0
s

and

0
t

.

Then

we

have

!w1

=R s s

=

0
s

=

0
s

and

!0
t

=

0
t

=t

r ]p = t r ]p = t r ]p = q

R v2 :

Hence,

:::

hv1

iw1

hs0

0
t

i

hv2

iw2

:::

is

also

an

R-chain.

For the other direction of
R-chain. Hence, there is a

the theorem, substitution

let : : : such

hv1
that

iw1
for

h i h i be an0 0 s t v2 w2 : : :
all pairs the instantiated

right-hand side reduces to the instantiated left-hand side of the next pair in

the chain. So in particular we have

! !andw1

R

0
s

0
t

R v2 :

We

know

that

hs

ti

narrows

to

hs0

0
t

i

via

some

substitution

. As the variables

in hs ti are disjoint from all other occurring variables, we may extend to

`behave' like

on the variables of s and t. Then we have s = s

=

0
s

and hence,

!Rw1 s :

27

Moreover, by the de

nition of narrowing, t

!R

0
t

.

This

implies

t

and as t = t , we have

!Rt v2 :

!R

0
t

Hence, : : : hv1 iw1 hs ti hv2 iw2 : : : is also an R-chain.

ut

Note that while dependency pairs may indeed be replaced by their narrowings, in general a similar replacement of rules by their narrowings is unsound, i.e., it does not preserve the termination behaviour. For example, in the TRS with the
rules f(1) ! f(0) and 0 ! 1, the right-hand side 1 of the second rule cannot be
narrowed. However, deleting this second rule transforms the non-terminating TRS into a terminating one. So narrowing of dependency pairs is di erent from narrowing of rules, because even if some dependency pairs are eliminated, still all rules can be used for the reductions between two dependency pairs.
Example 28 Narrowing pairs can be repeated several times if appropriate. So
instead of replacing the dependency pair (10) by (11) and (12) we could also apply narrowing again and replace (11) and (12) by those pairs they narrow to. For example, the pair (11) has a linear right-hand side which does not unify with the left-hand side of any pair. Thus it may be replaced by its narrowings
hP(x ; s0 ssy ; ssz) ;P(y z x ; s0)i hP(sx ; s0 sy ; ssz) P(y ; sz x ; 0)i:

In general, before application of Thm. 18 one can apply an arbitrary number of narrowing steps to the dependency pairs. Subsequently, the resulting set of pairs is considered to be the `set of dependency pairs' and the techniques presented to approximate the dependency graph and to synthesize the inequalities are applied. Finally, standard techniques are used to nd an ordering satisfying the generated inequalities.

By the use of narrowing the automation of our method can be improved signi cantly. For instance, if in our example we perform at least one narrowing step, then termination can again be veri ed automatically.

Note that if an ordering can be found that satis es the set of inequalities

obtained without narrowing any of the pairs, then the inequalities obtained

after narrowing are also satis ed by the same ordering. (If the ordering satis es

ands > t

l

r, then it also satis es s > t

0
t

via

the

substitution

. Hence, s > t resp. s

t0,
t

provided

implies

0
s

that
0
>t

t

R
resp.

0
s

0
t

for

any

narrowing

hs0

0
t

i

of

hs

ti.

Moreover,

if

hs0

0
t

i

and

hv0

w0i

are

narrowings of hs ti and hv wi respectively, then there can only be an arc

28

from hs0 t0i to hv0 w0i in the new dependency graph if there already was an

arc from hs ti to hv wi in the original dependency graph. The corresponding

statement

also

holds

for

our

approximation

of

dependency

graphs,

i.e.,

if

0
t

is

connectable

to

0
v

,

then

t

is

also

connectable

to

v.)

Thus,

replacing

pairs

by

their narrowings can only extend the set of TRSs for which termination can

be proved automatically.

2.6 Summary

Combining all re nements, we obtain the following technique to prove termination automatically using the dependency pair approach:
Determine the dependency pairs (this can be automated in a straightforward way). Replace some (dependency) pairs by all their narrowings. This step may be repeated several times. Approximate the dependency graph by estimating for all (dependency) pairs whether an arc exists between them. For this purpose, the functions cap and ren are introduced. The pairs that occur on a cycle in the approximated dependency graph are computed by standard graph algorithms. Pairs which are not on a cycle in the approximated dependency graph can be ignored. Transform the rules and the (dependency) pairs on cycles into inequalities. Find a well-founded weakly monotonic quasi-ordering satisfying the inequalities after normalizing them with respect to one of the possible AFSs. For nding suitable orderings standard techniques like the recursive path ordering or polynomial interpretations may be used. In this way, standard techniques can now be applied to prove termination of TRSs whose termination could not be proved automatically before. For a collection of examples to demonstrate the power of our approach see 4].

3 Proving innermost termination
Similar to our approach for termination we now introduce a method to prove innermost termination of TRSs. Several ideas and notions can be transferred from the termination case to the innermost termination case. Therefore many theorems in this section look similar to the theorems in the previous section and in their proofs we only indicate the di erences to the previous approach. In Sect. 3.1 we present a criterion for innermost termination corresponding to the termination criterion of Sect. 2. We show in Sect. 3.2 that this criterion
29

is also suitable for automation and that similar re nements for improving the technique can be developed (Sect. 3.3 and Sect. 3.4). The automated checking of this criterion enables us to prove innermost termination automatically, even if the TRS is not terminating. Additionally, for several classes of TRSs innermost termination already su ces for termination 27,28]. Moreover, numerous modularity results exist for innermost termination 5,7,27,35,36], which do not hold for termination. Therefore, for those classes of TRSs termination can be proved by splitting the TRS and proving innermost termination of the subsystems separately. The advantage of this approach is that there are several interesting TRSs where a direct termination proof is not possible with the existing automatic techniques (including the technique of Sect. 2). However in many of these examples, a suitable ordering satisfying the constraints generated by our technique for proving innermost termination can nevertheless be synthesized automatically. So for many TRSs proving innermost termination automatically is essentially easier than proving termination. In this way, innermost termination (and thereby, termination) of many also non-simply terminating systems can now be veri ed automatically. An overview of the technique is given in Sect. 3.5.
3.1 Innermost termination criterion
In contrast to the approach in the previous section, now our aim is to prove that the length of every innermost reduction is nite (where innermost redexes have to be contracted rst). Of course, termination implies innermost termination, but in general the converse does not hold.
Example 29 As an example consider the following TRS with the de ned sym-
bols f and g and the constructors 0 and s.
f(g(x) s(0) y) ! f(y y g(x)) g(s(x)) ! s(g(x)) g(0) ! 0
In this example, we have the following in nite (cycling) reduction.
f(gs0 s0 gs0) ! f(gs0 gs0 gs0) ! f(gs0 sg0 gs0) ! f(gs0 s0 gs0) ! : : :
However, this reduction is not an innermost reduction, because in the rst reduction step the subterm gs0 is a redex and would have to be reduced rst. Although this TRS is not terminating, it nevertheless turns out to be innermost terminating.
30

The aim of this section is to develop a criterion for innermost termination similar to our termination criterion of Sect. 2. In the above example we obtain the following dependency pairs.

hF(g(x) s(0) y) G(x)i hF(g(x) s(0) y) F(y y g(x))i hG(s(x)) G(x)i

(13) (14) (15)

Recall that a sequence of dependency pairs hs1 it1 hs2 it2 : : : is a chain, if
there exists a substitution such that tj reduces to sj+1 for all j. Here, the right-hand side of each dependency pair corresponds to a newly introduced
redex and the reductions tj !R sj+1 are used to contract the arguments of
the redex that is traced. However, chains correspond to arbitrary reductions, whereas now we are only interested in innermost reductions. Therefore, we have to restrict the de nition of chains in order to obtain a notion which corresponds to the innermost reduction strategy.

The rst restriction is motivated by the fact that when regarding innermost reductions, arguments of a redex should be in normal form before the redex is contracted. Therefore we demand that all sj should be normal forms. Additionally, when concentrating on innermost reductions, the reductions of the arguments to normal form should also be innermost reductions. This results in the following restricted notion of a chain (where innermost reductions are
denoted by `!i ').

De nition 30 (Innermost chain) Let R(D C R) be a TRS. A sequence of

dependency pairs hs1 i ht1 s2 it2 : : : is an innermost R-chain if there exists a

substitution such holds for every two

that all sj consecutive

are normal forms
pairs hsj itj and

and such that
h i insj+1 tj+1

tj
the

!i R sj+1
sequence.

In our example we have the innermost chain

hG(s(x1)) G(x1)i hG(s(x2)) G(x2)i hG(s(x3)) G(x3)i

because G(x1) !i R G(s(x2)) and G(x2) !i R G(s(x3)) holds for the substi-
tution that replaces x1 by s(s(x3)) and x2 by s(x3).

Of course, every innermost chain is also a chain, but not vice versa. For instance, the in nite sequence consisting of the second dependency pair (14) only is an in nite chain, because

F(y1 y1 g(x1)) !R F(g(x2) s(0) )y2

(16)

31

holds if (xj) = s(0) and (yj) = g(s(0)). However, this in nite chain is not an innermost chain, because for every substitution satisfying (16), the term F(g(x2) s(0) )y2 is not a normal form. The following theorem proves that the absence of in nite innermost chains is a su cient and necessary criterion for innermost termination. (Hence, the restriction of chains to innermost chains in fact corresponds to the restriction of reductions to innermost reductions.)
Theorem 31 (Innermost termination criterion) A TRS R(D C R) is innermost terminating if and only if no in nite innermost R-chain exists.

PROOF. The proof of this theorem is very similar to the proof of Thm.
6. In the same way as in the latter proof, an in nite sequence of dependency pairs can be constructed, whenever an in nite innermost reduction exists. The di erence, however, is that now the arguments of the terms are innermost reduced to normal form before building the next dependency pair, whereas in the proof of Thm. 6 the arguments were reduced an arbitrary number of steps. The sequence constructed in this way is in fact an innermost chain.

For the other direction, similar to the corresponding proof of Thm. 6 one can

show that any in nite innermost chain corresponds to an in nite innermost

reduction.

ut

3.2 Checking the innermost termination criterion automatically

In this section we present an automatic approach for innermost termination proofs using the criterion of Thm. 31, i.e., we develop a method to prove the absence of in nite innermost chains automatically.

Assume that there is a sequence hs1 iht1 s2 iht2 s3 it3 : : : of dependency pairs
and a substitution such that all terms sj are in normal form and such that tj reduces innermost to sj+1 for all j. Then to prove that this sequence is nite, it su ces again to nd a well-founded quasi-ordering such that the following inequalities are satis ed.

s1 > t1

s2 > t2

s3 > t3

:::

(4)

To ensure that all dependency pairs are decreasing, we again demand s > t
for all dependency pairs hs ti. In our example this results in the following
constraints, cf. (13), (14), (15):

F(g(x) s(0) y) > G(x) F(g(x) s(0) y) > F(y y g(x))

(17) (18)

32

G(s(x)) > G(x):

(19)

Moreover, we have to ensure tj sj+1 whenever tj !i R sj+1 holds.
Recall that to prove termination we demanded that all rules were weakly decreasing. This was necessary, because in chains, may be an arbitrary substitution and hence, every rule can be used in the reduction from tj to sj+1 9 . However, in contrast to the situation for chains, in an innermost chain only a subset of the rewrite rules of the TRS can be applied in the reduction in between the dependency pairs. Therefore, to prove innermost termination
we only demand the constraints l r for those rules l ! r that can be used
in an innermost reduction of tj . Note that as all terms sj are normal, is a normal substitution (i.e., it instantiates all variables with normal forms). Hence, for the dependency pairs (13) and (15) we directly obtain that no rule can ever be used to reduce a normal instantiation of G(x) (because G is no de ned symbol). The only dependency pair whose right-hand side can be reduced if its variables are instantiated with normal forms is (14), because this is a dependency pair with a de ned symbol in the right-hand side. As the only de ned symbol in F(y y g(x)) is g, the only rules that may be applied on normal instantiations of this term are the two g-rules of the TRS. Since these g-rules can never introduce a new redex with root symbol f, the two g-rules are the only rules that can be used to reduce any normal instantiation of F(y y g(x)). Hence, in this example we only have to demand that these rules should be weakly decreasing.

g(s(x)) s(g(x)) g(0) 0

(20)

In general, to determine the usable rules, i.e. (a superset of) those rules that may possibly be used in an innermost reduction of a normal instantiation of a term t, we proceed as follows. If t contains a de ned symbol f, then all f-rules are usable and furthermore, all rules that are usable for right-hand sides of f-rules are also usable for t. However, if one of these rules contains a redex as a proper subterm of the left-hand side, then we do not have to include it in the usable rules, since this rule can never be applied in any innermost reduction. (Of course, such rules could also be directly removed from the TRS before the innermost termination proof.)
De nition 32 (Usable rules) Let R(D C R) be a TRS. For any symbol f let Rules(R f) = fl ! r in R j ( )root l = f l has no redex as proper subtermg: For any term t, the set of usable rules U(R t) is inductively de ned as
9 Provided that a variable occurs in tj, but termination is decidable for TRSs with ground right-hand sides 14].
33

U(R x)

=

U ! U U(R

(f t1

:::

tn))

=

Rules(R f)
S
l r2Rules(R

Snj=1
f) (R0

(R0 r)

tj )

where 10

0
R

=

R

n

Rules(R

f ).

Hence, in our example we have

U(R F(y y g(x))) = Rules(R F) U(R y) U(R g(x)) = U(R g(x))
= Rules(R g)
U(ff(: : :) ! f(: : :)g x) U(ff(: : :) ! f(: : :)g s(g(x))) U(ff(: : :) ! f(: : :)g 0) = fg(s(x)) ! s(g(x)) g(0) ! 0g:

Observe that by the above de nition Rules(R f) = for any constructor f.

When proving termination we had to search for a weakly monotonic quasiordering satisfying the constraints obtained. The reason for demanding weak monotonicity was that l r for all rules had to ensure tj sj+1 whenever tj could be reduced to sj+1 . However, now for the tuple symbols we do not need weak monotonicity on all positions any more. For example, for the tuple symbol F we only have to ensure that all reductions starting from F(y y g(x)) are weakly decreasing (where is a normal substitution). Obviously, such reductions can never take place in the rst two arguments of F and hence, F does not have to be weakly monotonic in these arguments.

The constraints (20) already ensure that during reductions of F(y y g(x)) the value of the subterm g(x) can only be decreased. Of course, we have to guarantee that the value of the whole term F(y y g(x)) is weakly decreasing if an instantiation of g(x) is replaced by a smaller term. For that purpose, we demand that F(y y g(x)) must be weakly monotonic on the position of its subterm g(x), i.e., for the tuple symbol F we only have to demand the following monotonicity constraint:

) ( ) ( )x1 x2

F y y x1

F y y x2 :

(21)

U(10 R t) is well-de ned, because its rst argument R is decreasing.

34

We only compute such monotonicity constraints for the tuple symbols and for all other (lower case) symbols we demand weak monotonicity in all of their arguments. In general, we obtain the following procedure for the generation of constraints.

Theorem 33 (Proving innermost termination) Let R(D C R) be a
TRS and let be a well-founded quasi-ordering where both and > are closed under substitution. If is weakly monotonic on all symbols apart from the tuple symbols and if satis es the following constraints for all dependency
pairs hs ti

l r for all usable rules !l r in U(R t),

,s > t

^ ^ ) ] ],n nx1 y1 : : : x

y

nC x1 : : : x

nC y1 : : : y

if t = ( )C f1 ~u1 : : : fn(~un)], where C is a context without de ned symbols

and f1 : : : fn are de ned symbols,

then R is innermost terminating.

PROOF. The proof of this theorem corresponds to the proof of Thm. 7. Sup-

pose that hs1 i ht1 s2 it2 : : : is an in nite innermost R-chain. Then there exists

a substitution such that sj is a normal form and tj reduces innermost

to sj+1 for all j. Hence, replaces all variables by normal forms and there-

fore, the only rules that can be applied in this reduction are the usable rules

U(R tj). All usable rules are weakly decreasing and the terms tj are weakly

monotonic on all positions where reductions are applied. (The reason is that

lower case symbols are weakly monotonic and without loss of generality we

can assume that does not introduce any tuple symbols, i.e., the only tuple

symbol in tj is on the root position.) Hence, we have tj sj+1 . This re-

sults in an in nite decreasing sequence s1 > t1 s2 > t2 : : : which

is a contradiction to the well-foundedness of . Thus, no in nite innermost

R-chain exists and by Thm. 31, the TRS is innermost terminating.

ut

So there are two main di erences between the termination approach and the approach for innermost termination. The rst di erence is in the set of inequalities that is generated. As we restrict ourselves to innermost reductions and to terms sj that are normal forms, several inequalities that have to be demanded when proving termination are unnecessary when proving innermost termination (i.e., we do not have to demand l r for all rules any more, but it su ces if just the usable rules are weakly decreasing). After generating the inequalities, the second di erence is that the quasi-ordering satisfying the inequalities does not have to be weakly monotonic for all function symbols (i.e., tuple symbols only have to satisfy the monotonicity constraints that are stated explicitly).

35

Hence, in Ex. 29 to prove innermost termination it is su cient to nd a well-founded quasi-ordering satisfying the constraints in (17) { (21). For the synthesis of suitable quasi-orderings we proceed in the same way as it has been done for termination (Sect. 2.3) where for polynomial interpretations the di erence is that the polynomials do not have to be weakly monotonic in all arguments. For example, these constraints are ful lled by the polynomial ordering where the constant 0 is mapped to the number 0, s(x) is mapped to x + 1, g(x) is
mapped to x + 2, F(x y z) is mapped to ;( )x y 2 + 1, and G(x) is mapped to
x. Note that this quasi-ordering is not weakly monotonic on the tuple symbol F. The only monotonicity constraint in our example is (21), which is obviously satis ed as F(x y z) is mapped to a polynomial which is weakly monotonic 11 in its third argument z. However, this polynomial is not weakly monotonic in x or y. Unlike Thm. 7 for termination proofs, the existence of a quasi-ordering satisfying the conditions of Thm. 33 is su cient, but not necessary for innermost termination. The reason is that demanding the constraints of Thm. 33 for all instantiations may be too strong, since for innermost chains sometimes it would be su cient to regard certain instantiations only.
Example 34 For example, consider the innermost terminating TRS
f(s(x)) ! f(g(h(x))) g(h(x)) ! g(x) g(s(x)) ! s(x)
g(0) ! s(0) h(0) ! a:

In this example there are no in nite innermost chains. However, the constraints according to Thm. 33 include the inequalities

F(s(x)) > F(g(h(x))) g(h(x)) g(x)
g(0) s(0)

11 When using polynomial interpretations, monotonicity constraints like (21) can

also be represented as inequalities. For instance, if F is mapped to some polynomial

F], then instead of (21) one could demand that the partial derivative of F](y y x)

with respect to x should be non-negative, i.e. @ If one uses other techniques (e.g. path orderings)

F](y y x) w@hxich can

0, cf. only

23]. generate

monotonic

orderings, then of course one may drop monotonicity constraints like (21).

36

)x1 x2

F(x1) F(x2):

These constraints imply F(s(0)) > F(g(h(0))) F(g(0)) F(s(0)). Therefore they cannot be satis ed by any well-founded quasi-ordering closed under substitution.

However, the approach of Thm. 33 su ces to prove innermost termination of numerous important examples and challenge problems (including the TRS in Ex. 29) automatically, i.e., this technique allows the application of standard techniques for innermost termination proofs, even if the TRS is not terminating. Moreover, using the results of Gramlich 27,28], Thm. 33 can also be applied to prove termination of TRSs that are non-overlapping (or for locally con uent overlay systems).

cEqouxmoatp(muxtpeylsezj3)xy5kis).Aussedantoecxoammppuleter1eg+arjdx;ztyhke,

following TRS if x y and z

by
6= 0

Kolbe 34] where (i.e. quot(x y y)

quot(0 s(y) s(z)) ! 0 quot(s(x) s(y) z) ! quot(x y z)
quot(x 0 s(z)) ! s(quot(x s(z) s(z)))

The above system is not simply terminating (the left-hand side of the last rule is embedded in the right-hand side if z is instantiated with 0) and therefore most automatic approaches for termination proofs (which are restricted to simpli cation orderings) fail. Nevertheless, with our technique we can prove innermost termination and therefore termination of this system automatically. As quot is the only dened symbol of this system, we obtain the following dependency pairs.

hQ(s(x) s(y) z) Q(x y z)i hQ(x 0 s(z)) Q(x s(z) s(z))i

(22) (23)

In this example there are no usable rules, as in the right-hand sides of the dependency pairs no de ned symbols occur. Hence, due to Thm. 33 we only have to nd a well-founded ordering such that both dependency pairs are decreasing. These constraints are for instance satis ed by the polynomial ordering where 0 is mapped to the number 0, s(x) is mapped to x+1, and Q(x y z) is mapped
to x+(x;y + )z 2. Hence, innermost termination and thereby also termination
of this TRS is proved (as it is non-overlapping).

37

Note that again we bene t from the fact that the tuple symbol Q need not be weakly monotonic in its arguments. Therefore, an interpretation like the
polynomial x + (x ; y + )z 2 may be used, which is not weakly monotonic
in any of its arguments. In fact, if the set of usable rules is empty, then the quasi-ordering need not even be weakly monotonic for any symbol. The termination approach of Sect. 2 cannot be used to prove termination of this TRS automatically, since the generated inequalities are not satis ed by any well-founded weakly monotonic total quasi-ordering or any quasi-simpli cation ordering (not even after normalization by a suitable AFS).

3.3 Re nement using innermost dependency graphs

To prove innermost termination of a TRS according to Thm. 33 we have to
nd an ordering such that s > t holds for all dependency pairs hs ti. However,
similar to the re nement for termination proofs in Sect. 2.4, for certain rewrite systems this requirement can be weakened, i.e., it is su cient to demand s > t for some dependency pairs only. For instance, in the quot example (Ex. 35) up to now we demanded that both dependency pairs (22) and (23) had to be decreasing. However, two occurrences of the dependency pair (23) can never follow each other in an innermost chain, because Q(x1 s(z1) s(z1)) can never reduce to any instantiation of Q(x2 0 s(z2)). The reason is that the second arguments s(z1) resp. 0 of these two terms have di erent constructor root symbols. Hence, any possible in nite innermost chain would contain in nitely many occurrences of the other dependency pair (22). Therefore it is su cient if (22) is decreasing and if (23) is just weakly decreasing. In this way, we obtain the following (weakened) constraints.

Q(s(x) s(y) z) > Q(x y z) Q(x 0 s(z)) Q(x s(z) s(z))

(24) (25)

In general, to determine those dependency pairs which may possibly follow each other in innermost chains, we de ne the following graph.
De nition 36 (Innermost dependency graph) The innermost dependency graph of a TRS R is the directed graph whose nodes are the dependency pairs and there is an arc from hs ti to hv wi if hs tihv wi is an innermost R-chain.
For instance, in the innermost dependency graph for the quot example there are arcs from (22) to itself and to (23), and there is an arc from (23) to (22)

38

h iQ(s(x) s(y) z) Q(x y z)

h iQ(x 0 s(z)) Q(x s(z) s(z)) Fig. 2. The innermost dependency graph for the quot TRS (Ex. 35).

(but not to itself).

Of course, the fact that innermost chains are restricted chains cause innermost dependency graphs to be subgraphs of dependency graphs. Now any in nite innermost chain corresponds to a cycle in the innermost dependency graph.
Hence, it is su cient if s > t holds for at least one dependency pair hs ti on
every cycle and if s t holds for the other dependency pairs on cycles. So, similar to Thm. 18 (for termination) we obtain the following re ned theorem for automated innermost termination proofs.

Theorem 37 (Innermost dependency graph re nement) Let R(D C
R) be a TRS and let be a well-founded quasi-ordering where both and > are closed under substitution. If is weakly monotonic on all symbols apart from the tuple symbols and if satis es the following constraints for
all dependency pairs hs ti on a cycle of the innermost dependency graph

l r for all usable rules !l r in U(R t),

,s t
^ ^ nx1 y1 : : : x

) ]n ny C x1 : : : x

],nC y1 : : : y

if t = ( )C f1 ~u1 : : : (fn ~un)], where C is a context without de ned symbols

and f1 : : : fn are de ned symbols,

and if s > t holds for at least one dependency pair hs ti on each cycle of the innermost dependency graph, then R is innermost terminating.

PROOF. The proof that Thm. 37 is a consequence of Thm. 33 is completely

analogous to the proof that Thm. 18 is a consequence of Thm. 7.

ut

Hence, in the quot example the constraints (24) and (25) are in fact su cient for innermost termination. A suitable quasi-ordering satisfying these weakened constraints can easily be synthesized using the technique of Sect. 2.3. (For instance, one could use the polynomial interpretation where 0 and s are interpreted as usual and where Q(x y z) is mapped to x. If the constraints (24) and (25) are normalized w.r.t. an AFS which drops the second argument of Q, then they are also satis ed by the recursive path ordering.) This example demonstrates that the weakening of the constraints by using innermost

39

dependency graphs often enables the application of much simpler orderings (e.g., now we can use the recursive path ordering or a linear weakly monotonic polynomial ordering whereas for the original constraints of Sect. 3.2 we needed a non-monotonic polynomial of degree 2). However, for an automation of Thm. 37 we have to construct the innermost dependency graph. Again, this cannot be done automatically, since for two
pairs hs ti and hv wi it is undecidable whether there exists a substitution
such that t reduces innermost to v and such that s and v are normal forms. Hence, similar to the dependency graph, we can only approximate this graph by computing a supergraph containing the innermost dependency graph. Note that t may only reduce to v for some substitution , if either t has a de ned root symbol or if both t and v have the same constructor root symbol. Recall that cap(t) denotes the result of replacing all subterms in t with a de ned root symbol by di erent fresh variables. Then t can only reduce to v if cap(t) and v are uni able. However, this replacement of subterms of t must only be done for terms which are not equal to subterms of s. The reason is that such subterms are already in normal form when instantiated with . For example, if we modify the rst
rule of the TRS in Ex. 29 to f(g(x) s(0)) ! f(g(x) g(x)), then to determine
whether there is an arc from the resulting dependency pair
hF(g(x) s(0)) F(g(x) g(x))i

to itself, the subterms g(x) in the right-hand side do not have to be replaced by new variables. As both sides of this dependency pair do not unify after variable renaming, one can immediately see that this pair is not on a cycle of the innermost dependency graph (whereas cap(F(g(x) g(x)) = F(x1 )x2 would unify with the left-hand side).

Let caps(t) only replace those subterms of t by di erent fresh variables which

have a de ned root symbol and which are not equal to subterms of s. Then to

re ne the approximation of innermost dependency graphs instead of cap(t)

we check whether caps(t) uni es with v. Moreover,

uni er
hv wi

(mgu) in the

of caps(t) and v, then there innermost dependency graph,

can only if both s

if is be an
and

the most arc from v are in

general
hs ti to
normal

form.

So there are three di erences between the approximation of the dependency graph and the approximation of the innermost dependency graph. First, for the innermost dependency graph we only replace subterms of t which do not occur in s, i.e., we use caps(t) instead of cap(t). Second, to approximate the dependency graph, multiple occurrences of the same variable in cap(t) are replaced by fresh variables (using the function ren), whereas the variables

40

in caps(t) are left unchanged for the approximation of the innermost dependency graph. The reason is that any substitution used for instantiating the dependency pairs of an innermost chain is a normal substitution. Thus, variables are always instantiated by normal forms, and hence these instantiations are not reduced. Multiple occurrences of the same variable in a term result in multiple occurrences of the same subterm after reduction of the instantiated term. In contrast, for an arbitrary substitution, instantiated multiple occurrences of the same variable may result in di erent subterms after reduction of the instantiated term. The third di erence is that for innermost dependency graphs we only draw an
arc from hs ti to hv wi, if the mgu of caps(t) and v instantiates s and v to
normal forms. This condition is due to the restriction to innermost chains. Similar to the notion of connectable terms in Sect. 2.4, we call two dependency pairs innermost connectable if they should be connected by an arc in our approximation of the innermost dependency graph.
De nition 38 (Innermost connectable pairs) For any dependency pairs hs ti and hv wi, the pair hs ti is innermost connectable to hv wi if caps(t)
and v are uni able by some mgu such that s and v are in normal form. The following theorem proves the soundness of our approximation.
Theorem 39 (Computing innermost dependency graphs) Let R be a TRS and let hs ti and hv wi be dependency pairs. If there is an arc from hs ti to hv wi in the innermost dependency graph, then hs ti is innermost connectable to hv wi.

PROOF. Due to the additional conditions in the de nition of innermost
chains and the de nition of innermost connectable pairs, the proof is slightly di erent from the proof of Thm. 21.

By induction on the structure of t we show that if there exists a substitution

such that s is a normal form and t !R u for some term u, then there exists

a substitution (whose domain only includes variables that are introduced in

the construction of caps(t)) exists a substitution such then caps(t) = v (= v

with caps(t) = u. Thus, that s and v are normal , since the variables of v

in particular, if there

fodromnsoatnodcctur!inR

v, the

domain of ). Hence, caps(t) and v unify and the most general uni er is

such that s and v are normal forms. (There exist instantiations of these two

terms that are normal forms (viz. s = s and v = v ), hence the terms

s and v are normal forms themselves.)

If t equals a subterm of s, then t is in normal form, hence t equals u.

41

Moreover, we have caps(t) = t. So caps(t) = u, i.e., in this case is the empty substitution. If t is not equal to a subterm of s and ( )root t is de ned, then caps(t) is a fresh variable. Let replace caps(t) by u. Then we have caps(t) = caps(t) = u. Otherwise, t = (c t1 : : : tn) for some constructor c and we have
caps(t) = c(caps(t1) : : : caps(tn)):

In this case u is of the form (c u1 : : : un) and induction hypothesis there exist substitutions j

tsjuch!tRhautj

for all j. caps(tj)

By the j = uj.

Note that the variables newly introduced variables newly introduced in caps(ti) for

in
i 6=

caps(tj) are j. Hence, if

for all j we have caps(tj) = uj, and thus, caps(t) =

disjoint from those
ut= 1 : : : n, then
( ).nc u1 : : : u

Using the approximation of Thm. 39, we can now compute the innermost dependency graph for the quot example in Fig. 2 automatically.
Example 40 There are also examples where the innermost dependency graph
does not contain any cycles.

f(x g(x)) ! f(1 g(x)) g(1) ! g(0)

In this example, the dependency pair hF(x g(x)) F(1 g(x))i is not on a cy-

cle F(1

of the innermost dependency g(x1)) uni es with F(x2 g(x2

)g)raupshin, galathmougguhthcaatprFe(xp1lagc(ex1s))x(1F(a1ndg(xx21

))) by

= 1.

However, the instantiated left-hand side F(1 g(1)) is not a normal form, since

it contains the redex g(1). The other dependency pairs hF(x g(x)) G(x)i and hG(1) G(0)i cannot occur on cycles either, since G(: : :) does not unify with

F(: : :) and G(0) does not unify with G(1). Hence, using the re ned techniques

of Thm. 39 and 37 we obtain no constraint at all, i.e., innermost termina-

tion can be proved by only computing the (approximation of) the innermost

dependency graph.

3.4 Re ned innermost termination proofs by narrowing dependency pairs

Similar to the termination technique of Sect. 2, the power of our technique can be increased if we consider narrowings of the dependency pairs.

42

Example 41 For an illustration regard the following TRS. p(0) ! 0
p(s(x)) ! x le(0 y) ! true le(s(x) 0) ! false le(s(x) s(y)) ! le(x y) minus(x y) ! if(le(x y) x y) if(true x y) ! 0 if(false x y) ! s(minus(p(x) y))

Here, a `conditional' program for minus has been encoded into an unconditional TRS. The dependency pairs on cycles of the innermost dependency graph are

hLE(s(x) s(y)) LE(x y)i hM(x y) IF(le(x y) x y)i hIF(false x y) M(p(x) i)y :

(26) (27) (28)

However, the constraints resulting from application of Thm. 37 would imply M(s(x) 0) > M(p(s(x)) 0). Therefore an automatic innermost termination proof using quasi-simpli cation orderings fails. The only dependency pair whose right-hand side does not unify with any lefthand side of a dependency pair is (27). Hence, in any innermost chain at least one rule of the TRS must be applied in order to reduce an instantiation of IF(le(x y) x y) to an instantiation of a left-hand side. So instead of examining the dependency pair (27) we may rst perform all possible narrowing steps and replace (27) by

hM(0 y) IF(true 0 y)i hM(s(x) 0) IF(false s(x) 0)i hM(s(x) s(y)) IF(le(x y) s(x) s(y))i:

(29) (30) (31)

Note that while the right-hand side of (28) uni es with the left-hand side of the original dependency pair (27), after this replacement the right-hand side of (28) does not unify with left-hand sides any more. Hence, the rst narrowing of (27) now enables a subsequent narrowing of (28). So (28) is replaced by

hIF(false 0 y) M(0 y)i hIF(false s(x) y) M(x i)y :

(32) (33)

43

In this way, the original set of dependency pairs (26) { (28) is transformed into (26) and (29) { (33). The pairs (29) and (32) are not on cycles of the innermost dependency graph and can therefore be ignored in the innermost termination proof. Thus, our method determines that instead of the original dependency pair (27) one only has to regard instantiations where x is instantiated with a term of the form s(: : :). But for those terms, p is decreasing and hence, the call of M in the right-hand side of (33) is applied to smaller arguments than the call of M in the left-hand side of (30) or (31). Now innermost termination (and thereby termination) of the system can be proved by the technique of Thm. 37. This results in the following constraints.
le(0 y) true le(s(x) 0) false le(s(x) s(y)) le(x y) LE(s(x) s(y)) > LE(x y) M(s(x) 0) IF(false s(x) 0) M(s(x) s(y)) IF(le(x y) s(x) s(y)) IF(false s(x) y) > M(x y)
x1 x2 ) IF(x1 s(x) s(y)) IF(x2 s(x) s(y))
These constraints are satis ed by a polynomial interpretation where 0, true and false are mapped to 0, s(x) is mapped to x + 1, le(x y), LE(x y), and M(x y) are mapped to x, and IF(x y z) is mapped to y. They are also satis ed by the recursive path ordering if an AFS is used to eliminate the rst argument of IF. Narrowing pairs for the innermost termination technique has the side-e ect that one may also drop some inequalities l r corresponding to the rules
l ! r, since after narrowing the pairs some rules may not be usable any more.
For example, for the original dependency pairs, the p-rules were usable, since (28) contains an occurrence of p in its right-hand side. But after narrowing this dependency pair, the occurrence of p is deleted and hence we do not have to demand that the p-rules are weakly decreasing. So similar to the approach in Sect. 2.5 we may replace a dependency pair
hs ti by all its narrowings provided that the right-hand side t does not unify
with any left-hand side of a dependency pair. In fact, due to the restriction to innermost chains we may even perform such a replacement if t uni es with the left-hand side v of a dependency pair, as long as their mgu does not instantiate both s and v to normal forms. Note that in contrast to the termination case, for innermost termination proofs we do not have to demand that t must be a linear term. Hence, we can indeed narrow the dependency pair (27) in the
44

above example, although its right-hand side is not linear. However, this step would not have been possible with the method of Sect. 2. Therefore, for the TRS in Ex. 41 the constraints generated by the approach of Sect. 2 are not satis ed by any quasi-simpli cation ordering.
Theorem 42 (Narrowing re nement for innermost termination) Let R be a TRS and let P be a set of pairs of terms. Let hs ti 2 P such that all variables of t also occur in s and such that for all hv wi 2 P where t and v
are uni able by some mgu (after renaming the variables), one of the terms s or v is no normal form. Let
P0 = P n fhs tig fhs0 t0i j hs0 t0i is a narrowing of hs tig:
If there exists no in nite innermost R-chain of pairs from P0, then there exists no in nite innermost R-chain of pairs from P either.

PROOF. The proof is analogous to the proof of Thm. 27. The only di erence

is that the right-hand side t of the dependency pair does not have to be linear

any more. The reason is that in innermost chains we restrict ourselves to

normal substitutions and therefore, reductions of t can never take place

`in ' (as all variables of t also occur in s).

ut

Note that unlike Thm. 27 for termination, the replacement of dependency pairs by their narrowings can destroy the necessity of our innermost termination criterion. The reason is that narrowing does not respect the innermost reduction strategy.
Example 43 The TRS in Ex. 34 was innermost terminating. Hence, there
does not exist an in nite innermost chain of dependency pairs. However, if we
replace the dependency pair hF(s(x)) F(g(h(x)))i by its narrowings

hF(s(0)) F(g(a))i hF(s(x)) F(g(x))i

(34) (35)

then there exists an in nite innermost chain consisting of the new dependency
pair (35), because F(g(x1)) !i R F(s(x2)) holds if instantiates x1 and x2 by
0. (In particular, if (35) is again replaced by its narrowings, then we obtain the
new pair hF(s(0)) F(s(0))i which obviously forms an in nite innermost chain.)
Thus, although g(h(x)) has no redex as a proper subterm, narrowing this term leads to a failure of the innermost termination proof.

45

So there are examples where narrowing transforms a set of dependency pairs

without in nite innermost chains into a new set of pairs which form an in nite

innermost chain. However, this can only happen for examples where the au-

tomation of our method would have failed anyway, i.e. where the constraints

generated without using narrowing would already have been unsatis able (as

in Ex. 34). More precisely, if we use the approach of Thm. 37 and if we approx-

imate innermost dependency graphs by computing the innermost connectable

pairs (Thm. 39), then every ordering satisfying the constraints generated with-

out narrowing also satis es the constraints generated after narrowing depen-

dency pairs. In fact, every constraint obtained when using narrowing is implied

by the constraints that one would obtain without narrowing. (The reason is

that if hs0 t0i and hv0 w0i are narrowings of hs ti and hv wi respectively, then

hs

ti

is

innermost

connectable

to

hv

wi

whenever

hs0

0
t

i

is

innermost

con-

nectable

to

hv0

0
w

i.)

Hence,

the

application

of

narrowing

can

only

extend

the

number of systems where innermost termination can be proved automatically.

3.5 Summary

Combining all re nements, our technique to prove innermost termination automatically using the dependency pair approach works as follows:

Determine the dependency pairs.

Replace some (dependency) pairs by all their narrowings. Again, this step

could be repeated several times.

Approximate the innermost dependency graph by estimating for all (depen-

dency) pairs whether an arc exists between two of them. For that purpose

we introduced Compute the

the function usable rules

Uca, pi.se..

(a

superset

of)

those

rules

that

can

be

used for the reductions between two (dependency) pairs.

Transform the usable rules and the (dependency) pairs on cycles into in-

equalities.

Find a well-founded quasi-ordering satisfying the inequalities after normal-

izing them with respect to one of the possible AFSs.

As for the termination approach, standard techniques like the recursive path ordering or polynomial interpretations can be used to nd these orderings. However, since the ordering need not be weakly monotonic for tuple symbols, we may also search for di erent kinds of orderings, such as polynomial interpretations where some polynomials have negative coe cients.

Our approach is the rst automatic method which can also prove innermost termination of TRSs that are not terminating. Moreover, for those classes of TRSs where innermost termination already implies termination, the technique

46

described in this section can also be used for termination proofs. In particular, this holds for non-overlapping or at least locally con uent overlay systems. The di erence to the termination technique is that we only need to prove absence of in nite innermost chains. For that reason several steps in the technique are di erent to the technique of Sect. 2:
Right-hand sides of narrowed (dependency) pairs do not have to be linear and they may unify with left-hand sides as long as their mgu does not instantiate the left-hand sides to normal forms. For computing the innermost dependency graph instead of the functions ren and cap we use the function caps. We restrict ourselves to the usable rules when transforming the rules into inequalities. The quasi-ordering that has to be found in the end need not be weakly monotonic on tuple symbols (unless explicitly demanded). As long as the system is non-overlapping it is always advantageous to prove innermost termination only (instead of termination). The reason is that every ordering satisfying the constraints of the termination technique in Sect. 2 also satis es the constraints of our innermost termination technique, but not vice versa. For instance, termination of the systems in Ex. 35 and 41 can easily be proved with the technique introduced in this section, whereas the constraints generated by the method of Sect. 2 are not satis ed by any quasi-simpli cation ordering. A collection of examples demonstrating the power of our technique to prove innermost termination can be found in 4].
4 Conclusion and related work
We have introduced techniques to prove termination and innermost termination of term rewriting systems automatically. For that purpose we have developed su cient and necessary criteria for both termination and innermost termination. To automate the checking of these criteria, a set of constraints is synthesized for each TRS and standard techniques developed for termination proofs can be used to generate a well-founded ordering satisfying these constraints. If such an ordering can be found, then termination resp. innermost termination of the system is proved. Most other methods for automated termination proofs are restricted to simpli cation orderings. Compared to proving termination directly, our approach has the advantage that the constraints generated by our method are often satis ed by standard (simpli cation) orderings, even if termination of the original TRS cannot be proved with these orderings. Moreover, for all those TRSs where termination can be proved with a simpli cation ordering directly, this
47

simpli cation ordering also satis es the inequalities resulting from our technique. Therefore, instead of using simpli cation orderings for direct termination proofs, it is always advantageous to combine them with the technique presented in this paper. We implemented our technique for the generation of constraints and in this way termination could be proved automatically for many challenge problems from literature as well as for practically relevant TRSs from di erent areas of computer science. See 4] for a collection of numerous such examples, including arithmetical operations (e.g. mod, gcd, logarithm, average), sorting algorithms (such as selection sort, minimum sort, and quicksort), algorithms on graphs and trees, and several other well-known non-simply terminating TRSs (e.g. from 16,17,44]). Our termination criteria are based on the notion of dependency pairs. The concept of dependency pairs was introduced in 6] and a rst method for its automation was proposed in 1]. For that purpose, we transferred the estimation technique 24,25], which was originally developed for termination proofs of functional programs, to rewrite systems. However, this rst method was restricted to non-overlapping constructor systems without nested recursion. In this approach, the dependency pair technique was based on a special form of semantic labelling (cf. 48]), called self-labelling (similar to the notion of self-labelling in 40]). Self-labelling determines unique labels for the terms and a dependency pair can be regarded as a combination of the label for the lefthand side with the labels for the right-hand side of a rule. In 2] we developed a re ned framework for dependency pairs which is independent from semantic labelling. Therefore this framework is better suited for automation (as one does not have to construct an appropriate semantic interpretation any more) and its soundness can be proved in a much easier and shorter way. Moreover, in this framework we could show that our technique is applicable to arbitrary TRSs and we proved that the formulated criterion (Thm. 6) is not only su cient, but also necessary for termination. The present paper extends the approach of 2] by the introduction of argument ltering TRSs, the addition of narrowing dependency pairs, and by proving that the whole approach up to the search for suitable quasi-orderings is sound and complete, i.e., the inequalities for which an ordering should be found by standard techniques are satis able if and only if the TRS is terminating. This result suggests that the transformation described in this paper should always be applied before using any of the standard techniques for termination proofs. In 3] we presented a modi cation of the framework, in which the notion of chains was restricted to innermost chains and we showed that a TRS is innermost terminating if and only if no in nite innermost chains exist for the TRS.
48

This approach is the rst automatic method which can also prove innermost termination of systems that are not terminating. Moreover, our technique can very successfully be used for termination proofs of non-overlapping systems, because for those systems innermost termination is already su cient for termination. In the present paper we extended the technique described in 3] by a re ned de nition of innermost dependency graphs, a method to compute better approximations of these graphs, and a more powerful approach for narrowing dependency pairs. In 4] we give a collection of several examples which can now be proved terminating resp. innermost terminating automatically, but where automatic proofs using the techniques in 2,3] failed. We have presented a sound and complete termination criterion. In contrast to most other complete approaches (semantic path ordering 31], general path ordering 17], semantic labelling 48], etc.) our method is particularly well suited for automation as has been demonstrated in this paper. The only other complete criterion that has been used for automatic termination proofs (by Steinbach 44]) is the approach of transformation orderings 9,10]. It turns out that the termination of several examples where the automation of Steinbach failed can be proved by our technique automatically, cf. 4]. At rst sight there seem to be some similarities between our method and forward closures 17,38]. The idea of forward closures is to restrict the application of rules to that part of a term created by previous rewrites. Similar to our notion of chains, this notion also results in a sequence of terms, but these sequences have completely di erent semantics. For example, forward closures are reductions whereas in general the terms in a chain do not form a reduction. The reason is that in the dependency pair approach we do not restrict the application of rules, but we restrict the examination of terms to those subterms that can possibly be reduced further. Compared to the forward closure approach, the dependency pair technique has the advantage that it can be used for arbitrary TRSs, whereas the absence of in nite forward closures only implies termination for right-linear 14] or non-overlapping 22] TRSs. Moreover, in contrast to the dependency pair method, we do not know of any attempt to automate the forward closure approach. The framework of dependency pairs, as introduced in this paper, is very general and is therefore well suited to be used for more general rewriting problems, too. For example, the framework of dependency pairs can easily be extended for termination modulo associativity and commutativity 39]. Moreover, several well-known and new modularity results can be derived in this framework 5,7,26].
49

Acknowledgement
We would like to thank Hans Zantema, Aart Middeldorp, Thomas Kolbe, and Bernhard Gramlich for constructive criticism and many helpful comments. This work was partially supported by the Deutsche Forschungsgemeinschaft under grants no. Wa 652/7-1,2 as part of the focus program `Deduktion'.
References
1] T. Arts and J. Giesl. Termination of constructor systems. In H. Ganzinger, editor, Proceedings of the 7th International Conference on Rewriting Techniques and Applications, RTA-96, volume 1103 of Lecture Notes in Computer Science, pages 63{77, New Brunswick, NJ, USA, July 1996. Springer Verlag, Berlin.
2] T. Arts and J. Giesl. Automatically proving termination where simpli cation orderings fail. In M. Dauchet, editor, Proceedings of the 7th International Joint Conference on the Theory and Practice of Software Development, TAPSOFT '97, volume 1214 of Lecture Notes in Computer Science, pages 261{ 272, Lille, France, April 1997. Springer Verlag, Berlin.
3] T. Arts and J. Giesl. Proving innermost normalisation automatically. In H. Comon, editor, Proceedings of the 8th International Conference on Rewriting Techniques and Applications, RTA-97, volume 1232 of Lecture Notes in Computer Science, pages 157{171, Sitges, Spain, June 1997. Springer Verlag, Berlin.
4] T. Arts and J. Giesl. Termination of term rewriting using dependency pairs. Technical Report IBN 97/46, Darmstadt University of Technology, Germany, September 1997. http://www.inferenzsysteme.informatik.tu-darmstadt.de.
5] T. Arts and J. Giesl. Modularity of termination using dependency pairs. In T. Nipkow, editor, Proceedings of the 9th International Conference on Rewriting Techniques and Applications, RTA-98, volume 1379 of Lecture Notes in Computer Science, pages 226{240, Tsukuba, Japan, March/April 1998. Springer Verlag, Berlin.
6] T. Arts. Termination by absence of in nite chains of dependency pairs. In H. Kirchner, editor, Proceedings of the 21st International Colloquium on Trees in Algebra and Programming, CAAP '96, volume 1059 of Lecture Notes in Computer Science, pages 196{210, Linkoping, Sweden, April 1996. Springer Verlag, Berlin.
7] T. Arts. Automatically Proving Termination and Innermost Normalisation of Term Rewriting Systems. PhD thesis, Utrecht University, The Netherlands, May 1997.
50

8] T. Arts and H. Zantema. Termination of logic programs using semantic uni cation. In M. Proietti, editor, Proceedings of the 5th International Workshop on Logic Program Synthesis and Transformation, LoPSTr '95, volume 1048 of Lecture Notes in Computer Science, pages 219{233, Utrecht, The Netherlands, September 1995. Springer Verlag, Berlin.
9] L. Bachmair and N. Dershowitz. Commutation, transformation and termination. In J. H. Siekmann, editor, Proceedings of the 8th International Conference on Automated Deduction, CADE-8, volume 230 of Lecture Notes in Computer Science, pages 5{20, Oxford, England, July 1986. Springer Verlag, Berlin.
10] F. Bellegarde and P. Lescanne. Termination by completion. Applicable Algebra in Engineering, Communication and Computing, 1:79{96, 1990.
11] A. Ben Cherifa and P. Lescanne. Termination of rewriting systems by polynomial interpretations and its implementation. Science of Computer Programming, 9:137{159, 1987.
12] E. Bevers and J. Lewi. Proving termination of (conditional) rewrite systems. Acta Informatica, 30:537{568, 1993.
13] B. Courcelle. Recursive applicative program schemes. In J. van Leeuwen, editor, Formal Models and Semantics, volume B of Handbook of Theoretical Computer Science, pages 459{492. North-Holland, 1990.
14] N. Dershowitz. Termination of linear rewriting systems. In S. Even and O. Kariv, editors, Proceedings of the 8th International Colloquium on Automata, Languages and Programming, ICALP '81, volume 115 of Lecture Notes in Computer Science, pages 448{458, Acre, Israel, July 1981. Springer Verlag, Berlin.
15] N. Dershowitz. Orderings for term-rewriting systems. Theoretical Computer Science, 17:279{301, 1982.
16] N. Dershowitz. Termination of rewriting. Journal of Symbolic Computation, 3(1 and 2):69{116, 1987.
17] N. Dershowitz and C. Hoot. Natural termination. Theoretical Computer Science, 142(2):179{207, 1995.
18] N. Dershowitz and J.-P. Jouannaud. Rewrite systems. In J. van Leeuwen, editor, Formal Models and Semantics, volume B of Handbook of Theoretical Computer Science, pages 243{320. North-Holland, 1990.
19] J. Dick, J. Kalmus, and U. Martin. Automating the Knuth Bendix ordering. Acta Informatica, 28:95{119, 1990.
20] M. Ferreira and H. Zantema. Syntactical analysis of total termination. In G. Levi and M. Rodr guez-Artalejo, editors, Proceedings of the 4th International Conference on Algebraic and Logic Programming, ALP '94, volume 850 of Lecture Notes in Computer Science, pages 204{222, Madrid, Spain, September 1994. Springer Verlag, Berlin.
51

21] M. Ferreira and H. Zantema. Dummy elimination: Making termination easier. In H. Reichel, editor, Proceedings of the 10th International Conference on Fundamentals of Computation Theory, FCT '95, volume 965 of Lecture Notes in Computer Science, pages 243{252, Dresden, Germany, August 1995. Springer Verlag, Berlin.
22] O. Geupel. Overlap closures and termination of term rewriting systems. Technical Report MIP-8922 283, Universitat Passau, Passau, Germany, 1989.
23] J. Giesl. Generating polynomial orderings for termination proofs. In J. Hsiang, editor, Proceedings of the 6th International Conference on Rewriting Techniques and Applications, RTA-95, volume 914 of Lecture Notes in Computer Science, pages 426{431, Kaiserslautern, Germany, April 1995. Springer Verlag, Berlin.
24] J. Giesl. Termination analysis for functional programs using term orderings. In A. Mycroft, editor, Proceedings of the Second International Static Analysis Symposium, SAS' 95, volume 983 of Lecture Notes in Computer Science, pages 154{171, Glasgow, UK, September 1995. Springer Verlag, Berlin.
25] J. Giesl. Termination of nested and mutually recursive algorithms. Journal of Automated Reasoning, 19:1{29, 1997.
26] J. Giesl and E. Ohlebusch. Pushing the frontiers of combining rewrite systems farther outwards. In Proceedings of the Second International Workshop on Frontiers of Combining Systems, FroCoS '98, Applied Logic Series, Amsterdam, The Netherlands, October 1998. Kluwer Academic Publishers, Amsterdam.
27] B. Gramlich. Abstract relations between restricted termination and con uence properties of rewrite systems. Fundamenta Informaticae, 24:3{23, 1995.
28] B. Gramlich. On proving termination by innermost termination. In H. Ganzinger, editor, Proceedings of the 7th International Conference on Rewriting Techniques and Applications, RTA-96, volume 1103 of Lecture Notes in Computer Science, pages 93{107, New Brunswick, NJ, USA, July 1996. Springer Verlag, Berlin.
29] G. Huet and D. Lankford. On the uniform halting problem for term rewriting systems. Technical Report 283, INRIA, Le Chesnay, France, 1978.
30] J. M. Hullot. Canonical forms and uni cation. In W. Bibel and R. Kowalski, editors, Proceedings of the 5th International Conference on Automated Deduction, CADE-5, volume 87 of Lecture Notes in Computer Science, pages 318{334, Les Arcs, France, July 1980. Springer Verlag, Berlin.
31] S. Kamin and J.-J. Levy. Two generalizations of the recursive path ordering. Department of Computer Science, University of Illinois, IL, 1980.
32] J. W. Klop. Term rewriting systems. In S. Abramsky, D. M. Gabbay, and T. S. E. Maibaum, editors, Background: Computational Structures, volume 2 of Handbook of Logic in Computer Science, pages 1{116. Oxford University Press, New York, 1992.
52

33] D. E. Knuth and P. B. Bendix. Simple word problems in universal algebras. In J. Leech, editor, Computational Problems in Abstract Algebra, pages 263{297. Pergamon Press, 1970.
34] T. Kolbe. Challenge problems for automated termination proofs of term rewriting systems. Technical Report IBN 96/42, Darmstadt University of Technology, Germany, 1996.
35] M. R. K. Krishna Rao. Modular proofs for completeness of hierarchical term rewriting systems. Theoretical Computer Science, 151:487{512, 1995.
36] M. R. K. Krishna Rao. Some characteristics of strong innermost normalization. In M. Wirsing and M. Nivat, editors, Proceedings of the 5th International Conference on Algebraic Methodology and Software Technology, AMAST '96, volume 1101 of Lecture Notes in Computer Science, pages 406{420, Munich, Germany, July 1996. Springer Verlag, Berlin.
37] D. S. Lankford. On proving term rewriting systems are Noetherian. Technical Report Memo MTP-3, Louisiana Technical University, Ruston, LA, 1979.
38] D. S. Lankford and D. R. Musser. A nite termination criterion, 1978. 39] C. Marche and X. Urbain. Termination of associative-commutative rewriting
by dependency pairs. In T. Nipkow, editor, Proceedings of the 9th International Conference on Rewriting Techniques and Applications, RTA-98, volume 1379 of Lecture Notes in Computer Science, pages 241{255, Tsukuba, Japan, March/April 1998. Springer Verlag, Berlin. 40] A. Middeldorp, H. Ohsaki, and H. Zantema. Transforming termination by selflabelling. In M. A. McRobbie and J. K. Slaney, editors, Proceedings of the 13th International Conference on Automated Deduction, CADE-13, volume 1104 of Lecture Notes in Arti cial Intelligence, pages 373{387, New Brunswick, NJ, USA, July/August 1996. Springer Verlag, Berlin. 41] A. Middeldorp and H. Zantema. Simple termination of rewrite systems. Theoretical Computer Science, 175:127{158, 1997. 42] D. A. Plaisted. A recursively de ned ordering for proving termination of term rewriting systems. Technical Report R-78-943, Department of Computer Science, University of Illinois, Urbana-Champaign, IL, 1978. 43] J. Steinbach. Generating polynomial orderings. Information Processing Letters, 49:85{93, 1994. 44] J. Steinbach. Automatic termination proofs with transformation orderings. In J. Hsiang, editor, Proceedings of the 6th International Conference on Rewriting Techniques and Applications, RTA-95, volume 914 of Lecture Notes in Computer Science, pages 11{25, Kaiserslautern, Germany, April 1995. Springer Verlag, Berlin. Full Version appeared as Technical Report SR-92-23, Universitat Kaiserslautern, Germany, 1992. 45] J. Steinbach. Simpli cation orderings: History of results. Fundamenta Informaticae, 24:47{87, 1995.
53

46] Y. Toyama. Counterexamples to the termination for the direct sum of term rewriting systems. Information Processing Letters, 25:141{143, 1987.
47] H. Zantema. Termination of term rewriting: Interpretation and type elimination. Journal of Symbolic Computation, 17:23{50, 1994.
48] H. Zantema. Termination of term rewriting by semantic labelling. Fundamenta Informaticae, 24:89{105, 1995.
54

