Universidade de Brasília
Instituto de Ciênias Exatas
Departamento de Matemátia
Algoritmo de fatoração QR para geração de
animações faiais
por
Elenilson de Vargas Fortes
Brasília
2007
Universidade de Brasília
Instituto de Ciênias Exatas
Departamento de Matemátia
Algoritmo de fatoração QR para geração de
animações faiais
por
Elenilson de Vargas Fortes
*
Dissertação apresentada ao Departamento de Matemátia da Universidade de
Brasília, omo parte dos requisitos para obtenção do grau de
MESTRE EM MATEMÁTICA
Brasília, 13 de Dezembro de 2007
Comissão Examinadora:
Prof. Dr. Jorge Carlos Luero - MAT/UnB (Orientador)
Prof. Dr. Carlos Maber Carrión Riveros - MAT/UnB
(Membro)
Prof. Dr. Pledson Guedes de Medeiros - EST/UFRN
(Membro)
*
Este trabalho ontou om apoio naneiro parial do CNPq.
Somos o que pensamos. Tudo
o que somos surge om nossos pensamentos. Com nossos pensamentos,
fazemos o nosso mundo, (Buda).
Aos meus pais
Jonas de Vargas Fortes e Ozilia Loureti Fortes
Agradeimentos
À Deus pela vida e sabedoria onedida ao longo da minha aminhada estudan-
til.
Aos meus pais, Jonas de Vargas Fortes e Ozilia Loureti Fortes, aos meus queridos
irmãos, Emerson, Jonas (Junior), Jaqueline e Janielli.
Agradeço ao povo brasileiro, que através do pagamento de impostos permitiu ao
Conselho Naional de Desenvolvimento Cientío e Tenológio (CNPq), naniar
esta pesquisa.
Ao meu Orientador, Dr. Jorge Carlos Luero, pela orientação e paiênia que
teve durante a elaboração deste trabalho.
Aos professores da Universidade Federal do Espirito Santo (UFES): Aldo Vig-
natti, Alex sander, Eder Mahado, Gilvan, Jamil, Joitiel, Domingos, Ana Claudia
e Roha, pelos onselhos e inentivos.
Aos professores da bana examinadora Dr. Pledson Guedes de Medeiros e Dr.
Carlos Maber Carrión Riveros.
Aos olegas de graduação que ainda mantenho ontato: Meu grande amigo
Edinelço Dalumune, Wagner, Riedson, Sérgio e Vanessa. Aos olegas do urso
de verão que foram muito importantes para que eu tomasse a deisão de vir para
Brasília. E a todos os meus olegas do Departamento de Matemátia da Universi-
dade de Brasília que sempre me apoiaram nos bons e maus momentos. Alguns em
espeial omo Hailton pelo suporte ténio do site que riamos, Susanne, Riardo,
Enio, Sérgio, Luiana, Igor, Euro, Evander, Nilton, Walter e laro, Eliane Ferreira,
pelo arinho e atenção a mim onedidos.
Aos professores do Departamento de Matemátia da Universidade de Brasília
(UnB), Dr. Helmar Numes Moreira e em espeial Dr. Angel Rodolfo Baigorri, pelos
onselhos e onversas que foram de grande valia durante este período.
Aos Professores do Ensino Fundamental e Médio que de alguma forma aabaram
inueniando-me nesta onquista, em espeial Lenie, Ceília e Lena.
À todos que, de alguma forma alimentaram meus sonhos e ontribuiram para
esta grande onquista de minha vida. Obrigado!
Resumo
Nesta dissertação, onsideramos o problema da seleção de um subonjunto de
olunas independentes de uma matriz de dados, e sua resolução por meio da fatoração
QR om pivoteamento de olunas, (Luero et al., [12℄). Mostraremos omo este
problema pode ser apliado à identiação de padrões de deformação faial durante
a fala, para a onstrução de um modelo empírio da inemátia faial. O modelo
pode ser utilizado para a geração de animações da fala, sob ontrole de sinais olhidos
experimentalmente.
Palavras-haves: Seleção de Subonjunto, Fatoração QR, Animação
Faial.
Abstrat
In this work, we study the problem of the seletion of a subset of independent
olumns in matrix of data, and this resolution through the fatorization QR with
pivoted of olumns, (Luero et al., [12℄). We will show how this problem an be
applied to the identiation of patterns of faial deformation during speeh, for the
onstrution of an empiri model of the faial kinematis. The model an be used
for generating speeh animations, if we ontrol the signals hoosen experimentally.
Key Words: Subset Seletion, QR Fatorization , Faial Animation.
Sumário
Introdução 1
1 Coneitos Básios e Deomposição em Valores Singulares 5
1.1 Introdução . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5
1.2 Norma de Vetores . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5
1.3 Norma de Matrizes . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
1.4 Imagem, Espaço Nulo e Posto . . . . . . . . . . . . . . . . . . . . . . 9
1.5 Ortogonalidade . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11
1.6 Deomposição em Valores Singulares . . . . . . . . . . . . . . . . . . 12
1.7 Algumas Propriedades da SVD . . . . . . . . . . . . . . . . . . . . . 14
1.7.1 SVD e sua Relação om Normas . . . . . . . . . . . . . . . . . 14
1.7.2 Relações entre SVD e o Posto de uma Matriz . . . . . . . . . 16
1.7.3 Posto Numério . . . . . . . . . . . . . . . . . . . . . . . . . . 19
1.8 Análise e Disussão . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
2 A Fatoração QR 24
2.1 Introdução . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
2.2 Denição e Propriedades da Fatoração QR . . . . . . . . . . . . . . . 24
2.3 Reexão de Householder . . . . . . . . . . . . . . . . . . . . . . . . . 27
2.3.1 Reexão . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27
2.3.2 Denição e Propriedades da Reexão de Householder . . . . . 30
2.3.3 Esolha do Vetor de Reexão . . . . . . . . . . . . . . . . . . 31
2.4 Cálulo da Fatoração QR . . . . . . . . . . . . . . . . . . . . . . . . . 33
2.5 Relações da Fatoração QR om o Posto de uma Matriz . . . . . . . . 34
2.5.1 Uniidade da Fatoração QR . . . . . . . . . . . . . . . . . . . 35
2.5.2 Matriz de Permutação . . . . . . . . . . . . . . . . . . . . . . 35
i
2.5.3 Fatoração QR om Pivoteamento de Colunas . . . . . . . . . . 36
3 Apliações da Fatoração QR 39
3.1 Introdução . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
3.2 Sistemas Lineares . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40
3.3 Problema de Mínimos Quadrados . . . . . . . . . . . . . . . . . . . . 41
3.3.1 Matrizes de Posto Completo . . . . . . . . . . . . . . . . . . . 42
3.3.2 Matrizes de Posto Inompleto . . . . . . . . . . . . . . . . . . 46
3.4 O Problema da Seleção de Subonjunto . . . . . . . . . . . . . . . . . 48
3.4.1 Propriedades da Matriz AΠ . . . . . . . . . . . . . . . . . . . 48
3.4.2 Seleção de Subonjunto . . . . . . . . . . . . . . . . . . . . . . 50
3.4.3 Seleção de Subonjunto e Mínimos Quadrados . . . . . . . . . 51
3.5 Disussão . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54
4 Apliação a Animação Faial 55
4.1 Introdução . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55
4.2 Dados . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55
4.3 Pré-proessamento . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56
4.4 Posto Numério da Matriz de Dados . . . . . . . . . . . . . . . . . . 57
4.5 Alguns Resultados da Fatoração QR . . . . . . . . . . . . . . . . . . 59
4.6 Esolha dos Maradores Prinipais e suas Respetivas Regiões de In-
uênia . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61
4.7 Geração de Animações Faiais . . . . . . . . . . . . . . . . . . . . . . 66
4.8 Análise de Erros nas Trajetórias Computadas . . . . . . . . . . . . . 69
4.9 Análise para Seleção de Maradores . . . . . . . . . . . . . . . . . . . 72
Conlusões 76
Referênias Bibliográas 78
Apêndie A 81
Algoritmo A . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81
Algoritmo B . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83
Algoritmo C . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85
Algoritmo D . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86
Algoritmo E . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87
ii
Algoritmo F . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88
Algoritmo G . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89
Algoritmo H . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90
Algoritmo I . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93
Algoritmo J . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95
Algoritmo K . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98
Algoritmo L . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100
Apêndie B 104
Tabela 4.6 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104
Anexos 106
Teorema 2.6 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106
Teorema 2.7 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109
Teorema 2.9 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111
Teorema 2.10 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112
Teorema 2.13 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114
iii
Lista de Figuras
2.1 Reexão em torno da reta ξ. . . . . . . . . . . . . . . . . . . . . . . . . 28
2.2 Possibilidades de Reexão. . . . . . . . . . . . . . . . . . . . . . . . . . 31
3.1 Propriedades da Matriz AΠ. . . . . . . . . . . . . . . . . . . . . . . . . 49
4.1 Posição dos maradores faiais. . . . . . . . . . . . . . . . . . . . . . . 56
4.2 Elementos da diagonal da Matriz Σ. . . . . . . . . . . . . . . . . . . . . 58
4.3 Elementos da diadonal da Matriz R. . . . . . . . . . . . . . . . . . . . . 59
4.4 Valores normalizados dos 12 primeiros elementos na diagonal de R em
função da quantidade de amostras nos dados. . . . . . . . . . . . . . . . 60
4.5 Valores normalizados dos 12 primeiros elementos na diagonal de R em
função da quantidade de amostras nos dados permutados aleatoriamente. . 60
4.6 Regiões faiais ilustradas para os maradores 40, 34, 38, 02, 36 e 06. . . . 65
4.7 Regiões faiais ilustradas para maradores 20, 49, 13 e 52. . . . . . . . . . 66
4.8 Regiões de deformação faial nas direções ortogonais, linhas 1 a 6 de R. . . 67
4.9 Regiões de deformação faial nas direções ortogonais, linhas 7 a 10 de R. . 68
4.10 Quadro iniial das animações. . . . . . . . . . . . . . . . . . . . . . . . 69
4.11 Exemplo de trajetória real (linha de traços) e reonstruída pelo algoritmo
(linha heia), para o marador 28. . . . . . . . . . . . . . . . . . . . . . 70
4.12 Erro médio para um onjunto de k maradores seleionados, frases 31 e 32.
A linha heia (na horizontal) representa o erro de preisão dos dados. . . . 73
4.13 Erro médio para um onjunto de k maradores seleionados, frases 33 a 36.
A linha heia (na horizontal) representa o erro de preisão dos dados. . . . 74
iv
4.14 Erro médio para um onjunto de k maradores seleionados, para as frases
37 a 40. A linha heia (na horizontal) representa o erro de preisão dos
dados. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75
v
Lista de Tabelas
4.1 Os 12 primeiros maradores seleionados pelo algoritmo om k linhas na
matriz de dados. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62
4.2 Os 12 primeiros maradores seleionados pelo Algoritmo om k linhas per-
mutadas aleatoriamente. . . . . . . . . . . . . . . . . . . . . . . . . . . 62
4.3 Os 12 primeiros maradores seleionados pelo algoritmo. . . . . . . . . . . 63
4.4 Erro obtido para as trajetórias dos maradores que foram reonstituídas
através algoritmo para a sentença 39. . . . . . . . . . . . . . . . . . . . 71
4.5 Erro médio para trajetórias reonstituídas pelo algoritmo para as sentenças
31 a 40. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72
4.6 Conjunto de 40 sentenças em inglês: As 30 primeiras frases foram usadas
para onstruir o modelo e as 10 últimas para realizar testes e validar o modelo.105
vi
Introdução
Alguns problemas da Álgebra Linear, tais omo resolução de sistemas lineares, mí-
nimos quadrados e seleção de subonjunto (subset seletion problem) podem ser
onvenientemente tratados por meio da fatoração QR.
A fatoração QR é um método de deomposição em que a matriz A ∈ Rm×n é
deomposta em um produto A = QR, onde Q ∈ Rm×m e R ∈ Rm×n são matrizes
ortogonal e triangular superior, respetivamente.
Existem outros métodos para resolver os problemas aima. Por exemplo, para o
problema de mínimos quadrados, podem ser usadas as equações normais (ver [7, 20℄).
Os sistemas lineares podem ser soluionados através da fatoração LU ou eliminação
de Gauss (ver [10℄).
Foalizaremos, doravante, no tema de seleção de subonjuntos e suas variações.
Suponha que temos uma matriz de dados A ∈ Rm×n om m > n, a partir da qual
queremos predizer um vetor de observações b ∈ Rm×1, isto é, queremos enontar um
vetor x que miniminize ||Ax − b||2. No entanto, ao invés de usar todas as olunas
da matriz de dados A, desejamos predizer b a partir de apenas um subonjunto de
k olunas, eliminando aquelas que sejam redundantes e possam ser desonsideradas
(por exemplo, olunas linearmente dependentes, [7℄). Veremos que a seleção de dito
subonjunto de olunas não-redundantes de A é feita através da fatoração QR da
matriz A om pivoteamento de olunas, (ver [7, 6, 12℄).
Mostraremos que a seleção de subonjunto pode ser apliado a geração de anima-
ções faiais, onde queremos identiar um subonjunto de maradores independentes
para ser utilizado posteriormente, omo base para predizer o movimento de pontos
faiais arbitrários, obtendo dessa forma geração de animações, para ser utilizado
omo ferramenta omputaional em estudos sobre perepção e produção da fala. Os
estudos baseiam-se prinipalmente em Luero et al., (ver [12℄).
1
Introdução
Em artigo reente, a seleção de subonjuntos foi examinado por Hoog e Mattheij
(ver [8℄), onde onsideram uma matriz A ∈ Rm×n em que se deseja eliminar m − k
linhas de A de tal forma que a matriz resultante B ∈ Rk×n possua um subonjunto
de linhas linearmente independentes, isto é, para A ∈ Rm×n enontrar uma matriz
de permutação Π ∈ Rm×m tal que
ΠA =
(
B
C
)
, (1)
sendo B ∈ Rk×n a matriz pretendida. Neste artigo, os autores mostram uma ténia
de seleção de linhas basedo na norma de Frobenius e na Pseudo-Inversa (ver [7℄).
Outros métodos omo os algoritmos de tipo Bakward Greedy (ver [2℄) podem
ser utilizados para abordar o problema de seleção de subonjunto, uja essênia
onsiste na determinação reiterada, de ρ = min
x∈Rn
||Ax − b||2 para uma dada matriz
A ∈ Rm×n e um vetor de observações b ∈ Rn.
Espeiamente, retira-se uma oluna de A e alula-se min
x1∈Rn−1
||A1x1 − b||2.
Reinserida esta oluna na matriz A novamente retiramos outra oluna e alula-se
min
x1∈Rn−1
||A1x1−b||2. Repete-se este proesso para todas as olunas de A e elimina-se
a oluna que forneça min
x1∈Rn−1
||A1x1 − b||2 menor possível, onde A1 ∈ Rm×(n−1). Em
ada etapa do algoritmo, elimina-se uma oluna de A, sempre seguindo os passos
para eliminação da primeira oluna. Desta forma, o algoritmo elimina n− r olunas
de A e portanto, tem-se uma matriz Ar ∈ Rm×r, ou seja, o algoritmo seleiona um
subonjunto de r olunas de A.
Do mesmo modo pode ser utilizadas para examinar o problema de seleção de
subonjunto, diferente ténia (ver [7℄) denominada deomposição de valores singu-
lares (SVD), que adiaremos temporariamente e prontamente será apresentada no
Capítulo 1.
Em outro artigo (ver [18℄), a seleção de subonjunto é feita usando reursos
estatístios e algébrios. Iniia-se om a apliação de sanner a laser a 8 expresões
faiais estátias pré-determinadas originando igual número de matrizes om 71.900
pixels e 141.900 polígonos, que seguidamente são adaptadas a uma malha faial
deformável genéria onstituída por 576 nodos e 844 polígonos. A partir dessas 8
malhas faiais são gerados 8 (oito) vetores de 3×576 omponentes, que representam
2
Introdução
as oordenadas espaiais {x, y, z} de ada um dos nodos e onstituem os vetores
olunas da matriz de dados aleatórios A ∈ Rm×n, onde m = 3× 576 e n = 8. Após
alulada a matriz de ovariânia e via SVD obtem-se as omponentes prinipais
(PCA) dos vetores olunas de A dos quais seleiona-se o subonjunto dos mais
representativos no que se refere à variânia dos dados. Note-se que as omponentes
prinipais são os autovetores de A e que pelo signiado deorrentes do modelo
representam rostos disretizados na forma de malhas faias, o que os leva a serem
hamados de autofaes (eigenfae). No presente aso, gostariamos de obter um
modelo em termos de pouo maradores faiais, ao invés de vetores que representam
imagem da fae.
Outra alternativa interessante, foi proposta pelo trabalho de modelagem arti-
ulatória de Badin et al., (ver [4℄). Neste artigo, o PCA é usado para determinar
parâmetros artiulatórios para ontrolar a forma de uma região voal em 3D. Para
uma melhor relação à biomeânia subjaente, alguns dos parâmetros (por exemplo,
altura do maxilar, et.) são denidos a priori, e suas ontribuições são subtraídas
dos dados antes de omputar os omponentes restantes. Em nosso trabalho, nós
propomos onar inteiramente nos dados para predizer o omportamento dinâmio
da fae, om pouas suposições prévias omo possível.
Retornando à deomposição QR om pivoteamento de olunas omo proedi-
mento de seleção de subonjunto, é mister omentar algumas reentes apliações.
Foi apliada à matriz A ∈ Rm×n, om m < n ujas olunas se orrespondem om a
sequênia nita de profundidades do nível da água medida em um dado poço, em
intervalos arbitrários de tempo. O objetivo deste estudo foi a identiação de sub-
onjunto de poços independentes para posteriormente serem utilizados omo base
para a predição do desloamento do nivel de água em poços aleatoriamente esolhi-
dos (ver [16℄).
Como visto, existem várias ténias para se resolver o problema de seleção de
subonjunto e apliações. Conforme mostraremos, o algoritmo de fatoração QR om
pivoteamento de olunas permite identiar um subonjunto de maradores faiais
independentes, e desta forma explorar sua apliação à onstrução de modelos da
biomeânia faial (ver [12℄) e onsequentemente, movimentos arbitrários e anima-
ções da fala podem ser logo geradas, ontrolando esse modelo om sinais olhidos
experimentalmente (animação faial data driven).
3
Introdução
Os estudos sobre animações faiais deste presente trabalho está baseado em
Luero et al. (ver [12℄) e é resultado da análise de pesquisas anteriores, na ger-
ação de animações faiais realístias durante a fala. Nosso trabalho segue uma linha
de pesquisas omputaionais para a geração deste tipo de animação. Dentre esses
trabalhos, podemos itar um outro artigo reente de Luero et al. (ver [13℄). O
artigo propõe uma analise dos registros da posição 3D de um onjunto de mar-
adores oloados no rosto de um sujeito, enquanto este fala, indentiando grupos
de maradores om padrões de movimentos similares. Esses grupos denem regiões
inemátias independentes, que onstituem uma base para expressar o movimento
total da superfíie faial.
No que segue, esta dissertação terá a seguinte estrutura:
No primeiro Capítulo são introduzidos oneitos básios de álgebra linear, deni-
ções e resultados sobre a SVD e sua relação om o posto de uma matriz e nalizamos
om uma rápida disussão sobre a SVD.
No Capítulo seguinte, denimos fatoração QR e algumas propriedades desta
deomposição. Em seguida, apresentamos omo obter a fatoração QR por Reexão
de Householder, onluindo om alguns resultados que relaionam a fatoração QR
om o posto da matriz.
Já no tereiro Capítulo, apresentamos algumas apliações da fatoração QR, tal
omo na resolução de sistemas lineares, problema de mínimos quadrados e uma
solução para o problema de seleção de subonjunto, nalizando om uma breve
disussão deste Capítulo.
Por m, no quarto Capítulo, mostramos omo a fatoração QR pode ser útil
na obtenção de um modelo para geração de animações faiais e alguns resultados
aera da fatoração QR, além da análise dos erros. O Matlab foi utilizado em todos
os gráos e tabelas que apareem neste Capítulo.
Por último, apresentamos algumas Conlusões, Anexos e o Apêndie, onde está
disposto o ódigo fonte em Matlab da maioria dos programas que foram implemen-
tados nesta dissertação.
4
Capítulo 1
Coneitos Básios e Deomposição
em Valores Singulares
1.1 Introdução
Esse apítulo tem omo objetivo introduzir alguns oneitos de álgebra linear que
serão usados nos apítulos seguintes. Começaremos denindo normas, posto, orto-
gonalidade e alguns resultados sobre o mesmo.
Em seguida, foalizaremos nossos estudos na Deomposição de Valores singulares
(SVD) e provaremos alguns dos prinipais resultados que envolvem este tipo de de-
omposição, prinipalmente naqueles que relaionam SVD e o posto de uma matriz,
mostrando que a SVD pode ser usado para reduzir a dimensão de uma matriz de
dados.
Por m, usaremos o SVD para determinar o posto numério de uma matriz A e
onluiremos esse apítulo, fazendo uma análise desta deomposição.
1.2 Norma de Vetores
Uma norma é uma função
|| || : Rn → R
x → ||x||
que faz uma orrespondênia de um valor real (`omprimento') a ada vetor.
5
Capítulo 1. Resultados Básios e Deomposição em Valores Singulares
Para que orresponda a uma idéia razoável de omprimento, uma norma deve
satisfazer três axiomas. Para quaisquer x, y ∈ Rn e esalar α ∈ R,
1. ||x|| ≥ 0, e ||x|| = 0 se, e só se, x = 0;
2. ||x+ y|| ≤ ||x||+ ||y||;
3. ||αx|| = |α|||x||.
Em palavras, estas ondições expressam o seguinte: Por 1. a norma de um vetor
não-nulo é positiva, 2. é a famosa desigualdade do triângulo, 3. é a propriedade de
homogeneidade.
Pode-se provar (ver [7℄) que para quaisquer x, y ∈ Rn temos
||x.y|| ≤ ||x||.||y||.
Esta inequação é onheida omo desigualdade de Cauhy-Shwarz.
As normas mais utilizadas em Análise Numéria são as denominadas p-normas.
Denição 1.1 p-norma de um vetor x é dada por
||x||p =
(
m∑
i=1
|xi|p
) 1
p
, (1.1)
para todo x ∈ Rn.
Para os asos partiulares em que p é igual a 1, 2 ou ∞, temos as seguintes
normas:
1. 1-norma: ||x||1 =
m∑
i=1
|xi|;
2. 2-norma: ||x||2 =
(
m∑
i=1
|xi|2
) 1
2
;
3. ∞-norma: ||x||∞ = max
i=1,··· ,n
|xi|.
6
Capítulo 1. Resultados Básios e Deomposição em Valores Singulares
O ítem 1. é onheido omo norma da Soma, 2. omo norma Eulidiana e 3. é
a norma do Máximo.
Todas as normas em R
n
são equivalentes (ver [7℄), isto é, se || . ||α e || . ||β são
normas em R
n
, então existem onstantes positivas c1 e c2 tais que
c1||x||α ≤ ||x||β ≤ c2||x||α (1.2)
para todo x ∈ Rn.
Pode-se provar (ver [7℄) que, para todo x ∈ Rn, valem as seguintes desigualdades:
1. ||x||2 ≤ ||x||1 ≤
√
n||x||2;
2. ||x||∞ ≤ ||x||2 ≤
√
n||x||∞;
3. ||x||∞ ≤ ||x||1 ≤
√
n||x||∞.
Em geral, os valores das p-normas, p = 1, 2 e ∞ são distintos.
1.3 Norma de Matrizes
Uma matriz A ∈ Rm×n pode ser vista omo um vetor no espaço de dimensão mn,
ada um dos elementos onsiderados omo oordenada independente. Portanto,
qualquer norma vetorial pode ser utilizada para medir o `tamanho' de uma matriz.
Uma norma matriial é uma função
|| || : Rm×n → R
A → ||A||
que satisfaz 3 ondições. Para quaisquer A,B ∈ Rm×n e α ∈ R temos
1. ||A|| ≥ 0, e ||A|| = 0 se, e só se, A = 0;
2. ||A+B|| ≤ ||A||+ ||B|| ;
3. ||αA|| = |α|||A||.
7
Capítulo 1. Resultados Básios e Deomposição em Valores Singulares
Em alguns asos, podemos ter ainda uma propriedade adiional, que relaiona
a operação de multipliação de matriz, isto é, ||A.C|| ≤ ||A||.||C|| para quaisquer
A ∈ Rm×n e C ∈ Rn×m. Essa propriedade é hamada de onsistênia, (ver [7℄).
Por simpliidade, utilizaremos a mesma norma || ||p no domínio e na imagem,
a p-norma de A, e denotaremos por ||A||p. Assim,
Denição 1.2 p-norma de uma matriz A é dada por ||A||p = max
x 6=0
||Ax||p
||x||p , para
todo x ∈ Rn.
Equivalentemente à Denição 1.2 temos que
||A||p = max
x 6=0
||Ax||p
||x||p = maxx 6=0
∥∥∥∥A( x||x||p
)∥∥∥∥
p
= max
||x||p=1
||Ax||p.
Em partiular, se p = 1, 2 ou ∞ temos, respetivamente, que
1. ||A||1 = max
x 6=0
||Ax||1
||x||1 ;
2. ||A||2 = max
x 6=0
||Ax||2
||x||2 ;
3. ||A||∞ = max
x 6=0
||Ax||∞
||x||∞ .
Pode-se provar (ver [7℄) que se p = 1 e p =∞ temos, respetivamente, que
||A||1 = max
1≤j≤n
m∑
i=1
|aij | (1.3)
||A||∞ = max
1≤i≤m
n∑
j=1
|aij | (1.4)
Uma norma matriial, frequentemente utilizada, é hamada de Norma de Frobe-
nius ou Hilbert-Shmidt e é denida a partir de
Denição 1.3 Norma de Frobenius de uma matriz A ∈ Rm×n é dada por
||A||F =
√√√√ n∑
j=1
m∑
i=1
(aij)
2.
8
Capítulo 1. Resultados Básios e Deomposição em Valores Singulares
Seja B uma matriz om elementos bij onde 1 ≤ i ≤ m e 1 ≤ j ≤ n. Denotemos
por bl, om 1 ≤ l ≤ n, as respetivas olunas da matriz B. Então
n∑
l=1
||bl||22 = ||b1||22 + ||b2||22 + · · ·+ ||bn||22
= (b211 + b
2
21 + · · ·+ b2m1) + · · ·+ (b21n + b22n + · · ·+ b2mn)
= ||B||2F . (1.5)
Seja C = AB om entradas cik, denotamos a
T
i a i-ésima linha de A e bj a j-ésima
oluna de B. Então cij = a
T
i bj e por Cauhy-Shwartz |cij| ≤ ||ai||.||bj||. Assim,
||AB||2F =
n∑
i=1
m∑
j=1
|cij |2
≤
n∑
i=1
m∑
j=1
(||ai||2||bj ||2)2
=
n∑
i=1
(||ai||2)2
m∑
j=1
(||b||2)2
= ||A||2F ||B||2F . (1.6)
Como as normas vetoriais, as normas matriiais Ap om p = 1, p = ∞ e AF
também possuem relações de equivalênia. Podemos provar que (ver [7℄) dada uma
matriz A ∈ Rm×n temos
1. ||A||2 ≤ ||A||F ≤
√
n ||A||2 ;
2. max
i,j
|aij | ≤ ||A||2 ≤
√
mn max
i,j
|aij|;
3.
1√
n
||A||∞ ≤ ||A||2 ≤
√
m ||A||∞;
4.
1√
m
||A||1 ≤ ||A||2 ≤
√
n ||A||1.
1.4 Imagem, Espaço Nulo e Posto
Denição 1.4 Dada uma oleção de vetores a1, a2, · · · , an em Rn, o onjunto de
todas as ombinações lineares desses vetores é um subespaço denotado por Espaço
9
Capítulo 1. Resultados Básios e Deomposição em Valores Singulares
de a1, a2, · · · , an, ou seja,
〈a1, a2, · · · , an〉 =
{
n∑
j=1
βjaj ; βj ∈ R
}
.
Denição 1.5 Seja A ∈ Rm×n. Dizemos que a Imagem de A é
Im(A) = {y ∈ Rm; y = Ax para algum x ∈ Rn}
Em relação a Denição 1.5, observe que qualquer vetor y que pertene ao espaço
gerado pelas olunas de A pode ser esrito omo ombinação linear de suas olunas,
ou seja, y =
n∑
j=1
xjaj , logo y = Ax e portanto, y ∈ Im(A). Reiproamente, se
y ∈ Im(A) então y = Ax para algum x ∈ Rn e portanto, Ax é ombinação linear
das olunas de A. Assim, se A = [a1, a2, · · · , an] são as olunas partiionadas de A,
então
Im(A) = 〈a1, a2, · · · , an〉 . (1.7)
Denição 1.6 (Núleo) Seja A ∈ Rm×n. O Espaço Nulo ou Núleo de A é
dado por
N(A) = {x ∈ Rn; Ax = 0} .
Denição 1.7 (Posto) Dizemos que o Posto de uma matriz A é
posto(A) = dim(Im(A)).
Denição 1.8 Dizemos que A ∈ Rm×n possui Posto Inompleto, se posto(A) <
min {m,n}.
Pode-se provar que (ver [7℄):
1. posto(A) = posto(AT );
2. Se A ∈ Rm×n, então dim(N(A)) + posto(A) = n.
10
Capítulo 1. Resultados Básios e Deomposição em Valores Singulares
1.5 Ortogonalidade
Denição 1.9 Uma matriz Q ∈ Rm×n é dita Ortogonal se, e somente se, QQT =
QTQ = In.
Teorema 1.10 Se Q é uma matriz ortogonal, então
1. det(Q) = ±1;
2. QT é ortogonal.
3. ||Qx||2 = ||x||2, para todo vetor x;
4. ||QA||2 = ||A||2, para toda matriz A;
5. ||Q||2 = 1.
Demonstração:
Omitiremos a demonstração para os ítens 1, 2, 4 e podem ser enontradas em [19℄.
3. Se x é um vetor qualquer, então
||Qx||22 = (Qx)T (Qx)
= xTQTQx
= xTx
= ||x||22
= ||x||2. (1.8)
5. É onsequênia imediata de 2. e de ||I||2 = 1.

Teorema 1.11 Se Q1 e Q2 são matrizes ortogonais, então Q1Q2 é ortogonal.
Demonstração: Ver [19℄.

11
Capítulo 1. Resultados Básios e Deomposição em Valores Singulares
Teorema 1.12 Seja A ∈ Rm×n e Q ∈ Rm×m ortogonal, então ||QA||F = ||A||F ,
onde F é norma de Frobenius.
Demonstração:
Suponha que a1, a2, · · · , an sejam as olunas de A, então
||QA||2F = ||(Qa1, Qa2, · · · , Qan)||2F
=
n∑
i=1
||Qai||22
=
n∑
i=1
||ai||22
= ||A||2F . (1.9)

1.6 Deomposição em Valores Singulares
A Deomposição em Valores Singulares (SVD, Singular Value Deomposition) é
uma fatoração de matrizes freqüentemente utilizada em muitos algoritmos. É uma
ferramenta ontida na maioria dos paotes matemátios de omputação e muitos
problemas de Álgebra Linear podem ser resolvidos utilizando esta fatoração. Inii-
amos esta Seção, apresentando a denição de SVD.
Denição 1.13 Seja A ∈ Rm×n. A SVD de A é a fatoração
A = UΣV T (1.10)
onde U ∈ Rm×m e V ∈ Rn×n são Ortogonais e Σ ∈ Rm×n é uma matriz Diagonal,
isto é,
σij =
{
σij , se i = j,
0, se i 6= j.
Os elementos σii, i = 1, 2, · · · , p, onde p = min{m,n}, são denominados Valores
Singulares de A e denotados por σi sendo esolhidos de modo que σ1 ≥ σ2 ≥ · · · ≥
σp ≥ 0.
12
Capítulo 1. Resultados Básios e Deomposição em Valores Singulares
Cada uma das m olunas da matriz U , denotadas por uk, são hamadas Vetores
Singulares à Esquerda de A e ada uma das n olunas da matriz V , denotadas por vk,
são hamadas Vetores Singulares à Direita de A. Os vetores uk são os autovetores
da matriz ATA, e os vetores vk são os autovetores da matriz AA
T
.
Observações:
1. A deomposição de valores singulares denida em 1.13 reebe o nome de SVD
Completa.
2. Seja A ∈ Rm×n, om m ≥ n e A = UΣV T a SVD de A, onde U , V e Σ
são dados omo na Denição 1.13. Observe que para m > n a matriz Σ
possui todos m− n valores singulares iguais a zero. De modo que apenas os n
primeiros valores singulares de Σ inueniam na deomposição de A. Assim,
suponha que Σ tenha n valores singulares não-nulos. Logo, a equação (1.10)
denida em 1.13 pode ser reesrita omo
A = U
(
Σ̂
0
)
V T .
Desta forma, o produto aima anula m− n olunas de U e Σ̂ possui n valores
singulares. Logo
A = ÛΣ̂V T (1.11)
onde Û ∈ Rm×n, V ∈ Rn×n e Σ̂ ∈ Rn×n é uma matriz diagonal om σ1 ≥ σ2 ≥
· · · ≥ σn todos não-nulos. Essa deomposição é onheida omo SVD reduzida
de A.
Dada uma matriz A ∈ Rm×n pode-se provar que:
1. Toda matriz A sempre admite uma deomposição em valores singulares;
2. Seus respetivos valores singulares são únios;
3. Se os valores singulares forem distintos dois a dois, então os vetores singulares
(à esquerda e à direita) são únios a menos de sinal.
Demonstrações para esses resultados podem ser enontrados em [19℄.
13
Capítulo 1. Resultados Básios e Deomposição em Valores Singulares
1.7 Algumas Propriedades da SVD
Um dos aspetos que valorizam a SVD é sua apaidade de lidar om o oneito
de posto de matrizes. Nessa Seção mostraremos que o SVD é uma have para esse
problema por araterizar eientemente uma aproximação de matrizes de um posto
denido, (ver [6℄). Iniiaremos essa Seção, introduzindo algumas relações entre SVD
e normas (ver [7, 20℄), que serão úteis adiante, quando falaremos de posto numério.
1.7.1 SVD e sua Relação om Normas
Nessa Subseção apresentaremos alguns resultados que relaionam 2-norma e norma
de Frobenius om os valores singulares de uma matriz A que são importantes e
mereem ser destaadas. Estas relações serão mostradas nos Teoremas 1.14 e 1.15.
Teorema 1.14 Seja A ∈ Rm×n uma matriz om deomposição de valor singular
UΣV T , então
||A||2 = σ1 (maior valor singular). (1.12)
Demonstração:
Sabemos que ||U ||2 = ||V T ||2 = 1 porque U e V são ortogonais. Assim,
||A||2 = ||UΣV T ||2
= ||Σ||2
= max
x 6=0
||Σx||2
||x||2
= max
x 6=0
(
n∑
i=1
(σixi)
2
)1
2
(
n∑
i=1
x2i
) 1
2
= max
x 6=0
((σ1x1)
2 + (σ2x2)
2 + · · ·+ (σnxn)2)
1
2
(x21 + x
2
2 + · · ·+ x2n)
1
2
.
14
Capítulo 1. Resultados Básios e Deomposição em Valores Singulares
Como σ1 é o maior valor singular da matriz A, substituindo ada σi, onde i =
1, · · · , n, por σ1 teremos,
||A||2 ≤ max
x 6=0
(σ21(x
2
1 + x
2
2 + · · ·+ x2n))
1
2
(x21 + x
2
2 + · · ·+ x2n)
1
2
= max
x 6=0
σ1
(x21 + x
2
2 + · · ·+ x2n)
1
2
(x21 + x
2
2 + · · ·+ x2n)
1
2
= max
x 6=0
σ1
= σ1.
Portanto,
||A||2 ≤ σ1. (1.13)
Por outro lado, esolhendo x = e1, temos
||A||2 = ||UΣV T ||2.
= max
x 6=0
((σ1x1)
2 + (σ2x2)
2 + · · ·+ (σnxn)2)
1
2
(x21 + x
2
2 + · · ·+ x2n)
1
2
= max
x 6=0
((σ11)
2 + (σ20)
2 + · · ·+ (σn0)2)
1
2
(12 + 02 + · · ·+ 02) 12
= max
x 6=0
σ1
||A||2 = σ1. (1.14)
De (1.13) e (1.14) seque (1.12).

Teorema 1.15 Seja A ∈ Rm×n uma matriz om deomposição em valores singulares
UΣV T , então
||A||F =
(
σ21 + σ
2
2 + · · ·+ σ2n
) 1
2 . (1.15)
Demonstração:
Pelo Teorema 1.12 para qualquer matriz ortogonal Q temos que ||QA||F = ||A||F .
15
Capítulo 1. Resultados Básios e Deomposição em Valores Singulares
Considere UΣV T a deomposição em valores singulares de A, onde U ∈ Rm×n,
Σ ∈ Rn×n e V T ∈ Rn×n. Então
||A||F = ||UΣV T ||F
= ||ΣV T ||F
= ||(ΣV T )T ||F
= ||(VΣT )||F
= ||ΣT ||F
=
(
σ21 + σ
2
2 + · · ·+ σ2n
) 1
2 .

1.7.2 Relações entre SVD e o Posto de uma Matriz
Esta Subseção tem o propósito de relaionar a SVD e o posto de uma matriz, usando
os respetivos valores singulares. Começamos por um teorema que fornee uma
relação entre o posto e os valores singulares de uma matriz.
Teorema 1.16 (Posto) Seja A ∈ Rm×n e Σ a matriz de valores singulares de A.
Então, posto(A) = n se, e somente se, Σ têm n valores singulares não-nulos.
Demonstração:
Suponha que Σ têm n valores singulares não-nulos então posto(Σ) = n, já que Σ é
uma matriz diagonal. Por outro lado, A = UΣV T e omo U e V têm posto ompleto,
então posto(A) = posto(Σ). A reíproa é análoga.

O Teorema 1.16 fornee uma alternativa para se determinar o posto de uma ma-
triz em vez de usar a Denição 1.7, porém agora, usando a SVD. Conseqüentemente,
uma matriz A ∈ Rm×n terá posto inompleto, isto é, r < n, se σi > 0, i = 1, · · · , r
e σr+1 = · · · = σn = 0.
A fórmula seguinte é uma das mais importantes propriedades da deomposição
em valores singulares.
16
Capítulo 1. Resultados Básios e Deomposição em Valores Singulares
Teorema 1.17 Uma matriz A ∈ Rm×n om posto r, r ≤ n, pode ser esrita na
forma
Ar =
r∑
j=1
σjujv
T
j , (1.16)
em que ui, i = 1, · · · , r, são os primeiros r vetores singulares à esquerda de A, vi,
i = 1, · · · , r, são os primeiros r vetores singulares à direita de A e σi, i = 1, · · · , r,
são os valores singulares de A.
Demonstração:
Tem-se que
I = V V T
= (v1, v2, · · · , vn)(vT1 , vT2 , · · · , vTn )
= v1v
T
1 + v2v
T
2 + · · ·+ vnvTn ,
já que V é uma matriz ortogonal. Se multipliarmos por A a esquerda da equação
aima em ambos os membros da igualdade teremos:
A = A(v1v
T
1 + v2v
T
2 + · · ·+ vnvTn )
= (Av1)v
T
1 + (Av2)v
T
2 + · · ·+ (Avn)vTn
= σ1u1v
T
1 + σ2u2v
T
2 + · · ·+ σnunvTn .
Se A tem posto r = n, segue do Teorema 1.16 que A possui n valores singulares
não-nulos e portanto
A =
r∑
j=1
σjujv
T
j .
Caso ontrário, se A tem posto r < n, então pelo Teorema 1.16 temos que σr+1 =
σr+2 = · · · = σn = 0. Daí,
A = σ1u1v
T
1 + σ2u2v
T
2 + · · ·+ σrurvTr
=
r∑
j=1
σjujv
T
j .

17
Capítulo 1. Resultados Básios e Deomposição em Valores Singulares
Observação:
• Dados u1 =

u11
u21
.
.
.
um1
 e v1 =

v11
v21
.
.
.
vn1
 então,
u1v
T
1 =

u11
u21
.
.
.
um1
 (v11 v21 · · · vn1)
=

u11v11 u11v21 · · · u11vn1
u21v11 u21v21 · · · u21vn1
.
.
.
.
.
. · · · ...
um1v11 um1v21 · · · um1vn1
.
Portanto, as olunas da matriz u1v
T
1 são múltiplos do vetor u1, e assim, a
matriz u1v
T
1 tem posto 1. De maneira análoga, todas as matrizes uiv
T
i , om
i = 1, · · · , r têm exatamente posto 1.
A partir desta observação e do Teorema 1.17 podemos armar que qualquer
matriz (om posto r) é uma ombinação linear de r matrizes de posto 1. Os oe-
ientes desta ombinação linear são os valores singulares σ1, σ2, · · · , σr da matriz.
Em determinadas apliações, apareem matrizes ujos valores singulares menores
deveriam ser nulos, mas não o são por determinados motivos (por exemplo, erros de
arredondamento). É freqüente, nestes asos, substituir esses valores singulares por
zero, desprezando as suas ontribuições, e onsiderar uma matriz aproximada om
menos termos na ombinação linear das matrizes de posto 1.
Teorema 1.18 Seja A ∈ Rm×n. Para qualquer ν om 0 ≤ ν ≤ r, denimos
Aν =
ν∑
j=1
σjujv
T
j , (1.17)
18
Capítulo 1. Resultados Básios e Deomposição em Valores Singulares
se ν = p = min{m,n}, dena σν+1 = 0. Então
||A− Aν ||2 = min
posto(B)≤ ν
||A− B||2 = σν+1.
Demonstração: Ver [19℄.

Observações:
1. É fáil ver que UTAνV = diag(σ1, σ2, · · · , σν , 0, · · · , 0) e daí, posto(Aν) = ν.
Por outro lado, UT (A−Aν)V = diag(0, 0, · · · , 0, σν+1, · · · , σp) e pelo Teorema
1.14, temos ||A− Aν ||2 = σν+1.
2. Observe que de aordo om o Teorema 1.17 podemos usar o SVD para expres-
sar uma matriz A omo ombinação linear de uma base de vetores ortogonais.
Ou seja, dada uma matriz A ∈ Rm×n, podemos usar os primeiros r valores
singulares (r < n), e aproximar as olunas de A omo ombinação linear de
uma base de r vetores. De aordo om o Teorema 1.18, quando aproximamos
uma matriz A de posto n ≥ r, para uma matriz Ar = UΣrV T om posto r,
temos que essa aproximação no sentido da || . ||2 é a melhor possível de A,
pois o ínmo é atingido para toda matriz B denida por
B = U
(
Σ′
0
)
V T , (1.18)
onde Σ′ = diag(σ1, σ2, · · · , σr, 0, · · · , 0).
1.7.3 Posto Numério
Seja A ∈ Rm×n. Suponha que uma matriz A que originalmente tinha posto r < n
têm seus elementos perturbados por algum tipo de erro, por exemplo, arredonda-
mento ou erros de medidas. Certamente, esses erros de arredondamento, não per-
mitirá que a matriz A ontinue om posto exatamente igual a r. Realmente, o que
é provável, é que a matriz que foi pertubada terá posto maior que r.
19
Capítulo 1. Resultados Básios e Deomposição em Valores Singulares
Suponha que ambas as matrizes aima sejam submetidas a algoritmos numérios
ou estatístios. A proximidade de A para matriz pertubada não forneerá interpre-
tações erradas quando ambas as matrizes forem submetidas a esses algoritmos.
Assim, um modo de evitar possíveis problemas om a denição de posto (ver
[6℄), é espeiar uma tolerânia e dizer que a matriz A tem posto numeriamente
deiente, se dentro dessa tolerânia, a matriz A está próxima da matriz de posto
deiente. Em outras palavras,
Denição 1.19 Uma matriz A possui um ǫ-posto r om norma || || se
r = posto(A, ǫ) = inf{posto(B); ||A− B|| ≤ ǫ}.
Entretanto, essa denição pode apresentar problemas, pois um pequeno aumento
em ǫ poderia aarretar na diminuição do posto numério de A. É neessário então,
ahar um limite superior para ǫ para o qual o posto numério a pelo menos iqual
a r. Tal número é forneido por qualquer δ satisfazendo
Denição 1.20
ǫ < δ ≤ sup{η; ||A− B|| < η ⇒ posto(B) ≥ r},
onde ǫ é dado omo na Denição 1.19.
Através das Denições 1.19 e 1.20 podemos então araterizar posto numério
de uma matriz A, ou seja,
Denição 1.21 Uma matriz A tem Posto Numério (δ, ǫ, r) om norma || || se
δ, ǫ e r satisfazem as Denições 1.19 e 1.20.
Usando as Denições 1.19 e 1.20, podemos araterizar o posto numério de uma
matriz. O seguinte teorema tem esse propósito. Usaremos a notação posto(δ, ǫ, r)2
para araterizar o posto numério om || ||2.
20
Capítulo 1. Resultados Básios e Deomposição em Valores Singulares
Teorema 1.22 Sejam σ1 ≥ σ2 ≥ · · · ≥ σn os valores singulares de uma matriz A.
Então A tem posto numério (δ, ǫ, r)2 se, e somente se,
σr ≥ δ > ǫ ≥ σr+1. (1.19)
Demonstração:
Suponha (1.19). Pelo Teorema 1.18, se ||A − B||2 < δ logo, σr+1 < δ e portanto
posto(B) ≥ r e onseqüentemente satisfaz a Denição 1.18. Como a matriz B
denida em (1.18), tem posto r e portanto ||A − B||2 ≤ ǫ, daí satisfaz a Denição
1.19.
Reiproamente, suponha agora que δ, ǫ e r satisfazem as Denições 1.19 e 1.20
então δ > ǫ e por denição temos σr ≥ σr+1. Basta então mostrar que σr ≥ δ e que
ǫ ≥ σr+1. Suponha por ontradição que ǫ < σr+1, então, omo ||A − B||2 < ǫ, isso
impliaria que ||A− B||2 < σr+1, ontradição om o Teorema 1.18. Por outro lado,
pelo Teorema 1.18 tem-se σr ≥ δ. Isso prova o teorema.

Mais detalhes aera desta Subseção podem ser enontradas em [6℄.
1.8 Análise e Disussão
Como já menionamos na introdução, alguns trabalhos usam o PCA para geração
de animações faiais. Em geral, a SVD é utlizado na obtenção de uma base para o
PCA. Podemos itar por exemplo o trabalho de Kuratate et al., (ver [18℄).
Como vimos, a SVD é uma poderosa ténia que permite aproximar uma de-
terminada matriz A de posto n para uma matriz de posto r < n (Teorema 1.17).
Essa aproximação para uma matriz Ar de posto r < n é ótima no sentido da || ||2
(Teorema 1.18).
Sob a ótia do problema de seleção de subonjunto gostariamos de seleionar
r olunas de uma matriz de dados A ∈ Rm×n (m ≥ n). Tais r olunas devem
ser independentes de tal forma que podemos desprezar as ontribuições das outras
21
Capítulo 1. Resultados Básios e Deomposição em Valores Singulares
(n−r) olunas da matriz de dados A e portanto, poder aproximar as (n−r) olunas
(no sentido dos mínimos quadrados, [1℄) em termos de uma ombinação linear das
r olunas seleionadas.
Suponha que tivéssemos uma matriz A ∈ Rm×n om m ≥ n e deompomos esta
matriz usando SVD. Essa matriz A vai ser deomposta em soma de matrizes de
posto 1, A =
n∑
i=1
σiuiv
T
i . Pelos teoremas 1.17 e 1.18, a matriz de posto r que melhor
aproxima-se de A no sentido da 2-norma, é justamente a matriz Ar =
r∑
i=1
σiuiv
T
i ,
onde ui e vi são ulunas das matrizes U e V respetivamente. Pode-se mostrar que
ada uma das olunas a˜1, a˜2, · · · , a˜n dessa nova matriz Ar de posto r são esritas
omo
a˜1 = u1v11σ1 + u2v12σ2 + · · ·+ urv1rσr
a˜2 = u1v21σ1 + u2v22σ2 + · · ·+ urvr2σr
.
.
.· · ·.........
a˜r = u1vr1σ1 + u2vr2σ2 + · · ·+ urvrrσr
.
.
.· · ·.........
a˜n = u1vn1σ1 + u2vn2σ2 + · · ·+ urvnrσr
e daí,
Ar = UrX˜,
onde Ur ontém os vetores ortogonais u1, u2, · · · , ur e X˜ é uma matriz de oiientes
orrespondentes a vijσl, onde 1 ≤ i ≤ n e 1 ≤ j, l ≤ r.
Obeservações:
1. Cada uma das olunas de Ar, a˜i om i = 1, · · · , n, são esritas omo ombi-
nações lineares de uma base de vetores ui da matriz ortogonal U ;
2. A base de vetores ui é obtida a partir das n olunas da matriz A.
Por m, é realmente verdade que estamos interessados em reduzir a dimensão da
matriz A para uma matriz de posto r, mas também, queremos que essas r olunas
22
Capítulo 1. Resultados Básios e Deomposição em Valores Singulares
seleionadas sejam usadas para obter uma aproximação das outras (n− r) olunas.
Dessa forma, obteremos um modelo que pode ser usado para predizer as (n − r)
olunas restantes de uma matriz de dados qualquer, bastando apenas seleionar um
onjunto de r olunas independentes da matriz A. Com o SVD, isso não é possivel.
Primeiro, porque teríamos que enontrar todos os vetores ui, om i = 1, · · · , r para
obtermos a˜i onde i = 1, · · · , n, mas obviamente, esses vetores dependem de todas
as olunas da matriz A e isso não nos interessa, pois frustraria todo o nosso esforço
na tentativa de reduzir a dimensão dos dados da matriz A. Segundo, é verdade
que a interpretação dos resultados através da utilização dessa ténia é failitada
pela redução da dimensionalidade (posto), mantendo um elevado grau de expliação,
porém, quais olunas da matriz A foram usadas para obter as olunas da matriz Ar?
De fato, não sabemos e no presente aso, não queremos que isso oorra. Gostaríamos
de saber exatamente quais são essas olunas.
Como veremos nos Capítulos 2 e 3, a fatoração QR atende preisamente as nossas
neessidades, seleionando um onjunto de r olunas independentes de uma matriz
A. Posteriormente, essas r olunas são utilizadas para aproximar exatamente ada
uma das (n−r) olunas da matriz de dados A em termos de uma ombinação linear
de uma base de r olunas. Justiando nossa esolha de usar a fatoração QR para
obtenção do modelo.
23
Capítulo 2
A Fatoração QR
2.1 Introdução
Nesse Capítulo omeçaremos por apresentar a denição de Fatoração QR e alguns
resultados aera do mesmo. Em seguida, disutimos as hamadas matrizes de
Householder e omo podemos obter a deomposição QR usando essas matrizes.
Estudaremos as relações que existem entre a fatoração QR e o posto de uma
determinada matriz. Provaremos, que se uma matriz A tem posto ompleto, implia
na uniidade de sua deomposição QR e onseqüentemente, uma base para a Im(A).
Por nal, analisaremos o aso em que A não tem posto ompleto e omo obter
neste aso, uma base para a Im(A).
2.2 Denição e Propriedades da Fatoração QR
Sejam a1, a2, · · · , an as olunas da matriz A e a sequênia de subspaços gerados por
elas:
〈a1〉 ⊆ 〈a1, a2〉 ⊆ · · · ⊆ 〈a1, a2, · · · , an〉.
Assim, 〈a1〉 é um espaço 1-dimensional gerado por a1, 〈a1, a2〉 é o espaço 2-dimensio-
nal gerado por a1 e a2 e assim por diante. A idéia da fatoração QR está na onstru-
ção de uma sequênia de vetores q1, q2, · · · , qn ortonormais que geram essa mesma
sequênia de subespaços, (ver [7℄).
24
Capítulo 2. A Fatoração QR
Para sermos mais preisos, assumimos por um momento que A ∈ Rm×n om
m ≥ n e que posto(A) = n (nesse aso, dizemos que se A possui posto máximo, então
as n olunas de Q formam uma base ortonormal da imagem de A). Gostaríamos
que a sequênia q1, q2, · · · , qn tivesse a seguinte propriedade
〈a1, a2, · · · , ai〉 = 〈q1, q2, · · · , qi〉 , i = 1, · · · , n. (2.1)
Em partiular, tomando i = 2 na igualdade aima temos que 〈a1, a2〉 = 〈q1, q2〉.
Assim, para que a1 seja ombinação linear de q1, devemos ter um esalar r11 tal
que a1 = r11q1. Por denição, para que 〈a1, a2〉 = 〈q1, q2〉 devem existir esalares ti,
i = 1, · · · , 4 tais que t1a1 + t2a2 = t3q1 + t4q2. Substituindo a1 por r11q1, teremos:
t1a1 + t2a2 = t3q1 + t4q2
t1(r11q1) + t2a2 = t3q1 + t4q2
t2a2 = −t1(r11q1) + t3q1 + t4q2
t2a2 = q1(−t1r11 + t3) + t4q2
a2 = (
−t1r11 + t3
t2
)q1 +
t4
t2
q2
a2 = r12q1 + r22q2
onde, r12 e r22 esalares tais que, r12 =
−t1r11+t3
t2
e r22 =
t4
t2
. Analogamente, temos:
a1 = r11q1
a2 = r12q1 + r22q2
.
.
.
.
.
.
.
.
.
an = r1nq1 + r2nq2 + · · ·+ rnnqn.
Observando as equações aima, vemos que elas podem ser esritas utilizando
matrizes Q ortogonal e R triangular superior, onde A = QR.
Denição 2.1 Seja A ∈ Rm×n. A deomposição de uma matriz A do tipo A = QR,
onde Q ∈ Rm×m é uma matriz ortogonal e R ∈ Rm×n é triangular superior, é dita
Fatoração QR de A.
Observe que dada uma matriz A ∈ Rm×n, temos duas possibilidades para as
linhas de A, m ≥ n ou m < n. Daremos em seguida, alguns detalhes (ver [20, 7℄)
sobre omo obter a fatoração QR de uma matriz A para esses asos.
25
Capítulo 2. A Fatoração QR
1o Caso: m ≥ n
Teorema 2.2 Dada uma matriz A ∈ Rm×n, om m ≥ n, existe uma matriz ortogo-
nal Q ∈ Rm×m e uma matriz triangular superior R ∈ Rm×n tal que
A = QR. (2.2)
Demonstração:
A prova desse teorema será dada na Seção 2.4.

Observações:
1. Seja A ∈ Rm×n,m ≥ n. A deomposição QR onde existem matrizesQ ∈ Rm×m
e R ∈ Rm×n, onde Q é ortogonal e R =
(
Rˆ
0
)
, Rˆ ∈ Rn×n é triangular superior
é hamada de fatoração QR ompleta.
2. Suponha que A ∈ Rm×n, m ≥ n. Se m > n então pelo Teorema 2.2 e pela
observação 1, existem Q ∈ Rm×m e R ∈ Rm×n, onde Q é ortogonal e R =(
Rˆ
0
)
, Rˆ ∈ Rn×n é triangular seperior e A = QR. Seja Qˆ ∈ Rm×n uma
matriz que onsiste das n primeiras olunas de Q, logo Qˆ também é ortogonal.
Seja Q˜ ∈ Rm×(m−n) uma matriz ortogonal que representa as outra m − n
olunas restantes de Q. Então A = QR = [Qˆ Q˜]
(
Rˆ
0
)
= QˆRˆ + Q˜0, isto é,
A = QˆRˆ.
A fatoração QR de A ∈ Rm×n om m ≥ n onde, Q ∈ Rm×n é ortogonal e
R ∈ Rn×n é triangular superior é denominada de fatoração QR reduzida.
26
Capítulo 2. A Fatoração QR
2o Caso: m < n
Teorema 2.3 Seja A ∈ Rm×n, m < n. Então existem matrizes Q ∈ Rm×m e
R = (R11 R12) ∈ Rm×n, onde Q é ortogonal, R11 ∈ Rm×m triangular superior,
R12 ∈ Rm×(n−m) é retangular e A = QR.
Demonstração:
A prova desse teorema será dada na Seção 2.4.

Basiamente, existem três métodos para se obter a fatoração QR, são eles:
1. Reexão de Householder;
2. Rotação de Givens;
3. Proesso de Ortogonalização de Gram-Shmidt.
Desreveremos a seguir um método para se obter a fatoração QR. Esse método
é baseado na refexão de Householder.
2.3 Reexão de Householder
Para melhor entendimento da reexão de Householder, é onveniente denir reexão
(ver [20℄). Entretanto, não entraremos em detalhes, trataremos de um aso simples
de reexão no R
2
, apenas para podermos ter uma idéia geométria.
2.3.1 Reexão
Seja ξ uma reta em R2 que passa pela origem. O operador que reete ada vetor em
R
2
pela reta ξ é uma transformação linear, e portanto, pode ser representado por
uma matriz. Gostariamos de determinar esta matriz.
Seja v um vetor não nulo pertenente a ξ. Logo, ada vetor não-nulo que pertene
a ξ só pode ser múltiplo de v. Considere u um vetor não-nulo ortogonal a ξ. Segue
27
Capítulo 2. A Fatoração QR
que, {u, v} é uma base de R2, logo ada x ∈ R2 pode ser expressado omo ombinação
linear de u e v. Então x = αu + βv, om α, β ∈ R. A reexão de x por ξ é x =
−αu+βv (ver Figura 2.1), logo, a matriz Q de reexão deve satisfazer Q(αu+βv) =
−αu+ βv. Assim, para que isso oorra, é neessário e suiente que
Qu = −u e Qv = v. (2.3)
PSfrag replaements
u
ξ
v
x = αu+ βv
Qx = −αu+ βv
Figura 2.1: Reexão em torno da reta ξ.
Sem perda de generalidade, podemos supor que u foi esolido de tal forma que
||u||2 = 1.
Considere agora a matriz Q = uuT ∈ R2×2. Então Q possui a seguinte pro-
priedade
Qu = (uuT )u
= u(uTu)
= u||u||2
= u
e
Qv = (uuT )v
= u(uTv)
= u(u, v)
= 0
28
Capítulo 2. A Fatoração QR
já que u e v são ortogonais.
Portanto, a matriz Q não é uma reexão. Por outro lado, se denimos W =
I − 2Q temos
Wu = u− 2Qu
= u− 2u
= −u
e
Wv = v − 2Qv
= v − 0
= v.
Assim, a matriz W ∈ R2×2 que é dada por W = I − 2Q reete o vetor que passa
pela reta ξ, onde u é um vetor unitário e ortogonal a ξ. Logo, W é uma matriz de
reexão.
Teorema 2.4 Seja v ∈ Rn um vetor não nulo e P = I − 2vvT
vT v
. Então P é uma
reexão.
Demonstração:
P = I − 2vv
T
vTv
= I − 2 vv
T
||v||22
= I − 2 vv
T
||v||2.||v||2
= I − 2v̂ v
T
||v||
= I − 2v̂v̂T . (2.4)
Logo, P é uma reexão.

29
Capítulo 2. A Fatoração QR
2.3.2 Denição e Propriedades da Reexão de Householder
A denição seguinte é hamada de reexão de Householder devido ao matemátio e
psiólogo norte ameriano Alston Householder.
Denição 2.5 Seja v ∈ Rn um vetor não nulo. Uma matriz P da forma
P = I − 2vv
T
vTv
(2.5)
é hamada de reexão de Householder, ou em outros asos de matriz de
Householder ou ainda transformação de Householder. O vetor v é hamado
de vetor de Householder.
Para os nossos propósitos, omo veremos a seguir, é neessario obtermos algumas
propriedades relaionadas om a reexão de Householder (ver [19, 10, 20℄). Uma
reexão de Householder goza das seguintes propriedades:
Teorema 2.6 Seja P ∈ Rm×n uma reexão de Householder e A ∈ Rm×n. Então
1. P é simétria;
2. P é ortogonal;
3. ||Px||2 = ||x||2;
4. ||PA||2 = ||A||2;
5. P 2 = I.
Demonstração: Ver Anexo.

Umas das propriedades mais importantes da reexão de Householder se onsiste
em omo determinar um vetor v que dena tal reexão. O seguinte resultado mostra
omo enontrar o vetor v de Householder de tal forma que Px seja múltiplo de
e1 = (1, 0, · · · , 0)T .
30
Capítulo 2. A Fatoração QR
Teorema 2.7 Dado um vetor não-nulo x = (x1, x2, · · · , xn)T , podemos enontrar
um vetor v = (v1, v2, · · · , vn)T de maneira que Px é múltiplo de e1 onde a matriz
de householder P é denida pelo vetor v = x± ||x||2e1 e Px = ±||x||2e1.
Demonstração: Ver Anexo.

Portanto, todas as omponentes do vetor x à exeção da primeira são anuladas
por multipliação da matriz P .
De aordo om o Teorema 2.7 temos duas possibilidades de reexão para o vetor
x, Px = ||x||2e1 ou Px = −||x||2e1. A gura 2.2 representa geometriamente essa
situação, onde H+ e H− representam hiperplanos no espaço n-dimensional. Aliás,
um hiperplano, representa um onjunto de pontos no R
n
, tais que ax1+· · ·+axn = b,
om ai, i = 1, · · · , n e b são números reais. Em partiular, num espaço tridimensional
um hiperplano é o plano habitual. Num espaço bidimensional, um hiperplano é
uma reta. Num espaço monodimensional, um hiperplano é um ponto. Assim, um
hiperplano divide o espaço em que está denido em duas partes. Cada uma delas é
hamada de semi-espaço.
PSfrag replaements
x
H+
H−
−||x||2e1 +||x||2e1
Figura 2.2: Possibilidades de Reexão.
2.3.3 Esolha do Vetor de Reexão
Para evitar problemas no álulo da reexão, é importante determinarmos uma
boa esolha para o vetor v. Obeserve que através da Denição 2.5 e das equações
31
Capítulo 2. A Fatoração QR
(4.9) e (4.10) onlui-se que é indiferente esolher o sinal + ou − no vetor v para
anular todas as omponentes de Px. Por outro lado, se sign(x1) representar o
sinal da omponente x1 do vetor x e se o mesmo difere pouo de e1 então v =
x−sign(x1)||x||2e1 tem norma bastante reduzida. Isso implia que o produto esalar
vTv possa ser uma quantidade muito pequena, o que aarretariam problemas no
álulo da matriz P . Por essa razão o vetor v é habitualmente denido a partir de
v = x+ sign(x1)||x||2e1,
onde
sign(y) =

−1, se y < 0,
1, se y > 0,
0, se y = 0.
(2.6)
Além disso, omo todos os elementos da matriz vvT são produtos de duas om-
ponentes do vetor x, então valores grandes dessas omponentes podem impliar a
oorrênia de fenmenos de overow (o erro de overow oorre quando o resultado
de uma operação aritmétia exede o valor de 3.4028235 × 1038, ou seja, erro por
estouro de memória). Esse problema é resolvido onsiderando o vetor x 1||x||∞ em vez
de x na denição de v. Assim na denição da matriz P , o vetor v é denido por
v = x
1
||x||∞ + sign(x1)
∥∥∥∥x 1||x||∞
∥∥∥∥
2
e1 (2.7)
e portanto, omo Px = ±||x||2e1, então
Px = sign(x1)
∥∥∥∥ x||x||∞
∥∥∥∥
2
e1 =

− sign(x1)α
0
.
.
.
0
 (2.8)
onde
α =
∥∥∥∥ x||x||∞
∥∥∥∥
2
=
√√√√ n∑
i=1
(
xi
vmax
)2
(2.9)
e
vmax = max
i
|xi| .
32
Capítulo 2. A Fatoração QR
2.4 Cálulo da Fatoração QR
Como visto na Seção 2.2, provaremos a existênia da deomposição QR para uma
matriz A ∈ Rn×n. A prova do próximo teorema mostra a existênia da fatoração
QR quando m ≥ n, usando reexão de Householder.
Teorema 2.8 Seja P a matriz de Householder omo na Denição 2.5 e seja A ∈
R
m×n
, om m ≥ n. Então existem matrizes Q ∈ Rm×m e R ∈ Rm×n tal que A = QR.
Demonstração:
De fato, suponha que A ∈ Rm×n e seja P1 = I − β1v(1)v(1)T , onde β1 = 2
v(1)
T
v(1)
.
Como m ≥ n, temos que a matriz de Householder é uma matriz quadrada m ×m.
Então,
v(1) =
[
a11
vmax
+ sign(a11)α,
a21
vmax
, · · · , an1
vmax
]T
,
onde
α =
√√√√ n∑
i=1
(
xi
vmax
)2
, β1 =
2
v(1)
T
v(1)
,
assim
P1A = A
(2) =

a
(2)
11 a
(2)
12 · · · a(2)1n
0 a
(2)
22 · · · a(2)2n
.
.
.
.
.
.
.
.
.
.
.
.
0 a
(2)
m2 · · · a(2)mn
.
De maneira geral, ada matriz Pk de Householder é dada por Pk = I − βkv(k)v(k)T ,
v(k) =
[
0 · · · 0 a
(k)
kk
vmax
+ sign(a
(k)
kk )α
a
(k)
k+1,k
vmax
· · · a
(k)
nk
vmax
]T
om
vmax = max
i=k,··· ,n
∣∣∣a(k)ik ∣∣∣ ,
onde
α =
√√√√ n∑
i=k
(
aik
vmax
)2
, βk =
2
v(k)
T
v(k)
.
Assim,
33
Capítulo 2. A Fatoração QR
Pn−1Pn−2 · · ·P2P1A = R
donde segue,
A = P−11 P
−1
2 · · ·P−1n−2P−1n−1R
= P1P2 · · ·Pn−2Pn−1R.
Observe agora que todas as matrizes Pk são ortogonais e portanto, o produto
P1P2 · · ·Pn−2Pn−1 também é ortogonal, além disso, para ada k = 1, 2, ..., n, Pk é
uma matriz simétria, assim, P Tk = Pk. Além disso, Pk é ortogonal, logo PkP
T
k =
I. Isso implia que P Tk = P
−1
k e portanto, P
−1
k = Pk. Assim tomando Q =
P1P2 · · ·Pn−2Pn−1 podemos esrever
A = QR, (2.10)
onde Q ∈ Rm×m e R ∈ Rm×n.

Portanto, o Teorema 2.8 prova a existênia da deomposição QR quando m ≥ n.
Em relação ao Teorema 2.3 (quandom < n), sua demonstração é totalmente análoga
ao Teorema 2.8, basta onsiderarmos para esse aso, uma matriz de Householder
P ∈ Rm×m, onde m < n e obteremos uma matriz Q ∈ Rm×m ortogonal e R =
(R11 R12) ∈ Rm×n, R11 ∈ Rm×m triangular superior e R12 ∈ Rm×(n−m) retangular.
Nos limitaremos a partir das próximas Seções a obter resultados somente quando
A ∈ Rm×n om m ≥ n, pois essa matriz vai ser nosso objeto de estudo no Capítulo
4.
2.5 Relações da Fatoração QR om o Posto de uma
Matriz
Essa Seção objetiva estudar a uniidade da fatoração QR e analizar em que iruns-
tânias ela oorre. Veremos que o fato de uma matriz A posuir posto ompleto, im-
plia em sua uniidade, aso ontrário, a fatoração QR não produz neessariamente
uma base para Im(A). Assim, antes de darmos detalhes da uniidade, daremos uma
34
Capítulo 2. A Fatoração QR
prova para a suposição (2.1), pois a idéia da fatoração QR, está na onstrução para
uma base para Im(A).
Teorema 2.9 Seja A ∈ Rm×n e sua respetiva fatoração QR. Suponha posto(A) =
n e onsidere as seguintes partições A = [a1, a2, · · · , an] e Q = [q1, q2, · · · , qm], onde
ada ai e qj são as respetivas olunas de A e Q, 1 ≤ i ≤ n e 1 ≤ j ≤ m. Então
〈a1, a2, · · · , an〉 = 〈q1, q2, · · · , qn〉 , k = 1, · · · , n. (2.11)
Demonstração: Ver Anexo.

2.5.1 Uniidade da Fatoração QR
A uniidade da fatoração QR pode ser muito útil em ertas apliações, (ver [11, 7℄).
Portanto, poder determinar quando ela oorre, pode ser muito importante.
Teorema 2.10 Seja A ∈ Rm×n, om m ≥ n e suponha que posto(A) = n. Então
existe uma únia matriz Q ∈ Rm×n e R ∈ Rn×n tal que Q têm olunas ortogonais e
R é triangular superior om todas as entradas da diagonal positiva e
A = QR. (2.12)
Demonstração: Ver Anexo.

2.5.2 Matriz de Permutação
Se uma matriz A não tem posto ompleto, então a fatoração QR não neessariamente
produz uma base para Im(A). Esse problema pode ser orrigido implementando o
que hamamos de fatoração QR om pivoteamento de olunas. Antes falarmos sobre
pivoteamento de olunas, daremos algumas denições úteis que serão neessárias ao
entendimento desse método.
35
Capítulo 2. A Fatoração QR
Denição 2.11 Uma Matriz de Permutação Πij é uma matriz quadrada que se
obtém da matriz identidade por troa das suas linhas e olunas i e j.
Uma matriz de permutação Π tem as seguintes propriedades:
1. Πij = Π
T
ij
2. Πij = Π
−1
ij .
Uma matriz de permutação (ver [10℄) é o produto de um número nito de matrizes
da forma Πij . Se Π é uma matriz de permutação, então ΠA (AΠ) é uma matriz
que se obtém troando as linhas (olunas) de A orrespondentes aos fatores Πij que
onstituem Π. Assim, ΠTAΠ é a matriz que difere de A na ordem de um erto
número de linhas e olunas de A.
Denição 2.12 Uma matriz ΠTAΠ é denominada Permutação Prinipal de A.
2.5.3 Fatoração QR om Pivoteamento de Colunas
Vimos que quando uma matriz A possui posto ompleto, a fatoração QR é únia.
Porém, o que dizer quando o posto de uma matriz A ∈ Rm×n é inompleto? Essa
Subseção tem o propósito de responder a essa questão.
Desrevemos a seguir, omo esse problema pode ser resolvido alulando-se a fa-
toração QR de A om suas olunas permutadas (isto é, om pivotamento de olunas,
[7, 20℄). Essa fatoração é dada por AΠ = QR, onde Q e R são matrizes usuais da
fatoração QR e Π é uma matriz permutação.
Basiamente, a fatoração QR om pivoteamento de olunas permuta as oluna
de matriz A de tal forma os elementos da diagonal da matriz R que são `pequenos'
ou nulos, são movidos para a parte inferior da diagonal da matriz R. A idéia dessa
fatoração segue abaixo dividida em dois passos.
Primeiro Passo:
Para ada oluna da matriz A, alulamos a || . ||2 da j-ésima oluna, om 1 ≤
j ≤ n. Se a j-ésima oluna tem maior omprimento, isto é, maior || . ||2, então
36
Capítulo 2. A Fatoração QR
as olunas 1 e j são permutadas. Dessa forma, a primeira oluna da matriz AΠ
satisfaz ||(AΠ)1||2 = max
j
||aj||2, om 1 ≤ j ≤ n. Após a determinação da oluna
da matriz A om maior 2-norma, a reexão de householder transforma a primeira
oluna da matriz A em [r11 0 0 · · · 0]T . Como a primeira oluna é que tem maior
2-norma e Px = ±||x||2e1 = [|r11| 0 0 · · · 0]T então |r11| têm maior valor absoluto.
Em partiular, r11 6= 0, a menos que A seja identiamente nula.
Segundo Passo:
Terminado o primeiro passo, operamos em uma nova submatriz que denotaremos
por A
(k)
22 , onde o índie k india o número de interações e omo estamos na segunda
iteração, k = 2. Essa matriz é obtida por ignorar primeira linha e oluna da matriz
A. De maneira totalmente análoga, prosseguimos de aordo om o que foi feito
no primeiro passo, apenas om uma ressalva, quando troamos a oluna de A
(k)
22 , a
oluna ompleta deve ser troada e não apenas a oluna que pertene a A
(k)
22 .
Cada passo, opera em uma submatriz A
(k)
22 , obtida om uma oluna e uma linha a
menos que no passo anterior, justamente omo antes, exeto que as olunas troadas
são olunas ompletas. Observe que, o efeito de troa de olunas orresponde a troa
de olunas em A antes de efetuarmos a fatoração QR.
Teorema 2.13 Seja A ∈ Rm×n om posto(A) = r ≤ n. Então existem matrizes
Â, Q e R, tal que Â = AΠ é obtida de A por permutação de olunas, Q ∈ Rm×m
é ortogonal, R =
(
R11 R12
0 0
)
∈ Rm×n, R11 ∈ Rr×r é não-singular e triangular
superior.
Demonstração: Ver Anexo.

De forma análoga ao teorema aima obtemos deomposição QR om permutação
de olunas para uma matriz A ∈ Rm×n om m ≥ n, onde Q ∈ Rm×n e R ∈ Rn×n.
37
Capítulo 2. A Fatoração QR
Observações:
1. Seja A ∈ Rm×n, om m ≥ n. Consedere a deomposição AΠ = QR onde, R ∈
R
m×n
é uma matriz triangular superior, Q ∈ Rm×m é uma matriz ortogonal e
Π ∈ Rn×n uma matriz de permutação. Com o esquema de pivoteamento de
olunas desrito aima podemos esrever
AΠ = QR = Q
(
R11 R12
0 R22
)
(2.13)
onde os elementos da diagonal da matriz R estão todos dispostos em ordem
não-resente, isto é, r11 ≥ r22 ≥ r33 ≥ · · · ≥ rnn e ||R22||2 pequena, (ver [3℄);
2. Se uma matriz A ∈ Rm×n e posto(A) = r < n, então a fatoração QR de A
não neessariamente produz uma base ortonormal para a Im(A). Felizmente,
a fatoração QR om pivoteamento de olunas pode ser usada para produzir
uma base ortogonal para Im(A).
Pelo Teorema 2.13, existe uma matriz de permutação Π tal que AΠ = QR e
QTAΠ = R =
(
R11 R12
0 0
)
onde, R11 ∈ Rr×r triangular superior, R12 ∈ Rr×(n−r), Q é uma matriz ortogo-
nal e posto(A) = r. Sabemos que a matriz AΠ têm suas olunas reordenadas
de tal forma que AΠ = [a1, a2, · · · , ar, · · · , an] e Q = [q1, q2, · · · , qr, · · · qm].
Assim, para k = 1, · · · , n temos que
ai =
min{r,k}∑
i=1
rikqi ∈ 〈q1, ..., qr〉 , (2.14)
impliando que Im(A) = 〈q1, q2, · · · , qr〉.
38
Capítulo 3
Apliações da Fatoração QR
3.1 Introdução
Iniiaremos esse Capítulo resolvendo sistema de equações lineares Ax = b, onde
A ∈ Rn×n om posto(A) = n e veremos que a fatoração QR fornee uma boa
solução para esse sistema.
Em seguida, estudaremos o problema de mínimos quadrados (3.5). Mostraremos
sob quais ondições oorre a uniidade deste problema. Provaremos que a solução do
problema de mínimos quadrados está relaionado om o posto da matriz. Primeiro,
trataremos do aso em que uma matriz A tem posto ompleto e em seguida, quando
A não tem posto ompleto, analisando as duas soluções.
Deniremos o problema de seleção de subonjunto de uma matriz de dados A
e forneeremos uma solução para este problema, por meio da fatoração QR om
pivoteamento de olunas. Por m, daremos uma solução aproximada para o sistema
sobredeterminado Ax = b usando um subonjunto de k olunas independentes da
matriz A através de mínimos quadrados e nalizaremos este apítulo om algumas
onlusões.
39
Capítulo 3. Apliações da Fatoração QR
3.2 Sistemas Lineares
Considere o sistema de equações lineares
Ax = b
A ∈ Rm×n
b ∈ Rm, m = n.
(3.1)
e posto(A) = n.
Existem vários métodos disponíveis na literatura para resolver o sistema (3.1),
por exemplo, eliminação de Gauss, fatoração LU, dentre outros (ver [7℄). Porém, a
fatoração QR também é uma boa alternativa para enontrar a solução do sistema
(3.1). De fato, seja A omo denida em (3.1). Como A tem posto ompleto existem
únias matrizes Q e R tais que A = QR. Portanto, substituindo QR por A temos
que QRx = b. Multipliando por QT em ambos os membros da igualdade teremos
QTQRx = QT b e omo a matriz Q é uma matriz ortogonal (QTQ = I), temos
Rx = d, onde d = QT b ∈ Rn×n.
Assim, para enontrar a solução para o sistema (3.1), basta resolver o sistema
triangular superior Rx = d. Como a matriz R é triangular superior, temos rij = 0
para i > j, portanto temos um sistema da forma
r11x1 + r12x2 + r13x3 + · · ·+ r1nxn = d1
r22x2 + r23x3 + · · ·+ r2nxn = d2
r33x3 + · · ·+ r3nxn = d3
.
.
.
rnnxn = dn,
onde ada xi e di, om i = 1, · · · , n são omponentes dos vetores x e d respetiva-
mente.
Tais sistemas são resolvidos por substituições retroativas, através de equações da
forma:
xi =
bi −
n∑
j=i+1
rijxj
rii
(3.2)
para todo i = 1, · · · , n.
Observe que para enontrar a solução para o sistema (3.1), podemos através da
fatoração, de forma equivalente, resolver um sistema triangular superior, fáil de
40
Capítulo 3. Apliações da Fatoração QR
resolver. E de fato, essa é a grande vantagem de se resolver o sistema (3.1) usando
a fatoração QR.
3.3 Problema de Mínimos Quadrados
O método dos mínimos quadrados tem sido o proedimento padrão para a análise
de dados a partir do iníio de 1800. Um famoso exemplo deste método foi quando
Gauss om suesso predisse a órbita do asteróide Ceres, em 1801. Mais de duzentos
anos depois, mínimos quadrados ontinua sendo amplamente utilizado em áreas
omputaionais, engenharia, et (ver [1℄).
Considere um sistema (sobredeterminado) de m equações om n inógnitas, isto
é,m > n. Simboliamente, gostaríamos de enontrar um vetor x que satisfaz Ax = b,
onde A ∈ Rm×n e b ∈ Rm. Normalmente, este problema não tem solução. Pois, tal
vetor x só existe se b ∈ Im(A), mas b ∈ Rm e Im(A) é no máximo de dimensão
n. Assim, devemos enontrar um vetor x̂ ∈ Rn tal que Ax̂ é a melhor aproximação
para b.
Considere o vetor r = Ax − b. Supondo que r não é nulo, devemos fazê-lo tão
pequeno quanto possível. Desse modo, é natural a esolha de uma norma para medir
o tamanho de r, isto é, devemos enontrar um vetor x̂ tal que ||r||p = ||Ax̂ − b||p
seja mínimo, para alguma esolha de p. Porém, diferentes normas produzem difer-
entes soluções. Normalmente, a norma esolhida é a 2-norma pois possui algumas
propriedades importantes em relação as outras, 1-norma e ∞-norma, (ver [19, 7℄).
A 2-norma é preservada sob uma transformação ortogonal. Isto signia que pode-
mos enontrar uma matriz Q ortogonal tal que o problema se torna equivalente a
minimização ||QTAx−QT b||2 e omo veremos, fáil de resolver.
De fato, seja Q ∈ Rm×m uma matriz ortogonal e onsidere o sistema sobredeter-
minado
QTAx = QT b, (3.3)
obtido através de (3.1) por multipliação de QT em ambos os membros da igualdade.
Então:
s = QTAx−QT b = QT (Ax− b) = QT r. (3.4)
Como QT é ortogonal, temos ||s||2 = ||r||2. Logo, x ∈ Rn minimiza ||s||2 se, e
41
Capítulo 3. Apliações da Fatoração QR
somente se, minimiza ||r||2, isto é, os dois sistemas sobrederminados tem a mesma
solução.
A ténia que onsiste em enontar um vetor x̂ que minimize ||Ax− b||2, isto é,
Denição 3.1 Dados uma matriz A ∈ Rm×n, om m > n e b ∈ Rm, o Problema
de Mínimos Quadrados (Least Squares Problem) onsiste em enontrar x̂ ∈ Rn,
tal que, ||Ax̂− b||2 é mínima.
Usaremos a notação
min
x∈Rn
||Ax− b||2 (3.5)
para denotar o problema de enontrar o tal vetor x̂. O vetor
r = Ax̂− b (3.6)
é onheido omo vetor residual (ver [1℄). Usaremos a notação
||r||2 = ||Ax̂− b||2 (3.7)
e denotaremos por resíduo. Note que se ||r||2 é pequeno, dependendo de uma esolha
para o vetor x̂ (mas em geral, ||r||2 não é nulo), então podemos predizer b através
das olunas de A.
Nas Subseções seguintes, estudaremos a solução para o problema de mínimos
quadrados através da fatoração QR. Divideremos esse estudo em dois asos. Primeiro
trataremos do aso em que uma matriz A possui posto ompleto e em seguida, para
o aso ontrário.
3.3.1 Matrizes de Posto Completo
Teorema 3.2 Seja A ∈ Rm×n e suponha que posto(A) = n, então o problema de
mínimos quadrados para o sistema sobredeterminado Ax = b têm uma únia solução,
o qual pode ser resolvido pelo sistema triangular superior R̂x = c, onde c ∈ Rn×1,
QT b =
(
c
d
)
, e Q e R̂ são obtidas pela deomposição QR de A.
42
Capítulo 3. Apliações da Fatoração QR
Demonstração:
Queremos enontrar
min
x∈Rn
||Ax− b||22. (3.8)
Temos que A = QR, om Q ∈ Rm×m e R ∈ Rm×n. Logo
||Ax− b||22 = ||QRx− b||22
= ||QT (QRx− b)||22
= ||Rx−QT b||22. (3.9)
Fazendo QT b =
(
c
d
)
e R =
(
R̂
0
)
, temos que
||Ax− b||22 = ||R̂x− c||22 + ||d||22, (3.10)
onde c ∈ Rn×1, d ∈ R(m−n)×1 e R̂ ∈ Rn×n.
Como o termo ||d||22 é independente de x, temos que ||R̂x − c||22 + ||d||22 será
minimizado exatamente quando ||R̂x−c||22 for mínimo. Obviamente, ||R̂x−c||22 ≥ 0,
om igualdade se, e somente se, R̂x = c. Como A tem posto ompleto, R̂ é não-
singular. Assim, o sistema R̂x = c tem uma únia solução.

Portanto, a solução para o problema de mínimos quadrados para o aso em que
a matriz A possui posto ompleto é dada por R̂x = c, e seu resíduo é dado por ||d||22.
Vimos na Seção 3.2 deste mesmo apítulo, que o sistema de equações R̂x = c é
fáil de se resolver, ou seja, podem ser resolvidos por substituições retroativas. Dessa
forma, a fatoração QR se torma uma ferramenta bastante eaz para enontar uma
solução para o problema de mínimos quadrados no aso em que A possui posto
ompleto.
Observe que através do sistema sobredetreminado Ax = b, podemos apliar a
fatoração QR e enontrar Rx = QT b. Como posto(A) = n, temos R não-singular
e portanto podemos multipliar RT em ambos os membros do sistema triangular
superior Rx = QT b, obtendo RTRx = RTQT b. Daí, omo Q é ortogonal, isto é,
QTQ = I, segue
RTQTQRx = RTQT b.
43
Capítulo 3. Apliações da Fatoração QR
Como A = QR e AT = RTQT , temos que
ATAx = AT b. (3.11)
Podemos provar os seguintes resultados (ver [1℄) para o sistema de equações (3.11):
Armação 1:
ATA é positiva denida, isto é, xT (ATA)x > 0 para todo x, dado que posto(A) = n.
De fato
xTATAx = (Ax)T (Ax)
= ||Ax||22
≥ 0.
Além disso, omo A tem posto n temos que se Ax = 0, então x = 0. Logo, se x 6= 0
segue que Ax 6= 0. Isto signia que
xTATAx > 0
para todo x 6= 0, isto é, ATA é positiva denida.
Armação 2:
A matriz ATA é não-singular. De fato,
ATAx = 0 ⇒ xTATAx = 0
⇒ ||Ax||22 = 0
⇒ Ax = 0
⇒ x = 0
assim, a inversa (ATA)−1 na expressão (ATA)−1AT b existe.
Armação 3:
Mostremos que x̂ satisfaz
||Ax̂− b||22 < ||Ax− b||22, (3.12)
para todo x 6= x̂.
De fato,
||Ax− b||22 = ||(Ax− Axˆ) + (Axˆ− b)||22
= ||Ax−Axˆ||22 + ||Axˆ− b||22 + 2(Ax− Axˆ)T (Axˆ− b), (3.13)
44
Capítulo 3. Apliações da Fatoração QR
onde nesta segunda igualdade foi usado que
||u+ v||22 = (u+ v)T (u+ v)
= uTu+ 2uTv + vTv
= ||u||22 + ||v||22 + 2uTv.
Armação 4:
(Ax−Ax̂)T (Ax̂− b) = 0 (3.14)
De fato,
2(Ax− Ax̂)T (Ax̂− b) = (x− x̂)TAT (Ax̂− b)
= (x− x̂)T (ATAx̂−AT b)
= (x− x̂)T [ATA(ATA)−1AT b)− AT b]
= (x− x̂)T (AT b− AT b)
= (x− x̂)T0
= 0,
pois, x̂ = (ATA)−1AT b. Com essa simpliação,
||Ax− b||22 = ||A(x− x̂)||22 + ||Ax̂− b||22.
O primeiro termo é não negativo para todo x, e onseqüentemente
||Ax− b||22 > ||Ax− Ax̂||22.
Além disso, temos a igualdade somente se A(x − x̂) = 0, isto é, x = x̂ (pois, o
posto(A) = n). Portanto, onluímos que
||Ax− b||22 > ||Ax̂− b||22, ∀x 6= x̂.
As equações (3.11) são onheidas omo Equações Normais e omo foi provado
através das armações aima, também podem ser utilizadas para enontrar uma
únia solução para o problema de mínimos quadrados para o aso em que A tem
posto ompleto.
45
Capítulo 3. Apliações da Fatoração QR
3.3.2 Matrizes de Posto Inompleto
Vimos anteriormente que quando A tem posto ompleto a solução do problema de
mínimos quadrados min
x∈Rn
||Ax − b||2 é únia. Por outro lado, se uma matriz A não
possui posto ompleto, provaremos que existem innitas soluções para o problema
de mínimos quadrados, (ver [7℄).
Teorema 3.3 Seja A ∈ Rm×n e b ∈ Rn om m > n. Então o problema de mínimos
quadrados para o sistema sobredeterminado Ax = b sempre tem uma solução. Se
posto(A) < n, então há innitas soluções.
Demonstração:
Suponha que A ∈ Rm×n e posto(A) = r < n, pois se r = n, estamos no aso em que
A tem posto ompleto e portanto já existiria uma únia solução para o problema de
mínimos quadrados (Teorema 3.2). Usando a fatoração QR om pivoteamento de
olunas, temos AΠ = QR, onde Π ∈ Rn×n é uma matriz de permutação, Q ∈ Rm×m
om olunas ortogonais e R ∈ Rm×n é triangular superior tal que
R =
(
R11 R12
0 0
)
om R11 ∈ Rk×k e R12 ∈ Rn×(n−k).
Assim, podemos apliar mínimos quadrados para minimizar ||Ax−b||22. Portanto:
||Ax− b||22 = ||QTAx−QT b||22
= ||QTA(ΠΠT )x−QT b||22
= ||(QTAΠ)ΠTx−QT b||22
= ||RΠTx−QT b||22. (3.15)
Seja ΠTx =
(
x1
x2
)
e QT b =
(
b1
b2
)
, onde x1, b1 ∈ Rk×1, x2 ∈ R(n−k)×1 e b2 ∈
R
(m−k)×1
. Substituindo em (3.15) teremos:
46
Capítulo 3. Apliações da Fatoração QR
∥∥∥∥∥∥∥∥∥∥
(
R11 R12
0 0
) (
x1
x2
)
−
(
b1
b2
)∥∥∥∥∥∥∥∥∥∥
2
2
=
∥∥∥∥∥∥∥∥∥∥
(
R11x1 − R12x2 − b1
b2
)∥∥∥∥∥∥∥∥∥∥
2
2
. Assim,
∥∥∥∥∥∥∥∥∥∥
(
R11x1 +R12x2 − b1
b2
)∥∥∥∥∥∥∥∥∥∥
2
2
= ||R11x1 +R12x2 − b1||22 + ||b2||22. Logo o mínimo é
atingido quando ||R11x1 + R12x2 − b1||22 = 0, ujo resíduo é dado por ||b2||2. Como
R11 possui inversa temos que R11x1 + R12x2 − b1 = 0 ou x1 = R−111 (b1 − R12x2).
Lembrando que ΠTx =
(
x1
x2
)
segue que x = Π
(
R−111 (b1 −R12x2)
x2
)
.
Portanto a solução depende x2, ou seja, para ada esolha de x2 temos uma únia
solução para o problema de mínimos quadrados. Logo, innitas soluções.

Obeserve que o mínimo é atingido quando R11x1+R12x2−b1 = 0, isto é, R11x1 =
−R12x2 + b1, onde R11 é não-singular. Esolhendo x2 = 0 teremos R11x1 = b1 e
portanto
x = Π
(
R−111 b1
0
)
. (3.16)
Qualquer solução, onde Ax só envolve no máximo r olunas de A, é hamada de
solução básia. A solução básia é usada freqüentemente em várias apliações, por
exemplo, quando as olunas de A representam fatores redundantes em um modelo
linear, e queremos predizer um vetor de observações b usando r olunas de A, (ver
[1℄).
A solução básia não é a solução de 2-norma mínima a menos que a submatriz
R12 é nula, (ver [7℄).
Observe que (3.16) é novamente um sistema triangular superior e fáil de se
resolver por substituição retroativa.
47
Capítulo 3. Apliações da Fatoração QR
3.4 O Problema da Seleção de Subonjunto
Suponha que ao invés de usar todas as olunas da matriz de dados A para predi-
zer b, gostaríamos de predizê-lo a partir de apenas um subonjunto de suas olunas,
eliminando aquelas que sejam redundantes, ou seja, olunas que ontém informações
supéruas, que podem ser desonsideradas (por exemplo, olunas linearmente de-
pendentes, ver [7℄). O problema é então omo seleionar um subonjunto de olunas
não-redundantes de A. Como esolher estas olunas é o onheido omo problema de
seleção de subonjunto e é o assunto desta Seção. Veremos que esse problema pode
ser resolvido através da fatoração QR da matriz A, om pivoteamento de olunas,
(ver [7, 12℄).
Na subsesão seguinte, trataremos de omentar algumas importantes propriedades
da matriz AΠ que serão úteis mais adiante, quando disutiremos uma solução para
o problema de seleção de subonjunto.
3.4.1 Propriedades da Matriz AΠ
Seja A ∈ Rm×n, om m ≥ n. Ao usarmos fatoração QR om pivoteamento de
olunas, obtemos a seguinte deomposição para A,
AΠ = QR, (3.17)
onde Π ∈ Rn×n é uma matriz permutação , Q ∈ Rm×n uma matriz ortogonal e
R ∈ Rn×n é uma matriz triangular superior.
Para entendermos melhor as propriedades da matriz AΠ, trataremos de entender
o aso partiular em que m = n = 3. A fatoração QR om pivoteamento de olunas
para esse aso nos fornee uma matriz Q ∈ R3×3 e R ∈ R3×3 tal que AΠ = QR.
Denotemos por a1, a2, a3 as olunas de AΠ e q1, q2, q3 as olunas de Q então,
 a1 a2 a3

=
 q1 q2 q3

 r11 r12 r130 r22 r23
0 0 r33

48
Capítulo 3. Apliações da Fatoração QR
onseqüentemente,
a1 = r11q1
a2 = r12q1 + r22q2
a3 = r13q1 + r23q2 + r33q3.
PSfrag replaements q3
q2
q1
a1 = q1r11 a2
a3
r12
r22
r23
r33
r13
Figura 3.1: Propriedades da Matriz AΠ.
A gura 3.1 representa geometriamente o aso partiular de pivoteamento de
olunas para uma matriz A ∈ R3×3, onde os elementos da matriz R foram tomados
em módulo.
De aordo om a Subseção 2.5.3 do Capítulo 2, foi observado que quando efetu-
amos pivoteamento de olunas na matriz de dados A, obtemos uma matriz R om
os elementos da diagonal todos não-resente, ou seja, r11 ≥ r22 ≥ r33 ≥ · · · ≥ rnn.
Na Figura 3.1, a primeira oluna da matriz AΠ é esolhida dentre todas as
olunas de A que possuem maior 2-norma, (ver Subseção 2.5.3 do Capítulo 2) de
forma que q1 possui a mesma direção de a1. A próxima oluna para a matriz AΠ
foi esolhida dentre as olunas restantes a2 e a3, omo a oluna que maximiza r22 e
esta substitui a segunda oluna de AΠ. Desta forma, a última oluna da matriz AΠ
é justamente a oluna que minimiza r33 de R.
De maneira geral, temos portanto que os elementos da diagonal de R, ou seja,
49
Capítulo 3. Apliações da Fatoração QR
rkk, medem a omponente ortogonal de ada oluna k relativa as primeiras k − 1
olunas da matriz AΠ, e sempre apareem em ordem desresente para k = 1, · · · , n.
Portanto:
1. A primeira oluna da matriz permutada AΠ é justamente a oluna de A que
possui maior || . ||2;
2. A segunda oluna de AΠ é a oluna de A que tem a maior omponente em
direção ortogonal à primeira oluna da matriz AΠ;
3. Em geral, k-ésima oluna de AΠ é a oluna de A que tem a maior omponente
em direção ortogonal às k − 1 olunas da matriz AΠ.
3.4.2 Seleção de Subonjunto
A solução para o problema de seleção de subonjunto, depende do método om
que a fatoração QR om pivoteamento de olunas é omputada. Provavelmente, o
melhor algoritmo numério é o que está baseado na reexão de Householder, (ver
[6℄). Como vimos no Capítulo 2, este algoritmo baseia-se no seguinte: Suponha
que no k-ésimo passo a fatoração QR om pivoteamento de olunas foi omputada
e temos A(k)Π(k) = Q(k)R(k), onde k = 1, 2, · · · , n. No k-ésimo passo antes que
Q(k) e R(k) sejam omputados, há possibilidade de substituir a k-ésima oluna de
AΠ por uma das olunas restantes ak+1, ak+2, · · · , an. Se a oluna que maximiza o
(k, k)-elemento de R, isto é, rkk, é esolhida para substituir ak, então haverá uma
tendênia para que as olunas independentes de A sejam esolhidas de tal forma que
estejam representadas nas primeiras k olunas de AΠ, deixando as últimas olunas
da matriz AΠ justamente om as olunas dependentes de A, (ver [6℄).
Podemos justiar tal ritério de independênia das k primeiras olunas da matriz
AΠ fazendo uma análise das propriedades itadas na Subseção anterior. Lá, foi visto
que ada oluna da matriz AΠ é esolhida de tal forma que sua k-ésima oluna é
justamente a oluna de A que possui a maior omponente em direção ortogonal
às (k − 1) olunas da matriz AΠ. Desta forma, tal ritério de independênia, se
equivale na esolha das k olunas de A que possuem as maiores omponentes em
direção ortogonal. Em outras palavras, quando efetuamos a fatoração QR om
pivoteamento de olunas na matriz A, esta será deomposta da seguinte forma
50
Capítulo 3. Apliações da Fatoração QR
AΠ = QR = Q
(
R11 R12
0 R22
)
, (3.18)
onde R ∈ Rn×n é uma matriz triangular superior, Q ∈ Rm×n é uma matriz ortogo-
nal e Π ∈ Rn×n uma matriz de permutação. Logo, a submatriz R22 de R ontém
exatamente as (n − k) menores (ou nulos) omponentes em direção ortogonal. Se
os elementos da diagonal de R22 são identiamente nulos, ertamente as k primeiras
olunas de R11 forneem um subonjunto de k olunas da matriz AΠ que são justa-
mente as olunas de A que possuem as maiores omponentes em direção ortogonal.
Caso ontrário, omo todos os elementos da diagonal da matriz R estão todos em
ordem não-resente e R22 tem norma reduzida (ver [3℄), podemos desprezar suas
ontribuições e desta forma, seleionamos novamente, um onjunto de k olunas de
A que possuem as maiores omponentes em direção ortogonal, dados pelos elementos
da diagonal da matriz R11 que são forneidos pelas k primeiras olunas de AΠ.
Assim, as primeiras k olunas da matriz AΠ forneem uma base para Im(A) e
onsequentemente as primeiras k olunas da matriz Q são uma base ortogonal para
Im(A).
3.4.3 Seleção de Subonjunto e Mínimos Quadrados
Até o momento, vimos que o problema sobredeterminado Ax = b pode ser resolvido
usando a ténia de mínimos quadrados, este por sua vez, possui uma únia solução
quando a matriz A possui posto ompleto e innitas soluções para o aso em que a
matriz A possui posto inompleto. Em alguns asos, pode ser vantajoso reduzir a
dimensão da matriz de dados para resolver o sistema Ax = b, por exemplo, para a
geração de animações faiais (ver Capítulo 4).
Seleionado um subonjunto de k olunas independentes da matriz A, dadas por
AΠ1, obtidas através da fatoração QR om pivotemento de olunas, gostaríamos de
min
x∈Rn
||AΠ1x− b||22. (3.19)
De fato, a matriz A pode ser fatorada na forma AΠ = QR, que pode ser reesrita
partiionando a matriz Π = [Π1 Π2], onde Π1 ∈ Rm×k e Π2 ∈ Rm×(n−k). Assim,
A[Π1 Π2] = QR. Daí segue,
51
Capítulo 3. Apliações da Fatoração QR
A[Π1 Π2] = Q
(
R11 R12
0 R22
)
,
tal que AΠ1 ∈ Rm×k representa um subonjunto de k olunas independentes de
A onde, R11 ∈ Rk×k, R12 ∈ Rk×(n−k) e R22 ∈ R(n−k)×(n−k). Conseqüentemente,
AΠ1 = QR11 e AΠ2 ∈ Rm×(n−k).
Podemos resolver (3.19), que é um problema de mínimos quadrados usando fa-
toração QR. De fato, substituindo a matriz A por AΠ1 no Teorema 3.2 e repitindo
de forma análoga a demonstração do teorema enontraremos
||R11x− b1||22 + ||b2||22,
onde
QT b =
(
b1
b2
)
e b1 ∈ Rk×1 e b2 ∈ R(m−k)×1. Logo, o mínimo é atingido quando
R11x = b1. (3.20)
Assim, a solução para o problema de mínimos quadrados usando um subonjunto de
olunas independentes da matrizA é dada pelo sistema triangular superiorR11x = b1
e resíduo ||b2||2.
Dessa forma, podemos seleionar um subonjunto de k olunas independentes da
matriz A para predizer um vetor de observações b, utilizando a ténia de mínimos
quadrados.
Gostaríamos de aproximar as (n − k) olunas que não foram seleionadas pelo
algoritmo de fatoração QR om pivoteamento de olunas, dadas por AΠ2, em função
de uma ombinação linear das olunas independentes de A, dadas pelas primeiras
k olunas da matriz AΠ, isto é, AΠ1. Desse modo, obteríamos uma matriz Ak
de posto k, pois estamos predizendo (n − k) olunas da matriz A em termos de k
olunas independentes de A e portanto, reduziremos a dimensão (posto) da matriz
A. Como veremos no próximo apítulo, essa redução de posto está relaionada om
a obtenção do modelo para geração de animações faiais.
Podemos expressar esse problema om a minimização de
Ei = ||AΠ1xi − (AΠ2)i||22,
52
Capítulo 3. Apliações da Fatoração QR
om i = 1, · · · , (n− k). Como ada Ei ≥ 0 e ada parela Ei possui norma mínima,
logo
n−k∑
i=1
Ei terá norma mínima. Isto é equivalente a minimização de
E =
n−k∑
i=1
||AΠ1xi − (AΠ2)i||22
= ||AΠ1x1 − (AΠ2)1||22 + · · ·+ ||AΠ1xn−k − (AΠ2)n−k||22,
onde ada índie i representa ada uma das n − k olunas de AΠ2. Assim, pela
denição de norma de Frobenius e por (1.5) teremos
E = ||AΠ1X − AΠ2||2F , (3.21)
onde X ∈ Rk×(n−k).
Observe que (3.21) é equivalente a minimização de
E = ||QT (AΠ1X −AΠ2)||2F ,
visto que Q ∈ Rm×n é uma matriz ortogonal. Assim,
E = ||QT (AΠ1X − AΠ2)||2F
= ||QTAΠ1X −QTAΠ2||2F
=
∥∥∥∥QTQR11X −QTQ( R12R22
)∥∥∥∥2
F
pois, A[Π1 Π2] = Q
(
R11 R12
0 R22
)
. Então,
E =
∥∥∥∥QTQR11X −QTQ( R12R22
)∥∥∥∥2
F
=
∥∥∥∥R11X − ( R12R22
)∥∥∥∥2
F
=
∥∥∥∥( R11X − R12−R22
)∥∥∥∥2
F
= ||R11X − R12||2F + ||R22||2F . (3.22)
Portanto, para que (3.22) seja mínimo devemos ter
R11X = R12, (3.23)
onde sua parte residual é dada por ||R22||F .
53
Capítulo 3. Apliações da Fatoração QR
3.5 Disussão
A fatoração QR é de fato é uma ferramenta eiente. Através da fatoração QR, de-
duzimos as equações normais, enontramos uma solução para o sistema de equações
lineares Ax = b, onde A ∈ Rn×n e para o problema de mínimos quadrados min
x∈Rn
||Ax−
b||2, om A ∈ Rm×n, onde A possui ou não posto ompleto. Em ambos os asos a
solução é forneida om a resolução de um sistema triangular superior, que é fáil
de resolver.
Mostrou-se eaz na solução para o problema de seleção de subonjunto, for-
neendo um subonjunto de olunas independentes de uma matriz A, através de
pivoteamento de olunas.
Entretanto, é laro que existem outros métodos para enontrar soluções para os
problemas propostos nesse apítulo (ver [7℄), porém, para os propósitos do apítulo
4, a fatoração QR mostrou-se eaz, permitindo resolver os prinipais problemas
para se hegar em um modelo para geração de animações faiais.
54
Capítulo 4
Apliação a Animação Faial
4.1 Introdução
Neste Capítulo, mostraremos omo a fatoração QR pode ser utlizada na obtenção de
um modelo e produzir animações omputadorizadas da fala om um nível aeitável
de realismo. O algoritmo permite identiar um subonjunto de maradores faiais
independentes. Esse subonjunto pode ser utilizado posteriormente, omo uma base
para predizer o movimento de pontos faiais arbitrários.
Investigaremos as trajetórias reonstituídas pelo algoritmo, mostrando que o erro
médio obtido é relativamente pequeno e geraremos omputaionalmente animações
faiais. A maioria dos algoritmos que foram implementados nessa dissertação estão
disponíveis no Apêndie A. O software esolhido para os álulos foi o Matlab.
4.2 Dados
Os dados onsistem em registros da posição 3D de 57 maradores distribuídos na
fae de um sujeito (Figura 4.1). Foram olhidos om uma frequênia de amostragem
de 120 Hz, enquanto o sujeito pronuniava uma sequênia de 40 frases (ver Tabela
4.6 no Apêndie B) em inglês [12, 13℄. As primeiras 30 frases foram usadas para
onstruir o modelo, e as 10 últimas para validar o modelo e gerar animações. Antes
de pronuniar ada uma das 40 frases, o sujeito adotou uma posição de desanso
(neutra), para que fosse obtido o desloamento (separado) de ada marador.
55
Capítulo 4. Apliação a Animação Faial
Figura 4.1: Posição dos maradores faiais.
4.3 Pré-proessamento
Primeiramente, os desloamentos de ada marador foram alulados relativos à
posição neutra iniial e foram armazenados em uma matriz Bm×n, onde m = 16106
e n = 171. A matriz B possui 57 × 3 = 171 olunas, onde o fator 3 representa as
oordenadas espaiais {x, y, z} de ada marador.
Parte dos dados da matriz B foram reagrupados em uma nova matriz B̂ ∈ Rm̂×n
om as 30 primeiras frases, onde m̂ = 11975 e n = 171 (ver Seção 4.5).
Podemos representar a matriz B̂ omo segue
B̂ =
 x1,1 y1,2 z1,3 x1,4 y1,5 z1,6 · · · x1,169 y1,170 z1,171... ... ... ... ... ... · · · ... ... ...
xm,1 ym,2 zm,3 xm,4 ym,5 zm,6 · · · xm,169 ym,170 zm,171

onde (x11 · · ·xm1)T , (y12 · · · ym2)T e (z13 · · · zm3)T representam os desloamentos do
primeiro marador, (x14 · · ·xm4)T , (y15 · · · ym5)T e (z16 · · · zm6)T para o segundo mar-
ador e de forma análoga para o restante dos maradores.
Como veremos na Seção 4.7, devemos aproximar o desloamento de ada mar-
ador que não foi seleionado pelo algoritmo de fatoração QR omo uma ombinação
56
Capítulo 4. Apliação a Animação Faial
linear de k maradores seleionados. Seja Ps o desloamento obtido por ombinação
linear desses k desloamentos. Então
Ps = a1sP1 + a2sP2 + · · ·+ aksPk, (4.1)
aks são esalares. Por simpliidade, para obtermos os desloamentos de ada mar-
ador, vamos onatenar os desloamentos dos maradores em únio marador.
Dessa forma teremos
 xsys
zs
 = a1s
 x1y1
z1
 + a2s
 x2y2
z2
+ · · ·+ aks
 xkyk
zk
. (4.2)
Portanto, os desloamentos de ada marador foram representados em um únia
oluna da matriz de dados omo segue
x =

x1r
.
.
.
xmr
y =

y1j
.
.
.
ymj
z =

z1l
.
.
.
zml
,
onde r = {1, 4, 7, · · · , (n− 2)}, j = {2, 5, 8, · · · , (n− 1)} e l = {3, 6, 9, · · · , n}.
Assim, desloamentos dos maradores nas 30 primeiras frases foram onatena-
dos e arranjadas em uma matriz de dados A ∈ RM×N , onde N = n
3
é o número de
maradores (57) e M = 3 ×m. A fatoração QR om pivoteamento de olunas foi
apliada a matriz A, usando o software Matlab.
4.4 Posto Numério da Matriz de Dados
Luero et al. no seu artigo [12℄ obteve o posto numério da matriz de dados om
análise baseada na deomposição QR om pivoteamento de olunas. Mostraremos
57
Capítulo 4. Apliação a Animação Faial
nesta Seção que a mesma análise pode ser feita om deomposição de valores singu-
lares.
Como visto no Capítulo 1, o posto numério de uma matriz pode ser alulado
analisando os seus respetivos valores singulares. A Figura 4.2 mostra os elementos
da diagonal da matriz Σ. O pequeno valor entre os elementos σ57,57 = 0.07 em
relação ao σ56,56 = 18.88 india posto 56 para matriz de dados A. De fato, pelo
Teorema 1.22 temos que A tem posto numério (δ, ǫ, r)2 se, e somente se,
σr ≥ δ > ǫ ≥ σr+1. (4.3)
Em determinadas apliações (ver Capítulo 1), apareem matrizes ujos valores sin-
gulares menores deveriam ser nulos, mas não o são devido erros de arredondamentos,
et (ver [7℄). No que se refere aos dados, houve uma pequena margem de erro que
hega a aproximadamente 0.5mm (ver [14℄). Desse modo, se esolhermos r = 56
temos σr = σ56 = 18.88 e σr+1 = σ57 = 0.07. Portanto, δ = 1.0 satisfaz a Denição
1.20 e daí
18.88 ≥ 1.0 > 0.5 ≥ 0.07. (4.4)
Portanto, podemos supor posto numério 56 e identiar a dimensão dos dados.
0 10 20 30 40 50 60
0
200
400
600
800
1000
1200
1400
1600
1800
k
Σ k
k
Figura 4.2: Elementos da diagonal da Matriz Σ.
A gura 4.3 mostra os elementos da diagonal da matriz R, rkk, que medem a
omponente ortogonal de ada oluna k relativo as primeiras k − 1 anteriores, e
58
Capítulo 4. Apliação a Animação Faial
apareem em ordem desresente para k = 1, · · · , 57. Observe que há uma seme-
lhança entre os elementos da diagonal das matrizes R e Σ. Ambas as têm diagonal
em ordem deresente e apresentando uma abertura entre os elementos r56,56 = 25.41
e o r57,57 = 0.01 que pode ser usado para determinar o posto numério da matriz de
dados, (ver [6℄).
0 10 20 30 40 50 60
0
100
200
300
400
500
600
700
k
r k
k
Figura 4.3: Elementos da diadonal da Matriz R.
4.5 Alguns Resultados da Fatoração QR
Em seu artigo [12℄, Luero et al. observou que os dados estabilizavam para os
primeiros 10 valores de rkk, normalizados relativos a norma de R. Os valores estabi-
lizam para um onjunto de aproximadamente 15 sentenças onluindo que qualquer
onjunto de dados maior, é bastante seguro para onstruir um modelo, o que justi-
ou adoção de 30. Usaremos esta mesma metodologia aqui.
A esolha da quantidade de sentenças pode ser justiada através de uma análise
na Figura 4.4. Lá, os primeiros 12 valores de rkk estão normalizados relativos à norma
de R, em função da quantidade de amostras nos dados. Os valores estabilizam antes
de atingir o total de amostras disponíveis (aproximadamente 15a frase, já que ada
frase oupa aproximadamente em média 500 linhas da matriz de dados), o que
justia a adoção de 30 frases para onstruir o modelo. Dessa forma, sobram 10
frases para testar e validar o modelo.
59
Capítulo 4. Apliação a Animação Faial
0 20 40 60 80 100 120 140 160
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
Amostras × 100
r k
k/||
R|
| F
Figura 4.4: Valores normalizados dos 12 primeiros elementos na diagonal de R em função
da quantidade de amostras nos dados.
Na Figura 4.4, oorre estabilidade dos dados aproximadamente a partir da 15a
frase. Porém, quando permutamos as linhas de A aleatoriamente (Figura 4.5) obser-
vamos que a estabilidade é alançada mais rapidamente, ou seja, aproximadamente
entre a linha 1000 e 2000, o que nós dá aproximadamente 3 sentenças.
0 20 40 60 80 100 120 140 160
0.05
0.1
0.15
0.2
0.25
0.3
Amostras × 100
r k
k/||
R|
| F
Figura 4.5: Valores normalizados dos 12 primeiros elementos na diagonal de R em função
da quantidade de amostras nos dados permutados aleatoriamente.
De fato, em ada linha da matriz estão representados os desloamentos de todos
maradores. Assim, em um determinado momento, a matriz de dados poderá ter
60
Capítulo 4. Apliação a Animação Faial
ou não todos os detalhes dos movimentos manifestados na fae do indivíduo através
dos maradores: Por exemplo, a fala, pisar dos olhos, sorriso, et. Isto é, nem
sempre em determinadas frases, o indíviduo manifesta todas estas expressões faiais.
Portanto, em alguns asos, há neessidade de mais de uma frase até que todas estas
arateristias dos movimentos sejam inorporadas. Logo, quando dizemos que os
rkk estão se estabilizando, na verdade estamos dizendo que o onjunto de linhas
que foram seleionadas para apliar a fatoração QR, é suiente, no sentido de que
todos os movimentos da fae apturados pelos maradores estão agregadas nesse
onjunto de sentença. Daí, um onjunto 30 sentenças é suiente para que isso
aonteça (Figura 4.4). Por outro lado, quando permutamos aleatoriamente as linhas
da matriz de dados, temos um ruzamento de informações, isto é, expressões faiais
que antes eram manifestas em frases posteriores, por exemplo, agora se misturam.
Assim, movimentos faiais que antes eram obtidos om um onjunto de 30 frases
por exemplo, não é mais neessário e portanto, a estabilidade oorre bem antes (ver
Figura 4.5) em omparação om a Figura 4.4.
4.6 Esolha dos Maradores Prinipais e suas Res-
petivas Regiões de Inuênia
Em [12℄ é apresentado uma Tabela om 10 olunas. Cada oluna possui 12 mar-
adores seleionados pelo algoritmo. Um onjunto de dados de 30 sentenças foi
usado em todas as tentativas. Na primeira tentativa, as primeiras 30 sentenças do
onjunto foram usadas, e nas 9 tentativas restantes, as sentenças foram aleatoria-
mente seleionadas. As olunas seleionadas tiveram uma pequena mudança a ada
nova tentativa.
Neste trabalho, faremos um outro tipo de análise. A Tabela 4.1 mostra experi-
mentos feitos om k linhas da matriz de dados, onde k varia de 1000 a 11975 linhas
na matriz A. Cada oluna da tabela representa os maradores seleionados pelo al-
goritmo na k-ésima linha. E omo já tínhamos observado na Figura 4.4, os dados se
estabilizam a partir da 7a oluna, que orresponde a 15a sentença aproximadamente.
A Tabela 4.2 mostra os maradores que o algoritmo seleionou om as linhas
permutadas aleatoriamente na matriz de dados A, onde k varia 1000 a 11975. Cada
oluna da tabela representa os maradores seleionados pelo algoritmo na k-ésima
61
Capítulo 4. Apliação a Animação Faial
Ordem Maradores Seleionados
1 2 3 4 5 6 7 8 9 10 11 12
1 40 48 48 40 40 40 40 40 40 40 40 40
2 34 34 34 34 34 34 02 34 34 34 34 34
3 51 51 51 38 38 38 38 38 38 38 38 38
4 20 20 20 2 2 2 2 2 2 2 2 2
5 36 02 03 36 36 20 20 20 36 36 36 36
6 32 07 36 20 20 36 08 36 36 36 36 36
7 11 36 39 49 49 08 36 36 20 08 08 20
8 56 39 11 07 07 49 49 49 49 49 49 49
9 12 57 06 52 52 11 13 13 13 13 13 13
10 44 11 44 13 13 52 52 12 12 52 52 52
11 39 32 32 23 54 12 12 54 54 54 54 54
12 16 47 47 57 23 54 54 52 47 56 47 47
Amostras ×100 10 20 30 40 50 60 70 80 90 100 110 119.75
Tabela 4.1: Os 12 primeiros maradores seleionados pelo algoritmo om k linhas na
matriz de dados.
linha. Como observamos na Figura 4.5, os dados se estabilizam a partir da 2o oluna
ou aproximadamente 5a sentença.
Ordem Maradores Seleionados
1 2 3 4 5 6 7 8 9 10 11 12
1 40 40 40 40 40 40 40 40 40 40 40 40
2 34 34 34 34 34 34 34 34 34 34 34 34
3 38 38 38 38 38 38 38 38 38 38 38 38
4 2 2 2 2 2 2 2 2 2 2 2 2
5 36 36 36 36 36 36 36 36 36 36 36 36
6 20 08 06 06 06 06 06 20 20 06 06 06
7 49 20 20 20 20 20 20 06 06 20 20 20
8 06 49 49 49 49 49 49 49 49 49 49 49
9 11 13 13 13 13 13 13 13 13 13 13 13
10 47 52 52 52 52 52 52 52 52 52 52 52
11 54 54 54 54 54 54 54 54 54 54 54 54
12 47 47 47 47 47 47 47 47 47 47 47 47
Amostras ×100 10 20 30 40 50 60 70 80 90 100 110 119.75
Tabela 4.2: Os 12 primeiros maradores seleionados pelo Algoritmo om k linhas permu-
tadas aleatoriamente.
A partir do momento em que os dados omeçam a estabilizar, há pouas mu-
danças entre as olunas seleionadas pelo algoritmo. Assim, usando os resultados
62
Capítulo 4. Apliação a Animação Faial
das Tabelas 4.1 e 4.2 seleionamos um onjunto de 12 maradores. A tabela 4.3
representa essa seleção.
Ordem Marador
1 40
2 34
3 38
4 2
5 36
6 06
7 20
8 49
9 13
10 52
11 54
12 47
Tabela 4.3: Os 12 primeiros maradores seleionados pelo algoritmo.
Nos ítens a seguir, estão relaionados os 12 maradores que foram seleionados
pelo algoritmo e suas respetivas regiões de inuênia para ada um dos maradores.
• O primeiro marador seleionado é o 40, no entro do lábio inferior (Figura
4.1), que tem o maior desloamento;
• Os próximos dois maradores são o 34 e o 38, em ambos antos dos lábios;
• O quarto marador é o 02, próximo da sobranelha direita;
• Na 5a posição aparee o marador 36 e situá-se no entro do lábio superior. O
marador 06 aparee em seguida e está situado aima do olho esquerdo.
• O marador 20 aparee na 7a posição e se enontra ao lado direito do nariz;
• O marador 49 aparee em seguida e enontra-se na parte inferior dos lábios,
a esquerda;
• O marador 13 representa a aão de pisar do olho esquerdo;
• Na 10a posição aparee o marador 52 e este se enontra ao lado esquerdo do
rosto;
63
Capítulo 4. Apliação a Animação Faial
• O marador 54, na pálpebra esquerda, aparee na 11a posição, e enontra-se
bem próximo do marador 52;
• Por último, aparee o marador 47 e enontra-se na parte inferior dos lábios,
a direita.
Os valores rkk assoiados aos 4 primeiros maradores são bem maiores em om-
paração om os outros (ver Figura 4.2), o que sugere que seus movimentos determi-
nam grande parte da inemátia faial geral.
Após seleionar os maradores (olunas) prinipais, alulamos om o auxílio de
mínimos quadrados das olunas restantes resolvendo
R11X = R12, (4.5)
omo na Seção 3.4 do Capítulo 3. Como um exemplo numério, usamos os resul-
tados da a Tabela 4.3. Em [12℄, Luero et al. adotou uma base onstituída de 09
maradores. Nesta dissertação, adotamos base de 12 maradores (ver Seção 4.9) que
inlui até o marador 47. As Figuras 4.6 e 4.7 mostram os resultados desse ajuste.
Lá, os oeientes apropriados omputados para os maradores seundários foram
estendidos a outros pontos faiais por interpolação úbia.
As regiões assoiadas a ada um dos maradores prinipais inluem as sub-regiões
positivas (vermelho) e negativas (azuis), onde o movimento está no mesmo sentido
e no oposto, respetivamente, ao movimento do marador prinipal. As regiões
apareem no mesmo número e posição similar em ambos os lados do rosto, embora
tenham uma grande assimetria. A respeito das pálpebras, note que embora um
dos dois maradores da pálpebra seja um marador prinipal, ambos têm os pesos
similares, indiando padrões quase iguais do movimento.
O gráos das Figuras 4.6 e 4.7 representam as linhas da matriz X obtidas pela
equação (4.5), interpoladas a toda a superfíie faial. Cada gráo mostra a região
ontrolada pelo marador i, que orresponde a linha i de X.
Do mesmo modo, podemos fazer gráos similares (Figuras 4.8 e 4.9), porém
nesse aso, onsiderando a matriz R. Sabemos que a primeira linha de R ontém as
projeções de ada oluna da matriz A (om as olunas já permutadas) na direção
da primeira oluna da matriz Q (que tem maior norma). A segunda linha de R
64
Capítulo 4. Apliação a Animação Faial
Figura 4.6: Regiões faiais ilustradas para os maradores 40, 34, 38, 02, 36 e 06.
ontém as projeções de ada oluna de A em direção ortogonal à primeira oluna da
matriz Q. Em geral, a k-ésima linha de R ontém as projeções de ada oluna de A
em direção ortogonal à k − 1 olunas da matriz Q. Então, gráos das linhas de R
65
Capítulo 4. Apliação a Animação Faial
Figura 4.7: Regiões faiais ilustradas para maradores 20, 49, 13 e 52.
mostram a projeção do desloamento de ada ponto faial nas direções ortogonais
denidas pela matriz Q. Isto é, os gráos (regiões mais esuras) mostram quais os
padrões regionais de deformação faial nessas direções ortogonais.
4.7 Geração de Animações Faiais
Como exemplo de animação faial, usaremos a frase 39 do onjunto de sentenças
disponível no Apêndie B (ver Tabela 4.6). As animações faiais de movimentos ar-
bitrários podem ser produzidas, ontrolando o movimento dos maradores prinipais
om sinais apropriados.
Seja P1 ∈ Rm×k a matriz om os desloamentos dos maradores prinipais rela-
tivos à posição neutra iniial. Uma vez omputados todos os oeientes da matriz
66
Capítulo 4. Apliação a Animação Faial
Figura 4.8: Regiões de deformação faial nas direções ortogonais, linhas 1 a 6 de R.
X, alulamos o desloamento para os maradores seundários, resolvendo
P2 = P1X. (4.6)
Calulados os desloamento para os maradores seundários, a posição iniial de
67
Capítulo 4. Apliação a Animação Faial
Figura 4.9: Regiões de deformação faial nas direções ortogonais, linhas 7 a 10 de R.
todos os maradores é introduzida para obter sua posição no espaço (3D). Desse
modo, riamos um malha faial equiespaçada ontendo 2500 pontos faiais arbi-
trários. Interalamos esses pontos faiais através da interpolação úbia, isto é, ada
urva entre dois pontos adjaentes onsiste num polinómio de tereira ordem ujos
oeientes foram obtidos resolvendo sistema de equaões lineares montadas a partir
ondições preestabeleidas.
Finalmente, nós produzimos animações faiais para a sentença 39, em formato
AVI (ver Algoritmo L do Apêndie A). Outros exemplos de animações que usam
esta ténia podem ser visualizadas em http://vargas.mat.unb.br/. A Figura
4.10 mostra o quadro iniial das animações geradas usando esse método.
Em geral, as animações são visualmente realistas, sem nenhuma distorção per-
eptível nos padrões de movimento.
68
Capítulo 4. Apliação a Animação Faial
Figura 4.10: Quadro iniial das animações.
4.8 Análise de Erros nas Trajetórias Computadas
Como já omentado, deixamos 10 frases para testar e validar o modelo e omo
exemplo numério, esolhemos a frase 39 do onjunto de sentenças.
Calulada a matriz P2 que ontém os desloamentos para os maradores se-
undários, omo em (4.6), podemos medir o erro, omparando os desloamentos
dos maradores seundários que foram reonstituídos pelo algoritmo, om os deslo-
amentos originais dos maradores. Para alular o erro, adotamos o Erro Médio
Quadrátio dado pela seguinte fórmula
E =
√√√√ 1
N
N∑
i=1
(xi − xi)2 + (yi − yi)2 + (zi − zi)2, (4.7)
onde xi, yi, zi são omponentes dos desloamentos dos maradores originais, xi, yi e
zi omponentes dos desloamentos obtidos através da reonstituição dos maradores
pelo algoritmo.
A Figura 4.11 mostra a omparação entre a trajetória real (linha em traços) e a
nova trajetória que foi reonstituída pelo algoritmo (linha heia), no presente aso,
para o marador 28. Observe que o marador 28 enontra-se na parte inferior do
rosto (ver Figura 4.1), uma região onde há muito desloamento, ainda assim, há
grande semelhança entre as trajetórias originais e as reonstituídas pelo algoritmo,
mostrando que a fatoração QR é de fato um bom algoritmo para reonstrução das
trajetórias.
69
Capítulo 4. Apliação a Animação Faial
0 100 200 300 400 500 600
−5
−4
−3
−2
−1
0
1
Amostras
x
 (m
m)
0 100 200 300 400 500 600
−0.5
0
0.5
1
1.5
2
2.5
3
3.5
Amostras
y 
(m
m)
0 100 200 300 400 500 600
−2.5
−2
−1.5
−1
−0.5
0
0.5
1
1.5
Amostras
z
 (m
m)
Figura 4.11: Exemplo de trajetória real (linha de traços) e reonstruída pelo algoritmo
(linha heia), para o marador 28.
A Tabela 4.4 ontém os erros obtidos através da reonstituíção dos desloamentos
dos maradores pelo algoritmo. Em relação a Tabela 4.4 destaamos:
1. O erro alulado para o 11o marador é quase nulo, na ordem de 1.07×10−5mm.
Se analisarmos a Figura 4.1 veremos que o 11o marador é simétrio ao 13o
marador, que é um marador seleionado pelo algoritmo, portanto ambos
possuem pesos similares, e omo o 13o possui erro nulo, isso justia o erro do
11o marador ser tão pequeno;
2. Além do marador 11 que é simétrio ao marador 13, o menor erro é justa-
mente para o marador 10, aproximadamente 0.30mm e de fato já era esperado,
pois esse marador enontra-se justamente na parte superior na sombraelha
direita, loal onde há pouo desloamento dos maradores;
70
Capítulo 4. Apliação a Animação Faial
Maradores Erro Maradores Erro Maradores Erro
01 0.80 20 0.00 39 1.05
02 0.00 21 0.76 40 0.00
03 0.40 22 0.66 41 0.68
04 0.50 23 0.93 42 0.93
05 0.66 24 0.61 43 0.74
06 0.00 25 0.49 44 0.82
07 0.70 26 0.38 45 0.58
08 0.55 27 0.56 46 0.65
09 0.49 28 0.35 47 0.00
10 0.30 29 0.70 48 0.84
11 1.07× 10−5 30 0.75 49 0.00
12 0.94 31 0.97 50 0.61
13 0.00 32 0.95 51 0.72
14 0.88 33 0.54 52 0.00
15 0.44 34 0.00 53 0.51
16 0.63 35 0.61 54 0.00
17 0.65 36 0.00 55 0.80
18 0.67 37 0.78 56 0.70
19 0.39 38 0.00 57 0.84
Tabela 4.4: Erro obtido para as trajetórias dos maradores que foram reonstituídas através
algoritmo para a sentença 39.
3. O erro alulado para os 12 maradores primários (maradores seleionados
pelo algoritmo de fatoração QR om pivoteamento de olunas) é nulo, uma
vez que xi = xi, yi = yi e zi = zi;
4. De todos os erros alulados, os maradores 39, 42, 48 e 57 são os que possuem
os maiores erros e hegam a 1.05mm para o marador 39, 0.93mm para o
marador 42, 0.84mm para o marador 48 e 57. Se observarmos que esses
maradores (ver gura 4.1) se enontram na parte inferior do rosto, que é a
região onde se têm os maiores desloamento de maradores, era natural que
tivéssemos nessa região os maiores erros.
A Tabela 4.5 mostra o erro médio para ada uma das sentenças usadas para
validar o modelo. As sentenças 39 e 31, 37 são justamente as que apresentam o
menor e o maior erro médio respetivamente. Comparado om o erro de preisão
dos dados, era de 0.5mm (ver [14℄), o erro para as trajetórias reonstruídas para os
71
Capítulo 4. Apliação a Animação Faial
maradores faiais é pequeno, já que em média, o erro é de 0.64mm (ver Algoritmo
I do Apêndie A).
Sentenças Amostras Erro Médio
31 468 1.10
32 323 0.84
33 424 1.06
34 416 0.93
35 474 1.08
36 454 0.68
37 315 0.71
38 308 0.97
39 589 0.64
40 364 1.01
Tabela 4.5: Erro médio para trajetórias reonstituídas pelo algoritmo para as sentenças
31 a 40.
Em [12℄, Luero et al. obteve seu modelo adotando uma base de 09 maradores.
Neste apítulo, alulamos os erros, reonstruímos as trajetórias, obtivemos anima-
ções faiais através de uma base onstituída de 12 maradores om erro médio de
0.90mm e omo já era esperado, menor que o erro médio que Luero, de 1.05mm,
pois em seu artigo, a base adotada ontém 03 maradores a menos.
4.9 Análise para Seleção de Maradores
Esta Seção objetiva justiar a esolha dos 12 maradores na Seção 4.6 para análise
de erros, trajetórias e geração de animações faiais através de uma frase predenida
do onjunto de sentenças, omo nas Seções 4.7 e 4.8.
Sabemos que as primeiras k olunas da matriz AΠ forneem uma solução para
o problema de seleção de subonjunto (ver Capítulo 3). No nosso aso, as olunas
desta matriz são representadas por desloamentos de 57 maradores.
O modelo (matriz X) é obtido a partir da seleção de k maradores na matriz de
desloamentos, resolvendo R11X = R12 (ver Capítulo 3). Em seguida, onseguimos
os maradores seundários resolvendo P1X = P2 (ver Seção 4.7). Para ada on-
junto de k maradores seleionados temos uma matriz X (modelo) e uma matriz P2
72
Capítulo 4. Apliação a Animação Faial
(desloamentos seundários). Fazendo k variar de 1 a 57 (número de maradores) e
esolhendo uma frase predenida do onjunto de sentenças, logramos para ada sub-
onjunto de k maradores um erro médio. Sabemos a priori que o erro de preisão
dos dados é de 0.5mm (ver [14℄), então qualquer subonjunto de k maradores em
que o erro médio é aproximadamente do mesmo valor é apropriado para onstruir o
modelo. As Figuras 4.12, 4.13 e 4.14, representam os gráos para as frases 31 a 40
do onjunto de sentenças (a esquerda, frases ímpares e a direita as pares).
0 10 20 30 40 50
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
k
E
rr
o 
M
éd
io
 (m
m)
0 10 20 30 40 50
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
k
E
rr
o 
M
éd
io
 (m
m)
Figura 4.12: Erro médio para um onjunto de k maradores seleionados, frases 31 e 32.
A linha heia (na horizontal) representa o erro de preisão dos dados.
Nas Figuras 4.12, 4.13 e 4.14, a linha horizontal representa aproximadamente o
erro de preisão dos dados e observamos que as frases 31 e 35, são as que possuem
os maiores subonjuntos de maradores neessários, aproximadamente 40, para se
obter um erro médio próximo de 0.5mm. Por outro lado, as frases 36 e 39, possuem
os menores subonjunto de maradores, em torno de 20, para onseguir erro médio
similar.
Através de uma análise das Figuras 4.12, 4.13 e 4.14 onluimos que o erro médio
diminui quando se aumenta o número de maradores e pelo observado aima, uma
quantidade razoável para se onstruir o modelo deveria ser de pelo menos 40. Por
outro lado, não é interessante uma base muito numerosa, já que propomos desde
o iníio deste trabalho um modelo em termos de `pouos' maradores faiais. Na
verdade, não há proedimento que estime a priori o número de maradores a serem
esolhidos. Porém ertamente, podemos armar que a base om 12 maradores
mostrou bons resultados, om erro médio relativamente pequeno e uma boa ani-
73
Capítulo 4. Apliação a Animação Faial
0 10 20 30 40 50
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
k
E
rr
o 
M
éd
io
 (m
m)
0 10 20 30 40 50
0
0.5
1
1.5
2
2.5
k
E
rr
o 
M
éd
io
 (m
m)
0 10 20 30 40 50
0
0.5
1
1.5
2
2.5
3
k
E
rr
o 
M
éd
io
 (m
m)
0 10 20 30 40 50
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
k
E
rr
o 
M
éd
io
 (m
m)
Figura 4.13: Erro médio para um onjunto de k maradores seleionados, frases 33 a 36.
A linha heia (na horizontal) representa o erro de preisão dos dados.
mação faial sem distorções pereptíveis.
Os algoritmos utilizados para fazer as Figuras 4.12, 4.13 e 4.14 estão disponíveis
em http://vargas.mat.unb.br/.
74
Capítulo 4. Apliação a Animação Faial
0 10 20 30 40 50
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
k
E
rr
o 
M
éd
io
 (m
m)
0 10 20 30 40 50
0
0.5
1
1.5
2
2.5
k
E
rr
o 
M
éd
io
 (m
m)
0 10 20 30 40 50
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
k
E
rr
o 
M
éd
io
 (m
m)
0 10 20 30 40 50
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
k
E
rr
o 
M
éd
io
 (m
m)
Figura 4.14: Erro médio para um onjunto de k maradores seleionados, para as frases
37 a 40. A linha heia (na horizontal) representa o erro de preisão dos dados.
75
Conlusões
Neste trabalho, estudamos a fatoração QR e suas apliações. Através desta deom-
posição, enontramos uma solução para o sistema de equações lineares Ax = b, onde
A ∈ Rn×n e para o problema de mínimos quadrados min
x∈Rn
||Ax− b||2, om A ∈ Rm×n
e m > n, tal que A possui ou não posto ompleto. Em ambos os asos a solução
é forneida om a resolução de um sistema triangular superior. Tais sistemas são
resolvidos por substituições retroativas, através de equações da forma
xi =
bi −
n∑
j=i+1
rijxj
rii
para todo i = 1, · · · , n.
A fatoração QR om pivoteamento de olunas mostrou-se eaz, forneendo uma
solução para o problema de seleção de subonjunto, extraindo um subonjunto de
olunas linermente independentes de uma matriz A.
Entretanto, é laro que existem outros métodos para enontrar soluções para
os problemas propostos nesta dissertação (ver [7℄), porém, para os propósitos deste
trabalho, fatoração QR mostrou bons resultados, permitindo resolver os prinipais
problemas para se hegar em um modelo para geração de animações faiais.
Tal proedimento mostrou-se eiente, pois permitiu identiar um subonjunto
base de maradores faiais independentes, posteriormente utilizados para prognos-
tiar o movimento de pontos faiais arbitrários.
Através da Figura 4.11 podemos observar que as trajetórias reonstituídas pelo
algoritmo estão bem próximas das originais, mostrando a eássia da fatoração QR
na reonstrução das trajetórias dos maradores. As animações omputadorizadas
produzidas através da fatoração QR om pivoteamento de olunas não possuem
nenhuma distorção pereptível nos padrões movimento faiais.
76
Conlusões
Em [12℄, Luero et al. obteve seu modelo adotando uma base de 09 maradores e
um erro de aproximadamente 1.05mm. Neste trabalho, reonstruímos as trajetórias,
obtivemos animações faiais através de uma base onstituída de 12 maradores om
erro médio de 0.90mm e omo já era esperado, houve uma diminuição do erro.
Salientamos que os maradores faiais seleionados são utilizados na obtenção de
um modelo linear individualizado da inemátia faial, pois ada indivíduo possui
suas próprias propriedades da pele, teidos, peso ou estruturas musulares diferentes.
Possivelmente, alguns aspetos desta ténia requerem algumas melhorias. Por
exemplo, um melhor ritério para determinar uma dimensão apropriada na seleção
dos maradores utilizados para onstruir o modelo poderiam inferir melhores resul-
tados. Por exemplo, na geração de animações faiais. Mas estas e outras questões
ans, deixamos omo assunto para futuros trabalhos de pesquisas.
77
Referênias Bibliográas
[1℄ Björk, A., Numerial Methods for Least Squares Problems, SIAM, Philadel-
phia (1996).
[2℄ Couvreur, C.; Breler, Y., On the optimality of the bakward greedy algorithm
for the subset seletion problem, SIAM Journal on Matrix Analysis and Appli-
ations 21, 797− 808 (2006).
[3℄ Chan, T. F.; Hansen P. C., Low-rank revealing QR fatorizations, Numerial
Linear Algebra with Appliations 1, 33− 44 (1994).
[4℄ Beautemps, D.; Badin, P.; Bailly, G., Linear degrees of freedom in speeh
prodution: Analysis of ineradio-and labio-lm data and artiulatory-aousti
modeling, Journal Aoustial Soiety of Ameria 109, 2165− 2180 (2001).
[5℄ Fukuda, H. E., Reuperação de Informações por Álgebra Linear Computaional,
Universidade de São Paulo - USP, Brasil (2004).
[6℄ Golub, G.; Klema, V.; Stewart, G. W., Rank degeneray and least squares
problems, Computer Siene Department Stanford University, STAN  CS 
76− 559 (1976).
[7℄ Golub, G. H.; Van Loan, C. F., Matrix Computations, The John Hopkins
University Press, Baltimore (1996).
[8℄ Hoog, F. R.; Mattheij, R. M. M., Subset seletion for matries, Journal of the
Linear Algebra and Appliations 422, 349− 459 (2007).
[9℄ Hong, Y. P.; Pan, C. T., Rank - revealing QR fatorizations and the singular
value deomposition, Mathematis of Computation 58, 213− 232 (1992).
78
Referênias Bibliográas
[10℄ Júdie, J. J; Patríio, J. M., Sistemas de Equações Lineares, Departamento de
Matemátia da Universidade de Coimbra, Portugal (1996).
[11℄ Leon S. J., Linear Algebra with Appliations, Prentie-Hall International Edi-
tions, New York (1994).
[12℄ Luero, J. C.; Baigorri, R. A.; Munhall K. G., Data-driven faial animation of
speeh using a QR fatorization algorithm, Proeedings of the 7th International
Seminar on Speeh Prodution, pp. 135− 142, Ubatuba - SP (2006).
[13℄ Luero, J. C.; Maiel, S. T. R.; Johns, D. A.; Munhall, K. G., Empirial mode-
ling of human fae kinematis during speeh using motion lustering, Journal
Aoustial Soiety of Ameria 118, 405− 409 (2005).
[14℄ Munhall, K. G., informação privada via e-mail: <munhallkpost.queensu.a>.
[15℄ Alexa, M.; Müller, W., Representing animations by prinipal omponents, EU-
ROGRAPHICS 2000 (Gross M.; Hopgood F. R. A., eds.), pp. 1− 8, Blakwell
Publishers, Malden (2000).
[16℄ Maiel, S. T. R.; Silva, A. M.; Luero, J. C., Fatoração QR para o problema
de seleção de subonjuntos apliado a uma rede de monitoramento da variação
da piezometria, XXX Congresso Naional de Matemátia Apliada Computa-
ional - CNMAC. Anais do XXX Congresso Naional de Matemátia Apliada
e Computaional 1, 1− 7 (2007).
[17℄ Setnes, M.; Babusˇka, R., Rule base redution: some omments on the use of
orthogonal transforms, IEEE Transations on Systems, Man and Cybernetis -
Part C: Appliations and Reviews 31, 199− 206 (2001).
[18℄ Kuratate, T.; Yehia, H.; Vatikiotis-Bateson, E., Kinematis-based synthesis of
realisti talking faes, International Conferene on Auditory - Visual Speeh
Proessing (AVSP'98) (Burnham, D.; Robert-Ribes, J.; Vatikiotis-Bateson E.,
eds.), pp. 185  190, Causal Produtions, Terrigal-Sydney (1998).
[19℄ Trefethen, L. N.; Bau, D., Numerial Linear Algebra, SIAM, Philadelphia
(1997).
79
Referênias Bibliográas
[20℄ Watkins, D. S., Fundamentals of Matrix Computations, John Wiley & Sons,
New York (1991).
80
Apêndie A
Estão relaionados abaixo o ódigo fonte dos programas implementados em Matlab
para gerar os gráos e tabelas que apareem no texto. Alguns programas, Algorit-
mos J, K e L foram adaptados de [12℄ e os outros foram elaborados neste trabalho.
Algoritmo A
Código fonte para gerar a Figura 4.4.
___________________________________________________________________
lear all
load Matriz
MARCADORES = 57;
[k,l℄ = size(trM5);
 = 2;
l = 0;
n = 12;
m = 0;
while (k >= 57) & ( > 1)
for j = 1:k
if mod(j,100) == 0
D = trM5(1:j,:);
C = reshape(D,3*j,MARCADORES);
 = 0;
[q,r,e℄ = qr(C,0);
81
Apêndie A
a = norm(r,'fro');
for i = 1:n
l = l + 1;
R(l) = r(i,i);
b(l) = R(l)/a;
end
end
end
for i = 1:(l/n)
for j = 1:n
m = m + 1;
M(i,j) = b(m);
end
end
plot(abs(M),'-o','MarkerSize',4,'MarkerFaeColor','blak');
xlabel('Amostras \times 100')
ylabel('r_{kk}/||R||_F')
end
if (k < 57)
display('k tem que ser maior ou igual a 57')
end
82
Apêndie A
Algoritmo B
Código fonte para gerar a Figura 4.5.
_____________________________________________________________________
lear all
load MatrizHexa
[M,N℄ = size(A);
P = randperm(M);
C = A(P,:);
k = 16106;
 = 2;
l = 0;
n = 10;
m = 0;
while (k >= 57) & ( > 1)
for j = 1:k
if mod(j,100) == 0
H = C(1:j,:);
W = reshape(H,6*j,N/6);
 = 0;
[q,r,e℄ = qr(W,0);
a = norm(r,'fro');
for i = 1:n
l = l + 1;
R(l) = r(i,i);
b(l) = R(l)/a;
end
end
end
for i = 1:(l/10)
for j = 1:10
83
Apêndie A
m = m + 1;
D(i,j) = b(m);
end
end
plot(abs(D),'-o','MarkerSize',4,'MarkerFaeColor','blak');
xlabel('Amostras \times 100')
ylabel('R_{kk}/||R||_F')
end
if (k < 57)
display('n tem que ser maior ou igual a 57')
end
84
Apêndie A
Algoritmo C
Código fonte para gerar a Figura 4.2.
_____________________________________________________________________
lear all
load DataW
[m,n℄= size(trM);
N = n/3;
trM3 = reshape(trM,3*m,N);
[U,T,V℄ = svd(trM3,0);
for i = 1:57
R(i) = T(i,i);
k(i) = i;
end
plot(k,R,'-ro','MarkerSize',5,'MarkerFaeColor','blak');
xlabel('k')
ylabel('\Sigma_{kk}')
85
Apêndie A
Algoritmo D
Código fonte para gerar a Figura 4.3.
_____________________________________________________________________
lear all
load DataW
[m,n℄= size(trM);
N = n/3;
trM3 = reshape(trM,3*m,N);
[q,r,e℄ = qr(trM3,0);
SIGMA = diag(r);
SIGMA = SIGMA';
for i = 1:57
if SIGMA(i) < 0
M(i,i) = - 1;
else
M(i,i) = 1;
end
end
D = M*r;
for i = 1:57
R(i) = D(i,i);
k(i) = i;
end
plot(k,R,'-ro','MarkerSize',5,'MarkerFaeColor','blak');
xlabel('k')
ylabel('r_{kk}')
86
Apêndie A
Algoritmo E
Código fonte para gerar as Tabela 4.1.
_____________________________________________________________________
lear all
load DataW
[m,n℄ = size(trM);
j = 0;
for i = 1:12
j = j + 1000;
if j < 11975
D = trM(1:j,:);
C = reshape(D,3*j,57);
[q,r,e℄ = qr(C,0);
M(:,i) = e(1:12);
else
j = j - 25;
D = trM(1:j,:);
C = reshape(D,3*j,57);
[q,r,e℄ = qr(C,0);
M(:,i) = e(1:12);
end
end
87
Apêndie A
Algoritmo F
Código fonte para gerar a Tabela 4.2.
_____________________________________________________________________
lear all
load DataW
[m,n℄ = size(trM);
P = randperm(m);
E = trM(P,:);
j = 0;
for i = 1:12
j = j + 1000;
if j < 11975
D = E(1:j,:);
C = reshape(D,3*j,57);
[q,r,e℄ = qr(C,0);
M(:,i) = e(1:12);
else
j = j - 25;
D = E(1:j,:);
C = reshape(D,3*j,57);
[q,r,e℄ = qr(C,0);
M(:,i) = e(1:12);
end
end
88
Apêndie A
Algoritmo G
Código fonte para gerar a Tabela 4.3.
_____________________________________________________________________
lear all
load DataW
[m,n℄ = size(trM);
C = reshape(B,3*m,57);
[q,r,e℄ = qr(C,0);
M = e(1:12);
89
Apêndie A
Algoritmo H
Código fonte para gerar a Figura 4.11.
___________________________________________________________________
lear all
load DataW
load Resultados
load Posiao
IC = 11;
[m,n℄ = size(snt_39);
N = n/3;
%Cálulo do Desloamento
for i = 1:m
for j = 1:n
D(i,j) = snt_39(i,j) - Pos9(1,j);
end
end
[m,n℄ = size(D);
%Matriz Desloamento dos Maradores Prinipais
P3 = reshape(D,3*m,N);
for j = 1:IC
P1(:,j) = P3(:,e(j));
end
% Desloamento dos Maradores Seundários
P2 = P1*AA2;
for i = 1:m
for j = 1:N
x1(i,j) = P3(i,j);
y1(i,j) = P3(m + i,j);
z1(i,j) = P3(2*m + i,j);
90
Apêndie A
x2(i,j) = P2(i,j);
y2(i,j) = P2(m + i,j);
z2(i,j) = P2(2*m + i,j);
end
end
%Comparação dos Maradores Originais om seundários
for i = 28:28
X = [x1(:,i),x2(:,i)℄;
Y = [y1(:,i),y2(:,i)℄;
Z = [z1(:,i),z2(:,i)℄;
plot(X(:,1),'k--');
hold on
plot(X(:,2),'k-');
xlabel('Amostras','FontSize',12);
ylabel('x (mm)','FontSize',12);
%legend('Marador primário x_i', 'Marador seundário x_i');
pause
hold off
lear X
lf
plot(Y(:,1),'K--');
hold on
plot(Y(:,2),'K-');
xlabel('Amostras','FontSize',12);
ylabel('y (mm)','FontSize',12);
%legend('Marador primário y_i','Marador seundário y_i');
pause
hold off
lear Y
lf
plot(Z(:,1),'k--');
hold on
plot(Z(:,2),'k-');
xlabel('Amostras','FontSize',12);
91
Apêndie A
ylabel('z (mm)','FontSize',12);
%legend('Marador primário z_i','Marador seundário z_i');
pause
hold off
lear Z
lf
end
92
Apêndie A
Algoritmo I
Código fonte para gerar as Tabelas 4.4 e 4.5.
_____________________________________________________________________
lear all
load DataW
load Resultados
load Posiao
IC = 10;
[m,n℄ = size(snt_39);
N = n/3;
T = m*3;
k = T*N;
M = 0;
S = 0;
%Cálulo do Desloamento
for i = 1:m
for j = 1:n
D(i,j) = snt_39(i,j) - Pos9(1,j);
end
end
%Matriz Desloamento dos Maradores Prinipais
P3 = reshape(D,3*m,N);
for j = 1:IC
P1(:,j) = P3(:,e(j));
end
% Desloamento dos Maradores Seundários
P2 = P1*AA2;
%Erro de ada Marador Primário e Seundário Respetivamente
for j = 1:N
for i = 1:m
93
Apêndie A
M = M + (P3(i,j) - P2(i,j)).^2 + (P3(m + i,j) -
P2(m + i,j)).^2 + (P3(2*m + i,j) - P2(2*m + i,j)).^2 ;
end
erro(j) = sqrt((1/m)*M);
M = 0;
l(j) = j;
end
erro_medio = sum(erro)/46;
94
Apêndie A
Algoritmo J
Código fonte para gerar a Figuras 4.6 e 4.7.
_____________________________________________________________________
funtion QRanalysis(dfile)
if nargin<1
[filename, pathname℄ = uigetfile( ...
{ '*.mat','MAT files (*.mat)'; ...
'*.*', 'All Files (*.*)'}, ...
'Selet data file', ...
'MultiSelet', 'off');
dfile=fullfile(pathname,filename);
end
load(dfile);
load DataW
[m,n℄ = size(trM);
IC = 10;
N = n/3;
C = reshape(trM,3*m,N);
% QR
[q,r,e℄ = qr(C,0);
% Solve least squares
AA = [eye(IC),r(1:IC,1:IC)\r(1:IC,IC+1:N)℄;
% Put olumns bak into original positions
[a,b℄ = sort(e);
AA2 = AA(:,b);
% Plot faial regions
load map
olormap(map);
LGRID = 100;
% Grid dimension
95
Apêndie A
for i = 1:N;
x(i) = mPos(1,1+(i-1)*3);
y(i) = mPos(1,2+(i-1)*3);
z(i) = mPos(1,3+(i-1)*3);
end
xlin = linspae(min(x),max(x),LGRID);
ylin = linspae(min(y),max(y),LGRID);
[X,Y℄ = meshgrid(xlin,ylin);
Z = griddata(x,y,z,X,Y,'ubi');
ZPos(1,:) = reshape(X,1,LGRID*LGRID);
ZPos(2,:) = reshape(Y,1,LGRID*LGRID);
ZPos(3,:) = reshape(Z,1,LGRID*LGRID);
ZPos = reshape(ZPos,1,3*LGRID*LGRID);
for iC = 1:IC
w = AA2(iC,:);
W = griddata(x,y,w,X,Y,'ubi');
%ZW(iC,:) = reshape(W,1,LGRID*LGRID);
C = W + ones(size(W));
surf(X,Y,W,C,'FaeColor','interp','EdgeColor','none')
axis([0 2℄);
daspet([5 5 1℄)
view(0,90)
axis tight
axis equal
xlabel('X (mm)','FontSize',12);
ylabel('Y (mm)','FontSize',12);
title(['Região n^{o}:',int2str(iC),'-Marador',int2str(e(iC))℄)
hold on
plot3(x,y,z,'ro','MarkerSize',4,'MarkerFaeColor','blak');
pause
hold off
%print('-deps',int2str(iC));
end
% Save results
96
Apêndie A
[filename2, pathname2℄ = uiputfile( ...
{'*.mat','MAT-files (*.mat)'; ...
'*.*', 'All Files (*.*)'}, ...
'Save as', 'Resultados.mat');
save(fullfile(pathname2,filename2),'e','AA2','IC','mPos');
97
Apêndie A
Algoritmo K
Código fonte para gerar as Figuras 4.8 e 4.9.
_____________________________________________________________________
lear all
load DataW
% Reshape trajetory matrix
[m,n℄ = size(trM);
trM3 = reshape(trM,3*m,n/6);
%QR
[q,r,e℄ = qr(trM3,0);
% Plot faial regions
load map
olormap(map);
b = max(abs(r(:,1)));
RR = r/b;
[a,b℄ = sort(e);
RR2 = RR(:,b);
LGRID = 100;
% Grid dimension
for i = 1:n/6;
x(i) = mPos(1,1+(i-1)*3);
y(i) = mPos(1,2+(i-1)*3);
z(i) = mPos(1,3+(i-1)*3);
end
xlin = linspae(min(x),max(x),LGRID);
ylin = linspae(min(y),max(y),LGRID);
[X,Y℄ = meshgrid(xlin,ylin);
Z = griddata(x,y,z,X,Y,'ubi');
ZPos(1,:) = reshape(X,1,LGRID*LGRID);
ZPos(2,:) = reshape(Y,1,LGRID*LGRID);
98
Apêndie A
ZPos(3,:) = reshape(Z,1,LGRID*LGRID);
ZPos = reshape(ZPos,1,3*LGRID*LGRID);
for i = 1:n/6
w = RR2(i,:);
W = griddata(x,y,w,X,Y,'ubi');
C = W + ones(size(W));
surf(X,Y,W,C,'FaeColor','interp','EdgeColor','none')
axis([0 2℄);
daspet([5 5 1℄);
view(0,90)
axis tight
xlabel('x (mm)','FontSize',12);
ylabel('y (mm)','FontSize',12);
title(['Região n^{o}:',int2str(i),' - Linha ',int2str(i)℄)
hold on
plot3(x,y,z,'ko','MarkerSize',4,'MarkerFaeColor','blak');
pause
hold off
%print('-deps',int2str(i));
end
99
Apêndie A
Algoritmo L
Código fonte para gerar animações faiais utilizadas na seção 4.7.
_____________________________________________________________________
lear all
NMARKERS = 57;
IC = 10;
load Resultados
load DataW
iFile = 39;
snt_iFile = eval(['snt_',int2str(iFile)℄);
sentti = CID_31to40{iFile-30};
LGRID = 30;
m = [0.9 0.9 0.7℄;
for i = 1:NMARKERS;
x(i) = mPos(1,1+(i-1)*3);
y(i) = mPos(1,2+(i-1)*3);
z(i) = mPos(1,3+(i-1)*3);
end
xlin = linspae(min(x),max(x),LGRID);
ylin = linspae(min(y),max(y),LGRID);
[X,Y℄ = meshgrid(xlin,ylin);
Z = griddata(x,y,z,X,Y,'ubi');
ZPos(1,:) = reshape(X,1,LGRID*LGRID);
ZPos(2,:) = reshape(Y,1,LGRID*LGRID);
ZPos(3,:) = reshape(Z,1,LGRID*LGRID);
ZPos=reshape(ZPos,1,3*LGRID*LGRID);
for iC = 1:IC
w = AA2(iC,:);
W = griddata(x,y,w,X,Y,'ubi');
ZW(iC,:) = reshape(W,1,LGRID*LGRID);
100
Apêndie A
end
nS = length(snt_iFile);
trM = snt_iFile-ones(nS,1)*mPos;
trM = round(10*trM)/10;
% Reshape trajetory matrix
[m,n℄ = size(trM);
trM3 = reshape(trM,3*m,NMARKERS);
bb1 = trM3(:,e(1:IC))*ZW;
bb1 = reshape(bb1,m,3*LGRID*LGRID);
pos2 = reshape(snt_iFile,3*m,NMARKERS);
position2 = pos2(:,e(1:IC));
position2 = reshape(position2,m,3*IC);
lear pos2 trM trM3 Data AA2 X Y Z x y z w W
lf
olordef blak;
h1 = figure(1);
pf = get(h1,'Position');
pf = [10 200 480 332℄;
set(h1,'Position',pf);
a1=axes;
aviobj = avifile(['QR_',int2str(iFile),'_',int2str(IC),'_huge.avi'℄,
'FPS',120,'COMPRESSION','none');
[m,n℄ = size(bb1);
position = bb1+ones(m,1)*ZPos;
lear bb1
initF=1;
for iT = initF:m
disp(['Now proessing frame ',int2str(iT),'/',int2str(m)℄);
for iM = 1:n/3
x0(iM) = position(iT,1+(iM-1)*3);
y0(iM) = position(iT,2+(iM-1)*3);
z0(iM) = position(iT,3+(iM-1)*3);
end
zz0=reshape(z0,30,30);
101
Apêndie A
for iM = 1:IC
x2(iM) = position2(iT,1+(iM-1)*3);
y2(iM) = position2(iT,2+(iM-1)*3);
z2(iM) = position2(iT,3+(iM-1)*3);
end
if iT == initF
p1 = subplot(1,2,1);
set(p1,'FontSize',10,'LineWidth',1);
p11 = plot(x0,y0,'o','MarkerSize',1,...
'Color',m,'MarkerFaeColor',m);
hold on;p11b=plot(x2,y2,'o','MarkerSize',4,...
'Color','red','MarkerFaeColor','red');hold off;
axis equal
xlabel('X (mm)','FontSize',10);
ylabel('Y (mm)','FontSize',10);
axis([-80 90 -190 -20℄);
set(p1,'Position', [0.124 -0.007 0.427 0.975℄);
set(p1,'NextPlot','add','DrawMode','fast')
p2 = subplot(1,2,2);
set(p2,'FontSize',10,'LineWidth',1);
p12 = plot(z0,y0,'o','MarkerSize',1,...
'Color',m,'MarkerFaeColor',m);
hold on; p12b=plot(z2,y2,'o','MarkerSize',4,...
'Color','red','MarkerFaeColor','red');hold off;
axis equal
xlabel('Z (mm)','FontSize',10);
axis([-80 60 -190 -20℄);
set(p2,'YTikLabel',[℄);
set(p2,'Position',[0.604 0.068 0.352 0.826℄);
set(p2,'NextPlot','add','DrawMode','fast');
t1=title(sentti);
set(t1,'Position',[-124.194 -2.097 1101.181℄,'FontSize',10);
else
set(p11,'XData',x0,'yData',y0);
102
Apêndie A
set(p12,'XData',z0,'yData',y0);
set(p11b,'XData',x2,'yData',y2);
set(p12b,'XData',z2,'yData',y2);
end
drawnow
aviobj = addframe(aviobj,h1);
end
lear x0 y0 z0
aviobj = lose(aviobj);
lose(h1);
103
Apêndie B
Tabela ontendo o onjunto de 40 frases no inglês usadas para onstruir o modelo.
01 It's time to go.
02 If you don't want these old magazines, throw them out.
03 Do you want to wash up?
04 It's a real dark night so wath your driving.
05 I'll arry the pakage for you.
06 Did you forget to shut o the water?
07 Fishing in a mountain stream is my idea of a good time.
08 Fathers spend more time with their hildren than they used to.
09 Be areful not to break your glasses!
10 I'm sorry.
11 You an ath the bus aross the street.
12 Call her on the phone and tell her the news.
13 I'll ath up with you later.
14 I'll think it over.
15 I don't want to go to the movies tonight.
16 If your tooth hurts that muh you ought to see a dentist.
17 Put that ookie bak in the box!
18 Stop fooling around! 
19 Time's up.
20  How do you spell your name?
21 Musi always heers me up.
22 My brother's in town for a short while on business.
23 We live a few miles from the main road.
24 This suit needs to go to the leaners.
25 They ate enough green apples to make them sik for a week.
26 Where have you been all this time?
27 Have you been working hard lately? 
28  There's not enough room in the kithen for a new table.
29 Where is he?
104
Apêndie B
30 Look out!
31 I'll see you right after lunh.
32 See you later.
33 White shoes are awful to keep lean.
34 Stand there and don't move until I tell you!
35 There's a big piee of ake left over from dinner.
36 Wait for me at the orner in front of the drugstore.
37 It's no trouble at all.
38 Hurry up!
39 The morning paper didn't say anything about rain this afternoon or tonight.
40 The phone all's for you.
Tabela 4.6: Conjunto de 40 sentenças em inglês: As 30 primeiras frases foram usadas
para onstruir o modelo e as 10 últimas para realizar testes e validar o modelo.
105
Anexos
Enontram-se abaixo as demonstrações dos Teoremas 2.6, 2.7, 2.9, 2.10 e 2.13 que
apareem no Capítulo 2.
Teorema 2.6
_____________________________________________________________________
Teorema 2.6 Seja P ∈ Rm×n uma reexão de Householder. Então
1. P é simétria;
2. P é ortogonal;
3. ||Px||2 = ||x||2;
4. ||PA||2 = ||A||2;
5. P 2 = I.
onde A ∈ Rm×n.
Demonstração de 1.:
P T = (I − 2vv
T
vTv
)T
= IT − (2vv
T
vTv
)T
= I − 2vv
T
vTv
= P
106
Anexos
Portanto, P é simétria.

Demonstração de 2.:
Pelo ítem 1. temos que P é simétria, então P = P T , assim
PP T = P TP
= (I − 2vv
T
vTv
)2
= I − 4vv
T
vTv
+ 4
v(vTv)vT
(vTv)(vTv)
Como ||v||2 = vTv, então
I − 4vv
T
vTv
+ 4
v(vTv)vT
(vTv)(vTv)
= I − 4vv
T
vTv
+ 4
v(||v||22)vT
||v||42
= I − 4vv
T
vTv
+ 4
vvT
||v||22
= I − 4vv
T
vTv
+ 4
vvT
vTv
= I.
Portanto, P é ortogonal.

Demonstração de 3.:
Usando 1. e 2. temos,
||Px||22 = ||P Tx||22
= (P Tx)T (P Tx)
= (xTP )(P Tx)
= xTx
= ||x||22
portanto, ||Px||2 = ||x||2.

107
Anexos
Demonstração de 4.:
Segue imediatamente do Teorema 1.10.

Demonstração de 5.:
Como P = P T e multipliando por P em ambos os membros, teremos:
P 2 = P TP
= I

108
Anexos
Teorema 2.7
_____________________________________________________________________
Teorema 2.7 Dado um vetor não-nulo x = (x1, x2, · · · , xn)T , podemos enontrar
um vetor v = (v1, v2, · · · , vn)T de maneira que Px é múltiplo de e1 onde a matriz
de householder P é denida pelo vetor v = x± ||x||2e1 e Px = ±||x||2e1.
Demonstração:
Notemos que:
Px =
(
I − 2vv
T
vTv
)
x
= x− 2vv
Tx
vTv
onde Px ∈ 〈e1〉. Este último implia que v ∈ 〈x, e1〉, om isso, v pode ser esrito
omo v = x+ αe1. Assim,
vTx = (x+ αe1)
Tx
= xTx+ αβ
e
vTv = (x+ αe1)
T (x+ αe1)
= xTx+ 2αβ + α2.
Portanto
Px = x− 2 x
Tx+ αβ
xTx+ 2αβ + α2
(x+ αe1)
= x− 2 x
Tx+ αβ
xTx+ 2αβ + α2
x− 2 x
Tx+ αβ
xTx+ 2αβ + α2
αe1
=
(
1− 2 x
Tx+ αβ
xTx+ 2αβ + α2
)
x−
(
2
xTx+ αβ
xTx+ 2αβ + α2
)
αe1. (4.8)
Como Px ∈ 〈e1〉, seque que o omponente em x deve ser nulo, logo(
1− 2 xT x+αβ
xTx+2αβ+α2
)
= 0,
109
Anexos
mas isso só se veria se, e somente se,
xTx+ 2αβ + α2 − 2xTx− 2αβ = 0
e daí, ⇒ α = ±||x||2 e portanto,
v = x∓ ||x||2e1. (4.9)
Sem perda de generalidade, podemos tomar α = ||x||2 e substituindo em (4.8)
obtemos:
Px = −
(
2
xTx+ ||x||2β
xTx+ 2||x||2β + ||x||22
)
||x||2e1
= −
(
2
(||x||2)2 + ||x||2β
||x||22 + 2||x||2β + ||x||22
)
||x||2e1
= −
(
2
||x||22 + ||x||2β
2||x||22 + 2||x||2β
)
||x||2e1
= −
(
2
||x||22 + ||x||2β
2(||x||22 + ||x||2β)
)
||x||2e1
= −||x||2e1. (4.10)
Analogamente, se α = −||x||2 então, Px = ||x||2e1.

110
Anexos
Teorema 2.9
_____________________________________________________________________
Teorema 2.9 Seja A ∈ Rm×n e sua respetiva fatoração QR. Suponha posto(A) =
n e onsidere as seguintes partições A = [a1, a2, · · · , an] e Q = [q1, q2, · · · , qm], onde
ada ai e qj são as respetivas olunas de A e Q, 1 ≤ i ≤ n e 1 ≤ j ≤ m. Então
〈a1, a2, · · · , an〉 = 〈q1, q2, · · · , qn〉 , k = 1, · · · , n. (4.11)
Demonstração:
Comparando a k-ésima oluna de A = QR, onluímos que
ak =
k∑
i=1
rikqi ∈ 〈q1, · · · , qn〉 . (4.12)
Assim, 〈a1, · · · , an〉 ⊆ 〈q1, · · · , qk〉. Como posto(A) = n segue que a matriz R é não
singular, portanto possui inversa, logo AR−1 = Q e daí,
qk =
k∑
i=1
rikak, k = 1, · · · , n, (4.13)
logo, 〈a1, · · · , an〉 ⊇ 〈q1, · · · , qk〉. Daí, 〈a1, a2, · · · , an〉 = 〈q1, q2, · · · , qn〉 onde k =
1, · · · , n.

111
Anexos
Teorema 2.10
_____________________________________________________________________
Teorema 2.10 Seja A ∈ Rm×n, om m ≥ n e suponha que posto(A) = n. Então
existe uma únia matriz Q ∈ Rm×n e R ∈ Rn×n tal que Q têm olunas ortogonais e
R é triangular superior om todas as entradas da diagonal positiva e
A = QR. (4.14)
Demonstração:
Vimos na Seção 2.2 que existem matrizez Q̂ ∈ Rm×n e R̂ ∈ Rn×n, Q̂ om olunas
ortogonais e R̂ triangular superior (não neessariamente om todas as entradas da
diagonal positiva) tal que
A = Q̂R̂.
Como posto(A) = n então a matriz R̂ é não singular, ou seja, det (R̂) 6= 0. Seja D
uma matriz diagonal om elementos dii denida por
dii =
{
1, se r̂ii > 0
−1, se r̂ii < 0. (4.15)
Então D = DT = D−1 e portanto, DDT = I logo, D é ortogonal. Segue que
Q = Q̂D−1 possui todas as olunas ortogonais e R = DR̂ é triangular superior om
rii = diir̂ii > 0 e A = QR. Isso prova a existênia.
Para provar a uniidade usaremos Deomposição de Cholesky (ver [7℄). Esta
deomposição onsiste no seguinte: Dada uma matriz A ∈ Rn×n positiva e denida,
então existe uma únia matriz triangular inferiorG ∈ Rn×n om entradas da diagonal
todas positivas tal que A = GGT .
Suponha que existissem matrizes Q1, Q2, R1 e R2 tais que A = Q1R1 = Q2R2
onde Qi e Ri são matizes om olunas ortogonais e triangular superior respetiva-
mente e i = 1, 2.
AAT = (Q1R1)
T (Q1R1) = R
T
1 Q
T
1Q1R1 = R
T
1 R1
112
Anexos
AAT = (Q2R2)
T (Q2R2) = R
T
2 Q
T
2Q2R2 = R
T
2 R2
daí, RT1 R1 = R
T
2 R2. Pela uniidade da deomposição de Cholesky, devemos ter
RT1 = R
T
2 e portanto, R1 = R2, logo Q1 = Q2. Isso prova a uniidade.

113
Anexos
Teorema 2.13
_____________________________________________________________________
Teorema 2.13 Seja A ∈ Rm×n om posto(A) = r ≤ n. Então existem matrizes
Â, Q e R, tal que Â = AΠ é obtida de A por permutação de olunas, Q ∈ Rm×m
é ortogonal, R =
(
R11 R12
0 0
)
∈ Rm×n, R11 ∈ Rr×r é não-singular e triangular
superior.
Demonstração:
Suponha que r = n, então a matriz A tem posto ompleto e portanto todas as en-
tradas da diagonal da matriz R são todas não-nulas. Portanto, o resultado é uma
deomposição Â = QR, onde Â é a matriz obtida através de A por permutação de
suas olunas. R =
(
R̂
0
)
, onde R̂ é uma matriz triangular superior e não-singular.
Suponha agora que r < n, portanto a matriz A possui posto inompleto. Então,
pelo o que vimos anteriormente, em algum passo durante a deomposição QR om
pivoteamento de olunas, temos que rii = 0, r < i ≤ n. Observe que isso só oorre
se, e somente se, todas as entradas da submatriz restante é nula.
Suponha que isso oorra depois de r passos omputados. Sejam Pi ∈ Rm×m deno-
tando a reexão obtida no passo i, então temos PrPr−1 · · ·P1Â =
(
R11 R12
0 0
)
=
R, onde R11 ∈ Rr×r é triangular superior não singular om as entradas da diagonal
r11, r22, · · · , rrr todas não-nulas e R12 ∈ Rr×(n−r).
Seja Q = P1P2 · · ·Pr, daí QT = PrPr−1 · · ·P1 e portanto QT Â = R donde temos
que Â = QR. Assim, posto(A) = posto(Â) = posto(R) = r onde Q ∈ Rm×m e
R ∈ Rm×n.

114
