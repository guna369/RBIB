Annals of Pure and Applied Logic 134 (2005) 5–41
www.elsevier.com/locate/apal
Comparing and implementing calculi of explicit
substitutions with eta-reduction✩
Mauricio Ayala-Rincóna,∗, Flávio L.C. de Mouraa,
Fairouz Kamareddineb
aDepartamento de Matemática, Universidade de Brasília, Brasília D.F., Brazil
bMathematical and Computer Sciences, Heriot-Watt University, Edinburgh, United Kingdom
Received 17 December 2002; received in revised form 10 May 2004; accepted 23 June 2004
Available online 14 November 2004
Abstract
The past decade has seen an explosion of work on calculi of explicit substitutions. Numerous
works have illustrated the usefulness of these calculi for practical notions like the implementation of
typed functional programming languages and higher order proof assistants. It has also been shown
that eta-reduction is useful for adapting substitution calculi for practical problems like higher order
unification. This paper concentrates on rewrite rules for eta-reduction in three different styles of
explicit substitution calculi: λσ , λse and the suspension calculus. Both λσ and λse when extended
with eta-reduction rules, have proved useful for solving higher order unification. We enlarge the
suspension calculus with an adequate eta-reduction rule which we show to preserve termination and
confluence of the associated substitution calculus and to correspond to the eta rules of the other two
calculi. We prove that λσ and λse as well as λσ and the suspension calculus are non-comparable
while λse is more adequate than the suspension calculus in simulating one-step beta-reduction.
After defining the eta-reduction rule in the suspension calculus, and after comparing these three
calculi of explicit substitutions (all with an eta rule), we then concentrate on the implementation of the
rewrite rules of eta-reduction in these calculi. We note that it is usual practice when implementing the
eta rule for substitution calculi, to mix isolated applications of eta-reduction with the application of
other rules of the corresponding substitution calculi. The main disadvantage of this practice is that the
✩Research partially supported by Grant 47488/01-6 from CNPq.∗ Corresponding author. Fax: +55 61 273 27 37.
E-mail addresses: ayala@mat.unb.br (M. Ayala-Rincón), flavio@mat.unb.br (F.L.C. de Moura),
fairouz@macs.hw.ac.uk (F. Kamareddine).
0168-0072/$ - see front matter © 2004 Elsevier B.V. All rights reserved.
doi:10.1016/j.apal.2004.06.009
6 M. Ayala-Rincón et al. / Annals of Pure and Applied Logic 134 (2005) 5–41
eta rewrite rules so obtained are unclean because they have an operational semantics different from
that of the eta-reduction of the λ-calculus. For the three calculi in question enlarged with adequate
eta rules we show how to implement these eta rules. For the λse we build a clean implementation of
the eta rule and we prove that it is not possible to follow the same approach for the λσ and λSUSP.
© 2004 Elsevier B.V. All rights reserved.
Keywords: Explicit substitutions; λ-calculi; Eta-reduction
1. Introduction
Recent years have witnessed an explosion of work on explicit substitutions [1,7,9,16,17,
21,23,4] and on its usefulness for: automated deduction and theorem proving [32,33], proof
theory [40], programming languages [8,20,28,34] and higher order unification [3,15]. This
paper studies three styles of substitutions:
(1) The λσ -style [1] which introduces two different sets of entities: one for terms and one
for substitutions.
(2) The suspension calculus [37,34], which introduces three different sets of entities: one
for terms, one for environments and one for lists of environments.
(3) The λs-style [23] which uses a philosophy of de Bruijn’s Automath [38] elaborated in
the new item notation [22]. The philosophy states that terms are built by applications
(a function applied to an argument), abstraction (a function), substitution or updating.
The advantages of this philosophy include remaining as close as possible to the
familiar λ-calculus (cf. [22]).
Desired properties of explicit substitution calculi include (a) simulation of β-reduction, (b)
confluence (CR) on closed terms, (c) CR on open terms, (d) strong normalization (SN)
of explicit substitutions and (e) preservation of SN of the λ-calculus. The λσ -calculus
(without eta) satisfies (a), (b), (d) and satisfies (c) only when the set of open terms is
restricted to those which admit meta-variables of sort term. The λs-calculus (without
eta) satisfies (a), . . . , (e) but not (c). However, the λs-calculus has an extension λse (again
without eta) for which (a), (b), (c) hold, but (e) fails and (d) is unknown. The suspension
calculus (which does not have eta) satisfies (a) and when restricted to well-formed terms it
also satisfies (b), (c), (d). For the suspension calculus, (e) is unknown.
The above discussion holds for these calculi without eta-reduction. However, work on
higher order unification (HOU) in λse and λσ established the importance of combining eta-
reduction (as well as expansion) with explicit substitutions. This has provided extensions
of λse and λσ with eta-reduction rules also referred to as λse and λσ (cf. [15,3]). In fact,
due to the importance of eta-reduction, calculi of explicit substitutions (including λσ ) have
been extended with eta rules earlier than the application of λσ to HOU [19,39,12,29]. Eta-
reduction (as well as expansion) is necessary for working with functions and programs,
since one needs to express functional or extensional equality. In particular, when the
application of two lambda terms a and b to any term c yields the same result, then a
and b should be considered equal.
Although λse and λσ have already been extended with eta-reduction, the suspension
calculus still has not. This paper fills the gap and gives the first extension of the rewriting
M. Ayala-Rincón et al. / Annals of Pure and Applied Logic 134 (2005) 5–41 7
system of the suspension calculus with an eta-reduction rule bringing to it the advantages of
the use of eta-reduction in substitutions calculi. Once the suspension calculus is extended
with this eta-reduction rule, one can then compare these three calculi and assess the way
eta-reduction should be implemented in each of them. This paper deals with three useful
notions for these three calculi:
• Extending the suspension calculus with an eta-reduction rule resulting in λSUSP. We
show the soundness of this rule and the confluence and strong normalization of the
underlying substitution calculus with eta.
• Comparing the adequacy of the reduction process of these three substitution calculi
extended with eta-reduction, using the efficient simulation of β-reduction of [26] which
showed that λs and λσ are non-comparable. In this paper we show that λse and λσ
as well as λσ and λSUSP are non-comparable, that λse is more adequate than λSUSP for
simulating one-step beta-reduction.
• Reflecting on the correct definition and adequate implementation of the eta-reduction
rewrite rules in these calculi. It is usual practice when implementing the eta rule
for substitution calculi [11,2] to mix isolated applications of eta-reduction with
the application of other rules of the corresponding substitution calculi. The main
disadvantage of this practice is essentially that the eta rewrite rules so obtained are
unclean because they have an operational semantics different from that of the eta-
reduction rule of the λ-calculus: the notion of functional equivalence embedded in
the eta-reduction should be interpreted modulo the semantics of the corresponding
substitution calculus. For the three calculi enlarged with adequate eta rules we show how
to implement in practice these eta rules without mixing the isolated application of the
eta-reduction with the application of other rules of the associated substitution calculi.
The definition of a successful implementation depends on an effective specification of
a practical method for evaluating the conditions of these eta rules which are conditional
rules of the rewriting systems of the three treated calculi. For each of these explicit
substitution calculi, our implementation consists basically of a linear verification
along a term of the non-existence of occurrences of the free variable of the eta-
reduction while simultaneously upgrading all other free de Bruijn indices and without
applying any additional rewrite rule of the corresponding substitution calculus. The
three implementations are proved complete in the sense that they effectively simulate
eta-reduction over pure lambda terms.
After including the necessary notations and motivation about explicit substitutions, in the
second section, we present the λσ , the λse and the suspension calculus. We enlarge the
latter with an eta-reduction rule which is proved sound in the third section. Then, in the
fourth and fifth sections, we compare the adequacy of these calculi in simulating one-
step beta-reduction and the appropriateness of the defined eta rewriting rules. Finally, and
before concluding, we discuss the clean implementation of these eta rules in the sixth and
seventh sections.
2. Preliminaries
We assume familiarity with the notion of term algebra T (F ,X ) built on a (countable)
set of variablesX and a set of operatorsF . Variables in X are denoted by X, Y, . . . and for
8 M. Ayala-Rincón et al. / Annals of Pure and Applied Logic 134 (2005) 5–41
a term a ∈ T (F ,X ), var(a) denotes the set of variables occurring in a. Throughout, we
take a, b, c, . . . to range over terms. Additionally, we assume familiarity with basic notions
of rewriting as in [5]. In particular, for a reduction relation R over a set A, we denote by=→R the reflexive closure of R , with →∗R or just →∗ the reflexive and transitive closure
of R and with →+R or just →+ the transitive closure of R . When a →∗ b we say that
there exists a derivation from a to b . By a →n b, we mean that the derivation consists of
n steps of reduction and call n the length of the derivation. Syntactical identity is denoted
by a = b. For a reduction relation R over A, (A,→R), we use the standard definitions
of (locally) confluent or (weakly) Church–Rosser (W)CR, normal forms and strong and
weak normalization/termination SN and WN. Suppose R is a SN reduction relation and
let t be a term; then R-nf(t) denotes its normal form. As usual we use indiscriminately
either “Noetherian” or “terminating” instead of SN.
A valuation is a mapping from X to T (F ,X ). The homomorphic extension of a
valuation, θ , from its domain X to the domain T (F ,X ) is called the grafting of θ . As
usual, valuations and their corresponding graftings are denoted by the same Greek letter.
The application of a valuation θ or its corresponding grafting to a term a ∈ T (F ,X ) will
be written in postfix notation aθ . The domain of a grafting θ , is defined by Dom(θ) =
{X | Xθ = X, X ∈ X }. Its range is defined by Ran(θ) = ∪X∈Dom(θ)var(Xθ).
We let var(θ) = Dom(θ) ∪ Ran(θ). For explicit representations of a valuation and its
corresponding grafting θ , we use the notation θ = {X → Xθ | X ∈ Dom(θ)}. Note that the
notion of grafting, usually called first-order substitution, corresponds to simple syntactic
substitution without renaming.
We use notation from [6] for the λ-calculus. Let V be a (countable) set of variables
denoted by lower case last letters of the Roman alphabet x, y, . . . .
Definition 2.1. Terms Λ(V) of the λ-calculus with names are inductively defined by:
Λ(V) ::= x | (Λ(V) Λ(V)) | λx .Λ(V), where x ∈ V . We call λx .a resp. (a b) abstraction
resp. application terms.
Terms in Λ(V) are called closed λ-terms or terms without substitution meta-variables.
An abstraction λx .a represents a function of formal parameter x , whose body is a. Its
application (λx .a b) to an argument b returns the value of a, where x is replaced by
b. This replacement of formal parameters with arguments is known as β-reduction. In
the context of the first-order substitution or grafting, β-reduction would be defined by
(λx .a b) → a{x →b}.
But in this context problems arise forcing the use of α-conversion to rename bound
variables:
(1) Let θ = {x → b}. There are no semantic differences between the abstractions λx .x
and λz .z; both abstractions represent the identity function. But (λx .x)θ = λx .b and
(λz .z)θ = λz .z are different.
(2) Let θ = {x → y}. (λy .x)θ = λy .y and (λz .x)θ = λz .y; thus a capture is possible.
Consequently, β-reduction should be defined in a way that takes care of renaming bound
variables when necessary to avoid harmful capture of variables.
The λ-calculus usually considers substitution as an atomic operation leaving implicit
the computational steps needed to effectively perform computational operations based on
M. Ayala-Rincón et al. / Annals of Pure and Applied Logic 134 (2005) 5–41 9
substitution such as matching and unification. In any real higher order deductive system,
the substitution required by basic operations such as β-reduction should be implemented
via smaller operations. Explicit substitution is an appropriate formalism for reasoning
about the operations involved in real implementations of substitution. Since explicit
substitution is closer to real implementations than to the classic λ-calculus, it provides
a more accurate theoretical model for analyzing essential properties of real systems
(termination, confluence, correctness, completeness, etc.) as well as their time/space
complexity. For further details of the importance of explicit substitution see [28,4].
α-conversion should be performed before applying the substitution in the body of an
abstraction. The grafting of a fresh variable avoids the possibility of capture. It is important
to note that renaming selects fresh variables that have not been used previously. Moreover,
since fresh variables are selected randomly, the result of the application of a substitution
θ to a term a, which we denote in prefix notation θa for discriminating substitution from
grafting, can be conceived as a class of equivalence of terms.
Definition 2.2. β-reduction is the rewriting relation defined by the rewrite rule (β) and
η-reduction is the rewriting relation defined by the rewrite rule (η), where:
(β) (λx .a b) → {x/b}(a)
(η) λx .(a x) → a, if x ∈ Fvar(a),
where Fvar(a) denotes the free variables occurring in a.
Note that our notion of substitution is not completely satisfactory because fresh variables
depend on the history of the renaming process. λ-terms with meta-variables or open λ-
terms are given by:
Definition 2.3. Terms Λ(V,X ), of the λ-calculus with names and meta-variables are
inductively defined by: Λ(V,X ) ::= x | X | Λ(V,X ) Λ(V,X )| λx .Λ(V,X ), where x ∈ V
and X ∈ X .
We have seen that the names of bound variables and their corresponding abstractors play
a semantically irrelevant role in the λ-calculus. So any term inΛ(V) orΛ(V, X) can be seen
as a syntactical representative of its obvious equivalence class. Hence, during syntactic
unification, the role that names of bound variables and their corresponding abstractors play
increases the complexity of the process and creates confusion.
Avoiding names is an effective way of clarifying the meaning of λ-terms and, for the
unification process, of eliminating redundant renaming. De Bruijn proposed in [14] that
names of bound variables be replaced by indices which relate these bound variables to
their corresponding abstractors.
It is clear that the correspondence between an occurrence of a bound variable and its
associated abstractor operator is uniquely determined by its depth, that is the number of
abstractors between them. Hence, λ-terms can be written in a term algebra over the natural
numbersN, representing depth indices, the application operator (_ _) and a sole abstractor
operator λ_; i.e., T ({(_ _), λ_} ∪ N).
In de Bruijn’s notation, indexing the occurrences of free variables is given by a
referential according to a fixed enumeration of the set of variables V , say x, y, z, . . . , and
prefixing all λ-terms with . . . λz .λy .λx ._.
10 M. Ayala-Rincón et al. / Annals of Pure and Applied Logic 134 (2005) 5–41
Now we can define the λ-calculus in de Bruijn notation with open terms or meta-
variables.
Definition 2.4. The set ΛdB(X ) of λ-terms in notation of de Bruijn is defined inductively
as:
ΛdB(X ) ::= n | X | (ΛdB(X ) ΛdB(X )) | λΛdB(X ), where X ∈ X and n ∈ N \ {0}.
ΛdB(X )-terms without meta-variables are called closed λ-terms.
We write de Bruijn indices as 1, 2, 3, . . . , n, . . . , to distinguish them from scripts. Since
all considered calculi of explicit substitutions are built over the language of ΛdB(X ), we
will use Λ to denote ΛdB(X ).
Defining β-reduction in de Bruijn notation’s as (λa b) → {1/b}a (where {1/b}a is
the substitution of the index 1 in a with b) fails: (1) when eliminating the leading
abstractor all indices associated with free variable occurrences in a should be decremented;
(2) when propagating the substitution {1/b} crossing abstractors through a the indices of
the substitution (initially 1) and of the free variables in b should be incremented.
Hence, we need new operators for detecting, incrementing and decrementing free
variables.
Definition 2.5. Let a ∈ ΛdB(X ). The i -lift of a, denoted as a+i is defined inductively as
follows:
(1) X+i = X , for X ∈ X (2) (a1 a2)+i = (a+i1 a+i2 )
(3) (λa1)+i = λa+(i+1)1 (4) n+i =
{
n+ 1, if n > i
n, if n ≤ i.
The lift of a term a is its 0-lift and is denoted briefly as a+.
Definition 2.6. Let n, m ∈ N \ {0}. The application of the substitution by b at the depth
n−1, denoted as {n/b}a, on a term a in ΛdB(X ) is defined inductively as follows:
(1) {n/b}X = X , for X ∈ X (2) {n/b}(a1 a2)={n/b}a1 {n/b}a2
(3) {n/b}λa1 = λ{n + 1/b+}a1 (4) {n/b}m =


m− 1, if m > n
b, if m = n
m, if m < n.
Definition 2.7. β-reduction in the λ-calculus with de Bruijn indices is defined as
(λa b) → {1/b}a.
Observe that the rewriting system of the sole β-reduction rule is left-linear and non-
overlapping (i.e. orthogonal). Consequently, the rewriting system defined over ΛdB(X ) by
the β-reduction rule is CR.
In the λ-calculus with names, the η-reduction rule is defined by λx .(a x) → a, if x ∈
Fvar(a). In ΛdB(X ), the left side of this rule is written as λ(a′ 1), where a′ stands for the
corresponding translation of a under some fixed referential of variables into the language
of ΛdB(X ). “a has no free occurrences of x” means, in Λ(X ), that there are neither
occurrences in a′ of the index 1 at height zero nor of the index 2 at height one nor of
the index 3 at height two, etc. Hence, there is, in general, a term b such that b+ = a.
M. Ayala-Rincón et al. / Annals of Pure and Applied Logic 134 (2005) 5–41 11
Definition 2.8. η-reduction in the λ-calculus with de Bruijn indices is:
λ(a 1) → b if b+ = a.
3. Calculi à la λσ , λse and the suspension calculus
We present λσ , λse and the suspension calculus. We enlarge the latter with an eta-
reduction rule which we prove to be sound and to preserve the confluence of the suspension
calculus.
3.1. The λσ -calculus
The λσ -calculus is a first-order rewriting system that contains the lambda calculus in
de Bruijn notation and which makes explicit the substitutions started by β-reductions [1].
This calculus works on 2-sorted terms: (proper) terms (over which a, b, . . . range), and
substitutions (over which s, t, . . . range). In this calculus, when a substitution {n/b} is
applied to a term a: {n/b}a, we internalize this as a[1. . . . .n− 1.b. ↑n+1]. This means that
all de Bruijn indices except n remain unchanged, while n is replaced with b. Notice that b
is placed at position n of the substitution list, which allows for simultaneous substitutions;
for instance, a[b1.b2. . . .] replaces 1, 2, . . . with b1, b2, . . ., respectively. Operationally, this
calculus applies this kind of substitution decrementing by one the size of the substitution
list as well as the de Bruijn indices. When doing that the operator ↑ is reached, a[↑k]
internalizes the k-lifting of the term a. In this calculus only 1 is used and the other de
Bruijn indices are coded by lifting 1 as we will explain below. For details see [1].
Definition 3.1. The λσ -calculus is defined as the calculus of the rewriting system λσ of
Table 1 where
TERMS a ::= 1 | X | (a a) | λa | a[s], where X ∈ X
SUBSTITUTIONS s ::= id | ↑ | a.s | s ◦ s.
For every substitution s we define the iteration of the composition of s inductively as
s1 = s and sn+1 = s ◦ sn . We use s0 to denote id. Note that the only de Bruijn index used
is 1 , but we can code n by 1[↑n−1].
The equational theory associated with the rewriting system λσ defines a congruence
denoted as =λσ . The congruence obtained by dropping Beta and Eta is denoted as =σ .
We use σ -reduction, σ -normal form, etc., with the obvious meaning, in the case when
reduction is restricted to the σ -rules.
The rewriting system λσ is locally confluent [1], CR on substitution-closed terms (i.e.,
terms without substitution variables) [39] and not CR on open terms (i.e., terms with term
and substitution variables) [13]. The possible forms of a λσ -term in λσ -normal form were
given in [39] by:
(1) λa, where a is a normal term;
(2) a1 . . . ap. ↑n , for a1, . . . , ap normal terms and ap = n;
(3) (a b1 . . . bn), where a is either 1, 1[↑n], X or X[s] for s = id a substitution term in
normal form.
12 M. Ayala-Rincón et al. / Annals of Pure and Applied Logic 134 (2005) 5–41
Table 1
The λσ rewriting system of the λσ -calculus with the eta rule
(Beta) (λa b) −→ a [b · id]
(App) (a b)[s] −→ (a [s]) (b [s])
(Abs) (λa)[s] −→ λ(a [1 · (s ◦ ↑)])
(Clos) (a [s])[t] −→ a [s ◦ t]
(VarCons) 1 [a · s] −→ a
(Id) a[id] −→ a
(Assoc) (s ◦ t) ◦ u −→ s ◦ (t ◦ u)
(Map) (a · s) ◦ t −→ a [t] · (s ◦ t)
(IdL) id ◦ s −→ s
(IdR) s ◦ id −→ s
(ShiftCons) ↑ ◦ (a · s) −→ s
(VarShift) 1· ↑ −→ id
(SCons) 1[s] · (↑ ◦ s) −→ s
(Eta) λ(a 1) −→ b if a =σ b[↑]
In the λ-calculus with names or de Bruijn indices, the rule X{y/a} = X , where y is
an element of V or a de Bruijn index, respectively, is necessary because there is no way to
suspend the substitution {y/a} until X is instantiated. In the λσ -calculus, the application of
this substitution can be delayed, since the term X[s] does not reduce to X . The fact that the
application of a substitution to a meta-variable can be suspended until the meta-variable
is instantiated will be used to code the substitution of variables in X by “X -grafting” and
explicit lifting. Consequently a notion of X -substitution in the λσ -calculus is unnecessary.
Observe that the condition a =σ b[↑] of the Eta rule is stronger than the condition a = b+
given in Definition 2.8 as X = X+, but there exists no term b such that X =σ b[↑].
Note that λσ -reduction is compatible with first-order substitution or grafting and hence
X -grafting and λσ -reduction commute.
3.2. Calculi à la λs and the λse-calculus
Calculi à la λs avoid introducing two different sets of entities and insist on remaining
close to the syntax of the λ-calculus using de Bruijn indices.1 Next to λ and application,
they introduce substitution σ and updating ϕ operators. A term containing neither
substitution nor updating operators is called a pure term. The role of the substitution
operator is to internalize the substitution. Essentially, aσ nb makes operational the
1 It can be argued that because we use de Bruijn indices, we remain close to de Bruijn’s philosophy rather than
to the syntax of the λ-calculus and that instead it is calculi like λx of [10] and λχ of [30] that remain close to the
syntax of the lambda calculus. So, we need to explain here that by staying with the syntax of the λ-calculus we
mean that we do not introduce substitutions and other categories of operators separately as in λσ , but that a term
for us is either an abstraction term, an application term, a substitution term or an updating term.
M. Ayala-Rincón et al. / Annals of Pure and Applied Logic 134 (2005) 5–41 13
Table 2
The λs-rules
σ -generation (λa) b −→ a σ 1 b
σ–λ-transition (λa) σ i b −→ λ(a σ i+1 b)
σ–app-transition (a1 a2) σ i b −→ (a1 σ i b) (a2 σ i b)
σ -destruction n σ i b −→


n− 1 if n > i
ϕi0 b if n = i
n if n < i
ϕ–λ-transition ϕik (λa) −→ λ(ϕik+1 a)
ϕ–app-transition ϕik (a1 a2) −→ (ϕik a1) (ϕik a2)
ϕ-destruction ϕik n −→
{
n+ i− 1 if n > k
n if n ≤ k
application of the substitution {n/b} to a. This operator is propagated into the body of
the abstractors, while all free de Bruijn indices (greater than n) are decreased by one. Once
an occurrence of n is found, b is adequately modified (lifted) by the updating operator. The
operational effect of ϕij b is the (i − 1)-lifting of all de Bruijn indices in b greater than j .
For details see [23,24].
Definition 3.2 (The λs-Calculus). Terms of the λs-calculus are given by:
Λs ::= N | ΛsΛs | λΛs | Λs σ iΛs | ϕikΛs where i ≥ 1 , k ≥ 0.
The set of rules λs is given in Table 2.
The λs-calculus was introduced in [23] with the aim of providing a calculus that preserves
strong normalization and has a confluent extension on open terms [24]. In [23,25], we
establish the properties of these calculi which we list in the following theorem.
Theorem 3.3. The s-calculus is SN; the λs-calculus is confluent on closed terms and
satisfies PSN. Moreover, the λs-calculus simulates β-reduction, is sound and has a
confluent extension on open terms.
We introduce the open terms and the rules that extend λs to obtain the λse-calculus.
Definition 3.4. The set of open terms, denoted as Λsop , is given as follows:
Λsop ::= V |N |ΛsopΛsop | λΛsop |Λsop σ iΛsop | ϕikΛsop where i ≥ 1, k ≥ 0
and where V stands for a set of variables, over which X , Y , . . . range. We take a, b, c to
range over Λsop . Furthermore, closures, pure terms and compatibility are defined as for
Λs.
14 M. Ayala-Rincón et al. / Annals of Pure and Applied Logic 134 (2005) 5–41
Table 3
The new rules of the λse-calculus
σ–σ -transition (a σ i b) σ j c −→ (a σ j+1 c) σ i (b σ j−i+1 c) if i ≤ j
σ–ϕ-transition 1 (ϕik a) σ
j b −→ ϕi−1k a if k < j < k + i
σ–ϕ-transition 2 (ϕik a) σ
j b −→ ϕik (a σ j−i+1 b) if k + i ≤ j
ϕ–σ -transition ϕik (a σ
j b) −→ (ϕik+1 a) σ j (ϕik+1− j b) if j ≤ k + 1
ϕ–ϕ-transition 1 ϕik (ϕ
j
l a) −→ ϕ
j
l (ϕ
i
k+1− j a) if l + j ≤ k
ϕ–ϕ-transition 2 ϕik (ϕ
j
l a) −→ ϕ j+i−1l a if l ≤ k < l + j
Working with open terms one loses confluence as shown by the following counter-
example:
((λX)Y )σ 11 → (Xσ 1Y )σ 11 ((λX)Y )σ 11 → ((λX)σ 11)(Yσ 11)
and (Xσ 1Y )σ 11 and ((λX)σ 11)(Yσ 11) have no common reduct. Moreover, the above
example shows that even local confluence is lost. But since
((λX)σ 11)(Yσ 11) → (Xσ 21)σ 1(Yσ 11)
the solution to the problem seems at hand if one has in mind the properties of meta-
substitutions and updating functions of the λ-calculus in the Bruijn notation. These
properties are equalities which can be given a suitable orientation and the new rules, thus
obtained, added to λs yield a rewriting system which happens to be locally confluent. For
instance, the rule corresponding to the meta-substitution lemma is the σ–σ -transition rule.
The addition of this rule solves the critical pair in our counterexample, since now we have
(Xσ 1Y )σ 11 → (Xσ 21)σ 1(Yσ 11).
Definition 3.5. The set of rules λse is obtained by adding the rules given in Table 3 to
the set λs. The λse-calculus is the reduction system (Λsop,→λse) where →λse is the
least compatible reduction on Λsop generated by the set of rules λse. The calculus of
substitutions associated with the λse-calculus is the rewriting system generated by the set
of rules se = λse − {σ -generation} and we call it se-calculus.
The equational theory associated with the rewriting system λse defines a congruence
=λse . The congruence obtained by dropping σ -generation and Eta (that will be defined
below in Table 4) is denoted by =se . The set of variables of sort TERM in a term a ∈
Tλse(X ) is denoted by T var(a).
We can describe the operators of the λse-calculus over the signature of a first-order
sorted term algebra Tλse(X ) built on X , the set of variables of sort TERM and its subsort
NAT⊂TERM by:
n : → NAT, ∀n ∈ N \ {0}
(_ _) : TERM × TERM → TERM
_σ i _ : TERM × TERM → TERM, ∀i ∈ N \ {0}
λ_ : TERM → TERM
ϕik_ : TERM → TERM, ∀i ∈ N, k ∈ N \ {0}.
M. Ayala-Rincón et al. / Annals of Pure and Applied Logic 134 (2005) 5–41 15
Table 4
The eta rule of the λse-calculus
(Eta) λ(a 1) −→ b if a =se ϕ20 b
In [24] we proved the following:
Theorem 3.6 (WN and CR of se). The se-calculus is weakly normalizing and confluent.
Lemma 3.7 (Simulation of β-Reduction). Let a, b ∈ λ; if a →β b then a → λse b.
Theorem 3.8 (CR of λse). The λse-calculus is confluent on open terms.
Theorem 3.9 (Soundness). Let a, b ∈ λ; if a → λse b then a → β b.
In [3] we proved that:
Proposition 3.10. X -grafting and λse-reduction commute.
This calculus was originally introduced without the Eta rule that was added in [3] to deal
with higher order unification problems as originally done in [15] for the λσ -calculus.
The characterization of the λse-normal forms was given in [24,3] by: a term a ∈ Λse is
a λse-nf if and only if one of the following holds:
(1) a ∈ X ∪ N;
(2) a = bc with b, c in λse-nf and b not an abstraction λd;
(3) a = λb, where b is a λse-nf excluding applications of the form (c 1) where ϕ20d =se c
for some d;
(4) a = bσ j c, where b, c in λse-nf and b is of the form: X or dσ i e, with j < i or ϕidk ,
with j ≤ k;
(5) a = ϕikb, where b is a λse-nf of the form: X or cσ j d , with j > k + 1 or ϕ jl c, with
k < l.
3.3. The suspension calculus
The suspension calculus [37,34] deals with λ-terms as computational mechanisms. This
was motivated by implementational questions related to λProlog, a logic programming
language that uses typed λ-terms as data structures [36]. The suspension calculus works
with three different types of entities:
SUSPENDED TERMS M , N ::= C | n | λM | (M N) | [[M, i, j, e1]]
ENVIRONMENTS e1, e2 ::= nil | et :: e1 | {{e1, i, j, e2}}
ENVIRONMENT TERMS et ::= @i | (M, i) | 〈〈et, i, j, e1〉〉
where C denotes any constant and i, j are non-negative natural numbers.
As constants and de Bruijn indices are suspended terms, the suspension calculus has
open terms. Rather than performing adjustments at each stage, the suspension calculus
notation performs the adjustments into a substitution term only at the final substitution
16 M. Ayala-Rincón et al. / Annals of Pure and Applied Logic 134 (2005) 5–41
Table 5
Rewriting rules of the suspension calculus
(βs ) ((λt1 t2)−→[[t1, 1, 0, (t2, 0) :: nil]]
(r1) [[c, ol, nl, e]]−→ c, where c is a constant
(r2) [[i, 0, nl, nil]]−→i+nl
(r3) [[1, ol, nl, @l :: e]]−→nl-l
(r4) [[1, ol, nl, (t, l) :: e]]−→[[t, 0, (nl-l), nil]]
(r5) [[i, ol, nl, et :: e]]−→[[i-1, (ol-1), nl, e]], for i > 1
(r6) [[(t1 t2), ol, nl, e]]−→ ([[t1, ol, nl, e]] [[t2, ol, nl, e]])
(r7) [[λ t, ol, nl, e]]−→λ [[t, (ol + 1), (nl + 1), @nl :: e]]
(m1) [[[[t, ol1, nl1, e1]], ol2, nl2, e2]]−→[[t, ol′, nl′, {{e1, nl1, ol2, e2}}]], where
ol′ = ol1 + (ol2 . nl1) and
nl′ = nl2 + (nl1 . ol2)
(m2) {{nil, nl, 0, nil}}−→ nil
(m3) {{nil, nl, ol, et :: e}}−→{{nil, (nl-1), (ol-1), e}}, for nl, ol ≥ 1
(m4) {{nil, 0, ol, e}}−→ e
(m5) {{et :: e1, nl, ol, e2}}−→〈〈et, nl, ol, e2〉〉 :: {{e1, nl, ol, e2}}
(m6) 〈〈et, nl, 0, nil〉〉−→ et
(m7) 〈〈@m, nl, ol, @l :: e〉〉−→@(l + (nl . ol)), for nl = m + 1
(m8) 〈〈@m, nl, ol, (t, l) :: e〉〉−→ (t, (l + (nl . ol))), for nl = m + 1
(m9) 〈〈(t, nl), nl, ol, et :: e〉〉−→ ([[t, ol, l′, et :: e]], m), where
l′ = ind(et) and m = l′ + (nl . ol)
(m10) 〈〈et, nl, ol, et ′ :: e〉〉−→〈〈et, (nl-1), (ol-1), e〉〉, for nl = ind(et)
stage. Intuitively, a suspended term of the form [[M, i, j, e1]] means that the first i variables
of the λ-term M must be substituted in a way determined by the environment e1 and its
remaining bound variables must be renumbered according to the fact that M used to appear
within i abstractions but now appears within j of them.
The suspension calculus owns a generation rule βs , that initiates the simulation of a
β-reduction (as for the λσ and the λse, respectively, the Beta and the σ -generation rules
do) and two sets of rules for handling the suspended terms. The first set, the r rules, for
reading suspensions and the second set, the m rules, for merging suspensions are given in
Table 5. As in [37] we denote by rm the reduction relation defined by the r and m rules
in Table 5. The associated substitution calculus, denoted by SUSP, is the one given by the
congruence =rm .
Definition 3.11 ([37]). The length len(e) of an environment e is given by:
len(nil) := 0; len(et :: e′) := len(e′) + 1 and
len({{e1, i, j, e2}}) := len(e1) + (len(e2) . i).
M. Ayala-Rincón et al. / Annals of Pure and Applied Logic 134 (2005) 5–41 17
The index ind(et) of an environment term et , and the l-th index indl(e) of environment
e and natural number l, are simultaneously defined by induction on the structure of
expressions:
ind(@m) = m + 1; ind((t ′, m)) = m;
ind(〈〈et ′, j, k, e〉〉) =
{
indm(e) + ( j . k) if len(e) > j . ind(et ′) = m
ind(et ′) otherwise
indl(nil) = 0; ind0(et :: e′) = ind(et) and indl+1(et :: e′) = indl(e′)
indl({{e1, j, k, e2}}) =


indm(e2) + ( j . k) if l < len(e1) and
len(e2) > m = j . indl(e1)
indl(e1) if l < len(e1) and
len(e2) ≤ m = j . indl(e1)
indl−l1+ j (e2) if l ≥ l1 = len(e1).
The index of an environment e, denoted as ind(e), is ind0(e).
Definition 3.12 ([37]). An expression of the suspension calculus is said to be well-formed
if the following conditions hold over all its subexpressions s:
• if s is [[t, ol, nl, e]] then len(e) = ol and ind(e) ≤ nl;
• if s is et :: e then ind(e) ≤ ind(et);
• if s is 〈〈et, j, k, e〉〉 then len(e) = k and ind(et) ≤ j ;
• if s is {{e1, j, k, e2}} then len(e2) = k and ind(e1) ≤ j .
In the following, we only deal with well-formed expressions of the suspension calculus.
The suspension calculus simulates β-reduction and its associated substitution calculus
SUSP is CR (over closed and open terms) and SN [37]. In [34] Nadathur conjectures that
the suspension calculus preserves strong normalization too but there is still no proof of this
conjecture. The following lemma characterizes the rm -normal forms.
Lemma 3.13 ([37]). A well-formed expression of the suspension calculus x is in its rm-nf
if and only if one of the following affirmations holds:
(1) x is a pure λ-term in de Bruijn notation;
(2) x is an environment term of the form @l or (t, l), where t is a term in its rm -nf;
(3) x is the environment nil or et :: e for et and e resp. an environment term and an
environment in rm-nf.
3.4. The suspension calculus enlarged with η-reduction: the λSUSP-calculus
The suspension calculus was initially formulated without η-reduction. Here we
introduce an adequate Eta rule that enlarges the suspension calculus preserving correctness,
confluence, and termination of the associated substitution calculus. The suspension
calculus enlarged with this Eta rule is denoted by λSUSP and we continue to call its
associated substitution calculus SUSP. The Eta rule is formulated in Table 6. Intuitively
Eta may be interpreted as: when it is possible to apply the η-reduction rule to the redex
18 M. Ayala-Rincón et al. / Annals of Pure and Applied Logic 134 (2005) 5–41
Table 6
The eta rule of the suspension calculus
(Eta) (λ (t1 1)) −→ t2 if t1 =rm [[t2, 0, 1, nil]]
λ(t1 1) we obtain a term t2 that has the same structure as t1 with all its free de Bruijn
indices decremented by one. This is possible whenever there are no free occurrences of the
variable corresponding to 1 in t1. Proposition 3.16 proves the correctness of Eta according
to this interpretation.
Remark 3.14. The reader may wonder whether this is the best formulation of Eta in the
suspension calculus. Indeed, the reader may ask this question also in connection with
the formulation of Eta in both the λσ - and λse-calculi. Initially, [15] intended to use
λ(a[↑]1) → a as a formulation of Eta in the λσ -calculus. However, this formulation
would lead to an infinite set of critical pairs. For this reason, [15] took the formulation
given in Table 1. The same reason led [3] to use a formulation of Eta in the λse-calculus
which uses se convertibility (see Table 4). And indeed for the suspension calculus, we also
get an infinite set of critical pairs if we use (λ ([[t1, 0, 1, nil]] 1)) −→ t1.
We follow [11] and [2] for λσ and λse respectively, and implement the Eta rule of the
λSUSP-calculus by introducing a dummy symbol , by:
λ(M 1) −→Eta N if N = rm -nf([[M, 1, 0, (, 0) :: nil]]) and  does not occur in N .
The correctness of this implementation is explained because an η-reduction λ(M 1) →η
N gives us a term N , which is obtained from M by decrementing by one all free
occurrences of de Bruijn indices, as previously mentioned, and which corresponds exactly
to the rm -normalization of the term ((λM) ) →βs [[M, 1, 0, (, 0) :: nil]], whenever
does not appear in this normalized term.
Lemma 3.15. Let A be a well-formed term of the suspension calculus. Then the SUSP-
normalization of the term [[A, k, k + 1, @k :: @k − 1 :: . . . :: @1 :: nil]] gives a term
obtained from A by incrementing by one all its de Bruijn free indices greater than k and
preserving unaltered all other de Bruijn indices.
Proof. By induction on the structure of A. The constant case is trivial.
• A = n. If n > k: [[n, k, k + 1, @k :: . . . ::@1 ::nil]] →kr5[[n− k, 0, k + 1, nil]] →r2 n+ 1.
If n ≤ k: [[n, k, k + 1, @k :: . . . ::@1 ::nil]] →n−1r5[[1, k − n + 1, k + 1, @k − n + 1 :: . . . ::@1 ::nil]] →r3 n.
• A = (B C). We apply r6 and induction hypothesis for B and C .
• A = (λB). Since B is bounded by an abstractor, only its free variables greater than
k + 1 should be incremented by one; the other variables remain unchanged. Since
[[(λB), k, k + 1, @k :: . . . :: @1 :: nil]] →r7
λ[[B, k + 1, k + 2, @k + 1 :: . . . :: @1 :: nil]], by applying induction hypothesis over
the previous term we obtain the desired result.
M. Ayala-Rincón et al. / Annals of Pure and Applied Logic 134 (2005) 5–41 19
• A = [[t, ol, nl, e]]. Without loss of generality A may be rm -normalized and by
Lemma 3.13 the term obtained is of one of the forms analysed in the previous
cases. 
Proposition 3.16 (Soundness of the Eta Rule). Every application of the Eta rule of λSUSP
to the redex λ(t1 1) gives effectively the term t2 obtained from t1 by decrementing all its de
Bruijn free indices by one.
Proof. The proof is by induction over the structure of t2 considering the premise t1 =rm
[[t2, 0, 1, nil]]. The effect of normalizing [[t2, 0, 1, nil]] is to increment by one all de Bruijn
free indices occurring at t2:
• t2 = n. [[n, 0, 1, nil]] →r2 n+ 1 =rm t1.
• t2 = (A B). Without loss of generality we can assume that both A and B are in
rm -nf. Observe that [[(A B), 0, 1, nil]] →r6 [[A, 0, 1, nil]] [[B, 0, 1, nil]]. Now, by the
induction hypothesis over A and B , we have that the normalization of the suspended
terms [[A, 0, 1, nil]] and [[B, 0, 1, nil]] have the desired effect and consequently the same
happens with the normalization of the suspended term [[(A B), 0, 1, nil]].
• t2 = (λA). As before, assume that A is in rm -nf. Note that [[(λA), 0, 1, nil]] →r7
(λ[[A, 1, 2, @1 ::nil]]). By applying Lemma 3.15 to the term [[A, 1, 2, @1 :: nil]] we
conclude that all free occurrences of de Bruijn indices greater than 1 at A are
incremented by one while the other indices are unchanged.
• t2 = [[t, i, j, e]]. If t is in rm -nf then [[t, i, j, e]] ∗rm t ′, where t ′ is a pure λ-term in de
Bruijn notation by Lemma 3.13. Hence, the analysis given in the previous three cases
applies here too. 
Noetherianity of SUSP plus the Eta rule enables us to apply the Newman diamond
lemma and the Knuth–Bendix critical pair criterion for proving its confluence.
Lemma 3.17 (SUSP+ Eta is SN ). The rewriting system associated with SUSP and the Eta
rule is Noetherian.
Proof (Sketch). This is proved by showing that the Eta rule is also compatible with
the well-founded partial ordering ≺ that is defined and proved compatible with rm
in [37]. 
A simple environment is an environment without subexpressions of the form
{{_, _, _, _}} or 〈〈_, _, _, _〉〉.
Lemma 3.18 ([37]). Let e1 be a simple environment and suppose that nl and ol are
naturals such that (nl − ind(e1)) ≥ ol. Then {{e1, nl, ol, e2}} ∗rm e1.
Lemma 3.19 (Local Confluence of SUSP+ Eta). The rewriting system of the substitution
calculus SUSP plus the Eta rule is locally confluent.
Proof. The rewrite relation rm , i.e., SUSP, was shown in [37] to be (locally) confluent.
Thus for proving that the associated rewriting system enlarged with the Eta rule is locally
confluent, it is enough to show that all additional critical pairs built by overlapping between
the Eta rule and the other rules of SUSP are joinable. Note that no critical pairs are generated
20 M. Ayala-Rincón et al. / Annals of Pure and Applied Logic 134 (2005) 5–41
from Eta and itself. Moreover, there is a unique overlapping between the set of rules in
Table 5 (minus (βs)) and Eta: namely, the one between Eta and (r7).
This critical pair is 〈[[t2, ol, nl, e]], λ[[(t1 1), ol + 1, nl + 1, @nl :: e]]〉, where t1 =rm
[[t2, 0, 1, nil]]. After applying the rules r6 and r3 the right-hand side term of this critical
pair reduces to λ([[t1, ol + 1, nl + 1, @nl :: e]] 1).
We prove by analyzing the structure of t1 that this critical pair is joinable. We take t1
and t2 as rm -nf’s.
• t1 = n. For making possible the Eta application, we need that n > 1. According to the
length of the environment @nl :: e (i.e., ol + 1) we have the following cases:
– ol + 1 < n. On one hand, λ([[n, ol + 1, nl + 1, @nl :: e]] 1) →ol+1r5
λ([[n-ol-1, 0, nl + 1, nil]] 1) →r2 λ(n-ol+ nl 1) →Eta n-ol+ nl-1. On the other
hand, t1 =rm [[t2, 0, 1, nil]]; hence t2 = n-1 and we have [[n-1, ol, nl, e]] →olr5[[n-1-ol, 0, nl, nil]] →r2 n-ol+ nl-1.
– ol + 1 ≥ n. On one hand, λ([[n, ol + 1, nl + 1, @nl :: e]] 1) →n−1r5
λ([[1, ol − n + 2, nl + 1, e1 :: e′]] 1) and the subsequent derivation depends on the
structure of e1: when e1 = @l we apply r3 obtaining λ(nl+ 1-l 1) →Eta nl-l and
on the other hand, [[n-1, ol, nl, e]] →n−2r5[[1, ol − n + 2, nl, @l :: e′]] →r3 nl-l; when e1 = (t, l), where without loss of
generality t is supposed to be in rm -nf, we have
λ([[1, ol − n + 2, nl + 1, (t, l) :: e′]] 1) →r4 λ([[t, 0, nl − l + 1, nil]] 1) →Etarm -n f ([[[[t, 0, nl + 1−l, nil]], 1, 0, (, 0) ::nil]]) →m1
rm -n f ([[t, 0, nl−l, {{nil, nl + 1−l, 1, (, 0) ::nil}}]]) →m3
rm -n f ([[t, 0, nl − l, {{nil, nl − l, 0, nil}}]]) →m2 rm -n f ([[t, 0, nl − l, nil]])
and on the other hand, [[1, ol − n + 2, nl, (t, l) :: e′]] →r4 [[t, 0, nl − l, nil]].
Since rm -n f ([[t, 0, nl − l, nil]]) and [[t, 0, nl − l, nil]] are joinable we obtain the
confluence.
• t1 = (A B). Since the sole rule of the λSUSP that truly “applies” applications is the βs ,
we can separately consider Eta-reductions for A and B and then apply the induction
hypothesis. That is, suppose inductively that λ([[A, ol + 1, nl + 1, @nl :: e]] 1) →Eta
A′′ and [[A′, ol, nl, e]], where
[[A′, 0, 1, nil]] =rm A as well as λ([[B, ol + 1, nl + 1, @nl :: e]] 1) →Eta B ′′ and
[[B ′, ol, nl, e]], where [[B ′, 0, 1, nil]] =rm B are joinable. Then since
λ([[(A B), ol + 1, nl + 1, @nl ::e]] 1) →r6
λ(([[A, ol + 1, nl + 1, @nl ::e]] [[B, ol + 1, nl + 1, @nl ::e]]) 1) →Eta (A′′ B ′′)
and [[(A′ B ′), ol, nl, e]] →r6 ([[A′, ol, nl, e]] [[B ′, ol, nl, e]]) we can conclude that there
is confluence.
• t1 = (λA). By the Eta rule implementation, it is enough to show the join-
ability of the Eta-reduction of the term λ([[(λA), ol + 1, nl + 1, @nl ::e]] 1),
that is SUSP-nf([[[[(λA), ol + 1, nl + 1, @nl ::e]], 1, 0, (, 0) ::nil]]) and the term
[[ SUSP -nf([[(λA), 1, 0, (, 0) ::nil]]), ol, nl, e]].
On the one hand, [[ SUSP -nf([[(λA), 1, 0, (, 0)::nil]]), ol, nl, e]] ∗rm
SUSP-nf([[[[(λA), 1, 0, (, 0)::nil]], ol, nl, e]]) →r7,r7
SUSP-nf((λ[[[[A, 2, 1, @0::(, 0)::nil]], ol + 1, nl + 1, @nl::e]])) ∗rm
(λ SUSP -nf([[[[A, 2, 1, @0::(, 0)::nil]], ol + 1, nl + 1, @nl::e]])) →m1
M. Ayala-Rincón et al. / Annals of Pure and Applied Logic 134 (2005) 5–41 21
(λ SUSP -nf([[A, ol + 2, nl + 1, {{@0::(, 0)::nil, 1, ol + 1, @nl::e}}]]))
and we have that {{@0::(, 0)::nil, 1, ol + 1, @nl::e}} →m5,m5
〈〈@0, 1, ol + 1, @nl::e〉〉::〈〈(, 0), 1, ol + 1, @nl::e〉〉::{{nil, 1, ol + 1, @nl::e}}→m7
@nl::〈〈(, 0), 1, ol + 1, @nl::e〉〉::{{nil, 1, ol + 1, @nl::e}} →m10
@nl::〈〈(, 0), 0, ol, e〉〉::{{nil, 1, ol + 1, @nl::e}} →m3,m4
@nl::〈〈(, 0), 0, ol, e〉〉::e. Then we obtain the term
(λ SUSP -nf([[A, ol + 2, nl + 1, @nl :: 〈〈(, 0), 0, ol, e〉〉 :: e]])). On the other hand,
SUSP-nf([[[[(λA), ol + 1, nl + 1, @nl :: e]], 1, 0, (, 0) :: nil]]) →r7,r7
SUSP-nf((λ[[[[A, ol + 2, nl + 2, @nl + 1 ::@nl ::e]], 2, 1, @0 ::(, 0) ::nil]])) ∗rm
(λ SUSP -nf([[[[A, ol + 2, nl + 2, @nl + 1 ::@nl ::e]], 2, 1, @0 ::(, 0) ::nil]])) →m1
(λrm -nf[[A, ol + 2, nl + 1, {{@nl + 1 ::@nl ::e, nl + 2, 2, @0 ::(, 0) ::nil]]) and we
have that {{@nl + 1 :: @nl :: e, nl + 2, 2, @0 :: (, 0) :: nil}} →m5,m5
〈〈@nl + 1, nl + 2, 2, @0 :: (, 0) :: nil〉〉 :: 〈〈@nl, nl + 2, 2, @0 :: (, 0) :: nil〉〉 ::
{{e, nl + 2, 2, @0 :: (, 0) :: nil}} →m7 @nl :: 〈〈@nl, nl + 2, 2, @0 :: (, 0) :: nil〉〉 ::
{{e, nl + 2, 2, @0 :: (, 0) :: nil}} ∗rm (by Lemma 3.18, since we are working with
well-formed terms and then) ind(e) ≤ nl)
@nl :: 〈〈@nl, nl + 2, 2, @0 :: (, 0) :: nil〉〉 :: e →m10
@nl :: 〈〈@nl, nl + 1, 1, (, 0) :: nil〉〉 :: e →m8 @nl :: (, nl) :: e.
Then we obtain the term (λ SUSP -nf([[A, ol + 2, nl + 1, @nl :: (, nl) :: e]])).
The sole difference of the obtained suspended terms is the second environment
term of their environments, that is 〈〈(, 0), 0, ol, e〉〉 and (, nl). But since the Eta
rule applies, when propagating the substitution between these suspended terms, the
dummy symbol and hence these second environment terms should disappear. Now we
can conclude that these terms are joinable. 
Finally, since the rewriting system associated with SUSP enlarged with the Eta rule
is locally confluent and Noetherian, we can apply the Newman diamond lemma for
concluding that it has confluence.
Theorem 3.20 (Confluence of SUSP+ Eta). The calculus SUSP jointly with the Eta rule is
confluent.
4. Comparing the adequacy of the calculi
According to the criterion of adequacy introduced in [26] we prove that the λσ and the
λSUSP as well as the λσ and the λse are non-comparable. Additionally, we prove that the
λse is more adequate in the simulation of one-step β-reduction than the λSUSP.
Let a, b ∈ Λ such that a →β b. A simulation of this β-reduction in λξ , for
ξ ∈ {σ, se, SUSP}, is a λξ -derivation a →r c →∗ξ ξ(c) = b, where r is the rule starting β
(beta for λσ , σ -generation for λse, βs for λSUSP) applied to the same redex as the redex in
a →β b. The criterion of adequacy is defined as follows:
Definition 4.1 ([26] Adequacy). Let ξ1, ξ2 ∈ {σ, se, SUSP}. The λξ1-calculus is more
adequate (in simulating one-step β-reduction) than the λξ2-calculus, denoted as λξ1 ≺ λξ2,
if:
22 M. Ayala-Rincón et al. / Annals of Pure and Applied Logic 134 (2005) 5–41
• for every β-reduction a →β b and every λξ2-simulation a →nλξ2 b there exists a λξ1-
simulation a →mλξ1 b such that m ≤ n;• there exists a β-reduction a →β b and a λξ1-simulation a →mλξ1 b such that for every
λξ2-simulation a →nλξ2 b we have m < n.
If neither λξ1 ≺ λξ2 nor λξ2 ≺ λξ1, then we say that λξ1 and λξ2 are non-comparable.
The counterexamples proving that λσ and λs are non-comparable presented in [26] apply
also to the incomparability of λσ and λse since λse is an extension of λs for open terms.
Proposition 4.2. The λσ - and the λse-calculi are non-comparable.
Lemma 4.3. Every λσ -derivation of ((λλ2) 1) to its λσ -nf has length greater than or
equal to 6.
Proof. In fact, all possible derivations are of one of the following forms.
• (λλ1[↑]) 1 →Beta (λ1[↑])[1.id] →Abs λ1[↑][1.((1.id)◦ ↑)] →Clos
λ1[↑ ◦(1.((1.id)◦ ↑))] →ShiftCons λ1[(1.id)◦ ↑] →Map λ1[1[↑].(id◦ ↑)] →VarCons
λ1[↑] = λ2;
• (λλ1[↑]) 1 →Beta (λ1[↑])[1.id] →Abs λ1[↑][1.((1.id)◦ ↑)] →Clos
λ1[↑ ◦(1.((1.id)◦ ↑))] →ShiftCons λ1[(1.id)◦ ↑] →Map λ1[1[↑].(id◦ ↑)] →IdL
λ1[1[↑]. ↑] →VarCons λ1[↑] = λ2;
• (λλ1[↑]) 1 →Beta (λ1[↑])[1.id] →Abs λ1[↑][1.((1.id)◦ ↑)] →Clos
λ1[↑ ◦(1.((1.id)◦ ↑))] →Map λ1[↑ ◦(1.(1[↑].(id◦ ↑)))] →ShiftCons
λ1[1[↑].(id◦ ↑)] →VarCons λ1[↑] = λ2;
• (λλ1[↑]) 1 →Beta (λ1[↑])[1.id] →Abs λ1[↑][1.((1.id)◦ ↑)] →Clos
λ1[↑ ◦(1.((1.id)◦ ↑))] →Map λ1[↑ ◦(1.(1[↑].(id◦ ↑)))] →ShiftCons
λ1[1[↑].(id◦ ↑)] →IdL λ1[1[↑]. ↑] →VarCons λ1[↑] = λ2;
• (λλ1[↑]) 1 →Beta (λ1[↑])[1.id] →Abs λ1[↑][1.((1.id)◦ ↑)] →Map
λ1[↑][1.(1[↑].(id◦ ↑))] →Clos λ1[↑ ◦(1.(1[↑].(id◦ ↑)))] →ShiftCons
λ1[1[↑].(id◦ ↑)] →VarCons λ1[↑] = λ2;
• (λλ1[↑]) 1 →Beta (λ1[↑])[1.id] →Abs λ1[↑][1.((1.id)◦ ↑)] →Map
λ1[↑][1.(1[↑].(id◦ ↑))] →Clos λ1[↑ ◦(1.(1[↑].(id◦ ↑)))] →ShiftCons
λ1[1[↑].(id◦ ↑)] →IdL λ1[1[↑]. ↑] →VarCons λ1[↑] = λ2;
• (λλ1[↑]) 1 →Beta (λ1[↑])[1.id] →Abs λ1[↑][1.((1.id)◦ ↑)] →Map
λ1[↑][1.(1[↑].(id◦ ↑))] →IdL λ1[↑][1.(1[↑]. ↑)] →Clos
λ1[↑ ◦(1.(1[↑]. ↑))] →ShiftCons λ1[1[↑]. ↑] →VarCons λ1[↑] = λ2. 
In the following lemmas, (M 1n) is shorthand for n applications of 1, i.e.,
(. . . ((M 1)1) . . . 1).
Lemma 4.4. Every λSUSP-derivation of (λλ(2 2)) 1n to its λSUSP-nf has length 4n + 5.
Proof. In fact, note that the sole possible derivation is:
(λλ(2 2)) 1n →βs [[(λ(2 2)), 1, 0, (1n, 0) ::nil]] →r7 λ[[(2 2), 2, 1, @0 ::(1n, 0) ::nil]] →r6
λ([[2, 2, 1, @0 ::(1n, 0) ::nil]] [[2, 2, 1, @0 ::(1n, 0) ::nil]]) →2r5
λ([[1, 1, 1, (1n, 0) ::nil]] [[1, 1, 1, (1n, 0) ::nil]]) →2r4 λ([[1n, 0, 1, nil]] [[1n, 0, 1, nil]])
→2(n−1)r6 λ(([[1, 0, 1, nil]])n ([[1, 0, 1, nil]])n) →2nr2 λ(2n 2n). 
M. Ayala-Rincón et al. / Annals of Pure and Applied Logic 134 (2005) 5–41 23
Lemma 4.5 ([26]). There exists a derivation of (λλ(2 2)) 1n to its λσ -nf whose length is
n + 9.
Proof. Consider the following derivation:
(λλ(2 2)) 1n = (λλ(1[↑] 1[↑])) 1n →Beta (λ(1[↑] 1[↑]))[1n.id] →Abs
λ((1[↑] 1[↑])[1.((1n .id)◦ ↑)]) →Map
λ((1[↑] 1[↑])[1.(1n[↑].(id◦ ↑))]) →n−1App λ((1[↑] 1[↑])[1.((1[↑])n.(id◦ ↑))]) →App
λ((1[↑][1.((1[↑])n.(id◦ ↑))]) (1[↑][1.((1[↑])n.(id◦ ↑))])) →Clos
λ((1[↑ ◦(1.(1[↑])n.(id◦ ↑))]) (1[↑][1.((1[↑])n.(id◦ ↑))])) →ShiftCons
λ((1[(1[↑])n.(id◦ ↑)]) (1[↑][1.((1[↑])n.(id◦ ↑))])) →VarCons
λ((1[↑])n (1[↑][1.((1[↑])n.(id◦ ↑))])) →3 λ((1[↑])n (1[↑])n) = λ(2n 2n). 
Proposition 4.6. The λσ - and λSUSP-calculi are non-comparable.
Proof. On one hand, by Lemmas 4.4 and 4.5, there exists a simulation (λλ(2 2)) 1n →λσ
λ(2 2) shorter than the shortest of the simulations
(λλ(2 2)) 1n →λSUSP λ(2 2). Then λSUSP ≺ λσ .
On the other hand, consider the following simulation in λSUSP:
((λλ2) 1) →βs [[(λ2), 1, 0, (1, 0) :: nil]] →r7 λ[[2, 2, 1, @0 :: (1, 0) :: nil]] →r5
λ[[1, 1, 1, (1, 0) :: nil]] →r4 λ[[1, 0, 1, nil]] →r2 λ2.
This simulation and the Lemma 4.3 allows us to conclude that λσ ≺ λSUSP. 
To prove that λse is more adequate in the simulation of one-step β-reduction than λSUSP
we need to estimate the lengths of derivations.
Definition 4.7. Let A, B, C ∈ Λ and k ≥ 0. We define the functions M : Λ → N and
Qk : Λ× Λ → N by:
• M(n)=1
• M(λA)= M(A)+1
• M(A B)= M(A)+M(B)+1
• Qk(n, B)=


n if n<k
n+M(B) if n=k
k+1 if n>k
• Qk((A B), C)= Qk(A, C)+Qk(B, C)+1 • Qk(λA, B)= Qk+1(A, B)+1.
Lemma 4.8. Let A ∈ Λ. Then all se-derivations of ϕik A to its se-nf have length M(A).
Proof. By simple induction over the structure of A. This is an easy extension of the same
lemma formulated for the λs-calculus in [26]. 
Lemma 4.9. Let A ∈ Λ. Then all SUSP-derivations of the well-formed term
[[A, i, i, @i − 1 :: . . . :: @0 :: nil]] to its SUSP-nf have length greater than or equal to
M(A).
Proof. By induction over the structure of terms.
• A = n. If n > i then [[n, i, i, @i − 1 :: . . . :: @0 :: nil]] →ir5 [[n− i, 0, i, nil]]→r2 n. The length of the derivation is i + 1 ≥ M(A). If n ≤ i then[[n, i, i, @i − 1 :: . . . ::@0 ::nil]]→n−1r5 [[1, i − n + 1, i, @i − n :: . . . ::@0 ::nil]]→r3 n.
The length of the derivation is n ≥ M(A).
24 M. Ayala-Rincón et al. / Annals of Pure and Applied Logic 134 (2005) 5–41
• A = (B C). We have that [[(B C), i, i, @i − 1 :: . . . :: @0 :: nil]] →r6
([[B, i, i, @i − 1 :: . . . :: @0 :: nil]] [[C, i, i, @i − 1 :: . . . :: @0 :: nil]]). By the induc-
tion hypothesis we conclude that the length of the derivation is greater than or equal to
1 + M(B) + M(C) = M(B C) = M(A).
• A = (λB). We have that [[(λB), i, i, @i − 1 :: . . . :: @0 :: nil]] →r7
λ[[B, i + 1, i + 1, @i :: . . . :: @0 :: nil]]. By the induction hypothesis we conclude that
the length of the derivation is greater than or equal to 1 + M(B) = M(λB) =
M(A). 
Lemma 4.10. Let B ∈ Λ and i, j ≥ 0. The derivation of the SUSP-term
[[B, i, j, @ j − 1 :: e]] to its SUSP-nf has length greater than or equal to M(B).
Proof.
• Case B = n, [[n, i, j, @ j − 1 :: e]] rewrites to its SUSP-nf in one or more steps
depending on n.
• Case B = (C D); we have [[(C D), i, j, @ j − 1 ::e]] →r6 [[C, i, j, @ j − 1 ::e]][[D, i, j, @ j − 1 :: e]]. By the induction hypothesis we obtain the desired result.
• Case B = (λC); [[(λC), i, j, @ j − 1 :: e]] →r7 λ[[C, i + 1, j + 1, @ j :: e′]] and by the
induction hypothesis we complete the proof. 
Proposition 4.11. Let A, B ∈ Λ and k ≥ 0. Then every SUSP-derivation of
[[A, k, k − 1, @k − 2 :: . . . :: @0 :: (B, l) :: nil]] to its SUSP-nf has length greater than or
equal to Qk(A, B).
Proof. By structural induction over A.
• A = n. If n < k then [[n, k, k − 1, @k − 2 :: . . . ::@0 ::(B, l) ::nil]] →n−1r5[[1, k − n + 1, k − 1, @k − n − 1 :: . . . ::@0 ::(B, l) ::nil]] → r3 n. This derivation has
length n ≥ Qk(n, B).
If n = k then [[n, k, k − 1, @k − 2 :: . . . ::@0 ::(B, l) ::nil]] →n−1r5[[1, 1, k − 1, (B, l) ::nil]] → r4 [[B, 0, k − 1 − l, nil]]. By Lemma 4.10 the last term
rewrites to its SUSP-nf in M(B) or more rewrite steps. The whole derivation has length
greater than or equal to n + M(B) = Qk(n, B) = Qk(A, B).
If n > k then [[n, k, k − 1, @k − 2 :: . . . ::@0 ::(B, l) ::nil]] →kr5 [[n-k, 0, k-1, nil]] →r2
n− 1. This derivation has length k + 1 ≥ Qk(n, B) = Qk(A, B).
• A = (C D). [[(C D), k, k − 1, @k − 2 :: . . . ::@0 ::(B, l) ::nil]] →r6
([[C, k, k-1, @k-2 :: . . . ::@0 ::(B,0) ::nil]] [[D, k, k-1, @k-2 :: . . . ::@0 ::(B,0) ::nil]]).
By the induction hypothesis the derivation has length greater than or equal to
1 + Qk(C, B) + Qk(D, B)= Qk((C D), B)= Qk(A, B).
• A = λC. [[(λC), k, k − 1, @k − 2 :: . . . ::@0 ::(B, l) ::nil]] →r7
λ[[C, k + 1, k, @k − 1 :: . . . ::@0 ::(B, l) ::nil]]. By the induction hypothesis we can
conclude that this derivation has length greater than or equal to
1 + Qk+1(C, B) = Qk(λC, B) = Qk(A, B). 
Proposition 4.12. Let A, B ∈ Λ and k ≥ 1. se-derivations of Aσ k B to its se-nf have length
≤ Qk(A, B).
M. Ayala-Rincón et al. / Annals of Pure and Applied Logic 134 (2005) 5–41 25
Proof. By structural induction over the pure lambda term A.
• A = n. By applying the σ -destruction rule, in the case n = k, we obtain either n− 1 or
n and, in the case n = k, ϕk0 B . In the case that n = k, the derivation has length equal
to 1 ≤ Qk(n, B). In the other case, we apply Lemma 4.8 obtaining that the complete
se-normalization has length 1 + M(B). In both cases the derivation has length less than
or equal to Qk(n, B).
• A = (C D). (C D)σ k B → (Cσ k B Dσ k B). By applying the induction hypothesis we
conclude that the complete derivation has length less than or equal to 1 + Qk(C, B) +
Qk(D, B) = Qk((C D), B).
• A = (λC). (λC)σ k B → λ(Cσ k+1 B). By the induction hypothesis we conclude that the
whole derivation has length less than or equal to 1 + Qk+1(C, B) = Qk(λC, B). 
Theorem 4.13 (λse ≺λSUSP). The λse is more adequate in the simulation of one-step β-
reduction than the λSUSP-calculus.
Proof. We prove the stronger result that if A ∈ Λ and A →βs B →mSUSP SUSP-nf(B)
is a λSUSP-simulation of a β-reduction then: A →σ−generation C →nse se-nf(C) has length
n + 1 ≤ m + 1.
In λSUSP, for any redex of βs we have (λD) E →βs [[D, 1, 0, (E, 0) ::nil]] →mSUSP SUSP-
nf([[D, 1, 0, (E, 0) ::nil]]). In the λse, (λD) E →σ−generation Dσ 1 E →nse se-nf(Dσ 1 E).
By Propositions 4.11 and 4.12, m ≥ Q1(D, E) ≥ n. Hence, the length of a λSUSP-
simulation of a β-reduction is not shorter than that of some λse-simulation.
The second part of being more adequate is shown by comparing the length of
simulations. For example, let (λ2) 1 →β 1. In λSUSP the only possible three-step simulation
is: (λ2) 1 →βs [[2, 1, 0, (1, 0) ::nil]] →r5 [[1, 0, 0, nil]] →r2 1. In λse the only possible two-
step simulation is: (λ2) 1 →σ−generation 2σ 11 →σ−destruction 1. 
As mentioned in the above proof, we prove a stronger result than simple better adequacy
of λse as in [26]. In fact, we prove that the lengths of all λse-simulations are shorter than
the length of any λSUSP-simulation. Examining the proofs of Propositions 4.11 and 4.12
which relate the length of derivations to the measure operator Qk , it appears evident that
the two calculi work similarly except that after having propagated suspended terms into the
body of abstractors, λSUSP deals with the substitutions in a less efficient way. To explain
that, compare the simulations of β-reduction from the term (λ(λni)) j, where n ≥ 0:
(λ(λni))j →σ−gen (λni)σ 1j →nσ−λ−trans λn(iσ n+1j) =: t1
(λ(λni))j→βs [[λni, 1, 0, (dbj, 0) :: nil]] →nr7
λn[[i, n + 1, n, @n-1 :: . . . :: @0 :: (j, 0) :: nil]] =: t2.
After that, the λse complete the simulation in one or two steps by checking arithmetic
inequations:
t1 →σ−dest


λni, if i < n + 1
λni− 1, if i > n + 1
λn(ϕn+10 j) →ϕ−dest λnj+ n, if i = n + 1.
26 M. Ayala-Rincón et al. / Annals of Pure and Applied Logic 134 (2005) 5–41
But in the λSUSP we have to destruct the environment list, environment by environment:
t2


→i−1r5 λn[[1, n-i + 2, n, @n-i :: . . . ::@0 :: (j, 0) ::nil]] →r3 λni, if i < n + 1
→n+1r5 λn[[i− n− 1, 0, n, nil]] →r2 λni− 1, if i > n + 1
→i−1r5 λn[[1, 1, n, (j, 0) ::nil]] →r4 λn[[j, 0, n, nil]] →r2 λnj+ n, if i = n + 1.
These simple considerations lead us to believe that the main difference of the two calculi
(at least in the simulation of β-reduction) is given by the manipulation of indices: although
λSUSP includes all de Bruijn indices, it does not profit from the existence of the built-in
arithmetic for indices. These observations may be relevant for the treatment of the open
question of preservation of strong normalization of λSUSP (conjectured positively in [34]),
since the λse has been proved to answer this question negatively in [18].
5. Relating the Eta rules
Ref. [3] established the correspondence between the Eta rules of λσ and λse through the
premises t[↑] =σ M and ϕ20 t =se M , where t ∈ ΛdB. This correspondence means that the
effect of applying the substitution [↑], in λσ , and the upgrading ϕ20 , in λse, to a pure λ-term
are identical. This implies that these Eta rules are equivalent when applied to a pure λ-term.
Hence, it remains to show that the results, in the two calculi, of applying the substitution
[↑] and the upgrading operator ϕ20 to a λ-term t are equal (up to the codification of the term
in the internal language of the calculus). This is the case k = 0 of the third item of the
following lemma.
Lemma 5.1 (Eta Correspondence of λσ and λse [3]).
(1) Let n be a de Bruijn index. Then, for k ≥ 0, the se-nf of ϕ2kn and the σ -nf of
n[1.1[↑].1[↑2] . . . 1[↑k−1]. ↑k+1] are corresponding de Bruijn indices.
(2) Let λt an abstraction over ΛdB. Then, for k ≥ 0,
(λt)[1.1[↑].1[↑2]. . . . .1[↑k−1]. ↑k+1] σ -rewrites to
λ(t[1.1[↑].1[↑2] . . .1[↑k]. ↑k+2]).
(3) Let us have t ∈ ΛdB and t ′ its codification in the language of λσ , where all de Bruijn
indices n ∈ N occurring in t are replaced with 1[↑n−1]. Then, for k ≥ 0, the σ -nf of
t ′[1.1[↑].1[↑2]. . . . .1[↑k−1]. ↑k+1] corresponds to the se-nf of ϕ2k t.
Analogously to the previous lemma, in the next proposition we establish the
correspondence between the rules Eta of λSUSP and λse ; i.e., the correspondence, in the
above-mentioned sense, between the terms at their premises: [[t, 0, 1, nil]] and ϕ20 t , for
t ∈ ΛdB. This corresponds to the case k = 0 of the following proposition.
Proposition 5.2 (Eta Correspondence of λSUSP and λse). Let t ∈ ΛdB. Then, for all k ≥ 0,
the SUSP-nf of the suspended term
[[t, k, k + 1, @k :: @k − 1 :: . . . :: @1 :: nil]]
corresponds to the se-nf of ϕ2k t.
M. Ayala-Rincón et al. / Annals of Pure and Applied Logic 134 (2005) 5–41 27
Proof. This is done by induction on the structure of t .
• t = n. By Lemma 3.15 we have that for all k ≥ 0,
[[n, k, k + 1, @k :: @k − 1 :: . . . :: @1 :: nil]] →
{
n+ 1 if n > k
n if n ≤ k.
This coincides with the result of applying the rule ϕ-dest to the term ϕ2kn.• t = (A B). [[(A B), k, k+1, @k ::@k−1 :: . . .::@1 ::nil]] →r6
([[A, k, k + 1, @k :: . . . :: @1 :: nil]] [[B, k, k+1, @k :: . . .::@1 ::nil]]) I H≡
(ϕ2k A ϕ
2
k B). Also, ϕ
2
k t →ϕ−app (ϕ2k A ϕ2k B).• t = (λA). [[(λA), k, k+1, @k ::@k−1 :: . . .::@1 :: nil]] →r7
(λ[[A, k+1, k+2, @k+1 :: . . .::@1 ::nil]]) I H≡ (λϕ2k+1 A). Also, ϕ2k (λA) →σλ−trans
(λϕ2k+1 A). 
This correspondence is not obvious for open terms. In fact, let c be a constant. On one
hand, in λSUSP, we have that [[c, k, k + 1, @k :: . . . :: @1 :: nil]] →r1 c. On the other hand,
ϕ2k c is irreducible in λse. Both terms can, in a certain sense, be considered equivalent since
the upgrading operator ϕ2k does not modify the constant c and this correspondence could
be assumed in other practical contexts such as those of higher order unification via explicit
substitutions.
The following notational conventions are useful for the rest of the paper:
Notation 5.3. Let ξ ∈ {σ, se, SUSP}, and let λξ be the corresponding explicit substitution
calculus. The generation rules of λξ (i.e. the Beta, σ -generation or βs rules), will be
denoted correspondingly by λξ -gen. Similarly, Etaξ denotes the corresponding Eta rule.
ξ denotes the associated substitution calculus, that is given by the rewriting rules of
the calculus λξ except the ξ -gen and the Etaξ rules. The congruence generated by the
rules of the substitution calculus ξ is denoted by =ξ . We denote by ξ -nf(M) the ξ -normal
form of the λξ -term M. If M has a λξ -gen redex at the root position then we denote by
genλξ (M, root) its contractum.
Now, we establish the appropriateness of the three Eta rules of λσ , λse and λSUSP. By
appropriateness of a specific Eta rule we understand that every pure λ-term which contains
an Eta redex is reduced to the same pure λ-term by the usual η-rule as well as by the
specific Eta rule.
Lemma 5.4 (Appropriateness of the Eta Rules). Let a ∈ ΛdB. The following statements
are equivalent:
(a) λ(a 1)→ηb;
(b) λ(a 1)→Etaξ b, where ξ stands for σ , se or SUSP.
Proof. Suppose (a) is true. Then by structural induction on the term a:
(1) λSUSP: We will show that [[b, 0, 1, nil]] =SUSP a.
• a = n (n > 1): [[n− 1, 0, 1, nil]] →2 n.
• a = (c d). b+ = (c d) means that b is obtained from (c d) decreasing all its free
indices by one. Now note that the effect of normalizing [[b, 0, 1, nil]] is to increase
all free indices of b by one as shown in the proof of the Proposition 3.16.
28 M. Ayala-Rincón et al. / Annals of Pure and Applied Logic 134 (2005) 5–41
• a = λc. Suppose b+ = λc so b is obtained from λc decreasing all free indices in c
but 1 by one and conclude considering the same argument as the previous item.
(2) λse: This is a straightforward from the previous item and Proposition 5.2.
(3) λσ : This is a straightforward from the previous item and Lemma 5.1.
Conversely, we will show that:
(1) In λSUSP that [[b, 0, 1, nil]] =SUSP b+:
• [[n− 1, 0, 1, nil]] →r2 n = (n− 1)+.
• [[(c d), 0, 1, nil]] →r6 [[c, 0, 1, nil]] [[d, 0, 1, nil]] I H= c+ d+ = (c d)+.
• [[λc, 0, 1, nil]] →r7 λ[[c, 1, 2, @1 :: nil]] I H= λc+1 = (λc)+.
(2) In λse that ϕ20(b) = b+:
• ϕ20(n− 1) →ϕ−destr n = (n− 1)+
• ϕ20(c d) →ϕ−app ϕ20(c) ϕ20(d) I H= c+ d+ = (c d)+.
• ϕ20(λc) →ϕ−λ λ(ϕ21c) I H= λ(c+1) = (λc)+.
(3) In λσ that b[↑] = b+:
• 1[↑n−2][↑] →Clos 1[↑n−1] = (n− 1)+.
• (c d)[↑] →App c[↑] d[↑] I H= c+ d+ = (c d)+.
• (λc)[↑] →Abs λ(c[1. ↑2]) I H= λc+1 = (λc)+. 
6. Usual implementations of Eta
In the following we use “η” for η-reduction, and “Eta” for the Eta-reduction rules of the
explicit substitutions calculi. By an “implementation” of the Eta rule of any of the three
treated calculi of explicit substitutions we understand an effective computational mecha-
nism for evaluation of the premise of the conditional rewriting Eta rule, which allows for
deciding the occurrence of Eta-redices and their subsequent reduction. In other words, an
implementation is an effective mechanism for deciding the one step Eta-reduction relation.
When implementing the one-step reduction of these calculi one has to take into account
that the given Eta rule and its suggested implementation are not clean in the sense that
one application of Eta-reduction can involve applications of other rules of the substitution
calculus.
In an explicit substitutions calculus λξ , a clean implementation of the η-reduction
does not apply additional rules of the associated substitution calculus ξ during a one-step
application of the implemented η-reduction.
Definition 6.1 (Clean Implementations of η-Reduction). An implementation of η-reduc-
tion, say ImEtaξ , in an explicit substitution calculus λξ is said to be clean if for any
λξ -term M , whenever we obtain N from M by applying this implementation of the η-
reduction, denoted by M →ImEtaξ N , there is no N ′ such that M →Etaξ N ′ and N ′ →∗ξ N .
An implementation of η-reduction that is not clean is called unclean.
Lemma 6.2 (The Eta Rules are Unclean). The implementations of η-reduction directly
from the Etaξ rewriting rules of the three treated calculi are unclean.
M. Ayala-Rincón et al. / Annals of Pure and Applied Logic 134 (2005) 5–41 29
Table 7
Detection of redices for Abs of λσ
let rec matchingAbs exp l pos =
match exp with Dummy -> l | One -> l | Vr c -> l |
A(e1,e2) -> append (matchingAbs e1 l (append pos [1]))
(matchingAbs e2 [] (append pos [2])) |
L(e1) -> matchingAbs e1 l (append pos [1]) |
Sb(L(e1),sb) -> pos::append(matchingAbs e1 l (append pos [1;1]))
(matchingAbsSb sb [] (append pos [2]))|
Sb(e1,sb) -> append (matchingAbs e1 l (append pos [1]))
(matchingAbsSb sb [] (append pos [2]))
and matchingAbsSb subs l pos =
match subs with Up -> l | Id -> l |
Pt(e1,sb) -> append (matchingAbs e1 l (append pos [1]))
(matchingAbsSb sb [] (append pos [2])) |
Cp(s1,s2) -> append (matchingAbsSb s1 l (append pos [1]))
(matchingAbsSb s2 [] (append pos [2]));;
Proof. Counterexamples are easy to formulate (e.g. see the proof of Lemma 6.4) because
the equational premise of all the three rules is given in terms of the corresponding ξ
congruence =ξ : a =σ b[↑], a =se ϕ20(b) and a =SUSP [[b, 0, 1, nil]], respectively. 
6.1. Rule implementation for λσ
We used OCAML, a variation of the ML language, for implementing the rewriting
rules of the three treated calculi. The code of this implementation is available at
http://www.mat.unb.br/∼ayala/TCgroup/. For λσ , consider for example the rule Abs. We
should remark that λσ works with two different entities: terms (TERMS) and substitutions
(SUBS), which should be discriminated in any implementation. λσ -terms of the form 1,
λM , (M N) and M[S] are respectively represented as One, L(M), A(M,N) and Sb(M,S)
and λσ -substitutions of the form id, ↑, M.S and S ◦ T as Id, Up, Pt(M,S) and Cp(S,T).
Applications of the rules are implemented in two steps: the first one of detection of redices
and the second one, after selection of a possible redex, of true reduction. Detection of
redices for this rule is implemented as in Table 7. Note that the search for redices is
divided into the searches over terms and substitution entities. Once a redex at position
pr of the term exp is detected (and selected) the application of Abs is done by means of
the function specified in Table 8. Analogously, the application is divided in parts for terms
and substitutions. All other rules are similarly implemented.
6.2. Rule implementation for λse
The implementation for λse is simpler since we have to consider a sole entity, that is the
one of (lambda) terms. λse-terms are of the form n, (M N), λM , Mσ i N and ϕik M and are
represented in OCAML respectively as DB n, A(M,N), L(M), S(i,M,N) and P(k,i,M).
Searching for redices of the σ–λ transition and its application for a selected redex pr are
given in Tables 9 and 10, respectively.
30 M. Ayala-Rincón et al. / Annals of Pure and Applied Logic 134 (2005) 5–41
Table 8
Application of Abs of λσ
let rec absreduction exp pr =
match pr with [] -> (match exp with Sb(L(e1),sb) ->
L(Sb(e1,Pt(One,Cp(sb,Up)))) | _ -> exp) |
1 :: tail -> (match exp with
Dummy -> exp | One -> exp | Vr c -> exp |
A(e1,e2) -> A((absreduction e1 tail),e2) |
L(e1) -> L(absreduction e1 tail) |
Sb(e1,s2) -> Sb((absreduction e1 tail),s2))|
2 :: tail -> (match exp with
Dummy -> exp | One -> exp | Vr c -> exp |
L(e1) -> exp |
A(e1,e2) -> A(e1,(absreduction e2 tail)) |
Sb(e1,s2)-> Sb(e1,(absreductionSb s2 tail)))|
_ -> exp
and absreductionSb subs pr =
match pr with [] -> subs |
1 :: tail -> (match subs with
Id -> subs | Up -> subs |
Cp(s1,s2) -> Cp((absreductionSb s1 tail),s2)|
Pt(e1,s2) -> Pt((absreduction e1 tail),s2)) |
2 :: tail -> (match subs with
Id -> subs | Up -> subs |
Cp(s1,s2) -> Cp(s1,(absreductionSb s2 tail))|
Pt(e1,s2)-> Pt(e1,(absreductionSb s2 tail)))|
_ -> subs;;
Table 9
Detection of redices for the σ–λ transition of λse
let rec matchingSLtransition exp l pos =
match exp with Dummy -> l | DB i ->l | Vr c ->l |
A(e1,e2) -> append(matchingSLtransition e1 l(append pos [1]))
(matchingSLtransition e2 [] (append pos [2]))|
L(e1) -> (matchingSLtransition e1 l (append pos [1])) |
S(i,L(e1),e2) -> pos :: append
(matchingSLtransition e1 l (append pos [1;1]))
(matchingSLtransition e2 [] (append pos [2]))|
S(i,e1,e2) -> append
(matchingSLtransition e1 l (append pos [1]))
(matchingSLtransition e2 [] (append pos [2]))|
P(j,k,e1) -> (matchingSLtransition e1 l (append pos [1]));;
6.3. Rule implementation for λSUSP
Expressions in λSUSP can be of three different types: (suspended) terms, environments
and environment terms. Terms of the form C , n, (M N), λM and [[t, i, j, e]] are
M. Ayala-Rincón et al. / Annals of Pure and Applied Logic 134 (2005) 5–41 31
Table 10
Application of σ–λ transition of λse
let rec sltransition exp pr =
match pr with [] -> (match exp with
S(i,L(e1),e2) -> L(S(i+1,e1,e2)) | _ -> exp)|
1 :: tail -> (match exp with
A(e1,e2) -> A((sltransition e1 tail),e2) |
L(e1) -> L(sltransition e1 tail) |
S(i,e1,e2)-> S(i,(sltransition e1 tail),e2) |
P(j,k,e1) -> P(j,k,(sltransition e1 tail)) |
_ -> exp ) |
2 :: tail -> (match exp with
A(e1,e2) -> A(e1,(sltransition e2 tail)) |
S(i,e1,e2)-> S(i,e1,(sltransition e2 tail)) |
_ -> exp ) | _ -> exp;;
represented by Vr c, DB n, A(M,N), L(M) and Sp(t,i,j,e); environments of the form
nil, et :: e and {{env1, i, j, env2}} by Nilen, Con(et,e) and Ck(env1,i,j,env2); and
environment terms of the form @n, (t, l) and 〈〈envt, i, j, env〉〉 by Ar(n), Paar(t,l)
and LG(envt,i,j,env), respectively. The search for redices of the rule (r7) is given in
Table 11 and for its application in a selected position in Table 12. Note that the search for
redices and the application of the rule is divided into the searches over suspended terms,
environments and environment terms.
6.4. Implementations by ξ -normalization of Eta are unclean
Observe that except for the Eta rule, deciding the applicability of all other rewrite rules
of the three calculi (cf. Table 1 for λσ ; 2–4 for λse; 5 and 6 for λSUSP) is straightforward,
since these rules are either non-conditional rules or their premises are simple arithmetic
conditions easy to decide by means of built-in arithmetic mechanisms that are embedded
in all modern computational systems.
Nevertheless, the applicability of the Eta rules of the three calculi depends on checking
a condition over the congruence of the rewrite system, which can, in the first instance
be implemented following a suggestion by Borovanský in [11] for λσ and used in [2]
for λse. Note that the η-reduction λ(M 1) →η N gives a term N resulting from M
by decrementing all its free de Bruijn indices by one. And the suggestion is that this
corresponds to the normalization, after the application at the root position of the generation
rule of the considered calculus of the term ((λM) ) whenever  does not occur in this
normalization. The implementation of this suggestion is presented for the three calculi in
the following definition.
Definition 6.3 (ξ -nf Implementation of the η-Reduction). For the three treated calculi,
the direct implementation of the rewrite rule: λ(M 1) −→nfEtaξ N if N =
ξ -nf (genλξ (((λM) ), root)) and  does not occur in N , is called the implementation
by ξ -normalization of the η-reduction, denoted by nfEtaξ .
32 M. Ayala-Rincón et al. / Annals of Pure and Applied Logic 134 (2005) 5–41
Table 11
Detection of redices for r7 of λSUSP
let rec matching_r7 exp l pos = match exp with
Dummy ->l | DB i ->l | Vr c ->l |
A(e1,e2) -> append (matching_r7 e1 l (append pos [1]))
(matching_r7 e2 [] (append pos [2])) |
L(e1) -> (matching_r7 e1 l (append pos [1])) |
Sp(L(e1),_,_,env) -> pos :: append
(matching_r7 e1 l (append pos [1;1]))
(matchingEnv_r7 env [] (append pos [2]))|
Sp(e1,_,_,env) -> append
(matching_r7 e1 l (append pos [1]))
(matchingEnv_r7 env [] (append pos [2]))
and matchingEnv_r7 env l pos = match env with Nilen -> l |
Con(envt, env1) -> append
(matchingEt_r7 envt l (append pos [1]))
(matchingEnv_r7 env1 [] (append pos [2])) |
Ck(env1,_,_,env2) -> append
(matchingEnv_r7 env1 l (append pos [1]))
(matchingEnv_r7 env2 [] (append pos [2]))
and matchingEt_r7 envt l pos = match envt with Ar i -> l |
LG(envt1,_,_,env1) -> append
(matchingEt_r7 envt1 l (append pos [1]))
(matchingEnv_r7 env1 [] (append pos [2])) |
Paar(e1,i) -> (matching_r7 e1 l (append pos [1]));;
This implementation is sound for λσ (cf. [11]) as well as for λse (cf. [2]). However
this implementation is unclean because during ξ -normalization, rules of the substitution
calculi not strictly involved in η-reduction can be applied. For instance, the λse-term
λ((4σ 11) 1) →nfEtase 2, but λ((4σ 11) 1) →η 2. Of course, λ((4σ 11) 1) →σ−dest
λ(3 1) →η 2 (as well as λ(3 1) →nfEtase 2). Observe here that the Eta rule (Table 4)
does not correspond to the intended operational semantics of the η rule: λ(M 1) →η N
means that M and N are functionally equivalent.
Lemma 6.4 (nfEtaξ Implementations of the η-Reduction are Unclean). The implementa-
tions of the η-reduction by ξ -normalization for the three treated calculi are unclean.
Proof.
• For the λσ , consider the reduction λ((1[↑3][1[↑].id])1 ) →nfEtaσ 1[↑] = 2. But
λ((1[↑3][1[↑].id])1) →Etaσ 1[↑2][1.id] →∗σ 2.
• For the λse, consider the reduction λ((4σ 12)1) →nfEtase 2. But ϕ20(3σ 11) =se 4σ 12
and so λ((4σ 12)1) →Etase 3σ 11 →se 2.
• For the λSUSP, consider the reduction λ([[4, 1, 0, (2, 0) :: nil]] 1) →nfEtaSUSP 2. But[[[[3, 1, 0, (1, 0) :: nil]], 0, 1, nil]] =SUSP [[4, 1, 0, (2, 0) :: nil]] and so
λ([[4, 1, 0, (2, 0) :: nil]] 1) →EtaSUSP [[3, 1, 0, (1, 0) :: nil]] →∗SUSP 2. 
M. Ayala-Rincón et al. / Annals of Pure and Applied Logic 134 (2005) 5–41 33
Table 12
Application of r7 of λSUSP
let rec r7_reduction exp pr =
match pr with
[] -> (match exp with
Sp(L(e1),i,j,env) -> L(Sp(e1,i+1,j+1,Con(Ar(j),env))) |
_ -> exp ) |
1 :: tail -> (match exp with
A(e1,e2) -> A((r7_reduction e1 tail),e2) |
L(e1) -> L(r7_reduction e1 tail) |
Sp(e1,i,j,env) -> Sp((r7_reduction e1 tail),i,j,env) |
_ -> exp) |
2 :: tail -> (match exp with
A(e1,e2) -> A(e1,(r7_reduction e2 tail)) |
Sp(e1,i,j,env) -> Sp(e1,i,j,(r7_reductionEnv env tail)) |
_ -> exp)
and r7_reductionEnv env pr = match pr with
1 :: tail -> (match env with
Con(envt,env1) -> Con((r7_reductionEt envt tail),env1) |
Ck(env1,i,j,env2) -> Ck((r7_reductionEnv env1 tail),i,j,env2) |
_ -> env) |
2 :: tail -> (match env with
Con(envt,env1) -> Con(envt,(r7_reductionEnv env1 tail)) |
Ck(env1,i,j,env2) -> Ck(env1,i,j,(r7_reductionEnv env2 tail)) |
_ -> env)
and r7_reductionEt envt pr = match pr with
1 :: tail -> (match envt with
Paar(e1,i) -> Paar((r7_reduction e1 tail),i) |
LG(envt1,i,j,env1) -> LG((r7_reductionEt envt1 tail),i,j,env1) |
_ -> envt) |
2 :: tail -> (match envt with
LG(envt1,i,j,env1) -> LG(envt1,i,j,(r7_reductionEnv env1 tail))|
_ -> envt);;
In the following, we present a cleaner way to implement the Eta rules avoiding the
application of other rules of the substitution calculi than the ones strictly involved in the
η-reduction.
7. Clean implementations of Eta
We will adapt the above implementation idea, but will restrict the ξ -normalization of
the term genλξ ((λM) ). The restricted ξ -normalization, called ξ -pseudo-normalization,
should propagate the dummy symbol into the structure of the term M without applying
extra rules of the substitution calculus.
Essentially the idea for avoiding the application of extra rules of the substitution calculi
during the verification of the premise via pseudo-normalization is to apply rules only when
occurrences of  are detected:
l → r if  occurs in l.
34 M. Ayala-Rincón et al. / Annals of Pure and Applied Logic 134 (2005) 5–41
Table 13
σ -Pseudo-normalization
let rec sig-norm exp = match exp with
Dummy -> Dummy | One -> One | Vr c -> Vr c |
(*App*) Sb(A(e1,e2),sb)->(if occurdummy1sb(sb) then
A(Sb(e1,sig-normsb(sb)),Sb(e2,sig-normsb(sb))) else exp)|
(*Abs*) Sb(L(e1),sb)-> (if occurdummy1sb(sb) then
L(Sb(e1,sig-normsb(Pt(One,Cp(sb,Up))))) |
(*Clos*) Sb(Sb(e1,s1),s2) -> Sb(e1,sig-normsb(Cp(s1,s2))) |
(*VarCons*) Sb(One,Pt(e1,sb)) -> (if (occurdummy1(e1) ||
occurdummy1sb(sb)) then sig-norm(e1) else exp) |
(*Id*) Sb(e1,Id) -> (if occurdummy1(e1) then sig-norm(e1) else exp)
and sig-normsb subs = match subs with Up -> Up | Id -> Id |
(*SCons*) Pt(Sb(One,s1),Cp(Up,s2)) -> (if ((s1 = s2) &&
occurdummy1sb(s1)) then sig-normsb(s1) else subs) |
(*ShiftCons*) Cp(Up,Pt(e1,sb)) -> (if (occurdummy1(e1) ||
occurdummy1sb(sb)) then sig-normsb(sb) else subs) |
(*IdL*) Cp(Id,sb) -> sig-normsb(sb) |
(*IdR*) Cp(sb,Id) -> sig-normsb(sb) |
(*Map*) Cp(Pt(e1,s1),s2) -> (if (occurdummy1(e1) ||
occurdummy1sb(s1) || occurdummy1sb(s2)) then
sig-normsb(Pt(sig-norm(Sb(e1,s2)),sig-normsb(Cp(s1,s2))))
else subs) |
(*Assoc*) Cp(Cp(s1,s2),sb3) -> (if (occurdummy1sb(s1) ||
occurdummy1sb(s2) || occurdummy1sb(sb3)) then
sig-normsb(Cp(s1,sig-normsb(Cp(s2,sb3)))) else subs) |
_ -> subs;;
As for all the other rules previously illustrated, our OCAML implementation divides
the application of an Eta rule into two parts: detection of redices and reduction. For
λσ , genλσ ((λM) ) = M[.id]. The σ -pseudo-nf(M[.id]) has been implemented as
the function sig-norm in Table 13, where the occurdummy check search in linear time
the occurrence of Dummy in exp. Note that in sig-norm except for the rules IdL, IdR
and Clos, non-trivial reductions are possible only if  occurs. If these rules have been
conditioned like the others, it should be impossible to normalize very simple terms, for
instance 1[↑ ◦id], that are necessary for pseudo-normalizations as ((λ1[↑2]) ) →βs
1[↑2][.id] →Clos 1[↑2 ◦(.id)] →Assoc 1[↑ ◦(↑ ◦(.id))] →ShiftCons 1[↑ ◦id] →I d R
1[↑]. Since our objective is to propagate the dummy symbol into the structure of the
normalized term, that non-restricted application of these rules may be pointed out as a
deficiency because extra rules may be applied during the σ -pseudo-normalization.
For λse, we have genλse((λM) ) = Mσ 1. And the se-pseudo-normalization of a
λse-term, exp, is given by the function se-norm in Table 14. This pseudo-normalization is
simpler than the previous one, since we are dealing with a sole entity and additionally
the λse rewrite rules preserve, in a certain way, the structure of terms: the symbol 
remains always as last argument of the term to be normalized. As a consequence of this
regularity, implementation of the pseudo-normalization is done via unconditional rewrite
M. Ayala-Rincón et al. / Annals of Pure and Applied Logic 134 (2005) 5–41 35
Table 14
se-Pseudo-normalization
let rec se-norm exp = match exp with
Dummy -> Dummy | DB i -> DB i | Vr c->Vr c | S(i,Vr c,Dummy)-> exp|
(*si-dest*) S(i,DB j,Dummy) ->
(if j<i then DB j else (if j>i then (DB (j-1))
else P(0,i,Dummy))) |
(*si-app*) S(i,A(e1,e2),Dummy) ->
A((se-norm (S(i,e1,Dummy))),(se-norm (S(i,e2,Dummy)))) |
(*si-lambda*) S(i,L(e1),Dummy) -> L(se-norm (S(i+1,e1,Dummy))) |
(*si-si*) S(i,S(j,e1,e2),Dummy) -> (if i >= j then
S(j,(se-norm(S(i+1,e1,Dummy))),(se-norm(S(i-j+1,e2,Dummy))))
else exp) |
(*si-phi*) S(i,P(k,n,e),Dummy) ->
(if i>=k+n then P(k,n,(se-norm(S(i-n+1,e,Dummy))))
else (if i>k then P(k,n-1,e) else exp)) | _ -> exp;;
rules (without premises “if occurdummy”). Clearly, this represents an advantage over the
other two calculi.
In λSUSP this implementation is very similar to that of λσ . We have that
genλSUSP ((λM) ) = [[M, 1, 0, (, 0) :: nil]]. The function susp-norm in Table 15
implements the SUSP-pseudo-normalization of a λSUSP expression exp. Observations made
for the sig-norm of λσ apply for the susp-norm of λSUSP: except for three rules, one-step
reduction is decided via the occurdummy’s check that runs in linear time on the size of
exp. Rules r2 and r3 should be implemented without any Dummy. As for λσ , this implies
that rules other than those essential for the propagation of the  symbol may be applied
during this pseudo-normalization.
One may think there is a tradeoff because of the inclusion conditionals, but the
verification of occurrences of the Dummy symbol can be performed simultaneously when
solving the matching without additional cost.
Definition 7.1 (ξ -pse-nf Implementation of the η-Reduction). For the calculi λσ, λse and
λSUSP the previously proposed implementation of the η-reduction, that is formulated as
the rewrite rule: λ(M 1) −→pse-nfEtaξ N if N = ξ -pse-nf (genλξ (((λM) ), root)) and
 does not occur in N , is called the implementation by ξ -pseudo-normalization of the
η-reduction, denoted by pse-nfEtaξ .
From the argumentations before the previous definition, one can conclude that the
implementation of η-reduction by λse-pseudo-normalization is cleaner and more efficient
than the corresponding implementations of η-reduction for λσ and λSUSP.
Lemma 7.2 (pse-nfEtaSUSP and pse-nfEtaσ Implementations of the η-Reduction are
Unclean). The implementations of η-reduction by SUSP- and σ -pseudo-normalization are
unclean.
Proof. Observing the pseudo-normalization rules for these two calculi we can see that, for
λσ , the rules named Clos, IdL and IdR must be implemented without condition as the
36 M. Ayala-Rincón et al. / Annals of Pure and Applied Logic 134 (2005) 5–41
Table 15
SUSP-Pseudo-normalization
let rec susp-norm exp = match exp with
Dummy -> Dummy | DB i -> DB i | Vr c -> Vr c |
(*r1*) Sp(Dummy,i,j,env) -> Dummy |
(*r2*) Sp(DB i,0,j,Nilen) -> DB (i+j) |
(*r3*) Sp(DB 1,i,j,Con(Ar(k),env)) -> DB (j-k) |
(*r4*) Sp(DB 1,i,j,Con(Paar(e1,k),env)) ->
(if (occurdummy3 e1) then susp-norm(Sp(e1,0,j-k,Nilen))
else exp) |
(*r5*) Sp(DB i,j,k,Con(envt,env)) ->
(if((occurdummy3_Et envt) || (occurdummy3_Env env))
then susp-norm(Sp(DB (i-1),j-1,k,env))else exp) |
(*r6*) Sp(A(e1,e2),i,j,env) ->
(if ((occurdummy3 e1)||(occurdummy3 e2)||(occurdummy3_Env env))
then A(susp-norm(Sp(e1,i,j,env)),susp-norm(Sp(e2,i,j,env)))
else exp) |
(*r7*) Sp(L(e1),i,j,env) ->
(if ((occurdummy3 e1) || (occurdummy3_Env env))
then L(susp-norm(Sp(e1,i+1,j+1,Con(Ar(j),env))))
else exp) |_ -> exp;;
others, i.e., these rules do not propagate the  symbol. The justification for this can be
found in the third paragraph of Section 7.
An analogous argument is used in the case of λSUSP. 
Lemma 7.3 (pse-nfEtase Implementation of the η-Reduction is Clean). The implementa-
tion of η-reduction by se-pseudo-normalization is clean.
Proof. By direct inspection of the pseudo-normalization rules of the λse-calculus
(Table 15). Note that all applied rules just propagate the  symbol. 
The following three propositions show the completeness of the implementations of the
Eta rules based on these pseudo-normalizations, denoted by Etaξ for ξ ∈ {σ, se, SUSP},
restricted to pure lambda terms.
Lemma 7.4. Let M ∈ ΛdB. The σ -pseudo-nf of
M[1.1[↑]. . . . .1[↑k−2].[↑k−1]. ↑k−1]
gives a term that preserves all occurrences of terms in M corresponding to variables
less than k unchanged, replaces all occurrences corresponding to the kth variable with
[↑k−1] and decrements by one all occurrences corresponding to variables greater than k.
Proof. We use the word variable for occurrences of 1[↑k−1]. By induction on the structure
of M:
• M = n. If n<k then 1[↑n−1][1.1[↑] . . .1[↑k−2].[↑k−1]. ↑k−1] →Clos
1[↑n−1 ◦(1.1[↑] . . .1[↑k−2].[↑k−1]. ↑k−1)] →n−2Assoc
1[↑◦(↑◦(. . . (↑◦(1.1[↑] . . .1[↑k−2].[↑k−1].↑k−1))))] →n−1ShiftCons 1[↑n−1].
M. Ayala-Rincón et al. / Annals of Pure and Applied Logic 134 (2005) 5–41 37
If n = k then 1[↑n−1][1.1[↑] . . .1[↑k−2].[↑k−1]. ↑k−1]
→Clos 1[↑n−1 ◦(1.1[↑] . . . 1[↑k−2].[↑k−1]. ↑k−1)] →n−2Assoc
1[↑◦(↑◦(. . . (↑◦(1.1[↑] . . .1[↑k−2].[↑k−1].↑k−1))))] →n−1ShiftCons [↑n−1].
If n > k then 1[↑n−1][1.1[↑] . . .1[↑k−2].[↑k−1]. ↑k−1]
→Clos 1[↑n−1 ◦(1.1[↑] . . . 1[↑k−2].[↑k−1]. ↑k−1)] →n−2Assoc
1[↑◦(↑◦(. . . (↑◦(1.1[↑] . . .1[↑k−2].[↑k−1]. ↑k−1))))] →n−1ShiftCons
1[↑n−1−k ◦ ↑k−1] = 1[↑n−2].
• M = (A B). Directly by the induction hypothesis.
• M = (λA). Then
(λA)[1.1[↑] . . .1[↑k−2].[↑k−1].↑k−1] →Abs
λA[1.((1.1[↑] . . .1[↑k−2].[↑k−1]. ↑k−1)◦ ↑)] →kMap
λA[1.(1[↑].1[↑][↑] . . .1[↑k−2][↑].[↑k−1][↑].(↑k−1 ◦ ↑))]→Clos
λA[1.1[↑].1[↑2] . . . 1[↑k−1].[↑k].↑k]. And by the induction hypothesis we can
conclude. 
Proposition 7.5 (Completeness of pse-nfEtaσ ). Let M ∈ ΛdB. If λ(M 1) →η N then
λ(M 1) →pse-nfEtaσ N.
Proof. Here we are interpreting the de Bruijn index k in the language of λσ as usual by
1[↑k−1]. The proof is by induction on the structure of M .
• M = n. If n = 1 then on the one hand, λ(n 1) →η n− 1. On the other hand
we have to that n[.id] = 1[↑n−1][.id] σ -pseudo-normalizes to n− 1. In fact,
1[↑n−1][.id] →Clos 1[↑n−1 ◦(.id)] →Assoc 1[↑n−2 ◦(↑ ◦(.id))] →ShiftCons
1[↑n−2 ◦(id)] →IdR 1[↑n−2] = n− 1.
• M = (A B). For A and B without occurrences of the free de Bruijn index 1, by the
condition for the application of the η-reduction to (A B), we have that λ(A 1) →η A′
and λ(B 1) →η B ′, where A′ and B ′ are obtained from A and B by decrementing all
the free variables by one. Also, (A B)[.id] →App A[.id] B[.id]. By the induction
hypothesis the σ -pseudo-nf of A[.id] and B[.id] corresponds respectively to A′ and
B ′.
• M = (λA). A does not own occurrences of terms corresponding to the free de Bruijn
index 2. Then λ((λA) 1) →η λA′′, where A′′ is obtained from A by decrementing all
its free variables except 1 by one. Thus applying Lemma 7.4 to the term M[.id], we
obtain the desired result. 
Lemma 7.6. Let M ∈ ΛdB. Then the se-pseudo-nf of Mσ i gives a term obtained from M
by preserving all free de Bruijn indices less than i unchanged, replacing the occurrences
of the i th free de Bruijn index with ϕi0 and decrementing all the free occurrences of de
Bruijn indices greater than i by one.
Proof. Induction on the structure of M .
• M = n. If n < i then nσ i →σ−dest n. If n = i then nσ i →σ−dest ϕi0. If n > i
then nσ i→σ−dest n− 1.
38 M. Ayala-Rincón et al. / Annals of Pure and Applied Logic 134 (2005) 5–41
• M = (A B). (A B)σ i →σ−app (Aσ i) (Bσ i). And by the induction hypothesis
we can conclude.
• M = (λA). (λA)σ i →σ−λ λAσ i+1. And by the induction hypothesis we can
conclude. 
Proposition 7.7 (Completeness of pse-nfEtase).
Let M ∈ ΛdB. If λ(M 1) →η N then λ(M 1) →pse-nfEtase N.
Proof. Induction on the structure of M .
• M = n. If n > 1 then nσ 1→σ−dest n− 1.
• M = (A B). For A and B without free occurrences of the de Bruijn index 1, we
have that λ(A 1) →η A′ and λ(B 1) →η B ′, where A′ and B ′ are obtained from A
and B by decrementing all their free occurrences of de Bruijn indices by one. Also,
(A B)σ 1 →σ−app (Aσ 1) (Bσ 1), and by the induction hypothesis we have that
(Aσ 1) →Etase A′ and (Bσ 1) →Etase B ′.
• M = (λA). For A without free occurrences of the de Bruijn index 2, λ((λA) 1) →η
λA′′, where A′′ is obtained from A by decrementing all its free de Bruijn indices except
1 by one. Also, (λA)σ 1 →σ−λ λAσ 2. Now by Lemma 7.6 we get the desired
result. 
Lemma 7.8. Let A and B be well-formed λSUSP-terms and let us have k ≥ 0. Then the
rm-normalization of the well-formed term
[[A, k, k − 1, @k − 2 :: . . . :: @0 :: (B, l) :: nil]]
gives a term by decrementing by one all free de Bruijn indices greater than k occurring at
A, replacing the kth free variable of A with B (actualized according to the context of the
term), and keeps unchanged all other free occurrences of de Bruijn indices.
Proof. Similar to the proof of Lemma 3.15. 
Proposition 7.9 (Completeness of pse-nfEtaSUSP). Let M ∈ ΛdB. If λ(M 1) →η N then
λ(M 1) →pse-nfEtaSUSP N.
Proof. By induction on the structure of M .
• M = n. If n > 1 then [[n, 1, 0, (, 0) :: nil]] →r5 [[n− 1, 0, 0, nil]] →r2 n− 1.
• M = (A B). Similar to Lemma 7.8 using that [[(A B), 1, 0, (, 0) ::nil]] →r6
[[A, 1, 0, (, 0) ::nil]] [[B, 1, 0, (, 0) ::nil]] and IH: [[A,1,0,(,0) ::nil]] →EtaSUSP A′
and [[B, 1, 0, (, 0) ::nil]] →EtaSUSP B ′.
• M = (λA). For A without free occurrences of the de Bruijn index 2, λ((λA) 1)
→η λA′′, where A′′ is obtained from A decrementing by one all its free de Bruijn
indices except 1. Now use [[(λA), 1, 0, (,0) ::nil]] →r7 λ[[A, 2, 1, @0 ::(, 0) ::nil]]
and Lemma 7.8. 
M. Ayala-Rincón et al. / Annals of Pure and Applied Logic 134 (2005) 5–41 39
8. Future work and conclusion
Refs. [15,3] showed that η-reduction is of great interest for adapting substitution
calculi (λσ and λse) for important practical problems like higher order unification. In
this paper, we have enlarged the suspension calculus of [37,34] with an adequate Eta rule
for η-reduction and showed that this extended suspension calculus, named λSUSP, enjoys
confluence and termination of the associated substitution calculus SUSP (with Eta).
Additionally, we used the notion of adequacy of [26] for comparing these three calculi
when simulating one-step β-reduction. We concluded that λσ and λξ are mutually non-
comparable for ξ ∈ {se, SUSP} but that λse is more adequate than λSUSP in simulating
one-step beta-reduction. After all, although λσ is a first-order calculus and the other two
calculi are second order, comparing them is not unfair since the use of (built-in) arithmetic
is standard in all modern programming environments. Recently Liang and Nadathur
pointed out the importance of having the possibility of combining steps of beta-reduction
in practical implementations, which amounts to the ability of the calculus to compose
substitutions [31,35]. This results in natural applications for λσ and the suspension calculus
in contrast to the λse . Consequently, it will be of great importance to study possible
adaptations of the λse which enable this property. In particular, this would be interesting if
the work carried out for λse on HOU can be mapped into the λt [26] which is a calculus à la
λse but which updates à la λσ . That is, λt does partial updating, like λσ and the suspension
calculus, whereas λse does global updating. We leave this for future work.
Moreover, we established the correspondence of these Eta rules of the three calculi.
This correspondence means that the operational effects of applying these Eta rules over
pure λ-terms in the three calculi are identical. For the three calculi in question enlarged
with adequate eta rules we showed how to implement these eta rules. For the λse we
build a clean implementation of the eta rule, that is, avoiding the application of rules
of the substitution calculi other than the ones strictly involved in the verification of the
η-redices. And we proved that it is not possible to follow the same approach for the
λσ and λSUSP. We proved that these implementations are complete in the sense that any
η-reduction for dealing with pure λ-terms in de Bruijn notation can be simulated by
these Eta implementations. For the three treated calculi, the main advantage of our clean
eta implementation approach is that it is closer than previous implementations to the
operational semantics of the usual η-reduction of the λ-calculus. Additionally, we have
pointed out that for λSUSP as well as for the λσ -calculus, in these Eta implementations,
the application of rules not strictly involved with the η-reduction is necessary, but that
this is not the case for λse. We have also showed that for the former two calculi,
conditional rewriting rules whose premises are decided in linear time in the size of the
terms in normalization are necessary, while for λse, this is done via non-conditional
rules whose applicability is decided by simple matching of their left-hand sides. Our Eta
implementation is being incorporated into an ELAN prototype for simply typed higher
order unification via λse.
An immediate job to be done is to study two open questions: whether the se-calculus has
strong normalization (SN) [27], and whether λSUSP preserves SN. Interesting points arise
in this context since: λse is more adequate in the simulation of one-step β-reduction than
λSUSP; λse does not preserve SN [18]; and the substitution calculus of λSUSP has SN.
40 M. Ayala-Rincón et al. / Annals of Pure and Applied Logic 134 (2005) 5–41
Acknowledgements
First author was partially supported by the CNPq Brazilian Research Council. The
second author was supported by the Brazilian Higher Education Council CAPES.
References
[1] M. Abadi, L. Cardelli, P.-L. Curien, J.-J. Lévy, Explicit substitutions, Journal of Functional Programming 1
(4) (1991) 375–416.
[2] M. Ayala-Rincón, F. Kamareddine, On applying the λse-style of unification for simply-typed higher
order unification in the pure lambda calculus, in: Pre-Proceedings Eighth Workshop on Logic, Language,
Information and Computation, WoLLIC 2001, 2001, pp. 41–54.
[3] M. Ayala-Rincón, F. Kamareddine, Unification via the λse-style of explicit substitution, The Logic Journal
of the Interest Group in Pure and Applied Logics 9 (4) (2001) 489–523.
[4] M. Ayala-Rincón, C. Muñoz, Explicit substitutions and all that, Revista Colombiana de Computación 1 (1)
(2000) 47–71.
[5] F. Baader, T. Nipkow, Term Rewriting and All That, Cambridge University Press, 1998.
[6] H. Barendregt, The Lambda Calculus: Its Syntax and Semantics, revised edition, North-Holland, 1984.
[7] Z.-el-A. Benaissa, D. Briaud, P. Lescanne, J. Rouyer-Degli, λυ , a calculus of explicit substitutions which
preserves strong normalization, Journal of Functional Programming 6 (5) (1996) 699–722.
[8] Z.-el-A. Benaissa, P. Lescanne, K.H. Rose, Modeling sharing and recursion for weak reduction strategies
using explicit substitution, in: Programming Languages: Implementations, Logics and Programs, PLILP’96,
LNCS, vol. 1140, Springer-Verlag, 1996, pp. 393–407.
[9] R. Bloo, Preservation of termination for explicit substitution, Ph.D. Thesis, Department of Mathematics and
Computing Science, Eindhoven University of Technology, 1997.
[10] R. Bloo, K. Rose, Combinatory reduction systems with explicit substitution that preserve strong
normalisation, in: H. Ganzinger (Ed.), Seventh International Conference on Rewriting Techniques and
Applications, RTA-96, LNCS, vol. 1103, Springer-Verlag, 1996, pp. 169–183.
[11] P. Borovanský, Implementation of higher-order unification based on calculus of explicit substitutions,
in: M. Bartošek, J. Staudek, J. Wiedermann (Eds.), Proceedings of the SOFSEM’95: Theory and Practice of
Informatics, LNCS, vol. 1012, Springer-Verlag, 1995, pp. 363–368.
[12] D. Briaud, An explicit Eta rewrite rule, in: Typed Lambda Calculi and Applications, LNCS, vol. 902,
Springer-Verlag, 1995, pp. 94–108.
[13] P.-L. Curien, T. Hardin, J.-J. Lévy, Confluence properties of weak and strong calculi of explicit substitutions,
Journal of the ACM 43 (2) (1996) 362–397, Also as Rapport de Recherche INRIA 1617, 1992.
[14] N.G. de Bruijn, Lambda-calculus notation with nameless dummies, a tool for automatic formula
manipulation, with application to the Church–Rosser theorem, Indagationes Mathematicae 34 (5) (1972)
381–392.
[15] G. Dowek, T. Hardin, C. Kirchner, Higher-order unification via explicit substitutions, Information and
Computation 157 (1–2) (2000) 183–235.
[16] M.C.F. Ferreira, D. Kesner, L. Puel, Lambda-calculi with explicit substitutions and composition which
preserve beta-strong normalisation, in: Algebraic and Logic Programming, ALP’96, LNCS, vol. 1139,
Springer-Verlag, 1996, pp. 284–298.
[17] B. Guillaume, Un calcul des substitutions avec etiquettes, Ph.D. Thesis, Université de Savoie, Chambéry,
1999.
[18] B. Guillaume, The λse-calculus does not preserve strong normalization, Journal of Functional Programming
10 (4) (2000) 321–325.
[19] T. Hardin, Eta-conversion for the languages of explicit substitutions, in: Algebraic and Logic Programming,
LNCS, vol. 632, Springer-Verlag, 1992, pp. 306–321.
[20] T. Hardin, L. Maranget, B. Pagano, Functional runtime systems within the lambda–sigma calculus, Journal
of Functional Programming 8 (2) (1998) 131–176.
[21] F. Kamareddine, R.P. Nederpelt, On stepwise explicit substitution, International Journal of Foundations of
Computer Science 4 (3) (1993) 197–240.
M. Ayala-Rincón et al. / Annals of Pure and Applied Logic 134 (2005) 5–41 41
[22] F. Kamareddine, R.P. Nederpelt, A useful λ-notation, Theoretical Computer Science 155 (1996) 85–109.
[23] F. Kamareddine, A. Ríos, A λ-calculus à la de Bruijn with explicit substitutions, in: Proc. of PLILP’95,
LNCS, vol. 982, Springer-Verlag, 1995, pp. 45–62.
[24] F. Kamareddine, A. Ríos, Extending a λ-calculus with explicit substitution which preserves strong
normalisation into a confluent calculus on open terms, Journal of Functional Programming 7 (1997)
395–420.
[25] F. Kamareddine, A. Ríos, Bridging de Bruijn indices and variable names in explicit substitutions calculi,
The Logic Journal of the Interest Group of Pure and Applied Logic 6 (6) (1998) 843–874.
[26] F. Kamareddine, A. Ríos, Relating the λσ - and λs-styles of explicit substitutions, Journal of Logic and
Computation 10 (3) (2000) 349–380.
[27] F. Kamareddine, A. Ríos, Explicit substitutions à la de Bruijn: the local and global way, Electronic Notes in
Theoretical Computer Science 85 (7) (2003).
[28] F. Kamareddine, A. Ríos, J.B. Wells, Calculi of generalised β-reduction and explicit substitution: type free
and simply typed versions, The Journal of Functional and Logic Programming 1998 (5) (1998) 1–44.
[29] D. Kesner, Confluence of extensional and non-extensional λ-calculi with explicit substitutions, Theoretical
Computer Science 238 (1–2) (2000) 183–220.
[30] P. Lescanne, J. Rouyer-Degli, Explicit substitutions with de Bruijn’s levels, in: J. Hsiang (Ed.), Proceedings
of the International Conference on Rewriting Techniques and Applications, RTA-95, Chapel Hill, NC,
LNCS, vol. 914, Springer-Verlag, 1995, pp. 294–308.
[31] C. Liang, G. Nadathur, Tradeoffs in the intensional representation of lambda terms, in: S. Tison (Ed.),
Rewriting Techniques and Applications, RTA 2002, LNCS, vol. 2378, Springer-Verlag, 2002, pp. 192–206.
[32] L. Magnusson, The implementation of ALF—a proof editor based on Martin Löf’s type theory with explicit
substitutions, Ph.D. Thesis, Chalmers, 1995.
[33] C. Muñoz, Un calcul de substitutions pour la représentation de preuves partielles en théorie de types, Ph.D.
Thesis, Université Paris 7, 1997, English version in Rapport de recherche INRIA RR-3309, 1997.
[34] G. Nadathur, A fine-grained notation for lambda terms and its use in intensional operations, The Journal of
Functional and Logic Programming 1999 (2) (1999) 1–62.
[35] G. Nadathur, The suspension notation for lambda terms and its use in metalanguage implementations,
in: Proceedings Ninth Workshop on Logic, Language, Information and Computation, WoLLIC 2002,
ENTCS, vol. 67, Elsevier Science Publishers, 2002.
[36] G. Nadathur, D. Miller, An overview of λprolog, in: K.A. Bowen, R.A. Kowalski (Eds.), Proc. 5th Int. Logic
Programming Conference, MIT Press, 1988, pp. 810–827.
[37] G. Nadathur, D.S. Wilson, A notation for lambda terms a generalization of environments, Theoretical
Computer Science 198 (1998) 49–98.
[38] R.P. Nederpelt, J.H. Geuvers, R.C. de Vrijer, Selected Papers on Automath, North-Holland, 1994.
[39] A. Ríos, Contribution à l’étude des λ-calculs avec substitutions explicites, Ph.D. Thesis, Université de
Paris 7, 1993.
[40] R. Vestergaard, J.B. Wells, Cut rules and explicit substitutions, Mathematical Structures in Computer
Science 11 (1) (2001) 131–168.
