              
J. Symbolic Computation (1996) 21, 211{243
Uniflcation in the Union of Disjoint Equational
Theories: Combining Decision Procedures
FRANZ BAADERy AND KLAUS U. SCHULZz
yLuFg Theoretical Computer Science, RWTH Aachen, Ahornstr.55, 52074 Aachen, Germany
zCIS, University of Munich, Wagmu˜llerstr.23,80538 Mu˜nchen, Germany
(Received 15 November 1993)
Most of the work on the combination of uniflcation algorithms for the union of disjoint
equational theories has been restricted to algorithms that compute flnite complete sets
of uniflers. Thus the developed combination methods usually cannot be used to combine
decision procedures, i.e., algorithms that just decide solvability of uniflcation problems
without computing uniflers. In this paper we describe a combination algorithm for de-
cision procedures that works for arbitrary equational theories, provided that solvability
of so-called uniflcation problems with constant restrictions|a slight generalization of
uniflcation problems with constants|is decidable for these theories. As a consequence
of this new method, we can, for example, show that general A-uniflability, i.e., solvability
of A-uniflcation problems with free function symbols, is decidable. Here A stands for the
equational theory of one associative function symbol.
Our method can also be used to combine algorithms that compute flnite complete
sets of uniflers. Manfred Schmidt-Schau…’ combination result, the until now most general
result in this direction, can be obtained as a consequence of this fact. We also obtain
the new result that uniflcation in the union of disjoint equational theories is flnitary, if
general uniflcation|i.e., uniflcation of terms with additional free function symbols|is
flnitary in the single theories.
c° 1996 Academic Press Limited
1. Introduction
E-uniflcation is concerned with solving term equations modulo an equational theory E.
The theory is called \unitary" (\flnitary") if the solutions of a system of equations can
always be represented by one (flnitely many) solution(s). Otherwise the theory is of type
\inflnitary" or \zero" [see e.g., Siekmann (1989); Jouannaud and Kirchner (1991); Baader
and Siekmann (1994) for an introduction to uniflcation theory]. Equational theories of
uniflcation type unitary or flnitary play an important ro^le in automated theorem provers
with \built in" theories (see e.g., Plotkin, 1972; Stickel, 1985), in generalizations of the
Knuth-Bendix algorithm (see e.g., Jouannaud and Kirchner, 1986; Bachmair, 1991), and
in logic programming with equality (see e.g., Jafiar et al., 1987). The reason is that
y E-mail: baader@informatik.rwth-aachen.de
z E-mail: schulz@cis.uni-muenchen.de
0747{7171/96/020211 + 33 $18.00/0 c° 1996 Academic Press Limited
       
212 F. Baader and K. U. Schulz
these applications usually require algorithms which compute flnite complete sets of uni-
flers, i.e., flnite sets of uniflers from which all uniflers can be generated by instantiation.
However, with the recent development of constraint approaches to theorem proving (see
e.g., Bu˜rckert, 1990), term rewriting (see e.g., Kirchner and Kirchner, 1989), and logic
programming (see e.g. Jafiar and Lassez, 1987 or Colmerauer, 1990), the computation
of flnite complete sets of uniflers is no longer indispensable for these applications. It is
su–cient to decide satisflability of the constraints, that means e.g., solvability of the
uniflcation problems. In the present paper, the design of decision procedures for unifl-
cation in the combination of equational theories will be a major issue. First, we explain
why this combination problems arises naturally when using uniflcation algorithms in the
application domains mentioned above.
the signature matters
When considering uniflcation in equational theories one has to be careful with regard
to the signature over which the terms of the uniflcation problems can be built. This leads
to the distinction between elementary uniflcation (where the terms to be unifled are built
over the signature of the equational theory, i.e., the function symbols occurring in the
axioms of the theory), uniflcation with constants (where additional free constant symbols
may occur), and general uniflcation (where additional free function symbols of arbitrary
arity may occur).
The following facts show that there really is a difierence between the three types of
E-uniflcation:
(i) There exist theories that are unitary with respect to elementary uniflcation, but
flnitary with respect to uniflcation with constants. An example for such a theory is
the theory of Abelian monoids, i.e., the theory of an associative-commutative (AC)
function symbol with a unit element (see e.g., Herold, 1987).
(ii) There exists an equational theory for which elementary uniflcation is decidable, but
uniflcation with constants is undecidable (see Bu˜rckert, 1986).
(iii) From the development of the flrst algorithm for AC-uniflcation with constants
(Stickel, 1975; Livesey and Siekmann, 1975) it took almost a decade until the ter-
mination of an algorithm for general AC-uniflcation was shown by Fages (1984,
1987).
The applications of theory uniflcation mentioned above require algorithms for general
uniflcation. This fact is illustrated by the following example.
Example 1.1. The theory A = ff(f(x; y); z) = f(x; f(y; z))g only contains the binary
symbol f . When talking about A-uniflcation, one flrst thinks of unifying modulo A terms
built by using just the symbol f and variables, or equivalently, of unifying words over
the alphabet V of all variables.
However, suppose that a resolution theorem prover|which has built in the theory
A|receives the formula
9x: (8y: f(x; y) = y ^ 8y: 9z: f(z; y) = x)
as axiom. In a flrst step, this formula must be Skolemized, i.e., the existential quantiflers
           
Combining Decision Procedures 213
have to be replaced by new function symbols. In our example, we need a nullary symbol
e and a unary symbol i in the Skolemized form
8y: f(e; y) = y ^ 8y: f(i(y); y) = e
of the axiom. This shows that, even if we start with formulae containing only terms built
over f , the theorem prover eventually has to handle terms containing additional free
symbols.
the combination problem
We have mentioned that the question of how algorithms for elementary uniflcation (or
for uniflcation with constants) can be used to obtain algorithms for general uniflcation
is nontrivial and important for applications. Even more general, one often would like to
derive algorithms for uniflcation in the union of disjoint equational theories, i.e., in the
union of several equational theories over disjoint signatures, from uniflcation algorithms
in the single theories. The importance for applications of this so-called \combination
problem" is illustrated by the following example.
Example 1.2. Assume that we want to compute a canonical term rewriting system for
the theory of Boolean rings. Thus we have a signature consisting of two binary symbols
\+" and \⁄", a unary symbol \¡", and two nullary symbols \0" and \1". Since the
addition and multiplication in Boolean rings is associative and commutative, and since
commutativity cannot be oriented into a terminating rewrite rule, we must use rewriting
modulo associativity and commutativity of \+" and \⁄".
Thus, critical pairs must also be computed modulo associativity and commutativity of
these two symbols. To be more precise, we consider the theories AC+ := f(x+ y) + z =
x+ (y + z); x+ y = y + xg, and AC⁄ := f(x ⁄ y) ⁄ z = x ⁄ (y ⁄ z); x ⁄ y = y ⁄ xg. Critical
pairs are computed with the help of general uniflcation modulo AC+[AC⁄, i.e., modulo
the union of the two disjoint equational theories AC+ and AC⁄.
This example can also be used to demonstrate that going from elementary uniflcation
to general uniflcation is in fact an instance of the combination problem. If we deflne the
free theory for \¡", \0" and \1" to be F0;1;¡ = f¡x = ¡x; 0 = 0; 1 = 1g, then one can
use elementary uniflcation modulo AC+ [ AC⁄ [ F0;1;¡ instead of general uniflcation
modulo AC+ [AC⁄ for computing critical pairs.
When considering the combination problem, the attention was until now mostly re-
stricted to flnitary unifying theories, and by uniflcation algorithm one meant a procedure
that computes a flnite complete set of uniflers. The problem was flrst considered in Stickel
(1975), Stickel (1981), Fages (1987) and Herold and Siekmann (1987) for the case where
several AC-symbols and free symbols may occur in the terms to be unifled. More gen-
eral combination problems were, for example, treated in Kirchner (1985), Tiden (1986),
Herold (1986), Yelick (1987) and Boudet et al. (1989) but the theories considered in these
papers always had to satisfy certain restrictions (such as being collapse-free or regulary)
on the syntactic form of their deflning identities.
y A theory E is called collapse-free if it does not contain an identity of the form x = t where x is
a variable and t is a non-variable term, and it is called regular if the left and right hand sides of the
identities contain the same variables.
  
214 F. Baader and K. U. Schulz
The problem was flnally solved in its until now most general form by Schmidt-Schau…
(1989). His algorithm imposes no restriction on the syntactic form of the identities. The
only requirements for a combination of disjoint theories E;F are:
(i) All uniflcation problems with constants must be flnitary solvable in E and F .
(ii) All constant elimination problems must be flnitary solvable in E and F .
A more e–cient version of this algorithm has been described by Boudet (1993).
The method of Schmidt-Schau… can also handle theories that are not flnitary. In this
case, procedures enumerating complete sets of uniflers for the single theories can be
combined to a procedure enumerating a complete set of uniflers for their union. However,
even if uniflcation in the single theories is decidable, this does not show how to obtain a
decision algorithm for uniflability in the combined theory.
The inflnitary theory A = ff(f(x; y); z) = f(x; f(y; z))g is an example for this case.
Plotkin (1972) described a procedure that enumerates minimal complete sets ofA-uniflers
for general A-uniflcation problems, and in 1977 Makanin (1977) has shown that A-
uniflcation with constants is decidable. But in 1991, decidability of general A-uniflcation
was still mentioned as an open problem by Kapur and Narendran (1991) in their ta-
ble of known decidability and complexity results for uniflcation. Such a decision pro-
cedure could, for example, be useful when building associativity into a theorem prover
via constraint resolution; and it could be used to make Plotkin’s enumeration procedure
terminating for equations having flnite complete sets of A-uniflers.
In his paper on uniflcation in the combination of arbitrary disjoint equational theories,
Schmidt-Schau… (1989) also treats the problem of how to combine decision procedures.
But in this case he needs decision procedures for general uniflcation in the single theories
as prerequisites for his algorithm. Thus his result cannot be used to solve the above
mentioned open problem of decidability of general A-uniflcation.
The research that will be presented in this paper builds up on the ideas of Schmidt-
Schau… and Boudet. It was motivated by the question of how to design a decision pro-
cedure for general A-uniflcation. However, the results we have obtained are more gen-
eral. We shall present a method that allows one to decide uniflability in the union of
arbitrary disjoint equational theories, provided that solvability of so-called uniflcation
problems with constant restrictions|a slight generalization of uniflcation problems with
constants|is decidable for the single theories. In addition, our method can also be used
to combine algorithms that compute flnite complete sets of uniflers.
These main results and some of the interesting consequences will be described in the
next section. Among these consequences are the new results that general A-uniflcation
is in fact decidable, and that the union of disjoint equational theories is flnitary if the
single theories are flnitary with respect to general uniflcation.
In Section 3 we shall present the algorithm for the decision problem, and describe how
it can also be used to generate complete sets of uniflers. Section 4 proves the correctness
of the method. In Section 5 we shall describe conditions under which algorithms for
solving uniflcation problems with constant restrictions exist. Some of the consequences
mentioned in Section 2 depend on these results. In Section 6 we consider optimization
techniques.
         
Combining Decision Procedures 215
2. Main Results and Consequences
As mentioned in the introduction, we must consider a slight generalization of E-
uniflcation problems with constants, so-called E-uniflcation problems with constant re-
striction, which will be introduced below. Having an algorithm that solves these kind of
problems is the only prerequisite necessary for our combination method.
Recall that an E-uniflcation problem with constants is a flnite set of equations ¡ =
fs1 := t1; : : : ; sn := tng, where the terms s1; : : : ; tn are built from variables, the function
symbols occurring in the axioms of E, and additional free constant symbols. Now, an
E-uniflcation problem with constant restriction is an ordinary E-uniflcation problem with
constants, ¡, where each free constant c occurring in the problem ¡ is equipped with a
set Vc of variables, namely, the variables in whose image c must not occur. A solution
of the problem is an E-unifler ¾ of ¡ such that for all c; x with x 2 Vc, the constant c
does not occur in x¾. Complete sets of solutions of uniflcation problems with constant
restriction are deflned as in the case of ordinary uniflcation problems.
It turns out that our combination method does not really need an algorithm that can
handle E-uniflcation problems with arbitrary constant restrictions; it is su–cient to deal
with problems with a so-called linear constant restriction. Such a restriction is induced
by a linear ordering on the variables and free constants as follows: Let X be the set of
all variables and C be the set of all free constants occurring in ¡. For a given linear
ordering < on X [ C, the sets Vc are deflned as fx j x is a variable with x < cg.
We are now ready to formulate our flrst main result, which is concerned with combining
decision algorithms. The decomposition algorithm that is used to establish this result will
be described in the next section.
Theorem 2.1. Let E1; : : : ; En be equational theories over disjoint signatures such that
solvability of Ei-uniflcation problems with linear constant restriction is decidable for i =
1; : : : ; n. Then uniflability is decidable for the combined theory E1 [ ¢ ¢ ¢ [ En.
By \uniflability" we mean here solvability of elementary uniflcation problems. However,
we shall see below that the result can be lifted to general uniflcation, and to solvability of
uniflcation problems with linear constant restriction. The theorem also has several other
interesting consequences, which are listed below.
1 Let E be an equational theory such that solvability of E-uniflcation problems with
linear constant restriction is decidable. Then solvability of general E-uniflcation
problems is decidable.
In fact, for a given set › of function symbols we can always build the free theory F›
as exemplifled in Example 1.2. It is easy to see that F› satisfles the assumption of
the theorem; and obviously, any general uniflcation problem modulo E can be seen
as an elementary uniflcation modulo E [ F› (where › contains all the additional
free function symbols occurring in the problem).
2 This argument also shows why the result of the theorem can be lifted to general
uniflcation: in order to get decidability of general uniflcation modulo E1 [ ¢ ¢ ¢ [En,
apply the theorem to E1; : : : ; En; F›.
3 General A-uniflability is decidable.
For A, decidability of uniflcation problems with constant restriction is an easy
consequence (see Baader and Schulz, 1993) of a result by Schulz (1991) on a gener-
alization of Makanin’s procedure. This result shows that it is still decidable whether
         
216 F. Baader and K. U. Schulz
a given A-uniflcation problem with constants has a solution for which the words
substituted for the variables in the problem are elements of given regular languages
over the constants. It is easy to see that problems with constant restriction are a
special case of these more generally restricted problems.
4 General AI-uniflability, where AI := A [ ff(x; x) = xg, is decidable.
This was also stated as an open problem in Kapur and Narendran (1991). For AI,
decidability of uniflcation problems with constant restriction easily follows from the
well-known fact [see e.g. Howie (1976)] that flnitely generated idempotent semi-
groups are flnite [see Baader and Schulz (1993) for details] .
5 If solvability of the Ei-uniflcation problems with linear constant restriction can be
decided by an NP-algorithm, then uniflability in the combined theory is also NP-
decidable.
This fact will become obvious once we have described our decomposition algo-
rithm. As a consequence one obtains simple proofs of Kapur and Narendran’s results
(Kapur and Narendran, 1991) that solvability of general AC- and ACI -uniflcation
problems can be decided by NP-algorithms. For these theories, NP-decidability of
uniflcation problems with constant restriction can be shown very similarly as in the
case of ordinary uniflcation problems with constants [see Baader and Schulz (1993)
for details].
6 Let E1; : : : ; En be equational theories over disjoint signatures such that solvability
of general Ei-uniflcation problems is decidable for i = 1; : : : ; n. Then uniflability
is decidable for the combined theory E1 [ ¢ ¢ ¢ [ En. This result, which was flrst
proved by Schmidt-Schau… [see Schmidt-Schau… (1989), Theorem 10.6], can also be
obtained as a corollary to our theorem. In fact, we shall show that solvability of
E-uniflcation problems with linear constant restriction can be reduced to solvability
of general E-uniflcation problems (see Section 5).
7 Together with the second consequence mentioned above, this reduction also shows
that the result of Theorem 2.1 can be lifted to uniflcation problems with linear
constant restriction.
The algorithm that will be introduced for proving Theorem 2.1 can also be used to
compute complete sets of uniflers.
Theorem 2.2. Let E1; : : : ; En be equational theories over disjoint signatures such that
all Ei-uniflcation problems with linear constant restriction have flnite complete set of
solutions (i = 1; : : : ; n). Then the combined theory E1 [ ¢ ¢ ¢ [ En is flnitary.
Again, we are talking about elementary uniflcation for the combined theory; but as
for the case of the decision problem, the result can easily be lifted to general uniflcation,
and to uniflcation problems with linear constant restriction. It should be noted that this
result is efiective in the sense that we really obtain an algorithm computing flnite complete
set of uniflers for the combined theory, provided that for the single theories there exist
algorithms computing flnite complete sets of solutions of uniflcation problems with linear
constant restriction. In the following, we mention two other interesting consequences of
the theorem.
8 Let E1; : : : ; En be equational theories over disjoint signatures that are flnitary with
respect to general uniflcation. Then the combined theory E1 [ ¢ ¢ ¢ [ En is flnitary.
          
Combining Decision Procedures 217
In fact, we can show how flnite complete sets of uniflers for general Ei-uniflcation
problems can be used to construct flnite complete sets of solutions for uniflcation
problems with linear constant restriction (see Section 5).
9 Algorithms that compute flnite complete sets of uniflers for uniflcation with con-
stants, and flnite complete sets of constant eliminators can be used to construct
an algorithm computing flnite complete sets of solutions for uniflcation problems
with constant restriction (see Section 5). As a consequence, the combination result
of Schmidt-Schau… (1989, Corollary 7.14) mentioned in the introduction can also
be obtained as a corollary to Theorem 2.2.
the logical status
Most of the results mentioned above use the notion of an E-uniflcation problem with
linear constant restriction. On flrst sight, a constant restriction such as \c must not occur
in the value of x" seems to be a rather technical condition without an abstract logical
meaning. This impression is wrong, however, in the particular case of a linear constant
restriction. In fact, these conditions have a clear logical status.
Let E be an equational theory with signature §, and let L(§) denote the (purely
equational) flrst order language associated with §. We consider the positive fragment
L+(§) of L(§): formulae of L+(§) are built from equational atoms s := t using the
Boolean operators conjunction and disjunction (but no negation), and both universal
and existential quantiflcation. Let ` be an L+(§)-sentence of the form
(⁄) ` = Q1x1 ¢ ¢ ¢Qkxk
n^
i=1
(si
:= ti);
where the Qi are existential or universal quantiflers. From ` we obtain in a canonical way
an E-uniflcation problem with linear constant restriction, ¡, as follows: ¡ consists of the
equations si
:= ti (i = 1; : : : ; n). Existentially (universally) quantifled variables of ` are
treated as variables (constants), and the linear order on these variables and constants is
given by the quantifler preflx, i.e., x1 < x2 < ::: < xk. Obviously, this translation also
works in the converse direction, and thus we obtain for every E-uniflcation problem with
linear constant restriction, ¡, a unique L+(§)-sentence ` of the form (⁄). In Section 5
we shall prove that ` is a theorem of E if, and only if, ¡ has a solution. This fact has
several consequences. We say that the positive fragment of the theory of E is decidable
(or shorter: the positive theory of E is decidable) if there exists an algorithm that decides
for arbitrary L+(§)-sentencesy ` whether ` is a theorem of E.
10 Let E be an equational theory. The positive theory of E is decidable if, and only if,
solvability of E-uniflcation problems with linear constant restriction is decidable.
Now Theorem 2.1 and Result 7 can be reformulated:
Theorem 2.3. Let E1; : : : ; En be equational theories over disjoint signatures. Then the
positive theory of E1 [ ¢ ¢ ¢ [En is decidable if the positive fragments of all subtheories Ei
are decidable, for i = 1; : : : ; n.
y Note that arbitrary L+(§)-sentences are not necessarily of the form (⁄) since they may contain
disjunction. In Section 5 we show how disjunction is taken into account.
          
218 F. Baader and K. U. Schulz
Uniflcation problems with linear constant restriction have been considered elsewhere.
It is well-known that already Herbrand (1930, 1967) considered uniflcation of flrst order
terms. But what he really studied in his context were in fact uniflcation problems with
linear constant restriction, with an order induced by a quantifler preflx as described
above. The interplay between mixed quantifler preflxes and constant restrictions in the
context of simply typed ‚-terms has recently been considered by Miller (1992).
3. The Decomposition Algorithm
For the sake of convenience we shall restrict the presentation to the combination of two
theories. The combination of more than two theories can be treated analogously. Before
we can start with the description of the algorithm we must introduce some notation.
Let E1; E2 be two equational theories built over the disjoint signatures ›1;›2, and let
E = E1[E2 denote their union. Since we are only interested in elementary E-uniflcation,
we can restrict our attention to terms built from variables and symbols of ›1 [ ›2. The
elements of ›1 will be called 1-symbols and the elements of ›2 2-symbols. A term t is
called i-term ifi it is of the form t = f(t1; :::; tn) for an i-symbol f (i = 1; 2). A subterm s
of a 1-term t is called alien subterm of t ifi it is a 2-term such that every proper superterm
of s in t is a 1-term. Alien subterms of 2-terms are deflned analogously. An i-term s is
pure ifi it contains only i-symbols and variables. An equation s := t is pure ifi there exists
an i; 1 • i • 2, such that s and t are pure i-terms or variables; this equation is then
called an i-equation. Please note that according to this deflnition equations of the form
x
:= y where x and y are variables are both 1- and 2-equations. In the following, the
symbols x; y; z, with or without subscripts, will always stand for variables.
Example 3.1. Let ›1 consist of the binary (inflx) symbol \–" and ›2 of the unary
symbol \h", let E1 := fx – (y – z) = (x – y) – zg be the theory which says that \–" is
associative, and let E2 := fh(x) = h(x)g be the free theory for \h".
The term y – h(z – h(x)) is a 1-term, which has h(z – h(x)) as its only alien subterm.
The equation h(x1) –x2 := y is not pure, but it can be replaced by two pure equations as
follows. We replace the alien subterm h(x1) of h(x1)–x2 by a new variable z. This yields
the pure equation z – x2 := y. In addition, we consider the new equation z := h(x1). This
process of replacing alien subterms by new variables is called variable abstraction. It will
be the flrst of the flve steps of our decomposition algorithm.
the main procedure
The input for the decomposition algorithm is an elementary E-uniflcation problem, i.e.,
a system ¡0 = fs1 := t1; : : : ; sn := tng, where the terms s1; : : : ; tn are built from variables
and the function symbols occurring in ›1 [ ›2, the signature of E = E1 [ E2. The flrst
two steps of the algorithm are deterministic, i.e., they transform the given system of
equations into one new system.
Step 1: variable abstraction. Alien subterms are successively replaced by new vari-
ables until all terms occurring in the system are pure. To be more precise, assume
that s := t or t := s is an equation in the current system, and that s contains the
alien subterm s1. Let x be a variable not occurring in the current system, and let
s0 be the term obtained from s by replacing s1 by x. Then the original equation is
         
Combining Decision Procedures 219
replaced by the two equations s0 := t and x := s1. This process is iterated until all
terms occurring in the system are pure. It is easy to see that this can be achieved
after flnitely many iterations.
We obtain a new system ¡1. Now all the terms in the system are pure, but there may
still exist non-pure equations, consisting of a 1-term on one side and a 2-term on the
other side.
Step 2: split non-pure equations. Each non-pure equations of the form s := t is
replaced by two equations x := s; x := t where the x are always new variables.
It is quite obvious that these two steps do not change solvability of the system. The
result is a system ¡2, which consists of pure equations. The third and the fourth step
are nondeterministic, i.e., a given system is transformed into flnitely many new systems.
Here the idea is that the original system is solvable ifi at least one of the new systems is
solvable.
Step 3: variable identification. Consider all possible partitions of the set of all
variables occurring in the system. Each of these partitions yields one of the new
systems as follows. The variables in each class of the partition are \identifled" with
each other by choosing an element of the class as representative, and replacing in
the system all occurrences of variables of the class by this representative.
Step 4: choose ordering and theory indices. This step does not change a given
system, it just adds some information that will be important in the next step. For
a given system ¡3 obtained in Step 3, consider all possible strict linear orderings <
on the variables of the system, and all mappings ind from the set of variables into
the set of theory indices f1; 2g. Each pair (<; ind) yields one of the new systems ¡4
obtained from the given one.
The last step is again deterministic. It splits each of the systems already obtained into
a pair of pure systems.
Step 5: split systems. A given system ¡4 is split into two systems ¡5;1 and ¡5;2 such
that ¡5;1 contains only 1-equations and ¡5;2 only 2-equations. These systems can
now be considered as uniflcation problems with linear constant restriction. In the
system ¡5;i, the variables with index i are still treated as variables, but the variables
with alien index j 6= i are treated as free constants. The linear constant restriction
for ¡5;i is induced by the linear ordering chosen in the previous step.
The output of the algorithm is thus a flnite set of pairs (¡5;1;¡5;2) where the flrst
component ¡5;1 is an E1-uniflcation problem with linear constant restriction, and the
second component ¡5;2 is an E2-uniflcation problem with linear constant restriction.
Proposition 3.2. The input system ¡0 is solvable if and only if there exists a pair
(¡5;1;¡5;2) in the output set such that ¡5;1 and ¡5;2 are solvable.
A proof of this proposition is given in the next section. Obviously, if solvability of E1-
and E2-uniflcation problems with linear constant restrictions is decidable, the proposition
implies decidability of elementary E-uniflability, which proves Theorem 2.1.
          
220 F. Baader and K. U. Schulz
an example
We consider the theories E1 and E2 of Example 3.1, and the uniflcation problem
fh(x) – y = y – h(z1 – z2)g:
Step 1: variable abstraction. This step results in the new system
fx1 – y = y – x2; x1 = h(x); x2 = h(x3); x3 = z1 – z2g:
Step 2: split non-pure equations. Since all equations are already pure, nothing is
done in this step.
Step 3: variable identification. As an example, we consider the partition where x1
and x2 are in one class, and all the other variables are in singleton classes. Choosing
x1 as representative for its class, we obtain the new system
fx1 – y = y – x1; x1 = h(x); x1 = h(x3); x3 = z1 – z2g:
Step 4: choose ordering and theory indices. As an example, we take the linear
ordering
z1 < z2 < x3 < x < x1 < y;
and the theory indices
ind(x1) = ind(x) = ind(z1) = ind(z2) = 2 and ind(x3) = ind(y) = 1:
Step 5: split systems. On the one hand, we get the system
¡5;1 = fx1 – y = y – x1; x3 = z1 – z2g
consisting of pure 1-equations. In this system the variables with index 1, i.e., x3
and y, are still treated as variables, but the variables of index 2, i.e., x1, z1 and z2,
are treated as free constants. The linear constant restriction induced by the linear
ordering is given by Vx1 = fx3g; Vz1 = Vz2 = ;.
On the other hand, we obtain the system
¡5;2 = fx1 = h(x); x1 = h(x3)g
consisting of pure 2-equations. Here x and x1 are treated as variables, and x3 is
treated as free constant. The constant restriction is given by Vx3 = ;.
This pair (¡5;1;¡5;2) is one element in the set obtained as output of the algorithm. It is
easy to see that ¡5;1 has the solution fx3 7! z1 – z2; y 7! x1g, and ¡5;2 has the solution
fx1 7! h(x3); x 7! x3g. Consequently, the proposition implies that the original system
has a solution.
combination of unifiers
The decomposition algorithm can also be used to compute complete sets of uniflers for
elementary (E1[E2)-uniflcation problems, provided that one can compute flnite complete
sets of solutions for all Ei-uniflcation problems with linear constant restriction (i = 1; 2).
The reason is that solutions of the problems ¡5;1;¡5;2 in the output of the algorithm can
be combined to solutions of the original input system. This combined solution is deflned
inductively over the linear ordering chosen in Step 4 of the algorithm.
         
Combining Decision Procedures 221
Assume that ¾1 is a solution of ¡5;1 and ¾2 is a solution of ¡5;2. Without loss of
generality we may assume that the substitution ¾i maps all variables of index i to terms
containing only variables of index j 6= i (which are treated as free constants in ¡5;i)
or new variables, i.e., variables not occurring in ¡0, ¡5;1, or ¡5;2. This can simply be
achieved by renaming variables if necessary. First, we deflne the combined solution ¾ on
the variables occurring in the system obtained after Step 4 of the algorithm. Note that
the input system ¡0 may contain additional variables, which have been replaced during
the variable identiflcation step.
Let x be the least variable with respect to the linear ordering chosen in Step 4, and let
i be its index. Since the solution ¾i of ¡5;i satisfles the constant restriction induced by
the linear ordering, the term x¾i does not contain any variables of index j 6= i (Recall
that these variables are treated as free constants in ¡5;i.) Thus we can simply deflne
x¾ := x¾i.
Now let x be an arbitrary variable with index i, and let y1; : : : ; ym be the variables
with index j 6= i occurring in x¾i. Since ¾i satisfles the constant restriction induced by
the linear ordering, the variables y1; : : : ; ym (which are treated as free constants in ¡5;i)
have to be smaller than x. This means that y1¾; : : : ; ym¾ are already deflned. The term
x¾ is now obtained from x¾i by replacing the yk by yk¾ (k = 1; : : : ;m). Because we
have assumed that the other variables occurring in x¾i are new variables, we thus have
x¾ = x¾i¾.
Finally, let x be a variable of the input system that has been replaced by the variable
y during the variable identiflcation step. Thus y¾ is already deflned, and we can simply
set x¾ := y¾.
For all variables z not occurring in the input system we deflne z¾ := z.
Example 3.3. For the above example, the solutions ¾1 = fx3 7! z1 – z2; y 7! x1g and
¾2 = fx1 7! h(x3); x 7! x3g of ¡5;1;¡5;2 are combined to fz1 7! z1; z2 7! z2; x3 7!
z1 – z2; x 7! z1 – z2; x1 7! h(z1 – z2); x2 7! h(z1 – z2); y 7! h(z1 – z2)g.
This construction can now be used to generate complete sets of uniflers for elementary
(E1[E2)-uniflcation problems. For a given system ¡0, let f(¡15;1;¡15;2); : : : ; (¡n5;1;¡n5;2)g be
the output of the decomposition algorithm, if it is applied to the input ¡0. For i = 1; : : : ; n
and j = 1; 2, let Mi;j be a complete set of solutions of the Ei-uniflcation problem with
linear constant restriction ¡i5;j .
Proposition 3.4. The set of substitutions
n[
i=1
f¾ j ¾ is the combined solution obtained from ¾1 2Mi;1 and ¾2 2Mi;2g
is a complete set of (E1 [ E2)-uniflers of the input system ¡0.
A proof of this proposition will be given in the next section. Obviously, if all the sets
Mi;j are flnite, then the complete set given by the proposition is also flnite, which proves
Theorem 2.2.
            
222 F. Baader and K. U. Schulz
4. Correctness of the Decomposition Algorithm
In this section, we shall prove Proposition 3.2 and Proposition 3.4, which shows that
our combination method is correct both for the decision problem and for the problem of
computing complete sets of uniflers. Before we can start with our task, we must introduce
a useful tool, which has flrst been utilized in connection with the combination problem
in Boudet et al. (1989), namely unfailing completion applied to the combined theory.
Let E1; E2 be equational theories over disjoint signatures ›1;›2. We assume that
both theories are consistent, i.e., they have at least one model of cardinality greater than
one, or equivalently, the identity x =Ei y does not hold in either theory. One can now
apply unfailing completion [see e.g., Dershowitz and Jouannaud (1990) for deflnitions and
properties] to the combined theory E = E1 [E2. This yields a possibly inflnite ordered-
rewriting system R which is con°uent and terminating on ground terms. In the following,
we shall also apply this system to terms containing variables from a flxed countable set
of variables X0; but this is not a problem because these variables can simply be treated
like constants. In particular, this means that the simpliflcation ordering used during the
completion must also take care of these additional \constants." The ordered-rewriting
system R consists of (possibly inflnitely many) equations g = d. Such an equation can
be applied to a term s 2 T (›1 [ ›2; X0) ifi there exists an occurrence u in s and a
substitution ¿ such that s = s[uˆ g¿ ] (s = s[uˆ d¿ ], resp.) and g¿ is greater than d¿
(d¿ is greater than g¿ , resp.) with respect to the simpliflcation ordering. This application
results in the new term s[uˆ d¿ ] (s[uˆ g¿ ], resp.).
It is easy to see that, because the signatures of E1 and E2 are disjoint, the system R is
the union of two systems R1 and R2, where the terms in Ri are built over the signature
›i (i = 1; 2). In fact, Ri is just the system that would be obtained by applying unfailing
completion to Ei. This is an easy consequence of the deflnition of critical pairs used for
unfailing completion, and of the fact that E1 and E2 are assumed to be consistent.
Let T (›1 [ ›2; X0) be the set of terms built from function symbols in ›1 [ ›2 and
variables in X0, and let T#R denote its R-irreducible elements. We consider an arbitrary
bijection … : T#R ¡! Y where Y is a set of variables of appropriate cardinality. This
bijection induces mappings …1; …2 of terms in T (›1[›2; X0) to terms in T (›1[›2; Y ) as
follows. For variables x 2 X0, x…1 := …(x) (Note that variables are always R-irreducible.)
If t = f(t1; : : : ; tn) for a 1-symbol f , then t…1 := f(t…11 ; : : : ; t
…1
n ). Finally, if t is a 2-
term then t…1 := y where y = …(s) for the unique R-irreducible element s of the =E-
class of t. The mapping …2 is deflned analogously. The mappings …i may be regarded as
projections that map a possibly mixed term to an i-pure term. We write these mappings
as superscripts to distinguish them from substitutions. The inverse …¡1 of … can be
seen as a substitution that maps the variables y in Y back to the terms …¡1(y), and
is the identity on all other variables. Obviously, we have t…i…¡1 =E t for all terms
t 2 T (›1 [ ›2; X0), and if t is an R-irreducible term or an i-term such that all its alien
subterms are R-irreducible, then (t…i)…¡1 = t.
A substitution ¾ is called R-normalized on a flnite set of variables Z ifi z¾ 2 T#R for
all variables z 2 Z. The next lemma will be important in the proof of Proposition 3.2.
Lemma 4.1. Let s; t be pure i-terms or variables, and let ¾ be a substitution that is
R-normalized on the variables occurring in s; t. Then
s¾ =E t¾ ifi (s¾)…i =Ei (t¾)
…i :
          
Combining Decision Procedures 223
Proof. (1) The if-direction is easy to prove. Obviously, (s¾)…i =Ei (t¾)
…i implies that
(s¾)…i =E (t¾)…i , and thus (s¾)…i…¡1 =E (t¾)…i…¡1. By our assumptions on s; t and
¾, the j-terms (for j 6= i) in s¾ and t¾ are R-irreducible, which flnally yields s¾ =
(s¾)…i…¡1 =E (t¾)…i…¡1 = t¾.
(2) From s¾ =E t¾ follows the existence of an R-irreducible term r that is a common R-
descendant of s¾ and t¾. Let us now consider the derivation s0 := s¾ !R s1 !R ¢ ¢ ¢ !R r
more closely. The goal is to show s…i0 =Ei s
…i
1 =Ei ¢ ¢ ¢ =Ei r…i . Symmetrically, we could
then also deduce (t¾)…i =Ei r
…i , which would prove the lemma.
The case where s is a variable is trivial since then s0 is R-irreducible, which yields
s0 = r. Thus assume that s is a pure i-term. Since all alien subterms of s¾ are R-
irreducible, the flrst step of the derivation from s0 to r must take place at an occurrence
u which is not inside an alien subterm of s0 = s¾. In particular, this means that it is
done by applying a rule g = d of Ri. To be more precise, there exists a substitution ¿
such that s0 = s0[u ˆ g¿ ], s1 = s0[u ˆ d¿ ], and g¿ is greater than d¿ with respect to
the simpliflcation ordering. From the fact that u is not inside an alien subterm of s0 we
obtain that s…i0 = s
…i
0 [uˆ (g¿)…i ] and s…i1 = s…i0 [uˆ (d¿)…i ].
In order to conclude s…i0 =Ei s
…i
1 , it thus remains to be shown that (g¿)
…i =Ei (d¿)
…i .
To see this, we deflne the substitution ¿…i := fx 7! (x¿)…i j x occurs in g or dg. Since
g; d are pure i-terms or variables, we have g(¿…i) = (g¿)…i and d(¿…i) = (d¿)…i . Because
g = d 2 Ri implies g =Ei d, we thus obtain (g¿)…i = g(¿…i) =Ei d(¿…i) = (d¿)…i .
If we want to continue by induction, we have to know that all alien subterms of s1
are R-irreducible. This need not be the case for arbitrary derivations from s¾ to r. The
problem is that we only have an ordered-rewriting system that is terminating on ground
terms. For this reason it may well be the case that d contains variables not contained in
g; and in general we cannot be sure that the images of these variables under ¿ do not
introduce reducible alien subterms into s1. However, if we assume that the derivation
from s¾ to r is a bottom-up derivation where all the matching substitutions (such as our
¿) are R-normalized, then ¿ cannot introduce reducible alien subterms. This assumption
can be made without loss of generality because it is easy to see that, whenever a term is
not R-irreducible, then we can apply a rule of R to this term in a way that satisfles the
constraints of the assumption.
proof of proposition 3.2
For the remainder of the paper we shall use the following notational convention: ¡0
always denotes an input system of the decomposition algorithm. ¡i denotes a system
that is reached after applying Step i of the decomposition algorithm to ¡i¡1 (1 • i • 4),
and (¡5;1;¡5;2) denotes an output pair of the algorithm, resulting from a decomposition
of ¡4 as described in Step 5. Furthermore, Yi denotes the set of variables occurring in
system ¡i (0 • i • 4), and Y5;j denotes the subset of Y4 containing the variables of index
j (j = 1; 2). Thus Y4 is the disjoint union of Y5;1 and Y5;2.
First, we show soundness of the decomposition algorithm, i.e., we demonstrate that ¡0
is solvable if there exists a pair (¡5;1;¡5;2) in the output set such that ¡5;1 and ¡5;2 are
solvable.
Assume that ¾1 is a solution of ¡5;1 and ¾2 is a solution of ¡5;2. In the previous
section we have already described how these two solutions of the single problems can be
combined to a substitution ¾, which we have called the combined solution. It remains
       
224 F. Baader and K. U. Schulz
to be shown that ¾ is in fact a solution of ¡0. Obviously, it is su–cient to prove that ¾
is a solution of the system ¡4 that was split in Step 5 into ¡5;1 and ¡5;2. Let s
:= t be
an equation in ¡4, and assume without loss of generality that this equation was put into
¡5;1 in Step 5. Thus we know that s¾1 =E1 t¾1. As an easy consequence of the deflnition
of ¾, one obtains that ¾ = ¾1¾. Since s¾1 =E1 t¾1 obviously implies s¾1¾ =E1 t¾1¾, and
thus also s¾1¾ =E t¾1¾, this shows that s¾ =E t¾.
In the second part of the proof we must show completeness of the decomposition al-
gorithm, i.e., we must demonstrate that there exists a pair (¡5;1;¡5;2) in the output set
such that ¡5;1 and ¡5;2 are solvable, if ¡0 is solvable.
Let ¾ be a solution of ¡0. Without loss of generality we assume that ¾ is also a solution
of ¡2, that the set Y2 of all variables occurring in this system is disjoint to X0, and that
¾ is R-normalized on Y2. In particular, this implies that the variables occurring in y¾ for
y 2 Y2 are elements of X0. The solution ¾ can be used to deflne the correct alternatives
in the nondeterministic steps of the decomposition algorithm:
(i) The partition of the set of all variables, which has to be chosen in the third step, is
deflned as follows: two variables y and z are in the same class ifi y¾ = z¾. Obviously,
this means that ¾ is also a solution of ¡3, the system obtained after the variable
identiflcation step corresponding to this partition.
(ii) In the fourth step, the variable y gets index i if y¾ is an i-term. If y¾ is itself a
variable, y gets index 1. (This is arbitrary, we could have taken index 2 as well.)
(iii) In the fourth step, we must also choose an appropriate linear ordering on the vari-
ables occurring in the system. Consider the strict partial ordering deflned by y < z
ifi y¾ is a strict subterm of z¾. We take an arbitrary extension of this partial
ordering to a linear ordering on the variables occurring in the system.
The choices we have just described determine a system ¡4 and a particular pair of
systems (¡5;1;¡5;2) in the output set of the decomposition algorithm. Since Step 4 does
not modify any equation, ¾ solves ¡4. It remains to be shown that ¡5;1;¡5;2 are solvable.
In order to deflne solutions ¾i of these systems, we consider a bijection … from the R-
irreducible elements of T (›1 [ ›2; X0) onto a set of variables Y .
This bijection has to satisfy two conditions. First, Y should contain Y4, the set of
variables occurring in ¡4. Since ¾ is assumed to be R-normalized on Y2, we have that
y¾ is R-irreducible for all variables y 2 Y4. The second condition on … is that …(y¾) = y
for all y 2 Y4. For the satisflability of these conditions, the variable identiflcation step is
important. The reason is that only because of this step we can be sure that ¡4 does not
contain two difierent variables y; y0 with y¾ = y0¾.
As described above, the bijection … induces mappings …1; …2. These mappings will now
be used to construct the solutions ¾i for i = 1; 2. The substitution ¾i is deflned on the
variables y 2 Y4 by y¾i := (y¾)…i .
If y is a variable of index j 6= i, the term y¾ is either a variable in X0 or a j-term. In
both cases we obtain y¾i = (y¾)…i = …(y¾) = y by deflnition of ¾i and …i. This shows
that ¾i really treats the variables of index j as constants.
Now assume that s := t is an equation in ¡5;i. Since this equation is also contained
in ¡4, and since ¾ solves ¡4, we know that s¾ =E t¾. Since ¾ was assumed to be R-
normalized on Y2, and since s
:= t is an i-equation, we can apply Lemma 4.1 to get
(s¾)…i =Ei (t¾)
…i . Using the deflnition of ¾i and the fact that s
:= t is an i-equation, it is
easy to see that (s¾)…i = s¾i and (t¾)…i = t¾i. Thus ¾i really solves the equation s
:= t.
            
Combining Decision Procedures 225
It remains to be shown that ¾i satisfles the constant restriction. Assume that x is a
variable of index i, and that the variable y of index j 6= i (which is treated as a constant in
¡5;i) occurs in x¾i. We must show that x is not an element of Vy, i.e., that x 6< y. Recall
that x¾i = (x¾)…i , and that x¾ is R-irreducible. Thus, since y 62 X0, the occurrence
of y in x¾i must come from the occurrence of y¾ as a subterm of x¾. Because of the
identiflcation step, the fact that x and y are difierent variables also implies that x¾ and
y¾ are difierent terms. Thus y¾ is a strict subterm of x¾, which yields y < x because of
the way the linear ordering was chosen.
proof of proposition 3.4
In the flrst part of the proof of Proposition 3.2 we have already shown that the elements
of the set of substitutions deflned in the formulation of Proposition 3.4 are solutions of
¡0. It remains to be shown that this set is complete.
Let ¿ be a solution of ¡0. Without loss of generality we assume that ¿ is also a solution
of ¡2, that the set Y2 of all variables occurring in this system is disjoint to X0, and that
¿ is R-normalized on Y2. In the second part of the proof of Proposition 3.2 we have
shown that ¿ can be used to flnd a pair of systems (¡5;1;¡5;2) in the output set of the
decomposition algorithm, and to construct solutions ¿1 and ¿2 of these systems. This
construction makes use of a bijection … and mappings …1; …2 induced by this bijection as
described above.
Since ¿i is a solution of ¡5;i, there exist an element ¾i in the complete set of solutions
of ¡5;i and a substitution ‚i such that ¿i =Ei ¾i‚i hY5;ii.y Without loss of generality
we may assume that the substitution ¾i maps the variables in Y5;i to terms containing
only variables of index j 6= i (which are treated as constants by ‚i) or new variables
from a set of variables Zi. We may assume that the domain of ‚i is Zi, and that the sets
X0; Y2; Z1; Z2 are pairwise disjoint.
As described in the flrst part of the proof of Proposition 3.2, the solutions ¾1; ¾2
of ¡5;1;¡5;2 can be combined to a solution ¾ of ¡. Since this combined solution is an
element of the set of substitutions deflned in the formulation of Proposition 3.4, it remains
to be shown that there exists a substitution ‚ such that ¿ =E ¾‚ hY0i. We deflne
‚ := (‚1 [ ‚2)…¡1, where (‚1 [ ‚2) is meant to denote the substitution that is equal to
‚i on Zi (i = 1; 2), and the identity on all variables not contained in Z1 [ Z2.
First, we show ¿ =E ¾‚ hY5;1[Y5;2i. The proof is by induction on the linear ordering <
chosen in Step 4 of the decomposition algorithm. Without loss of generality, we consider a
variable y 2 Y5;1. By the deflnition of ¾, we have y¾‚ = (y¾1)¾‚. The variables occurring
in the term y¾1 are either variables of index 2, i.e., elements of Y5;2, or new variables,
i.e., elements of Z1. We want to show that on these variables, the substitutions ¾‚ and
‚1…
¡1 coincide modulo E.
Let z1 be an element of Z1 occurring in y¾1. Since we have assumed that the elements
of Z1 are new variables, z1 is not in the domain of ¾, which yields z1¾‚ = z1‚. By
deflnition of ‚, and since z1 2 Z1, we obtain z1‚ = z1‚1…¡1.
If y is the least variable with respect to the linear ordering <, then the term y¾1 does
not contain a variable of Y5;2, because ¾1 satisfles the linear constant restriction induced
by <. Now assume that y is an arbitrary variable in Y5;1, and let y2 be an element of Y5;2
y Recall that, for a flnite set Z of variables, –1 =E –2 hZi means that z–1 =E z–2 for all z 2 Z.
           
226 F. Baader and K. U. Schulz
occurring in y¾1. Since ¾1 satisfles the linear constant restriction, we know that y2 < y.
By induction, we thus obtain y2¾‚ =E y2¿ . We also have y2¿ = (y2¿)…1…¡1 = y2¿1…¡1.
Since ¿1 and ‚1 treat variables of index 2 as constants, we know that y2¿1…¡1 = y2…¡1 =
y2‚1…
¡1. Thus we have shown y2¾‚ =E y2‚1…¡1.
To sum up, we have just shown that, for all variables z occurring in y¾1, we have
z¾‚ =E z‚1…¡1. Consequently, we obtain y¾‚ = (y¾1)¾‚ =E (y¾1)‚1…¡1 =E y¿1…¡1 =
(y¿)…1…¡1 = y¿ as required.
Finally, assume that x is a variable occurring in ¡0, but x 62 Y5;1 [ Y5;2. This means
that x has been substituted by a variable y 2 Y5;1[Y5;2 during the variable identiflcation
step of the algorithm. On the one hand, this means that y¿ = x¿ (since this must have
triggered the identiflcation). On the other hand, because of this identiflcation step, we
have deflned x¾ := y¾. Thus we have x¿ = y¿ =E y¾‚ = x¾‚. This completes the proof
of the proposition.
5. Solving Uniflcation Problems with Constant Restriction
We have seen that algorithms for E-uniflcation with linear constant restriction may
be used to obtain|via our combination method|algorithms for general uniflcation. In
the flrst part of this section we shall describe how, conversely, algorithms for general
uniflcation can be used to solve uniflcation problems with linear constant restriction.
In the second part, constant elimination algorithms together with algorithms for uni-
flcation with constants are used to solve uniflcation problems with arbitrary constant
restriction. The third part of this section is concerned with the logical characterization
of E-uniflcation problems with linear constant restriction mentioned in Section 2.
In the following, E is assumed to be an arbitrary consistent equational theory.
5.1. using algorithms for general unification
In this subsection we shall consider both the problem of deciding solvability and of
generating complete sets of solutions of uniflcation problems with linear constant restric-
tions.
the decision problem
Let ¡ be an E-uniflcation problem with a linear constant restriction, and let < be the
linear ordering by which this restriction is induced. In the following, let X denote the set
of all variables and C denote the set of all free constants occurring in ¡. Our goal is to
construct a general E-uniflcation problem ¡0 such that ¡ is solvable ifi ¡0 is solvable.
In this new system ¡0, the free constants of ¡ will be treated as variables, i.e., the
solutions are allowed to substitute terms for these \constants." For any free constant c
of ¡ we introduce a new (free) function symbol fc of arity jVcj. Recall that Vc = fx 2
X j x < cg is the set of variables in whose ¾-image c must not occur for the solution ¾
of ¡ to satisfy the constant restriction. The general E-uniflcation problem|in which the
free constants of ¡ are treated as variables|is now deflned as
¡0 := ¡ [ fc := fc(x1; : : : ; xn) j c 2 C and Vc = fx1; : : : ; xngg :
Proposition 5.1. The E-uniflcation problem with linear constant restriction, ¡, is solv-
able ifi the general E-uniflcation problem ¡0 is solvable.
         
Combining Decision Procedures 227
Please note that the proposition only holds for uniflcation problems with linear con-
stant restriction. The following example demonstrates that the construction described
above cannot be used for uniflcation problems with arbitrary constant restriction.
Example 5.2. Let E be the empty theory, and let x; y be variables and c; d be free
constants. We consider the following E-uniflcation problem with constant restriction:
¡ = fx := d; y := cg; Vc = fxg; Vd = fyg:
It is easy to see that this restriction cannot be induced by a linear ordering on fx; y; c; dg.
Obviously, the problem has the solution fx 7! d; y 7! cg.
The corresponding general E-uniflcation problem is
¡0 = fx := d; y := c; c := fc(x); d := fd(y)g;
where c; d are now treated as variables. It is easy to see that this problem does not have
a solution.
However, as we shall prove below, our construction is correct for uniflcation problems
with linear constant restriction. But flrst, let us demonstrate that this construction also
works for the case of algorithms computing complete sets of uniflers.
generating complete sets of solutions
More precisely, we shall describe how we can obtain a flnite complete set of solutions
of ¡, provided that a flnite complete set of E-uniflers of ¡0 exists.
Let R be the possibly inflnite ordered-rewriting system that is obtained when applying
unfailing completion to E. We assume that the simpliflcation ordering used during the
completion also takes the additional symbols fc and variables (which are however treated
as constants by the ordering) out of a countable set X0 of new variables into account.
This means that we can apply R to terms built out of symbols in the signature of E, the
additional symbols fc, and variables in X0. Let T#R be the R-irreducible elements of the
set of these terms.
Now we shall show how an element ¾0 of a complete set of E-uniflers of ¡0 can be
used to deflne a solution ¾ of ¡. Without loss of generality, we may assume that ¾0 is
R-normalized on the variables occurring in ¡0. In fact, for any substitution there exists
an =E-equivalent substitution that is R-normalized on the variables occurring in ¡0;
and exchanging an element of a complete set of E-uniflers of ¡0 by an =E-equivalent
substitution still leaves us with a complete set of E-uniflers of ¡0.
Let … be a bijection from T#R onto a set of variables Y . This bijection has to satisfy two
conditions. First, Y should contain all the free constants occurring in ¡ (which are treated
as variables in ¡0). Since ¾0 is assumed to be R-normalized on the variables occurring in
¡0, we have that c¾0 is R-irreducible for all these constants c. The second condition on … is
that …(c¾0) = c for these constants c. The two conditions are satisflable because for c 6= c0
we have c¾0 6= c0¾0. In fact, since ¾0 solves ¡0, we know that c¾0 =E fc(x1¾0; : : : ; xn¾0)
and c0¾0 =E fc0(x1¾0; : : : ; xn¾0). But this implies that c¾0 has fc as root symbol, and c0¾0
the difierent symbol fc0 .
As described in Section 4, the bijection … induces a mapping …1. To this purpose we
treat the symbols of the signature of E as 1-symbols and the symbols fc as 2-symbols.
The mapping …1 is now used to deflne our solution ¾ of ¡. For all variables x occurring
         
228 F. Baader and K. U. Schulz
in ¡ we deflne x¾ := (x¾0)…1 . The constants c of ¡ are really treated as constants by ¾,
i.e., c¾ = c. However, note that c = (c¾0)…1 holds, anyway.
Proposition 5.3. Let C(¡0) be a complete set of E-uniflers of ¡0, which are (without
loss of generality) assumed to be R-normalized on the variables occurring in ¡0. Then the
set C(¡) := f¾ j ¾0 2 C(¡0)g, where ¾ is constructed out of ¾0 as described above, is a
complete set of solutions of the E-uniflcation problem with linear constant restriction, ¡.
Again, the proposition only holds for uniflcation problems with linear constant restric-
tion.
proof of proposition 5.1
Recall that X denotes the set of all variables and C denotes the set of all free constants
occurring in ¡.
To prove the \only-if" direction, assume that ¾ is a solution of ¡. Without loss of
generality, we may assume that for all x 2 X the variables occurring in x¾ are new
variables (i.e., variables not contained in X), and that ¾ is the identity on all variables
y 62 X. We deflne a substitution ¾0 on X [ C (where the elements of C are now treated
as variables) by induction on the linear ordering < that induces the constant restriction
of ¡.
First, we consider the least element of X [ C with respect to <. If this is a variable
x 2 X, then for all c 2 C we have x 2 Vc. This implies that x¾ does not contain any
of these free constants, and we can deflne x¾0 := x¾. If the least element of X [ C is a
constant c 2 C, then Vc = ;. This means that fc is a constant symbol, and we deflne
c¾0 := fc.
Now let x be an arbitrary element of X, and let c1; : : : ; cm 2 C be the free constants
occurring in x¾. Since ¾ satisfles the constant restriction induced by the linear ordering,
the constants c1; : : : ; cm (which are treated as variables in ¡0) must be smaller than x.
This means that we may assume by induction that c1¾0; : : : ; cm¾0 are already deflned.
The term x¾0 is now obtained from x¾ by replacing the ck by ck¾0 (k = 1; : : : ;m).
Finally, let c be an arbitrary element of C. By deflnition, the system ¡0 contains the
equation c := fc(x1; : : : ; xn), where x1; : : : ; xn are those elements of X that are smaller
than c with respect to <. Thus we can assume by induction that x1¾0; : : : ; xn¾0 are
already deflned, and we set c¾0 := fc(x1¾0; : : : ; xn¾0).
It remains to be shown that ¾0 is a solution of ¡0. Obviously, the deflnition of ¾0
implies that it solves the equations c := fc(x1; : : : ; xn) in ¡0. Now let s
:= t be an equation
of ¡. Since ¾ solves ¡, we know that s¾ =E t¾. In addition, it is easy to see that
for all c 2 C we have c¾0 = c¾¾0 and for all x 2 X we have x¾0 = x¾¾0. But then
s¾0 = s¾¾0 =E t¾¾0 = t¾0.
To prove the \if" direction, assume that ¾0 is a solution of ¡0. Without loss of generality,
we assume that ¾0 is R-normalized on the set X [ C of all variables occurring in ¡0. As
described above, ¾0 can be used to deflne a new substitution ¾ as follows: For all variables
x occurring in ¡ one deflnes x¾ := (x¾0)…1 . We have to show that ¾ solves ¡.
Let s := t be an equation of ¡. Since ¾0 solves ¡0, we know that s¾0 =E t¾0. Now we
can apply Lemma 4.1 to obtain (s¾0)…1 =E (t¾0)…1 . Using the deflnition of ¾ and the fact
that the terms s; t do not contain the symbols fc, it is easy to see that (s¾0)…1 = s¾ and
(t¾0)…1 = t¾. Thus ¾ really solves the equation s := t.
          
Combining Decision Procedures 229
It remains to be shown that ¾ satisfles the constant restriction. Let c 2 C be a free con-
stant. Since ¾0 solves ¡0, we know that c¾0 =E fc(x1¾0; : : : ; xn¾0), where fx1; : : : ; xng =
Vc. In addition, ¾0 was assumed to be R-normalized on X [ C, which implies that
c¾0; x1¾0; : : : ; xn¾0 are R-irreducible terms; and since the symbol fc does not occur in
any rule of R, the term fc(x1¾0; : : : ; xn¾0) is also R-irreducible. Thus we have c¾0 =
fc(x1¾0; : : : ; xn¾0), which shows that the term c¾0 is not a subterm of any of the terms
x1¾
0; : : : ; xn¾0. But then c cannot occur in xi¾ = (xi¾0)…1 (i = 1; : : : ; n).
proof of proposition 5.3
Now we shall show that the set C(¡), as deflned in the formulation of Proposition 5.3,
is a complete set of solutions of ¡. In the second part of the proof of Proposition 5.1, we
have already shown that the substitution ¾ constructed from a solution ¾0 of ¡0 is itself
a solution of ¡. Thus C(¡) is a set of solutions of ¡. It remains to be shown that it is a
complete set. As before, let X denote the set of variables and C the set of free constants
occurring in ¡. Recall that the elements of C are treated as variables in ¡0.
Let ¿ be a solution of ¡. Without loss of generality, we assume that, for all x 2 X, the
variables occurring in x¿ are elements of X0. As shown in the flrst part of the proof of
Proposition 5.1, ¿ can be used to deflne a solution ¿ 0 of ¡0. Because of our assumption
on ¿ , it is easy to see that for all z 2 X [ C, the variables occurring in z¿ 0 are elements
of X0.
Since C(¡0) is a complete set of E-uniflers of ¡0, there exists an element ¾0 of C(¡0) and
a substitution ‚0 such that ¿ 0 =E ¾0‚0 hX[Ci. Let ¾ be the element of C(¡) constructed
out of ¾0. Our aim is to deflne a substitution ‚ that satisfles ¿ =E ¾‚ hXi. Let Y0 µ Y
denote the set of all variables occurring in the terms x¾ for x 2 X. These terms may also
contain elements of C, which must, however, be treated as constants by ‚.
In the construction of ¾ out of ¾0 we have used a bijection … from T#R onto a set of
variables Y which contains C. In addition, this bijection had to satisfy …(c¾0) = c for all
c 2 C. The substitution ¾ was then deflned by x¾ := (x¾0)…1 for all x 2 X. In order to be
able to reverse the construction of ¿ 0 out of ¿ we shall now consider an analogous bijection
„ from T#R onto Y . The condition on „ is that „((c¿ 0)#R) = c for all c 2 C. Here (c¿ 0)#R
denotes the unique R-irreducible element of the =E-class of c¿ 0. As an easy consequence
of this condition together with the deflnition of ¿ 0, we obtain that x¿ = (x¿ 0)„1 for all
x 2 X.
The substitution ‚ is now deflned on all y 2 Y0 as y‚ := (y…¡1‚0)„1 . To complete the
proof of the proposition we must show that ¿ =E ¾‚ hXi.
In this proof we need a lemma that is a stronger version of Lemma 4.1 for the special
case of the union of an arbitrary equational theory E with a disjoint free theory.
Lemma 5.4. Let s; t be terms built out of symbols in the signature of E, the additional
symbols fc, and variables in X0. Then s =E t ifi s„1 =E t„1 .
Proof. (1) From s„1 =E t„1 we can deduce s„1„¡1 =E t„1„¡1, and we also have
s =E s„1„¡1 and t =E t„1„¡1.
(2) Obviously, it is su–cient to prove the \only-if" direction for the case where t is
obtained from s by one application of an identity of E. Thus assume that g = d is an
identity of E, u is an occurrence in s, and ¿ is a substitution such that s = s[u ˆ g¿ ],
          
230 F. Baader and K. U. Schulz
t = s[u ˆ d¿ ]. If the occurrence u is strictly below an occurrence of a free function
symbol, then it is easy to see that s„1 = t„1 . Otherwise, we have s„1 = s„1 [uˆ (g¿)„1 ]
and s„1 = s„1 [uˆ (d¿)„1 ]. What remains to be shown is (g¿)„1 =E (d¿)„1 , and this can
be done as in the proof of Lemma 4.1.
We can now continue with the proof of the proposition. For all x 2 X we have
x¿ 0 =E x¾0‚0 = (x¾0)…1…¡1‚0 = x¾…¡1‚0. But then the lemma yields x¿ = (x¿ 0)„1 =E
(x¾…¡1‚0)„1 . It remains to be shown that (x¾…¡1‚0)„1 =E x¾‚.
For this purpose, we deflne a substitution (…¡1‚0)„1 on Y0 [ C as follows: for all
z 2 Y0 [ C, z(…¡1‚0)„1 := (z…¡1‚0)„1 . Because the terms x¾ for x 2 X do not contain
any of the free function symbols fc, it is easy to see that (x¾…¡1‚0)„1 = (x¾)(…¡1‚0)„1 .
Obviously, the substitutions ‚ and (…¡1‚0)„1 coincide on Y0, but for c 2 C we need
not have c(…¡1‚0)„1 = c. However, we can show that c(…¡1‚0)„1 =E c. In fact, c…¡1‚0 =
c¾0‚0 =E c¿ 0, and thus the lemma yields (c…¡1‚0)„1 =E (c¿ 0)„1 . But our assumption on
„ yields (c¿ 0)„1 = c. To sum up, we have just seen that ‚ =E (…¡1‚0)„1 hY0 [Ci, which
implies (x¾)‚ =E (x¾)(…¡1‚0)„1 . This completes the proof of the proposition.
5.2. using algorithms for constant elimination and for unification with
constants
In this subsection we shall consider uniflcation problems with arbitrary constant re-
strictions. It will be shown how to reduce solving this kind of problems to solving both
uniflcation problems with constants and constant elimination problems.
A constant elimination problem in the theory E is a flnite set ¢ = f(c1; t1); :::; (cn; tn)g
where the ci’s are free constants (i.e., constant symbols not occurring in the signature of
E) and the ti’s are terms (built over the signature of E, variables, and free constants).
A solution to such a problem is called a constant eliminator. It is a substitution ¾ such
that for all i; 1 • i • n, there exists a term t0i not containing the free constant ci with
t0i =E ti¾. The notion complete set of constant eliminators is deflned analogously to the
notion complete set of uniflers.
Let ¡ be an E-uniflcation problem with arbitrary constant restriction. The goal is to
construct a complete set of solutions of this problem. In the flrst step, we just ignore the
constant restriction, and solve ¡ as an ordinary E-uniflcation problem with constants.
Let C(¡) be a complete set of E-uniflers of this problem. In the second step, we deflne
for all uniflers ¾ 2 C(¡) a constant elimination problem ¢¾ as follows:
¢¾ := f(c; x¾) j c is a free constant in ¡ and x 2 Vcg:
For all ¾ 2 C(¡), let C¾ be a complete set of solutions of the constant elimination problem
¢¾.
Before we can describe the complete set of solutions of the E-uniflcation problem with
constant restriction, ¡, we must deflne a slightly modifled composition \›" of substitu-
tions. Let ¾ be an element of C(¡), and let ¿ be a constant eliminator in C¾. Without loss
of generality, we assume that ¿ is the identity on variables not occurring in ¢¾, and that
the terms y¿ for variables y occurring in ¢¾ contain only new variables. In particular,
we shall need for technical reasons that they do not contain variables occurring in terms
x¾ for variables x occurring in ¡.
For a given variable x, let fc1; : : : ; cng be the set of all constants ci occurring in ¡ such
that x 2 Vci . If this set is empty (i.e., n = 0), we deflne x(¾›¿) := x¾¿ . Now assume
          
Combining Decision Procedures 231
that n > 0. Obviously, we have f(c1; x¾); : : : ; (cn; x¾)g µ ¢¾. Since ¿ is a solution of
¢¾, there exist terms s1; : : : ; sn such that for all i; 1 • i • n, x¾¿ =E si and ci does not
occur in si. It is easy to see that this also implies the existence of a single term s such
c1; : : : ; cn do not occur in s and x¾¿ =E s. We deflne x(¾›¿) := s.
Proposition 5.5. The set [
¾2C(¡)
f¾›¿ j ¿ 2 C¾g
is a complete set of solutions of the E-uniflcation problem with constant restriction, ¡.
Proof. First, we show that the elements ¾›¿ of this set solve all the equations s := t of
¡. Since ¾ is an E-unifler of ¡, we have s¾ =E t¾, which implies s¾¿ =E t¾¿ . But the
deflnition of ¾›¿ was such that ¾¿ =E ¾›¿ , and thus we get s(¾›¿) =E t(¾›¿).
Second, we prove that ¾›¿ satisfles the constant restriction. Assume that x 2 Vc. Then
the constant elimination problem ¢¾ contains the tuple (c; x¾). By deflnition of ¾›¿ ,
we obtain that x(¾›¿) is a term s not containing c.
Finally, it remains to be shown that the set is complete. Assume that µ is a solution
of the E-uniflcation problem with constant restriction, ¡. In particular, this means that
µ solves the E-uniflcation problem ¡ (where the restrictions are ignored). Hence there
exist an element ¾ of the complete set C(¡) and a substitution ‚ such that µ =E ¾‚ hXi,
where X denotes the set of all variables occurring in ¡. Thus we have
(i) for all x 2 X: xµ =E (x¾)‚, and
(ii) for all c with x 2 Vc: c does not occur in xµ,
which shows that ‚ solves the constant elimination problem ¢¾. Consequently, there
exist an element ¿ of the complete set C¾ and a substitution ‚0 such that ‚ =E ¿‚0 hY i,
where Y denotes the set of all variables occurring in ¢¾. Without loss of generality, we
assume that z‚0 = z‚ for all variables z not occurring in one of the terms y¿ with y 2 Y .
We want to show that, for all x 2 X, we have xµ =E x(¾›¿)‚0. For all x 2 X, we
know that xµ =E x¾‚, and since ¾¿ =E ¾›¿ we also have x(¾›¿)‚0 =E x¾¿‚0. Thus it
remains to be shown that x¾‚ =E x¾¿‚0. We must distinguish two cases. First, assume
that (c; x¾) 2 ¢¾ for some c. In this case all variables occurring in x¾ are elements of
Y , and thus ‚ =E ¿‚0 hY i yields x¾‚ =E x¾¿‚0. For the second case, assume that x¾
contains a variable z that is not an element of Y , the set of all variables occurring in ¢¾.
We are flnished if we can show that, nevertheless, z‚ =E z¿‚0 holds for all such variables
z. Since ¿ was assumed to be the identity on variables not occurring in ¢¾, we have
z¿ = z. Since z occurs in x¾ for a variable x 2 X, our second assumption on ¿ implies
that z does not occur in any term y¿ with y 2 Y . But then z‚0 = z‚ by our assumption
on ‚0, which completes the proof of x¾‚ =E x¾¿‚0.
5.3. linear constant restrictions and positive sentences
Let § denote the signature of E. At the end of Section 2 we have mentioned a re-
lationship between conjunctive L+(§)-sentences and E-uniflcation problems with linear
constant restriction. In this subsection we shall consider this relationship in more detail.
In particular, we shall prove Result 10 of Section 2.
            
232 F. Baader and K. U. Schulz
Let ` be a positive §-sentence. Obviously, it can be represented (modulo logical equiv-
alence) in the form
` = Q1x1 ¢ ¢ ¢Qkxk
n_
i=1
(
mi^
j=1
(ri;j
:= si;j));
where the Qi are existential or universal quantiflers, and x1; : : : ; xn are distinct variables.
The associated set of E-uniflcation problems with linear constant restriction, UPLCR(`),
consists of n problems ¡1; : : : ;¡n, where ¡i := fri;1 := si;1; : : : ; ri;mi := si;mig. In these
equations, existentially (universally) quantifled variables of ` are treated as variables
(constants), and the linear order x1 < x2 < ¢ ¢ ¢ < xk is induced by the quantifler preflx
of `.
Proposition 5.6. Let ` 2 L+(§) be a positive §-sentence. Then ` is a theorem of E
ifi one of the E-uniflcation problems with linear constant restriction in UPLCR(`) has
a solution.
Proof. Let us assume that
` = Q1x1 ¢ ¢ ¢Qkxk
n_
i=1
(
mi^
j=1
(ri;j
:= si;j))
is a §-theorem of E. We shall describe a series of equivalent statements, eventually show-
ing that one of the E-uniflcation problems with linear constant restriction in UPLCR(`)
has a solution.
First, we apply to ` a transformation that is known as Skolemization of universally
quantifled variables. For all universally quantifled variables x” of `, we replace in the
matrix
Wn
i=1(
Vmi
j=1(ri;j
:= si;j)) all occurrences of x” by the term fx” (x„1 ; : : : ; x„k). Here
9x„1 ; : : : ; 9x„k is the sequence of existential quantiflers preceding 8x” in the quantifler
preflx of `; the symbol fx” is a new free function symbol (\Skolem function symbol"),
where distinct Skolem function symbols are used for distinct universally quantifled vari-
ables. Let b§ be the enlarged signature that is obtained from § by adding the Skolem
function symbols for all universally quantifled variables of `. We denote the positive
existential b§-sentence that is obtained as result of the Skolemization process by
`S = 9x„1 ¢ ¢ ¢ 9x„l
n_
i=1
(
mi^
j=1
(rSi;j
:= sSi;j)):
Claim 1: `S is a b§-theorem of E.
Proof of Claim 1: By compactness, we may assume that E is given by a flnite set of
equational axioms. In fact, if `S is a logical consequence of a (possibly inflnite) set of
equational axioms, then it is already a logical consequence of a flnite subset of this set of
axioms. Assume, for notational convenience, that the universal sentence 8~y e axiomatizes
E, where ` and 8~y e do not have any variables in common. By assumption, `_:8~y e is
a valid sentence. Hence, the logically equivalent sentence in preflx normal form
Q1x1 ¢ ¢ ¢Qkxk9~y (
n_
i=1
(
mi^
j=1
(ri;j
:= si;j)) _ :e)
is valid as well. Skolemization of universal quantiflers [which preserves validity, just as
           
Combining Decision Procedures 233
Skolemization of existentially quantifled variables preserves satisflability Chang and Lee
(1973)] leads to the valid sentence
9x„1 ¢ ¢ ¢ 9x„l9~y (
n_
i=1
(
mi^
j=1
(rSi;j
:= sSi;j)) _ :e);
which is logically equivalent to `S _ :8~ye. This shows that Claim 1 holds.
In order to relate `S with the uniflcation problems in UPLCR(`), we use the fact
that, for positive b§-sentences, validity with respect to the class of all b§-models of E and
validity with respect to the E-free algebra T (b§; X)==E are equivalent conditions.y
Claim 2: One of the sentences
`Si := 9x„1 ¢ ¢ ¢ 9x„l
mi^
j=1
(rSi;j
:= sSi;j)
holds in T (b§; X)=E, for some 1 • i • n.
Proof of Claim 2: Since `S is positive, Claim 1 and the above observation yield that
T (b§; X)==E satisfles `S . Claim 2 follows because existential quantiflcation distributes
over disjunction, and since an algebra satisfles a disjunction of sentences ifi it satisfles
one of the disjuncts.
Each such (valid) sentence may be considered as a (solvable) general E-uniflcation
problem
frSi;1 := sSi;1; : : : ; rSi;mi
:= sSi;mig:
An equivalent general E-uniflcation problem is
¡0i := fri;1 := si;1; : : : ; ri;mi := si;mig [ FS ;
where FS consists of all equations of the form x”
:= fx” (x„1 ; : : : ; x„k), which relate the
universally quantifled variables x” of ` with their Skolem terms. Obviously, this proves
Claim 3: One of the general E-uniflcation problems ¡0i has a solution, for some 1 • i • n.
Claim 4: One of the E-uniflcation problems in UPLCR(`) has a solution.
Proof of Claim 4: Note that the problems ¡0i have exactly the form of the general
E-uniflcation problems ¡0 that we have considered in Subsection 5.1 when proving the
equivalence between E-uniflcation problems with linear constant restriction and general
E-uniflcation problems. It is easy to see that ¡0i is just the general E-uniflcation problem
that is associated with the E-uniflcation problem with linear constant restriction ¡i 2
UPLCR(`) that contains the equations fri;1 := si;1; : : : ; ri;mi := si;mig. Claim 4 is now
an immediate consequence of Proposition 5.1.
Until now, we have shown the \only-if" direction of Proposition 5.6. Since it is easy
to see that each of the steps leading from one claim to the next can be inverted, the \if"
direction follows as well.
Proposition 5.6 yields that the positive theory of E is decidable, if solvability of E-
uniflcation problems with linear constant restriction is decidable. Conversely, every E-
uniflcation problem with linear constant restriction, ¡ = frj := sj j j = 1; : : : ;mg, can
y This equivalence is well-known in universal algebra; see, e.g., Bockmayr (1992) for a self-contained
proof.
           
234 F. Baader and K. U. Schulz
be translated into an equivalent L+(§)-sentence
` = Q1x1 ¢ ¢ ¢Qkxk
m^
j=1
(rj
:= sj);
where fx1; : : : ; xkg are the variables and free constants occurring in ¡, and Qi is a
universal quantifler (existential quantifler) if xi is a constant (variable). The order in
the quantifler preflx is given by the linear order that induces the constant restriction.
Obviously, UPLCR(`) = f¡g, and thus Proposition 5.6 implies that ¡ has a solution ifi
` is a theorem of E.
Corollary 5.7. Let E be an equational theory. Then the positive fragment of E is de-
cidable if, and only if, solvability of E-uniflcation problems with linear constant restriction
is decidable.
6. Optimized Decision Procedures
Until now, our emphasis was mainly on giving a conceptually clear description of the
decomposition algorithm and its consequences, with the goal of keeping the algorithm
and the proofs as transparent as possible. For an actual implementation, one should, of
course, try to avoid as many nondeterministic choices as possible. In the following, we
shall restrict our attention to the combination of decision procedures. For the combination
of algorithms computing complete sets of uniflers, additional optimizations may become
possible that utilize the computed uniflers [see, e.g., Boudet (1993) for optimizations in
this direction].
6.1. an obvious optimization for the general case
For the combination of decision procedures, not many optimizations seem to be possible
without imposing additional restrictions on the theories to be combined. For the general
case, we shall consider one fairly obvious technique for restricting the choice of the linear
ordering. It depends on the observation that reordering variables of the same type in
the output systems does not in°uence the resulting constant restrictions, as long as the
relationship to variables of difierent type is not changed.
To make this more precise, let us assume that the set Y of all variables is equipped with
a standard ordering `Y . Let Y4 be the set of variables of an output system (¡5;1;¡5;2)
with indexing ind and linear ordering <.
Definition 6.1. We say that the pair (<; ind) is `Y -compatible ifi two variables y1; y2
of the same type that are consecutive with respect to < satisfy y1 `Y y2. If this condition
holds only for all variables of type i, then we say that (<; ind) is `Y -compatible with
respect to variables of type i (i = 1; 2).
Proposition 6.2. Let ¡0 be a solvable input system of the decomposition algorithm.
Then there exists a solvable output system (¡5;1;¡5;2) with indexing ind and linear or-
dering < such that (<; ind) is `Y -compatible.
Proof. The \if" direction is trivial. To show the \only-if" direction, assume that
         
Combining Decision Procedures 235
¡0 is solvable. By Proposition 3.2 we know that there exists a solvable output pair. If
the associated pair (<; ind) is not `Y -compatible then there are variables y1 < y2 of the
same type that are consecutive with respect to < such that y2 `Y y1. Since interchanging
the order of y1 and y2 does not modify the <-relationships of these two variables with
variables of difierent type, the induced constant restrictions are also not afiected thereby.
This shows that we can reach, after flnitely many steps, a solvable output system where
the linear ordering together with ind is `Y -compatible.
The proposition shows that it is su–cient to choose `Y -compatible pairs (<; ind) in
Step 4 of the decomposition algorithm.
6.2. combination with the free theory
To obtain further optimizations, we shall consider a particular class of combination
problems, namely those where an equational theory E is combined with an instance of
the free theory
F› := ff(x1; : : : ; xn) = f(x1; : : : ; xn) j f 2 ›g:
This combination yields a uniflcation algorithm for general E-uniflcation.
We shall proceed in three steps. The original decomposition algorithm, as described
in Section 3, will be called \Algorithm I" in the following. First, we present an opti-
mized version of the decomposition algorithm that always works in the specifled context
(Algorithm II). The idea is to use the most general unifler (mgu) of free subsystems to
rule out certain choices in the nondeterministic steps. Then we discuss a second opti-
mization (Algorithm III) that is possible under certain assumptions on the theory E.
These assumptions concern the type of uniflcation algorithms that are available for E.
For example, the theories A and AI satisfy these requirements. Finally, we introduce a
further simpliflcation (Algorithm IV) that is possible when dealing with a collapse-free
theory E (such as A).
optimized decomposition algorithm|algorithm II
Context: Combination of an equational theory E with the free theory F›. Decision
problem for general E-uniflcation.
The input is a flnite system ¡0 of equations between terms built from variables, free
constants, and function symbols belonging to › or the signature of E. As before, ¡i
denotes a system that is reached after step i, and Yi denotes the set of variables occurring
in ¡i. If all equations of ¡i are pure, then ¡i;F denotes the subsystem of all equations
containing only free function symbols, and ¡i;E denotes the subsystem with the equations
containing function symbols from the signature of E. In the following, we shall consider a
most general unifler „i of the free subsystem ¡i;F , for i = 2; 3. Without loss of generality,
we may assume that these uniflers are \nice" as deflned below.
Definition 6.3. A most general unifler „i of ¡i;F satisfying
(i) ¿ = „i¿ for all uniflers ¿ of ¡i;F , and
(ii) the variables occurring in the terms x„i for x 2 Yi are again in Yi.
           
236 F. Baader and K. U. Schulz
is called nicey.
Now, let us describe the optimized decomposition algorithm. The flrst two steps are
unchanged. The third (nondeterministic) step of the original algorithm is split into a
deterministic and a nondeterministic substep.
Step 3.1: first (deterministic) variable identification. We try to solve the free
subsystem ¡2;F , thereby treating all elements of Y2 as variables. If ¡2;F is unsolv-
able, then we stop with failure. Now, assume that ¡2;F is solvable, and let „2 be a
nice most general unifler of this system. We consider the partition …1 of Y2 in which
two variables x; y belong to the same class ifi x„2 = y„2. Based on this partition we
identify variables in ¡2, as described in the original Step 3. This yields the system
¡3:1 with set of variables Y3:1.
Step 3.2: second (nondeterministic) variable identification. Here we choose
a partition …2 of Y3:1 and identify variables in ¡3:1 according to this partition. This
yields the system ¡3 with set of variables Y3. If ¡3;F is unsolvable, or if the nice mgu
of ¡3;F identifles two distinct variables x and y of Y3 (the set of variables obtained
after the second identiflcation), then we stop with failure. Otherwise, we continue
with the next step.
Now, assume that ¡3;F is solvable with nice mgu „3 such that x„3 6= y„3 for all x 6= y
in Y3. In order to improve on Algorithm I in Step 4, we use „3 to restrict the choices of the
indices and, subsequently, the ordering of variables with index F z. Once a linear ordering
of the F -variables is flxed, there will be exactly one extension to a linear ordering on all
variables (i.e., no more nondeterministic choices are necessary here).
Step 4: choose theory indices and ordering. First, we choose a variable index-
ing ind that satisfles the following condition:
(1) for every variable x 2 Y4, if x„3 = f(t1; : : : ; tn) for a free function symbol f ,
then ind(x) = F .
Let Y3;F µ Y3 denote the set of all variables x with ind(x) = F , and let Y3;E µ Y3
be the remaining set of variables. We choose a linear ordering <F on Y3;F that
satisfles the following restriction:
(2) for all variables x; x0 2 Y3;F , if x0„3 is a subterm of x„3, then x0 <F x.
Due to the following two conditions, the extension of <F to a linear ordering < on
Y3 is completely deterministic:
(3) for all E-variables y and F -variables x, we have y < x ifi there exists an F -
variable x0 • x such that y occurs in x0„3, and
(4) the pair (ind; <) must be `Y -compatible on variables of type E.
y It is easy to see that an idempotent mgu that does not introduce new variables is nice. Thus,
most of the uniflcation algorithms for the free theory (e.g., Robinson’s original algorithm or solved-form
algorithms) compute a nice mgu.
z For mnemonic reasons, we shall use indices F and E instead of 1 and 2.
          
Combining Decision Procedures 237
In principle, (3) means that E-variables are made as large as possible compared to
F -variables. In fact, the E-variable y is only made smaller than an F -variable x, if this is
required by the mgu „3 and the already chosen ordering <F . The idea is that this places
the least severe restrictions on the solvability of the E-subsystem, while keeping „3 as a
solution of the F -subsystem.
In Step 5, the system ¡5 is split into a free subsystem ¡5;F and an E-subsystem ¡5;E
as before. Since, by Condition 3, the unifler „3 is a solution of ¡5;F , it is su–cient to
consider the systems of type ¡5;E as the output of the decomposition procedure.
correctness of algorithm II
Let R denote the possibly inflnite ordered-rewriting system that is obtained by apply-
ing unfailing completion to the theory E. We assume that the simpliflcation ordering also
takes the countable set of variables X0 (these variables are treated as constants by the
ordering) and all free function symbols from › into account. R is con°uent and terminat-
ing on ground terms. Let T (›; E;X0) be the set of all terms built from function symbols
in ›, functions symbols of the signature of E, and variables in X0. Let T#R denote its
R-irreducible elements. The following lemma will be useful in the proof of correctness of
Algorithm II. This lemma makes clear why we must use nice mgus in Algorithm II.
Lemma 6.4. Suppose that the free subsystem ¡i;F of ¡i has the nice mgu „i, and let
x 2 Yi. If ¾ is a substitution that is R-normalized on Yi, and if ¾ solves (modulo E) the
system ¡i, then ¾ also solves (modulo E) the system ¡i [ fx := x„ig (i = 2; 3).
Proof. In the second part of the proof of Proposition 3.2, we have seen how the
R-normalized solution ¾ of ¡i may be used to flnd, via projection, solutions ¾F and
¾E of an appropriate output pair (¡5;F ;¡5;E) of the original algorithm. By deflnition,
x¾F = (x¾)…F where …F is the flrst (F -) projection of terms based on the bijection …
(see the proof of Proposition 3.2 for details). Since ¾ is R-normalized on Yi, we have
x¾F…
¡1 = (x¾)…F …¡1 = x¾. This shows that ¾ is an instance of ¾F . But ¾F is a unifler
of ¡i;F . Since „i is nice we have x¾F = x„i¾F . Thus ¾F and its instance ¾ solve the
equation x := x„i.
Proposition 6.5. ¡0 is solvable ifi a system ¡II5;E in the output set of Algorithm II is
solvable.
Proof. Since every output of Algorithm II is a possible output of Algorithm I, soundness
of the latter procedure implies soundness of the former.
Thus, it remains to prove completeness of Algorithm II. Suppose that the input problem
¡0 has a solution ¾. As before, we may assume without loss of generality that ¾ is also a
solution of ¡2, the system reached by applying the flrst two steps of Algorithm II (which
coincide with the corresponding steps of Algorithm I), and that ¾ is R-normalized on
the set Y2 of variables occurring in ¡2. In the proof of Proposition 3.2 we have shown
how ¾ can be used to determine appropriate choices in the nondeterministic steps of
Algorithm I: this leads to output systems ¡I5;1 = ¡
I
5;F (free subsystem) and ¡
I
5;2 = ¡
I
5;E
(E-subsystem) of Algorithm I, which have solutions ¾IF and ¾
I
E that satisfy the chosen
linear constant restriction. More precisely, the following choices are made:
        
238 F. Baader and K. U. Schulz
(a) In Step 3, partition …I is chosen in such a way that variables x and y are identifled
ifi x¾ = y¾.
(b) in Step 4 we deflne indI(x) := E ifi x¾ = h(t1; : : : ; tn) for a symbol h belonging to
the signature of E, and indI(x) := F , otherwise.
(c) The linear ordering <I that is chosen is an arbitrary total extension of the partial
ordering ` deflned by y ` x ifi y¾ is a strict subterm of x¾.
Keeping this in mind facilitates understanding the proof that Algorithm II also yields
a solvable output system. This proof proceeds in four steps. First, we show that it is
admissible to take the same identiflcation of variables …I, and the same indexing of
variables indI in Algorithm II, i.e., we show that these choices do not violate the choice
principles underlying this algorithm (see Steps A and B below). Subsequently, we show
that „3 (the nice mgu of ¡3;F ) solves the free subsystem ¡I5;F (Step C). Consequently,
(„3; ¾IE) solves the output (¡
I
5;F ;¡
I
5;E) of Algorithm I. In the last step (Step D), we show
that the choice principles of Algorithm II lead to a similar output system (¡II5;F ;¡
II
5;E) of
Algorithm II, of which („3; ¾IE) is still a solution.
Step A: First, note that ¡2;F is solvable (in the free theory) since ¾IF solves ¡
I
5;F ,
which is a restricted version of the former system. Now, let „2 be a nice mgu of ¡2;F ,
and assume that x„2 = y„2. By Lemma 6.4, we know that x¾ =E x„2¾ = y„2¾ =E y¾.
Since ¾ is R-normalized, we even have x¾ = y¾. This shows that the partition …II1 used
in the identiflcation phase of Step 3.1 of Algorithm II is a reflnement of …I. Thus, an
appropriate choice of …II2 yields …
I after Step 3 of Algorithm II. It remains to be shown
that Step 3 of Algorithm II does not fail, i.e., that ¡3;F is solvable, and that the nice
mgu „3 of ¡3;F does not identify distinct variables of Y3. The flrst point is trivial since
¾IF solves ¡
I
5;F , which is a restricted version of ¡3;F . To see the second point, suppose
that „3 identifles the distinct variables x; y 2 Y3. As shown above, Lemma 6.4 yields in
this situation x¾ = y¾. This contradicts the choice of …I.
Step B: Assume that x„3 = f(t1; : : : ; tn) for a free function symbol f . Thus, indII(x) =
F , by Condition (1) of Step 4. We have x¾ =E x„3¾, by Lemma 6.4, and thus x¾ has
top-symbol f (since f is a free symbol). Consequently, indI(x) = F as well, by (b).
Step C: We show that „3 is a solution of ¡I5;F . Obviously, „3 solves all equations of
¡I5;F , since it is a unifler of ¡3;F , which contains the same equations. In order to show
that „3 treats the variables of type E as constants, we assume that x is such a variable.
Then we have
(⁄) x„3¾IF = x¾IF = x;
since ¾IF is a unifler of ¡3;F , and „3 is a nice mgu of ¡3;F . This shows that x„3 is a
variable. Moreover, since „3 is nice, x„3 2 Y3. Thus, if we assume that x„3 6= x, then (⁄)
means that ¾F identifles the distinct variables x and x„3. On the other hand, we know
that ¾ does not identify variables of Y3. Since ¾ is an instance of ¾IF (as we have seen in
the proof of the previous lemma), this implies that ¾IF does not identify variables of Y3,
which is a contradiction to our assumption that x and x„3 are difierent. Thus, x„3 = x,
and we have shown that „3 treats the variables of index E as constants. It remains to be
shown that „3 satisfles the linear constant restriction. For x 2 Y3 we have x„3¾IF = x¾IF .
Thus, every constant y 2 Y3;E occurring in x„3 also occurs in x¾IF . Since ¾IF satisfles all
constant restrictions of ¡I5;F , this implies that „3 satisfles these restrictions as well.
Step D: It remains to be shown that the possible choices of linear orderings in Step 4
of Algorithm II lead to a solvable output system (¡II5;F ;¡
II
5;E). To this purpose, we modify
         
Combining Decision Procedures 239
the ordering <I such that the modifled order satisfles Conditions 2, 3 and 4 from Step
4 of Algorithm II. Nevertheless, „3 and ¾IE will still be solutions of the resulting output
systems. First, let us consider Condition 2. Assume that x; x0 are distinct elements of
Y4;F , and that x0„3 is a subterm of x„3. Then x0„3¾ is a subterm of x„3¾. In addition,
by Lemma 6.4, x¾ =E x„3¾, and since both terms are R-irreducible, we even have
x¾ = x„3¾. Analogously, we can deduce x0¾ = x0„3¾. Thus, x0¾ is a subterm of x¾,
which implies x0 <I x, by (c). This shows that we may choose the restriction of <I to
F -variables as our ordering <IIF in Step 4 of Algorithm II. We cannot assume a priori
that <I satisfles Condition 3. It may be the case that there exists an E-variable y and
an F -variable x such that x is the least F -variable that is larger than y with respect
to <I, but y does not occur in x„3. In such a case we change the position of y. In
the modifled order, it will be the immediate successor of x. The relative positions of
all other variables are not changed. The result is a new output system where we have
one additional constant restriction for x, demanding that the constant y does not occur
in the value of x. However, „3 is still a solution of the free subsystem since it satisfles
this new restriction by assumption. On the other hand, the restrictions for y are relaxed
since now x may occur in the value of y. The restrictions for other variables are not
modifled. Thus, ¾IE is still a solution of the E-output system. It is clear that, after a
flnite number of similar steps, a modifled order is reached that satisfles Condition 3,
and leads to an output pair of which „3 and ¾IE are solutions. Finally, we may reorder
sequences of consecutive E-variables in order to obtain `Y -compatibility of E-variables
without changing the constant restrictions, and thus without afiecting solvability of the
output systems, as we have already seen in the proof of Proposition 6.2.
The arguments used in Step D of the proof might give the impression that in Step 4 of
Algorithm II we could even demand that the pair (ind; <) is `Y -compatible on variables
of both types. Note, however, that an additional reordering of blocks of consecutive F -
variables might run into con°icts with Condition 2 of Step 4. On the other hand, if
we erase this condition, then we can indeed demand `Y -compatibility of (ind; <) with
respect to all variables. It is not clear which possibility will turn out to have a better
efiect in practice.
partially specified linear constant restrictions
In some cases, one source of nondeterminism in Algorithm II can completely be elimi-
nated. It is possible to avoid the choice of a linear ordering on the F -variables in Step 4
of Algorithm II, if it is possible to solve problems with partially specifled linear constant
restriction for the theory E. Such a problem is given by an E-uniflcation problem with
constants, ¡, a partial ordering • on the variables and constants occurring in ¡, and pos-
sibly some further (decidable) conditions that characterize a set LLE(•) of \admissible"
linear orderings extending •. The problem has a solution ifi there exists an admissible
linear extension of • such that the uniflcation problem with linear constant restriction
induced by this admissible extension has a solution.
Before we describe a further improvement of the decomposition algorithm that is based
on the idea of using algorithms solving E-uniflcation problems with partially specifled
linear constant restriction, let us add a remark that tries to explain in which situations
this idea makes sense. When we only ask for decidability per se, without looking into
the complexity of the decision procedure, then uniflcation problems with linear constant
         
240 F. Baader and K. U. Schulz
restriction and uniflcation problems with partially specifled linear constant restriction
have the same status. In fact, if solvability of the former class of problems is decidable,
then the same holds for the latter class of problems. This is so because every partial
ordering on a flnite set has only a flnite number of linear extensions. Thus, given a
uniflcation problem with a partially specifled linear constant restriction, one could just
enumerate all admissible linear extensions of the underlying partial ordering, and test
whether one of them yields a solvable problem with linear constant restriction. This
would mean, however, that the nondeterminism in the choice of the linear ordering is
just pushed from the decomposition algorithm into the algorithm for the single theories.
One could call this a disjunctive treatment of the E-uniflcation problems with partially
specifled linear constant restriction, since the problem is reduced to a large disjunction
of E-uniflcation problems with linear constant restriction.
Considering partially specifled linear constant restrictions makes sense only if a non-
disjunctive treatment is possible, i.e., if the efiort to decide solvability of uniflcation
problems with such restrictions does not drastically exceed the efiort to decide solvability
of uniflcation problems with linear constant restriction. Examples of theories for which
this is the case are the theories A and AI [see Baader and Schulz (1993)]. For these
theories, a disjunctive treatment of all linear extensions can be avoided, and thus the
corresponding nondeterminism is really eliminated, not only pushed into the algorithm
for the single theory.
optimized decomposition algorithm|algorithm III
Context: Decision problem for general E-uniflcation, where solvability of E-uniflcation
problems with partially specifled linear constant restriction is decidable in a \non-
disjunctive manner," as explained above.
We simply proceed as in Algorithm II until we reach the point in Step 4 where the
variable indexing ind has been chosen. Now, we do not choose a linear ordering <F on
the F -variables, but propagate the partial ordering • on Y3 deflned by
y • x ifi y„3 is a strict subterm of x„3
to the remaining E-subsystem. Conditions 3 and 4 of Step 4 of Algorithm II characterize
the subset of admissible linear extensions LLE(•), thus deflning a system ¡5;E with
partially specifled linear constant restriction.
Proposition 6.6. ¡0 is solvable ifi some system ¡III5;E that is reached in Algorithm III
is solvable.
Proof. Immediately from Proposition 6.5.
the collapse-free case
Finally, let us consider the case where the theory E is collapse-free. For such a theory
we know that a term with top-symbol from the signature of E is only E-equivalent to
terms with top symbol from the same signature. This fact can be used to detect unsolv-
ability already during the early steps of the decomposition algorithm. As above, we also
         
Combining Decision Procedures 241
assume that decidability of E-uniflcation problems with partially specifled linear constant
restriction is decidable in \non-disjunctive manner." A prominent example where the fol-
lowing version of the decomposition algorithm can be used is the theory A, expressing
associativity of a binary function symbol [compare Baader and Schulz (1993)].
optimized combination algorithm|algorithm IV
Context: Decision problem for general E-uniflcation, where E is collapse-free.
Without loss of generality, we may assume that the input problem does not contain an
equation of the form f(s1; :::; sm)
:= h(t1; : : : ; tn) where f is a free function symbol and
h is a symbol of the signature of E. Since E is collapse-free, we could immediately stop
with failure in such a case.
Step 1 remains as in Algorithms II and III. Obviously, ¡1 cannot have non-pure equa-
tions. Thus Step 2 can be omitted. Step 3.1 (flrst variable identiflcation) remains almost
as in Algorithms II and III. We add, however, a control step that detects unsolvability:
if x„2 = f(s1; : : : ; sm) for a free function symbol f and if ¡2;E contains an equation
x
:= h(t1; : : : ; tn), then we stop with failure. In Step 3.2 (second variable identiflcation),
we do not identify variables x and y if x„2 = f(t1; : : : ; tm) for a free function symbol f
and if ¡3:1;E contains an equation y
:= h(s1; : : : ; sn). Step 4 of Algorithm III is modifled,
eliminating some nondeterminism in the choice of a variable indexing ind. We deflne
ind(y) = E whenever ¡3;E contains an equation y
:= h(s1; : : : ; sn), where h belongs to
the signature of E.
Correctness and completeness of Algorithm IV follow immediately from Proposition 6.6
and from the fact that the theory E is collapse-free.
7. Conclusions
We have presented a new method for treating the problem of uniflcation in the union
of disjoint equational theories. Unlike most of the other methods developed for this
purpose, it can be used to combine decision procedures as well as procedures computing
flnite complete sets of uniflers. Applicability of our method depends on a new type
of prerequisite, namely on the solvability of uniflcation problems with linear constant
restriction. Presupposing the existence of a constant elimination algorithm|as necessary
for the method of Schmidt-Schau…|seems to be a stronger requirement. In fact, we have
seen that constant elimination procedures can be used to solve uniflcation problems with
arbitrary constant restriction. However, it is still an open problem whether there exists an
equational theory for which solving uniflcation problems with linear constant restriction is
flnitary (or decidable) but solving uniflcation problems with arbitrary constant restriction
is not. In any case, we have seen that uniflcation with linear constant restriction seems to
be the more natural concept, since it has a clear logical interpretation: for an equational
theory E, uniflcation with linear constant restriction is decidable ifi the positive theory
of E is decidable.
Our main results, together with the results described in the Section 5.1, show that there
is also a close correspondence between solving uniflcation problems with linear constant
restriction and solving general uniflcation problems. For a given equational theory, the
flrst kind of problems is decidable (flnitary solvable) if, and only if, the second kind of
problems is so. As an interesting open problem it remains the question whether there
        
242 F. Baader and K. U. Schulz
exists an equational theory for which uniflcation with constants is decidable (flnitary),
but general uniflcation|or equivalently, solving uniflcation problems with linear constant
restrictions|is not. Using the logical interpretation of uniflcation with linear constant
restriction, this open problem can also be reformulated as follows: Is there an equational
theory E for which the positive AE-fragmenty is decidable, but the full positive theory
is undecidable? One should note that there already exist such results for the case of
single equations, i.e., uniflcation problems of cardinality one. Narendran and Otto (1990)
have shown that there exists an equational theory E such that solvability is decidable
for E-uniflcation problems (with constants) of cardinality one, but is undecidable for
E-uniflcation problems of cardinality greater than one, and thus also for general E-
uniflcation problems.
Since the submission of this article, its results have been generalized to the case of
disuniflcation problems (Baader and Schulz, 1995a), the combination of theories with
shared constants (Ringeissen, 1992), and to the combination of solvers for more general
constraint languages (Baader and Schulz, 1995b,c).
References
Bachmair, L. (1991) Canonical equational proofs, Progress in Theoretical Computer Science, Birkha˜user,
Boston
Baader, F., Schulz, K.U. (1993) General A- and AX-uniflcation via optimized combination procedures, in
H. Abdulrab, J.-P. Pµecuchet, editors, Proceedings of the Second International Workshop on Word
Equations and Related Topics, Rouen, 1991, Springer LNCS 677, pp. 23{42.
Baader, F., Siekmann, J.(1994) Uniflcation theory, in D. Gabbay, C. Hogger, J. Robinson, editors, Hand-
book of Logic in Artiflcial Intelligence and Logic Programming, Oxford University Press, Oxford,
UK, pp. 41{125.
Baader, F., Schulz, K.U. (1995a) Combination techniques and decision problems for disuniflcation The-
oretical Computer Science B 142, pp. 229{255.
Baader, F., Schulz, K.U. (1995b) Combination of constraint solving techniques: An algebraic point of
view Proceedings of the 6th International Conference on Rewriting Techniques and Applications,
RTA95 Kaiserslautern, Germany, Springer LNCS 914, pp. 352{366.
Baader, F., Schulz, K.U. (1995c) On the combination of symbolic constraints, solution domains and con-
straint solvers Proceedings of the International Conference on Principles and Practice of Constraint
Programming, CP95, Cassis, France, Springer LNCS 976, pp. 380{397.
Bockmayr, A. (1992) Algebraic and logical aspects of uniflcation in K.U. Schulz, editor, Proceedings of
the First International Workshop on Word Equations and Related Topics, Tu˜bingen, Germany,
1990, Springer LNCS 572, pp. 171{180.
Boudet, A., Jouannaud, J.P., Schmidt-Schau…, M. (1989) Uniflcation in Boolean rings and Abelian groups
J. Symbolic Computation 8, pp. 449{477.
Boudet, A. (1993) Combining uniflcation algorithms J. Symbolic Computation 16, pp. 597{626.
Bu˜rckert, H.-J. (1986) Some relationships between uniflcation, restricted uniflcation, and matching Pro-
ceedings of the 8th International Conference on Automated Deduction, Springer LNCS 230, pp.
514{524.
Bu˜rckert, H.-J. (1990) A resolution principle for clauses with constraints Proceedings of the 10th Inter-
national Conference on Automated Deduction, Springer LNCS 449, pp. 178{192
Chang, Ch.-L., Lee, R.Ch.-T. (1973) Symbolic Logic and Mechanical Theorem Proving, Computer Sci-
ence Classics, Academic Press, San Diego
Colmerauer, A. (1990) An introduction to PROLOG III C. ACM 33, pp. 69{90.
Dershowitz, N., Jouannaud, J.P. (1990) Rewrite systems in J. van Leeuwen, editor, Handbook of Theo-
retical Computer Science, Volume B, North-Holland, pp. 244{320
Fages, F. (1984) Associative-commutative uniflcation Proceedings of the 7th International Conference
on Automated Deduction, Springer LNCS 170, pp. 194{208.
Fages, F. (1987) Associative-commutative uniflcation J. Symbolic Computation 3, pp. 57{275.
y This fragment consist of positive formulae with a quantifler-preflx consisting of a block of universal
quantiflers followed by a block of existential quantiflers. It is easy to see that such formulae correspond
to uniflcation problems with (free) constants.
   
Combining Decision Procedures 243
Herbrand, J. (1930) Recherches sur la Th¶eorie de la D¶emonstration, Ph.D. Thesis, Sorbonne, Paris
Reprinted in W.D. Goldfarb, editor, Logical Writings, Reidel, 1971.
Herbrand, J. (1967) Investigations in proof theory: The properties of true propositions in J. van Hei-
jenoort, editor, From Frege to Go˜del: A Source Book in Mathematical Logic, 1879{1931, Harvard
University Press, pp. 525{581.
Herold, A. (1986) Combination of uniflcation algorithms Proceedings of the 8th International Conference
on Automated Deduction, Springer LNCS 230, pp. 450{469.
Herold, A. (1987) Combination of uniflcation algorithms in equational theories Dissertation, Fachbereich
Informatik, Universita˜t Kaiserslautern, 1987.
Herold, A., Siekmann, J.H. (1987) Uniflcation in Abelian semigroups J. Automated Reasoning 3, pp.
247{283.
Howie, J.M. (1976) An Introduction to Semigroup Theory Academic Press, London, 1976.
Jafiar, J., Lassez, J.L. (1987) Constraint logic programming Proceedings of 14th POPL Conference,
Munich, pp. 111{119.
Jafiar, J., Lassez, J.L., Maher, M. (1984) A theory of complete logic programs with equality J. Logic
Programming 1, pp. 211{223.
Jouannaud, J.P., Kirchner, H. (1986) Completion of a set of rules modulo a set of equations SIAM J.
Computing 15, pp. 1155{1194.
Jouannaud, J.P., Kirchner. C. (1991) Solving equations in abstract algebras: A rule-based survey of
uniflcation in J.-L. Lassez, G. Plotkin, editors, Computational Logic: Essays in Honor of Alan
Robinson, MIT Press, pp. 257{321.
Kapur, D., Narendran, P. (1992) Complexity of uniflcation problems with associative-commutative op-
erators J. Automated Reasoning 9, pp. 261{288.
Kirchner, C. (1985) M¶ethodes et Outils de Conception Syst¶ematique d’Algorithmes d’Uniflcation dans
les Th¶eories equationnelles, Thµese d’Etat, Univ. Nancy, France,
Kirchner, C., Kirchner, H. (1989) Constrained equational reasoning Proceedings of SIGSAM 1989 In-
ternational Symposium on Symbolic and Algebraic Computation, ACM Press, pp. 382{389.
Livesey, M., Siekmann, J.H. (1975) Uniflcation of AC-Terms (Bags) and ACI-Terms (Sets), Internal
Report, University of Essex, 1975, and Technical Report 3-76, Universita˜t Karlsruhe
Makanin, G.S. (1977) The problem of solvability of equations in a free semigroup Mat. USSR Sbornik
32, pp. 129{198.
Miller, D. (1992) Uniflcation under a mixed preflx J. Symbolic Computation 14, pp. 321{358.
Narendran, P., Otto, F. (1990) Some results on equational uniflcation Proceedings of the 10th Conference
on Automated Deduction, Springer LNCS 449, pp. 276{291.
Plotkin, G. (1972) Building in equational theories Machine Intelligence 7, pp. 73{90.
Ringeissen, Ch. (1992) Uniflcation in a combination of equational theories with shared constants and its
application to primal algebras Proceedings of the International Conference on Logic Programming
and Automated Reasoning, LPAR’92, Springer LNCS 624, pp. 261{272.
Schulz, K. (1991) Makanin’s Algorithm { Two Improvements and a Generalization, CIS-Report 91-39,
CIS, University of Munich.
Schmidt-Schau…, M. (1989) Uniflcation in a combination of arbitrary disjoint equational theories J.
Symbolic Computation 8, pp. 51{99.
Siekmann, J.H. (1989) Uniflcation theory: A survey J. Symbolic Computation 7, pp. 207{274.
Stickel, M. (1975) A complete uniflcation algorithm for associative-commutative functions Proceedings
of the International Joint Conference on Artiflcial Intelligence, Tblisi, USSR, pp. 71{82.
Stickel, M. (1981) A uniflcation algorithm for associative-commutative functions J. ACM 28, pp. 423{
434.
Stickel, M. (1985) Automated deduction by theory resolution J. Automated Reasoning 1, pp. 333{356.
Tiden, E. (1986) Uniflcation in combinations of collapse free theories with disjoint sets of function
symbols Proceedings of the 8th International Conference on Automated Deduction, Springer LNCS
230, pp. 431{449.
Yelick, K. (1987) Uniflcation in combinations of collapse free regular theories. J. Symbolic Computation
3, pp. 153{182.
