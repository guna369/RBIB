Short Proofs of Normalization
for the simply-typed λ-calculus, permutative conversions and Go¨del’s T
Felix Joachimski1, Ralph Matthes2
April 22, 2002
Abstract
Inductive characterizations of the sets of terms, the subset of strongly normalizing terms and
normal forms are studied in order to reprove weak and strong normalization for the simply-
typed λ-calculus and for an extension by sum types with permutative conversions. The
analogous treatment of a new system with generalized applications inspired by generalized
elimination rules in natural deduction, advocated by von Plato, shows the flexibility of the
approach which does not use the strong computability/candidate style a` la Tait and Girard. It
is also shown that the extension of the system with permutative conversions by η-rules is still
strongly normalizing, and likewise for an extension of the system of generalized applications
by a rule of “immediate simplification”. By introducing an infinitely branching inductive rule
the method even extends to Go¨del’s T.
Introduction
Normalization proofs for the simply-typed λ-calculus enjoy continuous interest [Gog95, vRS95,
vRSSX99] in the literature although the main results of weak and strong normalization have been
established quite early by Turing (around 1941, published in [Gan80]) and Sanchis [San67].
This article employs a proof method that allows to show strong normalization for all typed
terms without recourse to inclusive predicates such as strong computability [Tai67] or validity
[Pra71] that are not formalizable in primitive recursive arithmetic. A simple induction on types
verifies that (strong) normalizability is closed under application while closure under substitution
has to be shown simultaneously.
Separating concerns. With the prospect of computer-checkable formalization and of proof-theoretic
analyses of normalization proofs for more complicated calculi we identify independent steps in the
proof. This is done by introducing strictly positive inductive definitions of the underlying con-
cepts, thus abandoning geometric notions (such as positions in terms, reduction trees and reduction
sequences) that would lead to ponderous arguments in the desired extensions.
Strong normalizability. Intuitively, a term r is strongly normalizing iff there are no infinite re-
duction sequences starting with r. However, the data type of reduction sequences is notoriously
problematic for computer-assisted proof development. Following [Alt93] and the tradition in proof
theory, we define strong normalizability of a term r (with respect to a binary relation →) induc-
tively by
∀r′.r → r′ ⇒ r′ ⇓
r ⇓
Thus, when checking strong normalizability of a term r it is sufficient to consider every one-step
reduct of r instead of all possible (potentially infinite) reduction sequences.
Still, reduct analysis becomes increasingly annoying in normalization proofs for more and more
complex systems. Therefore, we characterize strong normalizability via an inductive definition of
a set SN given by syntax-directed Horn clauses, reducing the task of checking all one-step reducts
to analysing no more than one standard reduct and some subterms. The proof of equivalence with
the earlier definition is in fact the only place where reduct analysis has to be carried out.
1Mathematisches Institut der Ludwig-Maximilians-Universita¨t Mu¨nchen, felix@joachimski.de
2Institut fu¨r Informatik der Ludwig-Maximilians-Universita¨t Mu¨nchen, matthes@informatik.uni-muenchen.de
1
For pure untyped λ-calculus such an inductive characterization has first been presented by
van Raamsdonk/Severi [vRS95]. Among other goals, this article aims at extending the underlying
notion to extensions of the base calculus by recursion, case operators and generalized eliminations
(see below).3
Weak normalizability. A term r is weakly normalizing iff there is a finite reduction sequence
starting with r and ending with a term which allows no further reduction. We give an inductive
definition more suitable for a satisfying formalization. When checking weak normalization of a
term r according to this definition one has to check some reduct of r. Unfortunately this reduct is
not determined by r. Therefore, we also characterize weak normalizability via a syntax-directed
inductive definition, thus embodying a reduction strategy that easily allows to read off which
reduct to check.4 Establishing the characterization this time amounts to proving standardization.
Building on these preliminary considerations the normalization proofs in sections 4–7 exclu-
sively argue on the syntax-directed inductive definitions.
Notation for multiple eliminations. In the inductive characterization of strongly normalizing terms
we recognize the standard redex of a term by displaying it in head form. This requires the
introduction of a metasyntactic abbreviation: A list of terms r1, . . . , rn is written ~r and can
be used to denote iterated eliminations like in x~r and (λxs)r~r (which stand for xr1 . . . rn and
(λxs)rr1 . . . rn). Notice that those lists may actually be empty, leading to x~r ≡ x (where ≡ is
syntactic equality).
It is crucial that we can carry this style of writing down multiple eliminations to more complex
term systems as long as they enjoy an introduction/elimination dichotomy under the natural
deduction (Curry-Howard) interpretation. This holds for ordinary term application, recursion on
natural numbers (corresponding to N-elimination in natural deduction, i.e., induction on N) and
case analysis (+-elimination), generalized applications a` la von Plato as well as for many other
systems not studied in this paper.5 Thus we arrive at a more general notion of elimination rR of
the term r that may stand for the application of r to R (→-elimination with R a term), recursion
rR with R ≡ (s, t) (s the initial term, t the step term, usually written Rec s t r), case analysis rR
with R ≡ (x.s, y.t) (commonly denoted by case r of inj0x⇒ s, of inj1y ⇒ t) and generalized
application rR with R ≡ (s, x.t) (for r ≡ y written as tx{r, s} in [Sch99]).
The vector notation turns out to replace concepts like branches and endsegments [Pra71]
which have been important elements of normalization arguments in systems with permutative
conversions.
Simply-typed λ-calculus. The basic system is dealt with in the first four sections: In section 1
untyped λ-calculus, function types, reduction and weak and strong normalizability are defined.
In section 2 weak normalization is shown by a method relying on a proof by induction on normal
forms. As we define weak normalizability from the set of normal forms this method is free from any
notational overhead, i. e., any defined concept entering the proof is already needed for stating the
result, viz. weak normalization. Section 3 contains the characterizations of weakly and strongly
normalizing terms (also for the extension by the η-rule), section 4 the proof of strong normalization.
Permutative conversions. They—also called commuting conversions—recover the subformula prop-
erty6 for terms in normal form in a system with sum types and a case-construct. Difficulties arise
3Based on a draft version of the present article, an extension to a logical framework using dependent types has
been carried out by Goguen [Gog99] whose typed operational semantics [Gog95] has been found independently
of [vRS95]. Interestingly, the initial motivation for the work reported here was a kind of reverse engineering of
Goguen’s thesis [Gog94] for systems without dependent types.
4[vR96] stated and proved this characterization correct for pure untyped λ-calculus.
5[Mat98] employs this approach in an analysis of extensions of Girard’s system F by various forms of mono-
tone inductive types. More recently, [Joa01] even gives a precise definition and analysis of the general notion of
introduction/elimination systems which incorporate the underlying concept.
6“The type of any subterm of r : ρ is subtype of either the type of a free variable or of ρ.” See, e.g., [Hin97] for
a good exposition.
2
with so-called critical eliminations r(x.s, y.t) : τ of a term r of type ρ+σ where τ need neither be
a subtype of ρ nor of σ. This has led to the invention of endsegments and validity predicates (see
[Pra71] for a graphical and [vdP96] for a term-based definition) or improper reductions [Lei75].
In section 5 we use the vector notation together with an only marginal modification of the
basic normalization argument and come up with a short and easily formalizable proof which even
covers the η-reduction rules.
Generalized applications. They allow a further simplification of the grammar of normal forms for
the λ-calculus by means of a generalized application rule that corresponds to the left introduction
rule in sequent calculus. As in the case of sum types we have to add permutative conversions—now
for function types—in order to retain the subformula property for normal terms. The methods of
section 5 easily carry over to this system as shown in section 6, hence yielding strong normalization
which appears to be a new result.
Go¨del’s T. Although the normalization proofs in the previous sections of this paper do make use
of inductive definitions they could be formalized within primitive recursive arithmetic, since all
inductive clauses have finitely many premises only (see [Tro73]). For reasons of proof-theoretical
strength we cannot hope to extend the simple normalization proof to Go¨del’s T without major
modifications since it is well-known that termination of T implies consistency of Peano arithmetic
[Go¨d58] and that this fact is provable in primitive recursive arithmetic.
It will turn out that the inductive characterization SN of the strongly normalizing terms can be
extended to T while the embedding of the set of all terms requires the introduction of an infinitely
branching clause in an inductive definition of a subset Ω ⊂ SN to cover recursion. A vaguely
similar program has first been carried out for a combinatory version in [San67].7 In section 7 we
cover the full reduction relation of the λ-calculus with primitive recursion in finite types, profiting
from our vector-based term display.
Acknowledgments. We would like to thank our mentor Helmut Schwichtenberg for numerous
encouraging meetings and stimulating advice. Wilfried Buchholz provided invaluable insight into
inductive definitions. Jan von Plato brought to our attention the problem of strong normalization
for natural deduction with general eliminations, the solution of which now forms the core of
section 6. For repeated discussions and helpful remarks we are grateful to Henk Barendregt, Ulrich
Berger, Rene´ David, Healfdene Goguen, J. Roger Hindley, Tobias Nipkow8 and Anne Troelstra.
1 λ-calculus
1.1. Terms. (Raw) terms r, s, t ∈ Λ are generated from variables x, y, z (of an infinite supply) by
the grammar
Λ 3 r, s ::= x | rs | λxr.
x is bound in λxr. Notationally, we let application associate to the left, writing r~s for rs1 . . . sn ≡
(. . . (rs1) . . . sn) with a possibly empty vector ~s. As remarked in the introduction the use of lists
to denote multiple eliminations is a metasyntactic device. Pointwise application of a function f
or a predicate P to a list of terms ~r will be denoted by f(~r ) and P (~r ), respectively; the comma
serves to denote concatenation and elongation: r, ~r, ~s, s ≡ r, r1, . . . , rn, s1, . . . sm, s.
We use the point notation λx.r to omit the parentheses in λx(r), where the range of the point
extends as far as syntactically possible. The simultaneous substitution of terms ~s for ~x in r is
defined as usual and written either r~x[~s ] or r[~x := ~s ]. Terms which differ only in names of bound
variables are identified, i.e., α-equal terms are equal.
7Other approaches can be found for instance in [Dil68], [How80] and [Sch93].
8Nipkow verified lemmata 3.3, 3.4 and 4 with the theorem prover Isabelle and gave worthwhile hints for im-
provement.
3
1.2. Inductive characterization and normal forms. The set of terms is inductively characterized
by the following grammar —
Λ 3 r, s ::= x~r | λxr | (λxr)s~s,
where the last form captures non-normal terms; we will see later that this presentation exhibits
the leftmost outermost reducible expression (redex). Excluding this last clause we obtain the
grammar of normal forms
NF 3 r ::= x~r | λxr.
1.3. Types and type assignment. ρ, σ, τ are generated from basic types ι by the grammar
ρ, σ ::= ι | ρ→ σ.
Given a unique assignment x : ρ of types to variable symbols such that for each type infinitely
many variables exist, we can determine the typable terms and their unique type by the following
rules:9 r : ρ→ σ s : ρ
rs : σ
r : σ x : ρ
λxr : ρ→ σ
We will decorate (sub-)terms with types in superscripts (as in rρs) in order to signify that they
are typable and get the respective type. Λ→ denotes the set of typable terms under a fixed type
assignment for the variables.
1.4. Reduction. The reduction relation → := →β is generated from the β-conversion rule
(λxr)s→ rx[s] by means of the compatible closure, extending conversion inductively by
r → r′ =⇒ λxr → λxr′, rs→ r′s, sr → sr′.
→+ is the transitive closure of→ (defined inductively),→∗ is the transitive, reflexive closure. The
resulting reduction relation is also compatible in the sense that r → r′ implies sx[r]→∗ sx[r′], and
sx[r]→ sx[r′] if x occurs exactly once in s. It is substitutive insofar as r → r′ implies rx[s]→ r′x[s].
That reduction preserves typability and types is a consequence of compatibility together with the
fact that type-correct substitution respects types.10
We see how our inductive term characterization finds the leftmost outermost convertible ex-
pression11 and that NF exactly captures the irreducible terms.
→η is generated from the conversion rule λx.rx→ r (if x is not free in r) using the compatible
closure. We write →βη for →β ∪ →η.
Notations. We define r ↓ (r is weakly normalizing) inductively by
r ∈ NF
r ↓
r → r′ ↓
r ↓
Thus r ↓ ⇔ ∃s ∈ NF.r →∗ s.
r ⇓ (r is strongly normalizing) is defined in the introduction. The set {r | r ⇓} amounts to
the well-founded part WF→ of the reduction relation.12 r ⇓ is equivalent to: There is no infinite
reduction sequence starting with r [⇒: Induction on r ⇓. ⇐ is an instance of bar induction]. We
write #r for the finite height of the (finitely branching) reduction tree of strongly normalizing
terms r, given recursively by #r := sup{#r′ + 1 | r → r′}.
9Although our choice of typing discipline does shorten arguments considerably, it is not vital for the course of
proofs, since we are only dealing with simple types here.
10We will not further comment on typability and type issues for the rest of this paper in order to keep the
presentation short.
11See [Bar84] for a discussion of the mentioned concepts and various reduction strategies.
12Let  be a binary relation on the fixed set M .
Prog(X) :⇔ ∀x ∈M.(∀y ≺ x.y ∈ X)⇒ x ∈ X, (X is -progressive)
WF :=
⋂{X ⊆M | Prog(X)}.
• The definition of the well-founded part WF yields the schema Prog(X) =⇒WF ⊆ X of accessible
part induction. (footnote continued on page 5)
4
2 Weak normalization proof
2.1. The proof. In this section we assume that all mentioned terms are typable.
Lemma. r, sρ ∈ NF =⇒ (i) rs ↓, (ii) rx[s] ↓.
Proof by simultaneous induction on ρ, side induction on r ∈ NF.
y~r. Assume y~r ∈ NF has been obtained from ~r ∈ NF. (i). y~rs ∈ NF follows immediately. (ii).
Side induction hypothesis (ii) shows ~rx[s] ↓; let ~t be the respective normal forms. If x 6≡ y
then (y~r )x[s] = y~rx[s] ↓. Otherwise
(y~r )x[s] ≡ (x~r )x[s] = s~rx[s]→∗ s~t.
Thus for s~rx[s] ↓ it suffices to show s~t ↓. For this we use an additional induction on the
length of ~t. If this vector is empty s~t ≡ s ∈ NF by assumption. Otherwise ~t ≡ ~t′, t and by
induction hypothesis we have s~t′ ↓ with normal form s′. Since s~t′ is applied to t we know
that the type of t is a subtype of the type ρ of s. Hence the main induction hypothesis (i)
yields s′t ↓, with normal form s′′. Putting the reductions together we get (with the help of
compatibility)
s~t ≡ s~t′t→∗ s′t→∗ s′′ ∈ NF.
λyr. (i). λyr ∈ NF is derived from r ∈ NF. Hence the side induction hypothesis (ii) for r proves
ry[s] ↓. Consequently (λyr)s→ ry[s] also normalizes.
(ii). Without loss of generality y 6≡ x and y not free in s13, so (λyr)x[s] = λyrx[s]. By side
induction hypothesis (ii) rx[s] ↓, thus λyrx[s] ↓. Qed
Theorem. rρ ↓.
Proof by induction on r. x ∈ NF by definition. rs ↓ by the lemma (part (i)), using the induction
hypothesis for r and s. λxr ↓, since by induction hypothesis r ↓. Qed
2.2. Extracted program. By formalizing this constructive normalization proof in the style of
[Ber93] we obtain
• the algorithmic content nf : Λ→ → NF of the theorem (defined by recursion on the term
structure):
nf(x) := x
nf(λxr) := λx nf(r)
nf(rs) := app(nf(r),nf(s))
• the algorithms app : NF × NF → NF, substx : NF × NF → NF (with auxiliary function
apps : NF
∗ → NF for s ∈ NF where NF∗ denotes the set of finite lists over NF and ε is the
• WF is -progressive itself.
• Definition by recursion on WF is admissible, since WF is an example of a deterministic inductive defini-
tion.
• If  ⊆ ′ then Prog(X) implies Prog′ (X), hence WF′ ⊆WF, i.e., λ.WF is antitone with respect
to ⊆.
• WF = WF+ where + is the transitive closure of . [For the interesting part WF ⊆WF+ one has to
show that WF+ is -progressive. ⊇ uses antitonicity.] This means that “course-of-generation-induction”
is a derived induction principle, the use of which will be announced as induction on WF+ .
13thanks to the identification of α-equal terms
5
empty list), extracted from the proofs of part (i) and (ii) of the lemma (defined by recursion
corresponding to the induction principles used):
app(y~r, s) := y~rs
app(λyr, s) := substy(r, s)
substx(y~r, s) := if x ≡ y then apps(substx(~r, s)) else y substx(~r, s)
apps(ε) := s
apps(~t, t) := app(apps(~t ), t)
substx(λyr, s) := λy substx(r, s)
2.3. A reformulation. First notice that
(∗) r ∈ NF =⇒ rx ↓
[Case λxr:14 (λxr)x → r ∈ NF. Case y~r: y~rx ∈ NF if ~r ∈ NF]. This fact can be used to merge
the two assertions of the lemma into one that speaks about substitution only, allowing a shorter
proof that does no more involve an induction on the length of the application in the case of (ii)
y~r. We are grateful to Rene´ David for hinting at this trick which he found and showed to us for
the strong normalization case (see section 4) after our presentation of a very early version of the
present paper.15
Lemma. r, sρ ∈ NF =⇒ rx[s] ↓.
Proof by induction on ρ, side induction on r ∈ NF.
Case y~r. The proof is trivial if ~r is empty or x 6≡ y. Otherwise y~r = (xtρ0)ρ1~t with ρ = ρ0 → ρ1.
• By the side induction hypothesis tx[s] ↓,~tx[s] ↓ with normal forms t′, ~t′. Hence z1~t′ ∈ NF
for a new variable z1 of type ρ1.
• (∗) shows sz0 ↓ for any new variable z0 of type ρ0, let s′ be a16 normal form. By
substitutivity
st′ = (sz0)z0 [t
′]→∗ s′z0 [t′].
By induction hypothesis at ρ0 (which is a subtype of ρ) we get s′z0 [t
′] ↓ with normal
form — say — s0.
Together this allows to apply the induction hypothesis for ρ1 to obtain (z1~t′)z1 [s0] ↓ and this
provides a normal form of the term in question:
(xt~t )x[s] = stx[s]~tx[s]→∗ st′~t′ →∗ s0~t′ ↓ .
Case λyr. (λyr)x[s] = λyrx[s], so the side induction hypothesis proves the claim. Qed
Corollary. r, s ∈ NF =⇒ rs ↓.
Proof. Use the lemma for xs and r with new x. Qed
14This is a rather subtle application of bound variable renaming. It is, of course, possible to make it explicit.
15In [Dav01], this idea is made fruitful for the uniform proof of several known and also new characterizations of
terms typable in systems of intersection types by normalization properties.
16Confluence ensures that normal forms are unique but this is not required throughout the paper.
6
The extracted algorithms substx and app differ from the previously found programs and use the
constructive content appx : NF→ NF of the proof of (∗).
appx(λxr) := r 17
appx(y~r) := y~rx
substx(λyr, s) := λy substx(r, s)
substx(y, s) := if x ≡ y then s else y
substx(yt~t, s) := if x ≡ y
then substz1(z1substx(~t, s), substz0(app
z0(s), substx(t, s)))
(z0 not free in s, z1 not free in ~t, s)
else y substx(t, s)substx(~t, s)
app(r, s) := substx(xs, r), (x not free in s)
3 The sets WN and SN
In the proof of Lemma 2.1 we used three closure properties of the set {r | r ↓}.
~r ↓ =⇒ x~r ↓,
r ↓ =⇒ λxr ↓,
rx[s]~s ↓ =⇒ (λxr)s~s ↓ .
We now use these clauses to generate the sets WN and SN inductively which will turn out to
capture the concepts weakly and strongly normalizing exactly, even in the context of untyped
λ-calculus. The characterization of WN and SN with respect to the intuitive notions of weak and
strong normalizability can be found in [vRS95].18
3.1. Definition. The sets SN ⊂WN ⊂ Λ are defined inductively by the following rules.
~r ∈WN (Var)
x~r ∈WN
r ∈WN (λ)
λxr ∈WN
rx[s]~s ∈WN (β)
(λxr)s~s ∈WN
~r ∈ SN (Var)
x~r ∈ SN
r ∈ SN (λ)
λxr ∈ SN
rx[s]~s ∈ SN s ∈ SN (β)
(λxr)s~s ∈ SN
Remark. The derived term of each rule has a different form — in fact, there is a one-to-one
correspondence between the rules and the grammar rules in 1.2 — and therefore the sets WN and
SN are generated freely, rendering recursion admissible. Furthermore both sets contain NF by
definition.
Using the abbreviation f := (λx.xx)(λx.xx) ∈ Λ \WN we see that (λyz)f ∈WN \ SN.
3.2. Weak normalization for WN. r ∈ WN implies r ↓, since the defining rules are closure
properties of {r | r ↓}. But the converse direction also holds,19 so we have r ∈WN⇐⇒ r ↓. The
17If we used explicit renaming of bound variables this clause would read appx(λyr) := ry [x].
18See the introduction for the reasons why we do not simply refer to those results and the equivalence of the
intuitive definitions with r ↓ and r ⇓.
19This means that the reduction strategy that underlies the definition of WN actually is the standard reduction
strategy guaranteed to exist by the standardization theorem (see, e.g., [Dav95] for a short exposition).
7
normal form ↓(r) of a term r ∈WN can be defined by recursion as follows.20
↓: WN −→ NF,
↓(x~r ) := x ↓(~r ),
↓(λxr) := λx ↓(r),
↓((λxr)s~s ) := ↓(rx[s]~s ).
3.3. Lemma. (Soundness). SN ⊆WF→.
Proof by induction on SN, i.e., by showing that the set of strongly normalizing terms is closed
under the rules defining SN.
(Var). Assume ~r ⇓. Since each reduction on x~r has to take place in one of the ~r, we also get x~r ⇓.
(λ). Each reduction on λxr actually occurs in r, so the hypothesis r ⇓ yields λxr ⇓.
(β). We show (λxr)s~s ⇓ by main induction on s ⇓ and side induction on rx[s]~s ⇓.21 We have to
prove t ⇓ for any immediate reduct t. The following reductions are possible.
(λxr)s~s→ (λxr′)s~s. Then rx[s]~s → r′x[s]~s by substitutivity, hence by side induction hy-
pothesis (λxr′)s~s ⇓.
(λxr)s~s→ (λxr)s′~s. Then rx[s]~s →∗ rx[s′]~s by compatibility, hence also rx[s′]~s ⇓. The
main induction hypothesis yields (λxr)s′~s ⇓.
(λxr)s~s→ (λxr)s~s′. Then rx[s]~s→ rx[s]~s′, hence by side induction hypothesis (λxr)s~s′ ⇓.
(λxr)s~s→ rx[s]~s ⇓ by assumption. Qed
Along the lines of the proof one can verify the following inductive bounds on the height #r of the
reduction tree for terms r ∈ SN:
#x~r ≤∑#~r, #λxr ≤ #r22 and #(λxr)s~s ≤ 1 + #rx[s]~s+ #s.
3.4. Completeness. For the purpose of the normalization proof it is not necessary to know that
SN captures all strongly normalizing terms. Nevertheless the result is interesting in its own right.
Lemma. WF→ ⊆ SN.
The proof uses nested inductions on WF→ and the term structure. In fact, the lemma is an
instance of the following proposition, the generality of which will pay off in section 5.
Proposition. Let → be a binary relation on the set WF. with
∀r ∀r′ ∀r′′.r . r′ → r′′ ⇒ ∃r′′′.r → r′′′ . r′′ (commutation).
Then WF→ ⊆WF.∪→.
20Goguen’s typed operational semantics [Gog95], which inspired our work, can be understood as a combination
of SN,NF and the normal form function ↓ into one inductive definition.
21This argument is crucial to the proof of strong normalization and to our knowledge it is an unavoidable part
of any strong normalization proof amenable to a faithful formalization. Most often, however, it is hidden in an
argument via infinite reduction sequences. In order to clarify the intricate structure of the argument we spell out
the nesting of inductions precisely. Main induction on s ⇓ amounts to showing →-progressivity of the set
M := {s | ∀r, ~s.rx[s]~s ⇓ ⇒ (λxr)s~s ⇓}.
So assume that any one-step-reduct of s is in M . For s ∈ M we do side induction on rx[s]~s ⇓, i.e., we show
→-progressivity of the set
N := {t′ | t′ ⇓ ∧∀r, ~s.t′ = rx[s]~s⇒ (λxr)s~s ⇓}.
So assume t′ is a term and each immediate reduct is in N . We have to show t′ ∈ N . t′ ⇓ follows from the definition
of ⇓, since N ⊆ WF→. If t′ has the form rx[s]~s we have to show (λxr)s~s ⇓, so we prove t ⇓ for every one-step
reduct t. Henceforward, each clause of the proof in the main text can be recast using the pending assumptions.
22Clearly, the first two inequalities even hold with =.
8
Proof by (accessible part) induction on →. With := . ∪ → our goal is Prog→(WF), which
reads ∀r.(∀s←r.s ∈WF)⇒ r ∈WF. Using induction on . we need to prove
Prog.(λr.(∀s←r.s ∈WF︸ ︷︷ ︸
≡:∆(r)
)⇒ r ∈WF) ≡ ∀r.(∀t / r.∆(t)⇒ t ∈WF) ∧∆(r)⇒ r ∈WF.
So assume r with
(1) ∀t / r.∆(t)⇒ t ∈WF and
(2) ∆(r) ≡ ∀s←r.s ∈WF.
We need to show r ∈WF. Since the well-founded part WF is -progressive it suffices to show
∀s ≺ r.s ∈WF. So let r  s.
Case r → s. Then s ∈WF holds by (2).
Case r . s. Using (1) it suffices to know ∆(s), i.e., ∀t←s.t ∈WF. So assume r . s→ t. Then by
commutation there exists an r′ with r → r′ . t, so by (2) also r′ ∈WF, hence t ∈WF as
r′  t. Qed
To get the lemma, we first apply the proposition to → and a restricted subterm relation . given
by the clauses
x~r . rk, λxr . r, and (λxr)s~s . s.
Clearly, WF. = Λ. Commutation is shown by simple case analysis.
λxr . r → r′ =⇒ λxr → λxr′ . r′,
x~r . rk → r′k =⇒ x~r → x~r′ . r′k,
(λxr)s~s . s→ s′ =⇒ (λxr)s~s→ (λxr)s′~s . s′.
The proposition yields WF→ ⊆WF.∪→. The latter is a subset of SN by antitonicity of λ.WF,
since SN is generated as WFA with A extending . by head-conversion
(λxr)s~s A rx[s]~s.
3.5. On η. The set SN also captures exactly the notion of strongly normalizing for →βη. For
WF→βη ⊆ SN we apply antitonicity of λ.WF. For the converse inclusion, the proof of Lemma
3.3 remains largely unaltered due to the fact that η-reductions on the left side of an application
(as in (λx.rx)s →η rs) are also β-reductions and thus need not be considered. Furthermore
η-reductions on the right side of an application (i.e., rλx.sx →η rs) are always covered by the
induction hypothesis. So we only have to deal with the new case of a head-η-reduction λx.sx→ s
in part (λ) of the proof when showing that λx.sx ⇓ follows from sx ⇓, but clearly s ⇓, since the
set {r | r ⇓} = WF→βη of strongly normalizing terms is closed under subterms.
It has been shown elsewhere [AJ01] that strong normalization (and confluence) of combined β-
reduction and η-expansion follows from the same property of β-reduction alone. As a consequence
SN also exactly characterizes the set of strongly normalizing terms with respect to →βη↑ (defined
loc. cit.).
3.6. The SN-method [Mat98]. Having the characterization of strongly normalizing terms via
SN at hand, one can rearrange traditional strong normalization proofs, e.g., by the method of
logical predicates, such that they do not refer to reduction. Using suitable extensions of the vector
notation, SN can also be defined for system F and extensions such as by monotone inductive types.
The saturated sets variant [Tai75] of Girard’s normalization proof may be adapted, with the notion
of saturatedness naturally arising from the definition of SN. This is also true for systems with
permutative conversions as shown, e. g., in [Mat00].
9
4 Strong normalization proof
In this section we lift the proof of Lemma 2.1 to strong normalization, using the SN-method
explained above. We assume throughout that all displayed terms are typable.
Lemma. r ∈ SN, sρ ∈ SN =⇒ (i) rs ∈ SN, (ii) rx[s] ∈ SN.
Proof by simultaneous induction on ρ and side induction on the generation of r ∈ SN. In essence
the proof is parallel to that of Lemma 2.1 but the use of SN shortens arguments considerably.
(Var). r ≡ y~r ∈ SN is generated from ~r ∈ SN. (i). ~r ∈ SN together with s ∈ SN shows y~rs ∈ SN,
using (Var). (ii). Side induction hypothesis (ii) yields rk[x := s] ∈ SN for each rk in ~r. Now
if y 6≡ x we get y~rx[s] ∈ SN at once. Otherwise we need s~rx[s] ∈ SN, but this follows by
multiple applications of the main induction hypothesis for (i), since each of the arguments
in the nested application has a subtype of ρ.23
(λ). λyr ∈ SN is generated from r ∈ SN. (i). For (λyr)s ∈ SN it suffices to show ry[s] ∈ SN.
But this is exactly the side induction hypothesis for (ii). (ii). Side induction hypothesis (ii)
yields rx[s] ∈ SN and consequently λyrx[s] ∈ SN.
(β). (λyr)t~t ∈ SN is obtained from ry[t]~t ∈ SN and t ∈ SN. Therefore both side induction
hypotheses apply and yield (i) ry[t]~ts ∈ SN and (ii) (ry[t]~t )x[s], tx[s] ∈ SN, respectively. From
these we obtain the assertions (λyr)t~ts ∈ SN (i) and ((λyr)t~t )x[s] ∈ SN (ii) by definition of
SN. Qed
Remark. A proof of the statement of the lemma with SN replaced by WN is only marginally
simpler.
Theorem. All terms are strongly normalizable.
Proof. Show r ∈ SN by induction on the structure of r, using the lemma. Lemma 3.3 proves
strong normalizability of r. Qed
Again (compare with 2.3), we can merge parts (i) and (ii) of the lemma into closure under substi-
tution using the
Proposition. r ∈ SN =⇒ rx ∈ SN.24
Proof by induction on SN. Qed
Lemma. r, sρ ∈ SN =⇒ rx[s] ∈ SN.
Proof by induction on ρ, side induction on r ∈ SN. We only mention the variable case with a
non-trivial elimination (xtρ0)ρ1~t on the same variable x that is substituted by s. Then ρ = ρ0 → ρ1.
• By the side induction hypothesis we have tx[s],~tx[s] ∈ SN. Consequently also z~tx[s] ∈ SN
for a fresh variable z : ρ1.
• By the proposition we have syρ0 ∈ SN for a new y, hence by induction hypothesis for ρ0 also
stx[s] ∈ SN.
• The induction hypothesis for ρ1 shows (xt~t )x[s] = (z~tx[s])z[stx[s]] ∈ SN. Qed
As a corollary we get closure of SN under application, again.
23More precisely, this argument involves an additional induction on the length of the list ~r, analogous to the
proof of Lemma 2.1.
24Induction on rx ∈ SN would show the converse direction.
10
5 Extension to permutative conversions
We proceed to a typed calculus with sums and permutative conversions similar to those being
studied in [Pra71], [Lei75] or [GLT89]. In contrast to their expositions we do not consider product
types or other first-order extensions, although the proof method copes with them, too.
5.1. (Raw) terms. Let always i ∈ {0, 1}.
r, s, t ::= x | λyr | rs | injir | s(x0.t0, x1.t1).
The variables y, x0, x1 get bound in r, t0, t1, respectively.
5.2. Types and type assignment. The type grammar is extended to sums ρ+ σ. In order to get
unique types for typable terms we add a type subscript to the injection (writing inji,ρ) that will,
however, be omitted.
r : ρi
inji,ρ1−ir : ρ0 + ρ1
r : ρ0 + ρ1 s0 : σ s1 : σ
r(xρ00 .s0, x
ρ1
1 .s1) : σ
(The type superscripts of variables in the second rule indicate the type assignments for those
variables. In fact, the assignments are premises of the rule.) Note that typing rules out pathological
terms like (λxr)(x.s, y.t) or (injir)s.
In the rest of this section we require all mentioned terms to be typable.
5.3. Inductive characterization. We use capital letters R, S, T for eliminations25, which are either
terms or sum-eliminations (x0.s0, x1.s1):
R ::= r | (x0.s0, x1.s1).
The terms r, s0 and s1 are named elimination terms in this definition. Eliminations of the
form (x0.s0, x1.s1) are called critical. We write (x0.s0, x1.s1)x[t] for the capture-free substitution
(x0.s0[x := t], x1.s1[x := t]).
Using a square bracket notation [. . .] for optional syntax elements, we can inductively charac-
terize the set of typed terms by
Λ→+ 3 r, s ::= x~r [R] | λxr | injir |
x~r(x0.s0, x1.s1)S~S | (λxr)s~S | (inji)(x0.s0, x1.s1)~R.
5.4. Normal forms. The last three clauses in the inductive term characterization are not con-
sidered normal. This is intuitive for the β-redices (λxr)s~S and (injir)(x0.s0, x1.s1)~S. The term
x~r(x0.s0, x1.s1)S~S need not fulfil the subformula property in general.
NF 3 r ::= x~r [(x0.s0, x1.s1)] | λxr | injir.
Notice how the inductive term characterization uniquely determines the canonical redex of non-
normal terms.
5.5. Reduction. These redices are removed by means of β-conversion
(λxr)s→β→ rx[s], (injir)(x0.s0, x1.s1)→β+ si[xi := r],
and permutative conversions
r(x0.s0, x1.s1)S →pi r(x0.s0S, x1.s1S).26
25Note the ambiguity: R as well as rR are called eliminations (cf. the introduction).
11
The compatible closure → of these conversions is given by
r → r′ =⇒ sr → sr′, rS → r′S, λxr → λxr′, injir → injir′,
s(x.r, y.t)→ s(x.r′, y.t), s(y.t, x.r)→ s(y.t, x.r′).
5.6. Definition. The set SN is generated inductively by the following rules where (x.r, y.t) ∈ SN
is an abbreviation for r, t ∈ SN.
~r [,R] ∈ SN
(Var)
x~r [R] ∈ SN
r ∈ SN (λ)
λxr ∈ SN
x~r(x0.s0S, x1.s1S)~S ∈ SN (Varpi)27
x~r(x0.s0, x1.s1)S~S ∈ SN
r ∈ SN (inj)
injir ∈ SN
rx[s]~S ∈ SN s ∈ SN (β→)
(λxr)s~S ∈ SN
si[xi := r]~S ∈ SN s1−i~S ∈ SN r ∈ SN (β+)
(injir)(x0.s0, x1.s1)~S ∈ SN
Remark. x~R is necessarily generated from an x~r [R] where a potentially critical elimination
R occurs outermost, if at all. Furthermore x~r [R] can be obtained from x~R by permutative
conversions.
It is also worth mentioning that the definition of SN incorporates permutations for variable
eliminations only. The following lemma shows that this is sufficient to capture all strongly nor-
malizing terms.
Lemma. SN = WF→.
Proof. “⊆” (soundness): We again have to show that WF→ = {r | r ⇓} has the closure
properties which define SN. For (Var) and (λ) the proof remains unchanged, (inji) is as trivial as
(λ). The proof for (β→) is verbosely the same as that in section 3, replacing ~s by ~S. Notice that
now permutative conversions may affect the length of the list ~S.
(Varpi). Show x~r(x0.s0S, x1.s1S)~S ⇓=⇒ x~r(x0.s0, x1.s1)S~S ⇓ by induction on x~r(x0.s0S, x1.s1S)~S
∈WF→+ . We have to show t ⇓ for every reduct t of x~r(x0.s0, x1.s1)S~S. The only interesting
case arises with ~S ≡ T ~T and a permutation of S ≡ (y0.t0, y1.t1) with T leading to
t = x~r(x0.s0, x1.s1)(y0.t0T, y1.t1T )~T .
t ⇓ follows by induction hypothesis as
x~r(x0.s0S, x1.s1S)~S ≡ x~r(x0.s0(y0.t0, y1.t1), x1.s1(y0.t0, y1.t1))T ~T
reduces with three permutative reduction steps (hence once →+) to
x~r(x0.s0(y0.t0T, y1.t1T ), x1.s1(y0.t0T, y1.t1T ))~T .
26Strictly speaking, we require x0, x1 not to be free in S. Otherwise the rule would not comply with α-equality.
27This clause is subject to the same proviso as the rule of permutative conversion.
12
(β+). Show that si[xi := r]~S ⇓, s1−i~S ⇓ and r ⇓ imply (injir)(x0.s0, x1.s1)~S ⇓ by main induction
on r ⇓, side induction on si[xi := r]~S ⇓, side side induction on s1−i~S ⇓ and a third side
induction on the length of ~S. We have to show t ⇓ for every reduct t of (injir)(x0.s0, x1.s1)~S.
The most interesting case is when ~S ≡ T ~T and (x0.s0, x1.s1) is permuted with T , i.e.,
t = (injir)(x0.s0T, x1.s1T )~T . This is an application of the third side induction hypothesis
since (siT )[xi := r]~T = si[xi := r]~S ⇓, s1−iT ~T ⇓ and r ⇓.28
“⊇” (completeness): Use nested course-of-generation inductions on r ⇓ and r. Actually, we may
also apply the general proposition of 3.4. To this end define . as follows.
λxr . r, injir . r,
x~r [R] . rk, x~r (x0.s0, x1.s1) . si,
(λxr)s~S . s, (injir)(x0.s0, x1.s1)~S . s1−i~S and r.
Clearly WF. = Λ→+, since the size of the terms decreases in each clause. Commutation of .
with →+ is shown by simple case analysis where the crucial case necessitates →+ instead of →:
(injir)(x0.s0, x1.s1)~S . s1−i~S →+ t implies
(injir)(x0.s0, x1.s1)~S →∗ (injir)(x0.s0~S, x1.s1~S)→+
{
(inj0r)(x0.s0~S, x1.t)
(inj1r)(x0.t, x1.s1~S)
}
. t.
Proposition 3.4 yields WF→+ ⊆WF.∪→+ . Using properties of WF we get
WF→ = WF→+ ⊆WF.∪→+ ⊆WF.∪→ ⊆ SN.
Qed
Lemma. r(x0.s0S, x1.s1S)~S ∈ SN =⇒ r(x0.s0, x1.s1)S~S ∈ SN.
Proof by course-of-generation-induction on r(x0.s0S, x1.s1S)~S ∈ SN. Distinguish cases according
to the shape of r. Most cases are a trivial application of the induction hypothesis. Interesting are
Case x~r(y0.t0, y1.t1). Assume x~r(y0.t0, y1.t1)(x0.s0S, x1.s1S)~S ∈ SN. This has been concluded by
repeated application of (Varpi) from
x~r(y0.t0(x0.s0S, x1.s1S)~S, y1.t1(x0.s0S, x1.s1S)~S) ∈ SN,
i.e., we have got ~r ∈ SN and both ti(x0.s0S, x1.s1S)~S ∈ SN before. By induction hypothesis
we get ti(x0.s0, x1.s1)S~S ∈ SN. Hence
x~r(y0.t0(x0.s0, x1.s1)S~S, y1.t1(x0.s0, x1.s1)S~S) ∈ SN.
Using the rule (Varpi) repeatedly we obtain
x~r(y0.t0, y1.t1)(x0.s0, x1.s1)S~S ∈ SN.
Case injir. Assume (injir)(x0.s0S, x1.s1S)~S ∈ SN. This has been derived from (siS)[xi := r]~S =
si[xi := r]S~S ∈ SN and r, s1−iS~S ∈ SN. Hence (injir)(x0.s0, x1.s1)S~S ∈ SN. Qed
28This case requires s1−i~S ⇓ as second premise, justifying the somewhat peculiar fact that (β+) goes back to s1−i ~S
instead of the subterm s1−i of (injir)(x0.s0, x1.s1)~S. In an untyped calculus the term (inj0x)(x0.y, x1.λz.zz)(λz.zz)
would be a counter-example to SN ⊆WF→ with the wrong formulation: The permutative reduct has f as a subterm.
13
5.7. Lemma. For all types ρ, for all r ∈ SN,
(i) if sρ ∈ SN then rs ∈ SN,
(ii) if r : ρ ≡ ρ0 + ρ1 and s0, s1 ∈ SN then r(x0.s0, x1.s1) ∈ SN,
(iii) if sρ ∈ SN then rx[s] ∈ SN.
Proof. By simultaneous induction on ρ, side induction on r ∈ SN. Distinguish cases according
to r ∈ SN. We always first prove (i) and (ii) in parallel and later infer (iii), possibly with the help
of (ii).
x~r [R]. Let S ∈ SN. If [R] is void then x~rS ∈ SN simply follows from ~r, S ∈ SN. Otherwise we may
assume that R is a critical elimination of the form (x0.s0, x1.s1). For x~r(x0.s0, x1.s1)S ∈ SN
we need x~r(x0.s0S, x1.s1S) ∈ SN and this requires s0S, s1S ∈ SN. But the latter follows
from the side induction hypothesis for s0 and s1 which in case that S is critical applies
since they have the same type as x~r(x0.s0, x1.s1). In case (i) we do not need this last fact.
Note that in order to use the side induction hypothesis (ii) we always have to check that the
previously generated term in SN has the same (sum) type ρ.
x~r(x0.s0, x1.s1)T ~T ∈ SN has been derived from x~r(x0.s0T, x1.s1T )~T ∈ SN. The side induction hy-
pothesis for the latter yields x~r(x0.s0T, x1.s1T )~TS ∈ SN, so we obtain x~r(x0.s0, x1.s1)T ~TS ∈
SN at once.
λxr ∈ SN has been derived from r ∈ SN. Since λxr necessarily has a function type we only have to
deal with case (i) and may apply the side induction hypothesis for (iii) in order to conclude
rx[s] ∈ SN. Hence (λxr)s ∈ SN.
(λxr)t~T . If S ∈ SN then by the respective side induction hypothesis rx[t]~TS ∈ SN, hence
(λxr)t~TS ∈ SN by (β→).
injir ∈ SN is derived from r ∈ SN. Since injir has a sum type only case (ii) is possible. The
assertion (injir)(x0.s0, x1.s1) ∈ SN can be obtained from si[xi := r] ∈ SN using the (β+)-
rule, and that follows from the main induction hypothesis (iii) since r has a strictly smaller
type than injir.
(injir)(x0.s0, x1.s1)~S. Similar to the (β→)-case: (injir)(x0.s0, x1.s1)~S ∈ SN has been inferred from
si[xi := r]~S ∈ SN, s1−i~S ∈ SN and r ∈ SN. Since the first two terms also have type ρ the
side induction hypothesis may be applied and yields
si[xi := r]~SS ∈ SN and s1−i~SS ∈ SN,
so one application of the (β+)-rule proves the assertion
(injir)(x0.s0, x1.s1)~SS ∈ SN.
In the proof of (iii) the complicated cases are the variable eliminations (all other cases are covered
by the side induction hypothesis).
Case y~r [R]. The side induction hypothesis supplies us with ~rx[s] ∈ SN and Rx[s] ∈ SN.
• If x 6≡ y this suffices to conclude (y~r [R])x[s] ∈ SN.
• If x ≡ y and the elimination is empty the claim follows at once from s ∈ SN.
• If not we successively apply s to the substituted eliminations ~rx[s], using the induction
hypothesis for (i) repeatedly at subtypes of ρ, arriving at s~rx[s] ∈ SN. If [R] is not void
we may assume that R is critical. If, moreover, ~r is empty we apply (ii) at type ρ (which
already has been proved) in order to conclude that sRx[s] ∈ SN. Otherwise s~rx[s] has a
subtype of ρ and we apply the induction hypothesis for (ii), obtaining s~rx[s]Rx[s] ∈ SN.
For this to work it is vital that at most the last elimination is critical, because in
contrast to →-eliminations the types are not in general lowered by +-eliminations.
14
Case y~r(x0.s0, x1.s1)S~S. By induction hypothesis (y~r(x0.s0S, x1.s1S)~S)x[s] ∈ SN. In the more
difficult case of y ≡ x this term has the form
s~r′(x0.s′0S
′, x1.s′1S
′)~S′.
Using the previous lemma we obtain s~r′(x0.s′0, x1.s
′
1)S
′ ~S′ ∈ SN. Qed
Corollary. r ⇓.
5.8. On η. Let now →η be generated from the eta conversion rule for function types λx.rx→ r
(if x is not free in r) as before and the eta conversion rule for sum types r(x0.inj0x0, x1.inj1x1)→ r
and write→βpiη for→ ∪ →η. As in 3.5, WF→βpiη ⊆ SN by antitonicity of λ.WF. The converse
inclusion SN ⊆ WF→βpiη is shown by a slight extension of the soundness proof. We only discuss
the interesting new cases:
(Varpi). If x~r(x0.s0, x1.s1)S~S →η x~rS~S =: t due to si = injixi, then S has the form S ≡
(x0.t0, x1.t1)29 and
x~r(x0.s0S, x1.s1S)~S ≡ x~r(x0.(inj0x0)(x0.t0, x1.t1), x1.(inj1x1)(x0.t0, x1.t1))~S
reduces with two β+-steps to t, hence t ⇓ follows from the assumption alone.
If x~r(x0.s0, x1.s1)S~S →η x~r(x0.s0, x1.s1)~S =: t due to S ≡ (y0.inj0y0, y1.inj1y1), then
x~r(x0.s0S, x1.s1S)~S reduces to t in two η-steps, and therefore we again do not need the
induction hypothesis.
(β+). If (injir)(x0.s0, x1.s1)~S →η (injir)~S due to sj = injjxj for j ∈ {0, 1}, then (injir)~S =
si[xi := r]~S ⇓ by assumption.
We already know that Λ→+ ⊆ SN, hence also →βpiη is strongly normalizing.30
6 Extension to generalized applications
Generalized applications allow to further simplify the grammar of normal forms in λ-calculus. The
term system presented here is inspired by von Plato’s generalized natural deduction trees [vP01].
Its typed version contains → as the only type constructor, although the proofs directly carry
over to a system with products (with a generalization of projections) and sums (with the usual
elimination rule, treated above). In fact, the proofs in this section for → are guided by those of
the preceding section for +.
6.1. (Raw) terms.
ΛJ 3 r, s, t ::= x | λyr | s(t, y.r).
The variable y gets bound in r in these terms. By setting rs := r(s, y.y), Λ embeds into ΛJ.
6.2. Inductive characterization and normal forms. We use capital letters R, S, T for eliminations,
i. e., for syntactic objects of the form (s, z.t). We will write Rx[r] for the capture-free substitution
(sx[r], z.tx[r]). The set of terms is inductively characterized by the following grammar —
ΛJ 3 r ::= x | xR | λxr | xRS~S | (λxr)S~S,
where the last two forms capture non-normal terms: xRS~S is a permutative redex and (λxr)S~S
is a β-redex (see below). By excluding these last clauses we obtain the grammar of normal forms
NF 3 r, s, t ::= x | x(s, z.t) | λxr.
29Concerning the choice of variable names, see footnote 14.
30The double-negation-translation used in [dG99] for establishing strong normalization of → does not cover →η .
15
6.3. Types and type assignment. By using the types and type assignments for variables from 1.3,
the typable terms and their unique type are given by the rules:
r : ρ→ σ s : ρ t : τ
r(s, zσ.t) : τ
r : σ x : ρ
λxr : ρ→ σ
(The type superscript of z indicates the type assignment for z and could have been written as an
extra premise.) By restricting the first rule to r ≡ x, we get a typing of the normal forms and
arrive at a term notation for the cut-free Gentzen calculus (describing the implicational fragment
of intuitionistic propositional logic), the first rule being the left →-introduction rule.31 Therefore,
the typing rules are correct from a logical point of view.
Induction on NF verifies the subformula property of normal terms.32
6.4. Reduction. The conversions to be dealt with are β-conversion
(λxr)(s, z.t)→β t[z := rx[s]]
and permutative conversion
r(s, z.t)S →pi r(s, z.tS).33
Their compatible closure → is given by
r → r′ =⇒ rS → r′S, s(r, z.t)→ s(r′, z.t), s(t, z.r)→ s(t, z.r′), λxr → λxr′.
Clearly, reduction preserves typability and types, i. e., we have subject reduction for →.
6.5. Definition. The set SN is generated inductively by the following rules.
(Var0)
x ∈ SN
r ∈ SN (λ)
λxr ∈ SN
s, t ∈ SN
(Var)
x(s, z.t) ∈ SN
x(s, z.tS)~S ∈ SN
(Varpi)34
x(s, z.t)S~S ∈ SN
t[z := rx[s]]~S ∈ SN r, s ∈ SN (β)
(λxr)(s, z.t)~S ∈ SN
Lemma. SN = WF→.
Proof. “⊆” (soundness): Once again we show that WF→ = {r | r ⇓} has the closure properties
which define SN. (Var0) is trivial, for (Var) and (λ) we essentially take the proofs of section 3.
(Varpi) works in nearly the same way as in the preceding section. The proof for (β) is a combination
of (β) in section 3 with (β+) in section 5. The last two properties are shown in detail for reference
purposes.
(Varpi). Show x(s, z.tS)~S ⇓ =⇒ x(s, z.t)S~S ⇓ by induction on x(s, z.tS)~S ∈ WF→+ . We have to
show r ⇓ for every reduct r of x(s, z.t)S~S. The only interesting case arises with ~S ≡ T ~T
and a permutation of S ≡ (s′, z′.t′) with T leading to r = x(s, z.t)(s′, z′.t′T )~T . r ⇓ follows
by induction hypothesis as x(s, z.tS)~S ≡ x(s, z.t(s′, z′.t′))T ~T reduces with two permutative
reduction steps (hence once →+) to x(s, z.t(s′, z′.t′T ))~T .
31An alternative notation for x(s, z.t) proposed in [Sch99] is tz{x, s} which is motivated by the following
type-preserving translation into the normal forms of simply-typed λ-calculus: F (x) := x, F (λxr) := λxF (r),
F (x(s, z.t)) := F (t)[z := xF (s)]. Its natural extension F (r(s, z.t)) := F (t)[z := F (r)F (s)] translates ΛJ into Λ,
but does not simulate reduction, so it cannot serve to infer strong normalization from Λ→. Neither can the variant
with F (r(s, z.t)) := (λzF (t))(F (r)F (s)).
32xRS~S need not have the subformula property: xι→ι1 (y
ι
1, z
ι.λxρ→ρz)(λyρy, zι.z) : ι has the subterm λyρy of
type ρ→ ρ with arbitrary type ρ but only the free variables x1 and y1 of types ι→ ι and ι.
33z shall not be free in S, compare footnote 26.
34This clause is subject to the same proviso as the rule of permutative conversion.
16
(β). Show that t[z := rx[s]]~S ⇓, r ⇓ and s ⇓ imply (λxr)(s, z.t)~S ⇓ by main induction on s ⇓,
side induction on r ⇓, side side induction on t[z := rx[s]]~S ⇓ and a third side induction
on the length of ~S. We have to show r′ ⇓ for every reduct r′ of (λxr)(s, z.t)~S. In case
of the outer β-reduction the assumption is used; reduction in s needs the main induction
hypothesis, reduction in r the side induction hypothesis. Reductions in t and in ~S as well as
permutations between ~S are covered by the side side induction hypothesis. The remaining
case is when ~S ≡ T ~T and (s, z.t) is permuted with T , i.e., r′ = (λxr)(s, z.tT )~T . This is an
application of the third side induction hypothesis since (tT )[z := rx[s]]~T = t[z := rx[s]]~S.
“⊇” (completeness): Once again use nested course-of-generation inductions on r ⇓ and r or apply
the general proposition of 3.4 with . defined as follows:
x(s, z.t) . s and t, λxr . r, and (λxr)(s, z.t)~S . r and s.
Qed
Lemma. r(s, z.tS)~S ∈ SN =⇒ r(s, z.t)S~S ∈ SN.
Proof by course-of-generation-induction on r(s, z.tS)~S ∈ SN. Distinguish cases according to the
shape of r. The last two cases of the grammar in 6.2 are a simple application of the induction
hypothesis, the case of a variable is rule (Varpi). Interesting are
Case x(s′, z′.t′). Assume x(s′, z′.t′)(s, z.tS)~S ∈ SN. This has been concluded by repeated applica-
tion of (Varpi) from x(s′, z′.t′(s, z.tS)~S) ∈ SN, i. e., we have got s′ ∈ SN and t′(s, z.tS)~S ∈ SN
before. By induction hypothesis we get t′(s, z.t)S~S ∈ SN. Hence x(s′, z′.t′(s, z.t)S~S) ∈ SN.
Using the rule (Varpi) repeatedly we obtain x(s′, z′.t′)(s, z.t)S~S ∈ SN.
Case λxr. Assume (λxr)(s, z.tS)~S ∈ SN. This has been derived from r ∈ SN, s ∈ SN and
(tS)[z := rx[s]]~S = t[z := rx[s]]S~S ∈ SN. Hence (λxr)(s, z.t)S~S ∈ SN. Qed
6.6. Strong normalization. For the rest of this section we assume that all displayed terms are
typable.
Lemma. For all types ρ, for all r ∈ SN,
(i) if r : ρ ≡ ρ0 → ρ1 and s, t ∈ SN then r(s, z.t) ∈ SN,
(ii) if sρ ∈ SN then rx[s] ∈ SN.
Proof. By simultaneous induction on ρ, side induction on r ∈ SN. Distinguish cases according
to r ∈ SN. One always first has to prove (i) and later infers (ii), possibly with the help of (i). (i).
Case (Var0) only needs (Var); (Var), (Varpi) and (β) are covered by the side induction hypothesis
(check that the type of the main induction is not affected) and the rules (Varpi)&(Var0), (Varpi)
and (β), respectively. (ii). Case (Var0) needs either the assumption (if r ≡ x) or rule (Var0) again;
(Varpi), (λ) and (β) follow from the side induction hypothesis and the previous lemma, rules (λ)
and (β), respectively. Therefore, only (i)(λ) and (ii)(Var) are studied in detail. The reader is
invited to contrast them with case λxr and the third subcase of y~r [R] in the proof of 5.7.
(i)(λ). Let λxr : ρ0 → ρ1 be in SN due to rρ1 ∈ SN. Show that (λxr)(sρ0 , z.t) ∈ SN. By rule (β)
it suffices to show r, s ∈ SN and t[z := rx[s]] ∈ SN. By induction hypothesis (ii) for type ρ0,
rx[s] ∈ SN. rx[s] : ρ1, hence by induction hypothesis (ii) for type ρ1, t[z := rx[s]] ∈ SN.
(ii)(Var). Let y(s′, z′.t′) be in SN due to s′, t′ ∈ SN. Show that (y(s′, z′.t′))x[s] ∈ SN. By side
induction hypothesis (ii), s′x[s], t
′
x[s] ∈ SN. If y 6≡ x, we are done by rule (Var). Otherwise,
we have to show s(s′x[s], z
′.t′x[s]) ∈ SN. This is an instance of (i) for the same type ρ which
is proved before (ii) and hence already available. Qed
17
Corollary. r ⇓.
6.7. On κ. Following the idea of “immediate simplifications” in [Pra71, p. 254] which allow to
reduce +-eliminations r(x0.s0, x1.s1) to the term si if xi does not occur free in si (for i ∈ {0, 1}),
define the new conversion rule r(s, z.t) → t, if z is not free in t and write →κ for its compatible
closure and →βpiκ for → ∪ →κ. Then also →βpiκ is strongly normalizing because WFβpiκ has the
defining closure properties of SN: (Var0) and (λ) are trivial as before; (Var) may in addition have
an outer κ-conversion which is trivial to handle, though. The proofs for (Varpi) and (β) in 6.5
have to be extended by some cases:
(Varpi). If z is not free in t and r = tS ~S, then also x(s, z.tS)~S →κ r. If S ≡ (s′, z′.t′) with z′
not free in t′ and r = t′~S, then x(s, z.tS)~S →κ x(s, z.t′)~S →κ r since we may assume that
z is not free in t′. Finally, if ~S ≡ ~R(s′, z′.t′)~T with z′ not free in t′ and r = t′ ~T , then
x(s, z.tS)~S →κ r. Note that the induction hypothesis is never needed in these new cases.
(β). If z is not free in t and r′ = t~S, then this is also a β-reduction (an analogous situation
to that of η in 3.5). If ~S ≡ ~R(s′, z′.t′)~T with z′ not free in t′ and r = t′ ~T , then also
t[z := rx[s]]~S →κ r. Qed
7 Go¨del’s T
Compared with a combinatory version [Tai67, San67, Wei97], primitive recursion in finite types
over the λ-calculus presents additional difficulties in normalization proofs: β-reduction might
substitute variables in the recursion arguments, giving rise to new recursion steps. This mixing of
β- and recursion steps can be avoided by adapting a special reduction strategy [Dil68, How80] or
restricting recursion arguments to numerals only.35 In this section we show strong normalization
for the general form of a λ-calculus enriched by number and recursion constructors as well as
recursion reductions. In order to keep the presentation short we directly proceed to the typed
calculus although an untyped version of Go¨del’s T can be described (Example 3.3.5 in [Joa01]).
7.1. Terms and Types. We formulate T by adding a basic type N for the natural numbers, a
constant 0 : N and a unary function symbol S : N → N for the successor. Higher-order recursion
is implemented by the elimination rule
r : N s : ρ t : N→ ρ→ ρ
r(s, t) : ρ
We identify natural numbers n with the respective numerals S . . .S︸ ︷︷ ︸
n times
0.
7.2. Inductive characterization and normal forms. Once more we extend the notion of elimination
to capture N-recursion:
R, S ::= r | (r, s).
With this notation we can characterize terms by
T 3 r, s ::= x~R | λxr | 0 | Sr | 0(r, s)~S | (Sr)(s, t)~S | (λxr)s~S
and normal forms by
NF 3 r, s ::= x~R | λxr | 0 | Sr with R ::= r | (r, s).
35In combinatory versions of T the latter restriction is quite common [San67, Sch77].
18
7.3. Reduction. Additional conversion rules are
0(r, s)→ r (Sr)(s, t)→ tr(r(s, t)).
The compatible closure → is defined as expected:
r → r′ =⇒ t(r, s)→ t(r′, s), t(s, r)→ t(s, r′), rR→ r′R,Sr → Sr′, λxr → λxr′.
7.4. Definition. (r, s) ∈ SN is an abbreviation for r ∈ SN and s ∈ SN.
(0)
0 ∈ SN
r ∈ SN (S)
Sr ∈ SN
r ∈ SN (λ)
λxr ∈ SN
and for recursion
r~S ∈ SN s ∈ SN (R0)
0(r, s)~S ∈ SN
tr(r(s, t))~S ∈ SN
(RS)
(Sr)(s, t)~S ∈ SN
The rules (Var) and (β) now allow for N–eliminations.
~R ∈ SN (Var)
x~R ∈ SN
rx[s]~S ∈ SN s ∈ SN (β)
(λxr)s~S ∈ SN
Lemma. SN = WF→.
Proof. Parallel to the proofs in section 3, except for the rule (RS) in the proof of “⊆” where
induction on tr(r(s, t))~S ∈WF→+ is needed, because t and r occur twice in this term. Qed
Corollary. SN is closed under the subterm relation.
7.5. The set Ω. We cannot (hope to) extend the simple proof of closure under substitution for
SN for typed terms due to the variable rule. Therefore we investigate a subset of SN, termed Ω,
for which we can show this property.
Definition. The set Ω is generated by the same rules as SN, where (Var) and (RS) are restricted
~r ∈ Ω (Var)
x~r ∈ Ω
tn(n(s, t))~T ∈ Ω
(RS)
(Sn)(s, t)~T ∈ Ω
and the following infinitary ω-rule is added.
r ∈ Ω · · · n(s, t)~T ∈ Ω · · ·n∈N (ω)
r(s, t)~T ∈ Ω
Remark. N-eliminations of a variable can only enter Ω through the ω-rule.36
Lemma. r ∈ Ω, sρ ∈ Ω =⇒ (i) rs ∈ Ω, (ii) rx[s] ∈ Ω.
Proof. We use simultaneous induction on ρ and side induction on the generation of r ∈ Ω. We
only cover the new cases. (0) is trivial. (S), (R0) and (RS) follow directly from the side induction
hypotheses. So consider the rule (ω), where r(t0, t1)~T ∈ Ω is inferred from r ∈ Ω and infinitely
many assumptions rn := n(t0, t1)~T ∈ Ω.
(i) The side induction hypothesis shows rns ∈ Ω for each n ∈ N. Hence we may apply rule (ω)
in order to obtain r(t0, t1)~Ts ∈ SN.
(ii) The side induction hypothesis yields rx[s] ∈ Ω and ∀n.rn[x := s] ∈ Ω. Thus one application
of the rule (ω) proves (r(t0, t1)~T )x[s] ∈ Ω. Qed
36Thus in the untyped calculus the term x(λz.zz, y)(λz.zz) would be in SN \ Ω.
19
Corollary. r ∈ Ω.
Proof by induction on r. The interesting new case is an N-elimination (where we use the ω-rule):
Let r : N, s : ρ, t : N → ρ → ρ be in Ω. In order to conclude r(s, t) ∈ Ω it suffices to show
∀n.n(s, t) ∈ Ω. This is done by side induction on n.
Case 0. 0(s, t) ∈ Ω is inferred from s, t ∈ Ω by the rule (R0).
Case n+1. By the side induction hypothesis for n we have n(s, t) ∈ Ω. Two applications of lemma
(i) yield tn(n(s, t)) ∈ Ω, to which the rule (RS) applies. Qed
7.6. Injecting Ω into SN. The rules of Ω are restrictions of SN–rules, except for (ω) which is a
weakened version of the following rule of value expansion
r ∈ SN |r|(s, t)~S ∈ SN
(∗)
r(s, t)~S ∈ SN
where |r| is defined recursively for rN ∈ SN by
|x~R| := 0,
|0| := 0,
|Sr| := S|r|,
|(λxr)s~S| := |rx[s]~S|,
|0(r, s)~S| := |r~S|,
|(Sr)(s, t)~S| := |tr(r(s, t))~S|.
Therefore Ω can be embedded into SN extended by rule (∗). The following lemma shows that (∗)
is already admissible in SN, hence Ω ⊂ SN.
Lemma. (Value expansion). ~s N ∈ SN, r[~x := |~s |] ∈ SN =⇒ r[~x := ~s ] ∈ SN.
Proof. We abbreviate r~t := r~x[~t ] and set ~n := |~s |. The assertion is proved by induction on the
generation of r~n ∈ SN.
Case (S). Assume r~n = St ∈ SN has been concluded from t ∈ SN. If r = xk then t is a numeral
and r~s = x~sk = sk, so the claim is trivial. Otherwise r = St0 with t~n0 = t and the induction
hypothesis shows t~s0 ∈ SN, hence also St~s0 ∈ SN.
Case (0). Analogous, but simpler.
Case (Var). r~n = x~R ∈ SN has been concluded from ~R ∈ SN. x cannot be in ~x and we only need
to use the induction hypothesis for ~R.
Case (R0). Assume r~n = 0(r′0, r
′
1)~R
′ ∈ SN has been concluded from r′0 ~R′, r′1 ∈ SN. Now if
r = 0(r0, r1)~R then the claim follows easily from the induction hypothesis for r′0 ~R
′, r′1.
Otherwise r = xk(r0, r1)~R, nk = 0 and we have to show
sk(r~s0, r
~s
1)~R
~s ∈ SN.
We derive this as an instance of
∀sˆN ∈ SN.|sˆ| = 0 =⇒ sˆ(r~s0, r~s1)~R~s ∈ SN,
which is proved by side induction on sˆ ∈ SN. Since sˆ : N and |sˆ| = 0, the cases (S) and (λ)
cannot occur. Furthermore, all reduction steps (rules (R0), (RS), (β)) are easily reverted, so
we only consider the following two cases.
20
Case 0. This case is identical to the one where r = 0(r0, r1)~R.
Case x~S. We need x~S(r~s0, r
~s
1)~R
~s ∈ SN, which amounts to r~s0, ~R~s ∈ SN and r~s1 ∈ SN. The
latter follows from the main induction hypothesis for r~n1 = r
′
1. The other terms are
in SN since r~s0 ~R
~s ∈ SN by the main induction hypothesis (applied to r′0 ~R′) and SN is
closed under the subterm relation.
Case (RS). Suppose r~n = (Sr′)(s′, t′)~R′ ∈ SN comes from t′r′(r′(s′, t′))~R′ ∈ SN. Now if r =
(Sr′′)(s, t)~R then the claim follows easily from the induction hypothesis. Otherwise r =
xk(s, t)~R, nk is the successor of — say — m and we need to show
sk(s~s, t~s)~R~s ∈ SN.
Similar to the case (R0) we show the more general statement
∀sˆN.|sˆ| = Sm =⇒ sˆ(s~s, t~s)~R~s ∈ SN
by side induction on sˆ ∈ SN. Since |sˆ| = Sm, the variable cases and 0 can be excluded. All
reduction cases are easily handled by the side induction hypothesis. So we are left with the
case (S) where sˆ = S sˆ′ and |sˆ′| = m. It suffices to show
t~ssˆ′(sˆ′(s~s, t~s))~R~s ∈ SN.
This term can be expressed as r∗~x,x[~s, sˆ
′] with r∗ = tx(x(s, t))~R and a new variable x. More-
over,
r∗~x,x[~n,m] = t
′r′(r′(s′, t′))~R′,
so we can use the main induction hypothesis for that term to prove the claim.
The cases (λ) and (β) are simple applications of the induction hypothesis. Qed
Corollary. r ⇓.
References
[AJ01] Klaus Aehlig and Felix Joachimski. Operational aspects of normalization by evaluation. Sub-
mitted, 2001.
[Alt93] Thorsten Altenkirch. A formalization of the strong normalization proof for system F in LEGO.
In Bezem and Groote [BG93], pages 13–28.
[Bar84] Henk P. Barendregt. The Lambda Calculus: Its Syntax and Semantics. North–Holland, Ams-
terdam, second revised edition, 1984.
[Ber93] Ulrich Berger. Program extraction from normalization proofs. In Bezem and Groote [BG93],
pages 91–106.
[BG93] Marc Bezem and Jan F. Groote, editors. Typed Lambda Calculi and Applications, volume 664
of Lecture Notes in Computer Science. Springer Verlag, 1993.
[Dav95] Rene´ David. Une preuve simple de re´sultats classiques en λ calcul. C.R. Acad. Sci. Paris, t.
320, Se´rie I:1401–1406, 1995.
[Dav01] Rene´ David. Normalization without reducibility. Annals of Pure and Applied Logic, 107(1–
3):121–130, 2001.
[dG99] Philippe de Groote. On the strong normalisation of natural deduction with permutation-
conversions. In Paliath Narendran and Michae¨l Rusinowitch, editors, Rewriting Techniques
and Applications, 10th International Conference, RTA-99, Trento, Italy, July 2-4, 1999, Pro-
ceedings, volume 1631 of Lecture Notes in Computer Science, pages 45–59. Springer Verlag,
1999.
21
[Dil68] Justus Diller. Zur Berechenbarkeit primitiv-rekursiver Funktionale endlicher Typen. In Kurt
Schu¨tte, editor, Contributions to Mathematical Logic, pages 109–120. North–Holland, Ams-
terdam, 1968.
[Gan80] Robin O. Gandy. An early proof of normalization. In J.P. Seldin and J.R. Hindley, editors, To
H.B. Curry: Essays on Combinatory Logic, Lambda Calculus and Formalism, pages 453–455.
Academic Press, 1980.
[GLT89] Jean-Yves Girard, Yves Lafont, and Paul Taylor. Proofs and Types, volume 7 of Cambridge
Tracts in Theoretical Computer Science. Cambridge University Press, 1989.
[Go¨d58] Kurt Go¨del. U¨ber eine bisher noch nicht benu¨tzte Erweiterung des finiten Standpunkts.
Dialectica, 12:280–287, 1958.
[Gog94] Healfdene Goguen. A Typed Operational Semantics for Type Theory. PhD thesis, University
of Edinburgh, August 1994. Available as LFCS Report ECS-LFCS-94-304.
[Gog95] Healfdene Goguen. Typed operational semantics. In Mariangiola Dezani-Ciancaglini and
Gordon Plotkin, editors, Typed Lambda Calculi and Applications, volume 902 of Lecture Notes
in Computer Science, pages 186–200. Springer Verlag, 1995.
[Gog99] Healfdene Goguen. Soundness of the logical framework for its typed operational semantics. In
Jean-Yves Girard, editor, Typed Lambda Calculi and Applications, 4th International Confer-
ence, TLCA’99, L’Aquila, Italy, April 7-9, 1999, Proceedings, volume 1581 of Lecture Notes
in Computer Science, pages 177–197. Springer Verlag, 1999.
[Hin97] J. Roger Hindley. Basic Simple Type Theory, volume 42 of Cambridge Tracts in Theoretical
Computer Science. Cambridge University Press, 1997.
[How80] W.A. Howard. Ordinal analysis of terms of finite type. The Journal of Symbolic Logic,
45(3):493–504, 1980.
[Joa01] Felix Joachimski. Reduction Properties of ΠIE-Systems. PhD thesis, LMU Mu¨nchen, 2001.
[Lei75] Daniel Leivant. Strong normalization for arithmetic (variations on a theme of Prawitz). In
J. Diller and G.H. Mu¨ller, editors, Proof Theory Symposion Kiel 1974, volume 500 of Lecture
Notes in Mathematics, pages 182–197. Springer Verlag, 1975.
[Mat98] Ralph Matthes. Extensions of System F by Iteration and Primitive Recursion on Monotone
Inductive Types. Dissertation (PhD thesis), Universita¨t Mu¨nchen, 1998.
[Mat00] Ralph Matthes. Characterizing strongly normalizing terms for a lambda calculus with gen-
eralized applications via intersection types. In Jose´ D. P. Rolim, Andrei Z. Broder, Andrea
Corradini, Roberto Gorrieri, Reiko Heckel, Juraj Hromkovic, Ugo Vaccaro, and Joe B. Wells,
editors, ICALP Workshops 2000, Proceedings of the Satellite Workshops of the 27th Interna-
tional Colloquium on Automata, Languages, and Programming, Geneva, Switzerland, volume 8
of Proceedings in Informatics, pages 339–353. Carleton Scientific, 2000.
[Pra71] Dag Prawitz. Ideas and results in proof theory. In Jens E. Fenstad, editor, Proceedings of the
Second Scandianvian Logic Symposium, pages 235–307. North–Holland, Amsterdam, 1971.
[San67] Luis Elpidio Sanchis. Functionals defined by recursion. Notre Dame Journal of Formal Logic,
VIII(3):161–174, 1967.
[Sch77] Kurt Schu¨tte. Proof Theory. Springer-Verlag, Berlin, 1977.
[Sch93] Helmut Schwichtenberg. Proofs as programs. In P. Aczel, H. Simmons, and S.S. Wainer,
editors, Proof Theory. A selection of papers from the Leeds Proof Theory Programme 1990,
pages 81–113. Cambridge University Press, 1993.
[Sch99] Helmut Schwichtenberg. Termination of permutative conversions in intuitionistic Gentzen
calculi. Theoretical Computer Science, 212(1–2):247–260, 1999.
[Tai67] William W. Tait. Intensional interpretations of functionals of finite type I. The Journal of
Symbolic Logic, 32(2):198–212, 1967.
[Tai75] William W. Tait. A realizability interpretation of the theory of species. In R. Parikh, editor,
Logic Colloquium Boston 1971/72, volume 453 of Lecture Notes in Mathematics, pages 240–
251. Springer Verlag, 1975.
[Tro73] Anne S. Troelstra (editor). Metamathematical Investigation of Intuitionistic Arithmetic and
Analysis, volume 344 of Lecture Notes in Mathematics. Springer Verlag, Berlin, Heidelberg,
New York, 1973.
22
[vdP96] Jaco van de Pol. Termination of higher-order rewrite systems. Quaestiones Infinitae XVI,
Department of Philosophy, Utrecht University, 1996. Proefschrift (PhD thesis).
[vP01] Jan von Plato. Natural deduction with general elimination rules. Annals of Mathematical
Logic, 40(7):541–567, 2001.
[vR96] Femke van Raamsdonk. Confluence and Normalisation for Higher-Order Rewriting.
Academisch Proefschrift (PhD thesis), Vrije Universiteit te Amsterdam, 1996.
[vRS95] Femke van Raamsdonk and Paula Severi. On normalisation. Technical Report CS-R9545,
Centrum voor Wiskunde en Informatica (CWI), Amsterdam, June 1995. Forms a part of
[vR96].
[vRSSX99] Femke van Raamsdonk, Paula Severi, Morten Heine B. Sørensen, and Hongwei Xi. Perpetual
reductions in λ-calculus. Information and Computation, 149(2):173–225, 1999.
[Wei97] Andreas Weiermann. A proof of strongly uniform termination for Go¨del’s T by methods from
local predicativity. Archive for Mathematical Logic, 36:445–460, 1997.
23
