Term Rewriting Systems
J. W. Klop1
Contents
1 Abstract Reduction Systems : : : : : : : : : : : : : : : : : : : : : 3 1.1 Basic notions : : : : : : : : : : : : : : : : : : : : : : : : : : 11 1.2 Disjoint sums of Term Rewriting Systems : : : : : : : : : : 18 1.3 A termination proof technique : : : : : : : : : : : : : : : : 28 1.4 Completion of equational speci cations : : : : : : : : : : : : 39 1.5 An abstract formulation of completion : : : : : : : : : : : : 54 1.6 Uni cation : : : : : : : : : : : : : : : : : : : : : : : : : : : 61
2 Orthogonal Term Rewriting Systems : : : : : : : : : : : : : : : : 68 2.1 Basic theory of orthogonal TRS's : : : : : : : : : : : : : : : 69 2.2 Reduction strategies for orthogonal TRS's : : : : : : : : : : 76 2.3 Sequential orthogonal Term Rewriting Systems : : : : : : : 84
3 Conditional Term Rewriting Systems : : : : : : : : : : : : : : : : 98 4 References : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 107
Abstract
Term Rewriting Systems play an important role in various areas, such as abstract data type speci cations, implementations of functional programming languages and automated deduction. In this chapter we introduce several of the basic concepts and facts for TRS's. Speci cally, we discuss Abstract Reduction Systems; general Term Rewriting Systems including an account of Knuth-Bendix completion and (E-)uni cation; orthogonal TRS's and reduction strategies; strongly sequential orthogonal TRS's. The paper concludes with a discussion of conditional term rewriting systems. The emphasis throughout the chapter is on providing information of a syntactic nature.
1Research partially supported by ESPRIT project 432: Meteor (until Sept. 1989) and ESPRIT BRA projects 3020: Integration and 3074: Semagraph (since July 1989).
1

2 J. W. Klop
Introduction
The concept of a Term Rewriting System (TRS) is paradigmatic for the study of computational procedures. Already half a century ago, the calculus, probably the most well-known Term Rewriting System, played a crucial role in mathematical logic with respect to formalizing the notion of computability; much later the same TRS gured in the fundamental work of Scott, Plotkin and others leading to a break-through in the denotational semantics of programming languages. More recently, the related system of Combinatory Logic was shown to be a very fruitful tool for the implementation of functional languages. Even more recently another related family of TRS's, that of Categorical Combinatory Logic, has emerged, yielding a remarkable connection between concepts from category theory and elementary steps in machine computations.
Term rewriting systems are attractive because of their simple syntax and semantics|at least those TRS's that do not involve bound variables such as -calculus, but involve the rewriting of terms from a rst order language. This simplicity facilitates a satisfactory mathematical analysis. On the other hand they provide a natural medium for implementing computations, and in principle even for parallel computations. This feature makes TRS's interesting for the design of parallel reduction machines.
Another eld where TRS's play a fundamental role concerns the analysis and implementation of abstract data type speci cations (consistency properties, computability theory, decidability of word problems, theorem proving).
The aim of the present paper is to give an introduction to several key concepts in the theory of term rewriting, providing where possible some of the details. At various places some `exercises' are included. These contain additional information for which proofs are relatively easy; they are not primarily meant to have an educational purpose, if only because the distribution of the exercises is not very uniform.
The present introduction starts at a level of `rewriting' which is as abstract as possible and proceeds by considering term rewriting systems which have ever more `structure'. Thus we start with Abstract Reduction Systems, which are no more than sets equipped with some binary (`rewrite') relations. A number of basic properties and facts can already be stated on this level.
Subsequently, the abstract reductions are specialized to reductions (rewritings) of terms. For such general Term Rewriting Systems a key issue is to prove the termination property; we present one of the major and most powerful termination proof methods, recursive path orderings, in a new formulation designed to facilitate human understanding (rather than practical

Term Rewriting Systems

3

implementation). Proving termination is of great importance in the area of Knuth-Bendix completions. Here one is concerned, given an equational speci cation, to construct a TRS which is both con uent and terminating and which proves the same equations as the original speci cation. If the construction is successful, it yields a positive solution to the validity problem of the original equational speci cation. (Nowadays there are also several other applications of Knuth-Bendix-like completion methods, such as `inductionless induction' and `computing with equations'. For a survey of such applications we refer to Dershowitz & Jouannaud 90].)
Also in Chapter 1, we explain the basic ideas of Knuth-Bendix completion together with an interesting recent `abstract' approach of Bachmair, Dershowitz & Hsiang 86] to prove the correctness of Knuth-Bendix completion algorithms. We also present an elegant uni cation algorithm, and likewise for `E-uni cation'.
In Chapter 2 we impose more `structure' on TRS's, in the form of an `orthogonality' requirement (non-ambiguity and left-linearity). For such orthogonal TRS's a sizeable amount of theory has been developed, both syntactically and semantically. Here we will almost exclusively be concerned with the syntactical aspects; for semantical aspects we refer to Boudol 85], Berry & Levy 79], Guessarian 81]. Basic theorems (con uence, the Parallel Moves Lemma, Church's theorem, O'Donnell's theorem) are presented, where possible with some proof sketch. Also in this section we survey the most important facts concerning reduction strategies for orthogonal TRS's, strategies aiming at nding normal forms whenever possible. Chapter 2 concludes with an explanation of the beautiful theory of Huet & Levy 79] of (strongly) sequential TRS's. Such TRS's possess a `good' reduction strategy.
In the nal chapter (3) we consider TRS's with conditional rewrite rules. Some important topics have not found their way into this introduction. Most notable are: rewriting modulo a set of equations, proof-by-consistency procedures, and graph rewriting. For information about the rst two we refer to Bachmair 88] and Dershowitz & Jouannaud 90], for graph rewriting one may consult Barendregt e.a. 87]. This chapter is an extension of the short survey/tutorial Klop 87]; also most of the material in Klop 85] is included here.

1 Abstract Reduction Systems
Many of the basic de nitions for and properties of TRS's (Term Rewriting Systems) can be stated more abstractly, viz. for sets equipped with one or more binary relations. As it is instructive to see which de nitions and properties depend on the term structure and which are more basic, we start

4 J. W. Klop

with a section about Abstract Reduction Systems. Moreover, the concepts and properties of Abstract Reduction Systems also apply to other rewrite systems than TRS's, such as string rewrite systems (Thue systems), tree rewrite systems, graph grammars. First we present a sequence of simple de nitions.

De nition 1.0.1.

1.

An Abstract Reduction System (ARS) is a consisting of a set A and a sequence of

sbtirnuacrtyurreeAlat=ionhAs ;!(!

) on

2AI,i

also called reduction or rewrite relations. Sometimes we will refer to

! as . In the case of just one reduction relation, we also use !

without more. (An ARS with just one reduction relation is called

`replacement system' in Staples 75], and a `transformation system'
in Jantzen 88].) If for a; b 2 A we have (a; b) 2 ! , we write a ! b
and call b a one-step ( -)reduct of a.

2. The transitive re exive closure of ! is written as . (More cus-

tomary is the notation ! , but we prefer the double arrow notation

as we nd it more convenient in diagrams.) So a b if there is a

possibly
!

empty, an b.

nite sequence of `reduction Here denotes identity

sotfepesl'ema entas0

o!f A.a1

!
The

element b is called an ( -)reduct of a. The equivalence relation gen-

erated by ! is = , also called the convertibility relation generated

!by

!
is

. The re exive closure of ! !+. The converse relation

ofis!!

. is

The

otrra!ns?it1iv. eTchloesuurneioonf

! ! is denoted by ! : The composition ! ! is de ned

by: a ! ! b if a ! c ! b for some c 2 A:

3. If ; are reduction relations on A, we say that commutes weakly

with if the diagram of Figure 1.1a holds, i.e. if 8a; b; c 2 A 9d 2

A (c a ! b ) c d b), or in a shorter notation:

! : Further, commutes with if and

commute weakly. (This Dershowitz 86], where

terminology commutes

di ers with

firfom?1that

of

B?ac1hma:i)r

&

4. The reduction relation ! is called weakly con uent or weakly Church-
Rosser (WCR) if it is weakly self-commuting (see Figure 1.1b), i.e. if
8a; b; c 2 A 9d 2 A (c a ! b ) c d b): (The property WCR

is also often called `local con uence', e.g. in Jantzen 88].)

5. ! is subcommutative (notation WCR 1) if the diagram in Figure 1.1c holds, i.e. if 8a; b; c 2 A 9d 2 A (c a ! b ) c ! d b):

6. ! is con uent or is Church-Rosser, has the Church-Rosser property (CR) if it is self-commuting (see Figure 1.1d), i.e. 8a; b; c 2 A 9d 2 A (c a b ) c d b): Sometimes (6) is called `con uent' and

the situation as in Proposition 1.0.2(6) `Church-Rosser'.

Term Rewriting Systems
Proposition 1.0.2. The following are equivalent: 1. ! is con uent
2. is weakly con uent 3. is self-commuting 4. is subcommutative 5. the diagram in Figure 1.1e holds, i.e.

5

8a; b; c 2 A 9d 2 A (c a b ) c d b)

6. 8a; b 2 A 9c 2 A (a = b ) a c b) (Here `=' is the convertibility relation generated by !. See diagram in Figure 1.1f.)

Figure 1.1
De nition 1.0.3. Let A = hA; !i be an ARS. 1. We say that a 2 A is a normal form if there is no b 2 A such that
a ! b. Further, b 2 A has a normal form if b a for some normal form a 2 A: 2. The reduction relation ! is weakly normalizing (WN) if every a 2 A has a normal form. In this case we also say that A is WN.

6 J. W. Klop

3. A (or !) is strongly normalizing (SN) if every reduction sequence

a0 ! a1 ! eventually must terminate. (Other terminology: ! is

terminating, or noetherian.)
SN, we say that A (or !) is

SIfNt?h1e.

converse

reduction

relation

is

4. A (or !) has the unique normal form property (UN) if 8a; b 2 A(a = b

& a; b are normal forms ) a b).

5. A (or !) has the normal form property (NF) if 8a; b 2 A(a is normal

form & a = b ) b a):

6. A (or !) is inductive (Ind) if for every reduction sequence (possibly in nite) a0 ! a1 ! there is an a 2 A such that an a for all n.

7. A (or !) is increasing (Inc) if there is a map j j: A ! N such that 8a; b 2 A (a ! b ) j a j < j b j). Here N is the set of natural numbers

with the usual ordering < :

8. A (or !) is nitely branching (FB) if for all a 2 A the set of one

step reducts of a, relation is FB,

fb 2 A
we say

j a ! bg, is that A (or

nite.
!) is

FIfBt?h1e.c(oInnveHrsueetred80u]c,tiFoBn

is called `locally nite'.)

Er)exspbeercct cits)o.erSe1hd.ou0wc.t4ito.hna(tDUUeNN!ne)): ifAU8Na(o;!rb;,!cb2u) thAna(soatthceonubvn&eirqsaueely.nocr&mabl;

form
c are

property with normal forms

An ARS which is con uent and terminating (CR & SN) is also called complete (other terminology: `canonical' or `uniquely terminating').
Before exhibiting several facts about all these notions, let us rst introduce some more concepts.

De nition 1.0.5. Let A = hA; ! i and B = hB; ! i be two ARS's. Then A is a sub-ARS of B, notation A B, if:
1. A B
2. is the restriction of to A, i.e. 8a; a0 2 A (a ! a0 , a ! a0) 3. A is closed under , i.e. 8a 2 A (a ! b ) b 2 A): The ARS B is also called an extension of A.
Note that all properties introduced so far (CR, WCR, WCR 1, WN,
SN, UN, NF, Ind, Inc, FB) are preserved downwards: e.g. if A B and B is CR, then also A is so.
Of particular interest is the sub-ARS determined by an element a in an ARS.

De nition 1.0.6. Let A = hA; !i be an ARS, and a 2 A. Then G(a), the reduction graph of a, is the smallest sub-ARS of A containing a. So G(a) has as elements all reducts of a (including a itself) and is structured

Term Rewriting Systems

7

by the relation ! restricted to this set of reducts.

We will now collect in one theorem several implications between the various properties of ARS's. The rst part (1) is actually the main motivation for the concept of con uence: it guarantees unique normal forms, which is of course a desirable state of a airs in (implementations of) algebraic
data type speci cations. Apart from the fundamental implication CR )
UN, the most important fact is (2), also known as Newman's Lemma. The property CP (`co nality property') is de ned in Exercise 1.0.8(13) below.

Theorem 1.0.7. 1. CR ) NF ) UN 2. SN & WCR ) CR (Newman's Lemma) 3. UN & WN ) CR 4. UN & WN ) Ind 5. Ind & Inc ) SN 6. WCR & WN & Inc ) SN 7. CR , CP for countable ARS's.

Most of the proofs of (1)-(7) are easy. For Newman's Lemma a short

proof is given in Huet 80]; an alternative proof, illustrating the notion of

`proof ordering', is given in Section 1.5 (Exercise 1.5.4). Proposition (5)

is from Nederpelt 73]; (6) is proved in Klop 80a]; for (7) see Exercise

1.0.8(13) below. The propositions in the statement of the theorem (and

some more|for these see Exercises 1.0.8) are displayed also in Figure 1.2;

here it is important whether an implication arrow points to the conjunction

sign &, or to one of the conjuncts. Likewise

FarBro?w1&. (SEN.g?.1U)N

I&ncW, CNR))InUdN,

SN but

& WCR not CR

for
) )

the UN UN

t&aiWl oNf a, nInicm)pliScaNt?io1n,
& WN.)

It does not seem possible to reverse any of the arrows in this diagram

of implications. An instructive counterexample to WCR ) CR is the TRS

in Figure 1.3 (given by R. Hindley, see also Huet 80]).

There are several other facts about ARS's which often are very helpful

e.g. in proving properties of algebraic data type speci cations. We present

them in the form of the following series of Exercises 1.0.8. For an under-

standing of the sequel these additional facts are not necessary. Some proofs

require the notion of `multiset ordering', explained in Exercise 1.3.15.

Exercises 1.0.8.

1.

(cRomosmenuta7t3i]v)e,IfthhAen; !!12;

!2i is
is con

an ARS uent.

such

that

1= 2 and !1 is sub-

2.

(cHominmdluetyes6w4]i)thLe!t

hA;(! ) 2Ii be
. (In particular,

a!n

ARS such that for all ; commutes with itself.)

2 I;!
Then the

8 J. W. Klop

Figure 1.2

Figure 1.3

union ! = U 2I ! is con uent. (This proposition is sometimes referred
to as the Lemma of Hindley-Rosen; see e.g. Barendregt 81], Proposition

3.3.5.)

3.

(A!H1(ina; !d!le2y1cob6m4&m])uaLtee!.t 2hAc;)!1b;

!2i
2

be an d&c

ARS. Suppose: 8a; b; c 2 A !1 d). (See Figure 1.4a.)

9d 2
Then

4.

(Staples 75]) Let
A!1(a; !!21cobm&muate.

hA;
2c

!)1;b!2i2

be d

an &c

ARS. Suppose: 8a; b; c 2 A
1 d). (See Figure 1.4b.)

9d 2
Then

Term Rewriting Systems

9

5. (iFtfRhi8geonuasr;e!ebn;11c72.243ic]s)A.)cL9oTendto; ehupAe2rn;ot!Av.e(1:a; !if 2!1i 1bb;e&!aa2n aAreR2 Scco.)nDEbuFenINt2IadTnI&dOicNf :!!11 1ererqequ2ueedsts)st:s(!S!e2e2,

6.

8(Ra;obs;ecn
Figure

21.74A3d].)9)dLT;eehte2hnAA!;!(1a1r;e!q1u2ebis&tbsea!a!n2 :2AcR)S

such b

that 2d&

!2
c

is
1

con e

uent 2 d).

and (See

7. (a!iSt29acpi1slaeccso)n71b5uc]!)enL3te.2dtbL&h.eAtSc;u!!!pp313;ob!dsee).2tmiThobehreecenooavmn!eprA1o2tRshiiStasitoscnu8ocnaoh;fbut;hecna1t2t.a!An1d9dre2q2u,Aesi.(teas. !a 21!ab3n&db

8. (aml8AaSatert9;ienaobctpn;n2lcoee!s2fmA!2Ae7(n5ai19ts])d:ocDf2aL2l!EelAetbFd1()iI.naNaP!ItarThreo2eIvOnbeA1eN&Rmtc:hSebaI&nnthtAb!to1h;f2!ec!)i1A1s;1cRa!)ci,Sfc2toi!hhmA1et1nph;d!ae!&tir1be2;al2d!e.ius2rcIaeti1fiodctnmnho)e:meomrreperelaeonadtvttieuiboroclneft8iro!a!en;1b2nrbiee2e--

9.

(Staples nement

o7f5]!) 1L.etThhAen;:!!1;1!is2icobne

uaenntARi S!w2heisreco!n 2uiesnta.

compatible

re-

10. (Huet 80]) DEFINITION: Let hA; !i be an ARS. Then ! is called strongly

con uent (see Figure 1.4e) if 8a; b; c 2 A 9d 2 A (a ! b & a ! c ) b d & c ! d). Prove that strong con uence implies con uence.

11.

Let hA; (!
weakly with

)!2Ii.

be an ARS such that
DEFINITION: (a) !

for is

all ; 2
relatively

I;! commutes
terminating if no

rmfoerdanueycvteiro?ynsdtae02p!sA. (aba1n)d!!evae2hray!s s:p:2li:tt(Iiwnwhgeietrheea!ct!=if

U 2I there
b; a

!
are
!

) contains in nitely
a; b; c; 2 A such that
c; c d;b d,

the reduction b d consists of more than one step. To prove: if every

! ( 2 I) which has splitting e ect is relatively terminating, then ! is

con uent. (Note that this is equivalent to Newman's Lemma.)

12. (Winkler & Buchberger 83]) Let hA; !; >i be an ARS where the `reduc-

tion' pose

arel!atiobn

> is a implies

partial a > b.

order and SN. (So > Then the following

aisreweeqllu-fiovuanlednetd: .)(aS)u!p-

is con uent, (b) whenever a ! b and a ! c, there is a !-conversion

b a

>

ddi1

($i =d21;

$
:::

: ;

:n:).$Hedrne

c (for
each $

some n
is ! or

1) between b; c such that . (See Figure 1.4f.) (Note

that this strengthens Newman's Lemma.)

13. (Klop 80a]) Let A = hA; !i be an ARS. Let B A. Then B is co nal in

A if 8a 2 A 9b 2 B a b. Furthermore, A is said to have the co nality

property (CP) if in every reduction graph G(a); a 2 A, there is a (possibly

in co

nniatle)inreGd(uac)t.ioTnhesenq,ufeonrcceouantabal0e

!ARaS1's!: A:

:: is

such that
CR , A

fan j n
has CP.

0g is

14. Let A = hA;!i be an ARS. De ne: A is consistent if not every pair of elements in A is convertible. Note that if A is con uent and has two di erent normal forms, A is consistent. Further, let A = hA; ! i; B =

10 J. W. Klop

Figure 1.4

ehBxt;e!nsioinboef AARiSf '8s as;uac0h2thAa(taA=

aB0 .,Tahe=n

wae0

de ne: ). Note

B is
that

a a

conservative conservative

extension con uent

eoxfteanscioonnsiBsteonftAAiRs Sconisseargvaaitnivceo. nsistent.

Further, note

that

a

15. (Newman 42]) Let WCR1 be the following property of ARS's hA; !i : 8a; b; c 2 A 9d 2 A (c a ! b & b 6 c ) c ! d b). (See Figure 1.5a.) Prove that WCR1 & WN ) SN, and give a counterexample to the implication WCR 1 & WN ) SN.

16. (Bachmair & Dershowitz 86]) Let hA; ! ; ! i be an ARS such that 8a; b; c 2 A 9d 2 A (a ! b ! c ) a ! d c). (In the termi-

nology of Bachmair & Dershowitz 86]: quasi-commutes over .) (See

Figure 1.5b.) Prove that = is SN i is SN. (For the de nition of = ,

see Exercise 1.0.8(19) below.)

17. (Klop 80a]) Let A = hA; ! i and B = hB; ! i be ARS's. Let : A ! B and : B ! A be maps such that

(a) (b)

8a(;(aa0))2=Aa8fbor2allBa92b0A2; B (b !

a!

a0 ) b !

b0 !

a0)

(Reductions in A can be `lifted' to B.) See Figure 1.5c.

Prove that B is SN implies that A is SN.

18. (Geser 90]) Let hA; ! ; ! i be an ARS with two reduction relations ; such that is transitive. Then: is SN , is SN and is SN.

(Hint: use the following in nite version of Ramsey's Theorem, in which

faor6=absgetofStwthoe-enleomtaetnitonsubSs]e2tsis

used of S.

to denote the Furthermore,

Nsetisfftah;ebsgetj

a; b 2 S &
of natural

numbers. THEOREM: Let N ]2be partitioned into subsets X and Y. Then

Term Rewriting Systems

11

Figure 1.5

there is an in nite A N such that either A]2 X or A]2 Y .)

19. (Geser 90]) This exercise reformulates and slightly generalizes Exercise

1.0.8(11). Let hA; ! ; ! i be an ARS. DEFINITION: = (\ modulo

a

")

is

tche!redudction

relation b: Note

that

. So a ! = b i there are c; d such that
is relatively terminating (in the sense

of Exercise 1.0.8(11)) i = is SN. DEFINITION: is called nonsplitting

(with respect to ) if 8a; b; c 2 A9d 2 A(a ! b & a ! c ) c

d & b (! ) d): Prove: If = is SN, is WCR, and is non-splitting,

then is con uent.

1.1 Basic notions

Syntax of Term Rewriting Systems

A Term Rewriting System (TRS) is a pair ( ; R) of an alphabet or signature and a set of reduction rules (rewrite rules) R. The alphabet consists

of:

1.

a x;

cyo; uz;nxta0;byly0;

in :::

nite

set

of

variables

x1; x2; x3; : : :

also

denoted

as

2. a non-empty set of function symbols or operator symbols F; G; : : :; each equipped with an `arity' (a natural number), i.e. the number of

`arguments' it is supposed to have. We not only (may) have unary,

binary, ternary, etc., function symbols, but also 0-ary: these are also called constant symbols.

The set of terms (or expressions) `over' is Ter( ) and is de ned induc-

tively:

1. x; y; z; : : : 2 Ter( );

2.

if F then

is F

an (t1;

n-ary function
: : :; tn) 2 Ter(

symbol ). The

and ti (i

=t11; ;:

: :

: :

; :

;tnn)2arTeetrh(e

) (n 0), arguments

of the last term.

Terms not containing a variable are called ground terms (also: closed terms), and Ter0( ) is the set of ground terms. Terms in which no variable occurs twice or more, are called linear.

12 J. W. Klop

Contexts are `terms' containing one occurrence of a special symbol 2, denoting an empty place. A context is generally denoted by C ]. If t 2 Ter( ) and t is substituted in 2 , the result is C t] 2 Ter( ); t is said to be a subterm of C t], notation t C t]. Since 2 is itself a context, the trivial context, we also have t t. Often this notion of subterm is not precise enough, and we have to distinguish occurrences of subterms (or symbols) in a term; it is easy to de ne the notion of occurrence formally, using sequence numbers denoting a `position' in the term, but here we will be satis ed with a more informal treatment.

Example 1.1.1. Let = fA; M; S; 0g where the arities are 2,2,1,0 re-
spectively. Then A(M(x; y); y) is a (non-linear) term, A(M(x; y); z) is a linear term, A(M(S(0); 0); S(0)) is a ground term, A(M(2; 0); S(0)) is a context, S(0) is a subterm of A(M(S(0); 0); S(0)) having two occurrences:
A(M(S(0); 0); S(0)).

A substitution is a map from Ter( ) to Ter( ) which satis es

(h(eFre(t1n;

:

:

:0;)t.n)S)o,=

F( is

d(ett1e)r;m: :in:;ed(btny))itsforresetvreircytionn-atroy

function the set of

symbol F variables.

We also write t instead of (t):
A reduction rule (or rewrite rule) is a pair (t; s) of terms 2 Ter( ). It will be written as t ! s. Often a reduction rule will get a name, e.g. r, and we write r : t ! s. Two conditions will be imposed:

1. the LHS (left-hand side) t is not a variable,

2. the variables in the right-hand side s are already contained in t.

A reduction rule r : t ! s determines a set of rewrites t !r s for all
substitutions . The LHS t is called a redex (from `reducible expression'), more precisely an r-redex. A redex t may be replaced by its `contractum'

s inside a context C ]; this gives rise to reduction steps (or one-step

rewritings)

C t ] !r C s ]:

atrW2ended!ucctatnliloin!sosarrtetrrpheedseduuowccntetieoh-onsfatsvetepf0o,(rrpeinsdohusoascirctbtcio.loynrIdifrnaetnl0ancte!iitoewn)itrgheed!nutehcrtetaintonenwdotesbaeyatqiluosreon.nsCwceaorsnintdtce0actt!0oennacte1tpitn!ntgs,
introduced in Section 1.0.
Example 1.1.2. Consider as in Example 1.1.1. Let ( ; R) be the TRS
(specifying the natural numbers with addition, multiplication, successor and zero) with reduction rules R given in Table 1.1. Now M(S(S(0)); S(S(0))) S(S(S(S(0)))), since we have the following reduction:

Term Rewriting Systems

13

rr21 r3 r4

A(x; 0) A(x; S(y)) M(x; 0) M(x; S(y))

! ! ! !

x S(A(x; y)) 0 A(M(x; y); x)

Table 1.1

M(S(S(0)); S(S(0))) ! A(M(S(S(0)); S(0)); S(S(0))) ! S(A(M(S(S(0)); S(0)); S(0))) ! S(S(A(M(S(S(0)); S(0)); 0))) ! S(S(M(S(S(0)); S(0)))) ! S(S(A(M(S(S(0)); 0); S(S(0))))) ! S(S(A(0; S(S(0))))) ! S(S(S(A(0; S(0))))) ! S(S(S(S(A(0; 0))))) ! S(S(S(S(0)))):

Here in each step the bold-face redex is rewritten. Note that this is not the only reduction from M(S(S(0)); S(S(0))) to S(S(S(S(0)))).

Obviously, for each TRS ( ; R) there is a corresponding ARS, namely

(Ter( ); whether

(o!ner)dri2scRu)s.seHsertehewTe hRaSve(

to ;

be R)

careful: it may make a big di erence consisting of all terms, or the TRS

restricted to the ground terms (see the next example). We will adopt

the convention that ( ; R) has as corresponding ARS the one mentioned

already, and we write ( ; R)0 if the ARS (Ter0( ); (!r)r2R) is meant. Via

the associated ARS, all notions considered in Section 1.0 (CR, UN, SN,

. .. ) carry over to TRS's.

cE(Wnooxmhr;amRemmra0e)ulaptswflaoe(thrimev1r;i.e.tR1yH.R)3o0o0f.iwas=LdeSvdeRNetirt,,i(o((nf;.;AR;RNR()x0o)0b;w)0y0ei)(s(tt!nhh;oeReAlT0or)e(nRsyigstS;ernxiroco)stgftoi;oWE,nsaxoNsatmo:twhtipghetrlneeoeetuxs1ents.rre1dmad.2tArbeuayr(lnmxetd;hsey)ecx)oiipsnhnraesWisnsdsinNeetoser.
reductions possible in the reduction graph in Figure 1.6. The `bottom' term in that reduction graph is a normal form.

Many-sorted Term Rewriting Systems
TRS's ( ; R) as we just have de ned are sometimes called homogeneous (Ganzinger & Giegerich 87]), as they correspond to algebraic data type
speci cations (by replacing `!' by `=' in R) where the signature has

14 J. W. Klop
Figure 1.6 just one sort (which therefore was not mentioned).
It is straightforward to extend our previous de nitions to the heterogeneous or many-sorted case. The de nition of term formation is as usual in many-sorted abstract data type speci cations, and is left to the reader. We will stick to the homogeneous case, but note that `everything' extends at once to the heterogeneous case, at least with respect to the theory in this chapter; of course, the extension to the heterogeneous case presents a whole area of new features and problems (see e.g. Ehrig & Mahr 85], Drosten 89] for a treatment of many-sorted speci cations and rewriting).
Semi-Thue systems
Semi-Thue Systems (STS's), as de ned in Jantzen 88], can be `viewed' in two ways as TRS's. We demonstrate this by the following:
1. Let T = f(aba; bab)g be a one-rule STS. Then T corresponds to the
TRS R with unary function symbols a; b and a constant o, and the
reduction rule a(b(a(x))) ! b(a(b(x))). Now a reduction step in T, e.g.: bbabaaa ! bbbabaa, translates in R to the reduction step b(b(a(b(a(a(a(o))))))) ! b(b(b(a(b(a(a(o))))))). It is easy to see that
this translation gives an `isomorphism' between T and R (or more precisely (R)0, the restriction to ground terms). 2. The second way to let a STS correspond to a TRS is by introducing an associative concatenation operator, and letting the symbols of the STS correspond to constant symbols in the TRS. In fact, a `natural' correspondence in this way requires that we introduce equational TRS's, which we will not do here. (See e.g. Bachmair & Plaisted 85] or Plaisted 85].)

Term Rewriting Systems

15

Applicative Term Rewriting Systems
In some important TRS's there is a very special binary operator, called application (Ap). E.g. Combinatory Logic (CL), based on S; K; I, has the rewrite rules as in Table 1.2. Here S; K; I are constants. Often one uses

Ap(Ap(Ap(S; x); y); z) ! Ap(Ap(x; z); Ap(y; z))

Ap(Ap(K; x); y)

!x

Ap(I; x)

!x

Table 1.2 the in x notation (t s) instead of Ap(t; s), in which case the rewrite rules of CL read as follows:

((S x) y) z ! (x z) (y z) (K x) y ! x Ix ! x

Table 1.3 As in ordinary algebra, the dot is mostly suppressed; and a further notational simpli cation is that many pairs of brackets are dropped in the convention of association to the left. That is, one restores the missing brackets choosing in each step of the restoration the leftmost possibility. Thus the three rules become:

Sxyz Kxy

! !

xz(yz) x

Ix ! x

Table 1.4

Note that xz(yz) restores to (xz)(yz), not to x(z(yz)). Likewise Kxy

restores to (Kx)y, not K(xy). Of course not all bracket pairs can be

dropped: xzyz is when restored ((xz)y)z, which is quite di erent from

xz(yz). Note that e.g. SIx does not contain a redex Ix.

It is a convenient ction to view the S; K; I in the last three equations

as \operators with variable arity" or varyadic operators, since they may

be followed by an needs, in the case

oafrbSi,traatrylenasutmtbherereoaf ragrugmumenetnststot1u;s:e:

:t;hten(rnewrit0e).ruBleutfoirt

16 J. W. Klop
S; e.g.: St1t2t3t4t5t6 ! t1t3(t2t3)t4t5t6: Example 1.1.4. We have SII(SII) ! I(SII)(I(SII)) ! SII(I(SII)) !
SII(SII). The term SII(SII) has many more reductions, which constitute an interesting reduction graph (see Figure 1.7).
Figure 1.7 The TRS CL has `universal computational power': every (partial) recursive function on the natural numbers can be expressed in CL. This feature is used in Turner 79], where CL is used to implement functional programming languages. Actually, an extension of CL is used there, called SKIM (for S,K,I-Machine); it is also an applicative TRS (see Table 1.5). Note that this TRS has in nitely many constants: apart from the constants
S; K; : : :; eq there is a constant n for each n 2 N. There are also in nitely
many reduction rules, because the last four rules are actually rule schemes;
e.g. plus n m ! n + m stands for all reduction rules like plus 0 0 ! 0, plus 0 1 ! 1 ; : : :; plus 37 63 ! 100 ; : : : . In fact, the extra constants
in SKIM are there for reasons of e cient implementation; they can all be de ned using only S and K. E.g. de ning B as S(KS)K we have:
Bxyz S(KS)Kxyz ! KSx(Kx)yz ! S(Kx)yz ! Kxz(yz) ! x(yz)

Term Rewriting Systems

17

Sxyz ! xz(yz)

Kxy ! x

Ix ! x

Cxyz ! xzy

Bxyz Yx

! !

x(yz) x(Y x)

Uz(Pxy) ! zxy

cond true xy ! x

cond false xy ! y

plus n m ! n + m

times n m ! n m

eq n n ! true

eq n m ! false if n 6= m

Table 1.5 as we should have. Likewise, de ning C as S(BBS)(KK), we have Cxyz xzy as the reader may check. For the other de nitions one may consult Barendregt 81] or Hindley & Seldin 86].
It is harmless to mix the applicative notation with the usual one, as in CL with test for syntactical equality in Table 1.6.

Sxyz ! xz(yz)

Kxy Ix

! !

x x

D(x; x) ! E

Table 1.6 However, some care should be taken: consider the TRS in Table 1.7.

Sxyz ! xz(yz) Kxy ! x Ix ! x Dxx ! E

Table 1.7 where D is now a constant (instead of a binary operator) subject to the
rewrite rule, in full notation, Ap(Ap(D; x); x) ! E. These two TRS's have

18 J. W. Klop very di erent properties, as we shall see later (the rst TRS is con uent, the second is not).
Another interesting example of a TRS in such a mixed notation is Weak Categorical Combinatory Logic, which plays an important role in implementations of functional languages (see Curien 86] and Hardin 89]):
Id x ! x (x y)z ! x(yz) Fst (x; y) ! x Snd (x; y) ! y hx; yiz ! (xz; yz) App (x; y) ! xy (x)yz ! x(y; z)
Table 1.8
Here Id, Fst, Snd, App are constants, ; h; i and ( , ) are binary function
symbols and is a unary function symbol. Note that Fst, Snd are not binary symbols and that App is not the `underlying' application operator which was called in CL above Ap.
1.2 Disjoint sums of Term Rewriting Systems
In view of the need for modularisation of abstract data type speci cations, it would be very helpful if some properties of a TRS could be inferred from their validity for `parts' of that TRS. The simplest possible de nition of `parts' is that obtained by the concept of `disjoint sum' of TRS's:
De nition 1.2.1. Let R1; R2 be TRS's. Then the disjoint sum R1 R2
of R1; R2 is the TRS obtained by taking the disjoint union of R1 and R2. hocTotahhnvaesetrtwadinsiis,stjeiosfiywntmhteebatloaaplklsphehainrbaebecntoeastmmsamnoeddfoRncd)oe1,p;tRinhees2enRRart101eh;edRRid02sij2soojiftonoiRtnbt1(eR;sRut1hm2;eRsiuu2snchthihaoevntheooarnftdotithnhfeuaesnrseyectcucioonopnpiioeionessr.;
We have the following useful fact from Toyama 87b]:
Theorem 1.2.2. R1 R2 is con uent i R1 and R2 are con uent.
So, con uence is a `modular' property. One might think that the same is true for termination (SN), but Toyama 87a] gives a simple counterexample:
take R1 = ff(0; 1; x) ! f(x; x; x)g R2 = for(x; y) ! x; or(x; y) ! yg

Term Rewriting Systems

19

rtehdeunctRio1n; R: 2 are both SN, but R1 R2 is not, since there is the in nite

f(or(0; 1); or(0; 1); or(0; 1)) ! f(0; or(0; 1); or(0; 1)) ! f(0; 1; or(0; 1)) ! f(or(0; 1); or(0; 1); or(0; 1)) !

In this counterexample R2 is not con uent and thus one may conjecture that `con uent and terminating' (or CR & SN, or complete) is a modular property (i.e. R1 R2 is complete i R1; R2 are so). Again this is not the case, as a counterexample given by Barendregt and Klop (adapted by Toyama, see Toyama 87a]) shows: R1 has the eleven rules

F(4; 5; 6; x) ! F(x; x; x; x) F(x; y; z; w) ! 7

and R2 has the three rules
G(x; x; y) ! x G(x; y; x) ! x G(y; x; x) ! x:
(Similar counterexamples with the additional property of being `reduced' or `irreducible'|meaning that both sides of every rule are normal forms with respect to the other rules (see De nition 1.4.18 below for a more accurate de nition)|are given in Toyama 87a] and Ganzinger & Giegerich 87].) Now R1 and R2 are both complete, but R1 R2 is not:
F(G(1; 2; 3); G(1; 2; 3); G(1; 2; 3); G(1; 2; 3)) F(G(4; 4; 3); G(5; 2; 5); G(1; 6; 6); G(1; 2; 3))
F( 4; 5; 6; G(1; 2; 3)) !
F(G(1; 2; 3); G(1; 2; 3); G(1; 2; 3); G(1; 2; 3)):
Exercise 1.2.3. A simpler counterexample is given in Drosten 89]. Slightly
adapted it reads:

20 J. W. Klop

R1

F(0; 1; x) F(x;y; z)

! !

F(x;x; x) 2

0 !2

1 !2

and

R2

D(x;y; y) D(x;x; y)

! !

x y:

Now R1; R2 are complete; however, their disjoint sum is not. To see this, consider the term F(M; M; M) where M D(0; 1; 1) and show that F(M; M; M) has a cyclic reduction.

The last counterexamples involve a non-leftlinear TRS. This is essential, as the following theorem indicates. First we de ne this concept:

De nition 1.2.4. 1. A reduction rule t ! s is left-linear if t is a linear term.
2. A TRS is left-linear if all its reduction rules are left-linear.

Theorem 1.2.5. (Toyama, Klop & Barendregt 89]) Let
linear TRS's. Then: R1 R2 is complete i R1 and R2 are

Rco1m; Rp2lebtee.

left-

Some useful information concerning the inference the SN property for R1 and R2 separately is given in

oRfuSsNinofowriRtc1h

8R72a]fraonmd

Middeldorp 89b], in terms of `collapsing' and `duplicating' rewrite rules.

De nition 1.2.6. 1. A rewrite rule t ! s is a collapsing rule (c-rule) if s is a variable. 2. A rewrite rule t ! s is a duplicating rule (d-rule) if some variable has
more occurrences in s than it has in t.

Example 1.2.7. F(x; x) ! G(x; x) is not a d-rule, but F(x; x) ! H(x; x; x) is. Also P(x) ! G(x; x) is a d-rule.

Theorem 1.2.8. Let R1 and R2 be TRS's both with the property SN.

1. If neither R1 nor R2 contain c-rules, R1 R2 is SN.

2. If neither R1 nor R2 contain d-rules, R1 R2 is SN.

3.

If one SN.

of

the

TRS's

R1;

R2

contains

neither

c-

nor

d-rules,

R1

R2 is

Statements (1) and (2) are proved in Rusinowitch 87a]; statement (3) is proved in Middeldorp 89b].

Exercise 1.2.9. Prove that WN is a modular property.

Another useful fact, proved in Middeldorp 89a], is that UN is a modular

Term Rewriting Systems

21

property.

Theorem 1.2.10. R1 R2 is UN i R1 and R2 are so.
The proof of this theorem employs a lemma of independent interest; see the proof sketch in the following exercises.

Exercises 1.2.11. (Middeldorp 90])

1.

Let R be a respect to

TRS. For t 2
convertibility

TinerR(R: ),t]t]=defnto0 tjest

the =R

etq0gu.ivaFleunrtcheecrl,aVss(ot)f

t with is the

set de

nofedvaarsi:ab\let0s2ot]cVcu(rt0r)in: g

in

t.

EV

(t)

is

the

set

of

essential

variables

of

t,

2. Now let t(~x; y~ ) be a term with essential variables ~x = x1; : : : ; xn and non-essential variables ~y = y1; : : : ; ym. Prove that for arbitrary terms ~s = s1; : : : ; sm we have t(~x;~s ) =R t(~x; ~y ).

3. Let R have the property UN (unique normal forms). Show that a normal

form has only essential variables.

4. Let R contain a ground term (i.e., R contains a constant symbol). Show that every convertibility class t] contains a term s having only essential

variables.

5. Let R have the property UN and contain a ground term. Show that there
is a choice function ' from f t] j t 2 Ter(R)g to Ter(R), selecting from each
equivalence class t] a term such that

(a) (b)

'( if

t]) 2 t];
t] contains

a

normal

form

t0,

then

( t])

t0;

(c) '( t]) contains only essential variables.

6.

LEMMA. Let R be a TRS with property UN Then R can be extended to a con uent TRS

aRn0dwciothnttahienisnagmae

ground term. alphabet, the

same convertibility and the same Prove the lemma by considering
of reduction rules ft ! '( t]) j t

Rn20o,rTomerrai(glRinf)oart&minsgt.

6

from '(

R by
t])g.

adding the (Note that

set the

t ! '( t]) are added as reduction rules, not merely as reduction steps.)

7.

LEMMA. con uent

TLRetSRRb0 ewaithTRthSe

with property UN. Then R
same convertibility and the

can be extended to a same normal forms.

oPnnortoR,vew00.ethaedldemamcoanasstafnotlloCwsa:ndinacaruseleRCc!ontCaintso

ayiceoldnsRta00n.t,N(o6w)

applies; if apply (6)

Exercise 1.2.12. (Middeldorp 90]) Let R1; R2 be disjoint TRS's, both
UhtRctRhhoas0101enavetviasnetnatgRhr;dmtet02it0beRhpilaseer02creocecvpinonairvnnonoeouRprrubste01meeirebntaxtiytllae,iRtrkfUaycoe02niNrn.smdae.ndsThStdisoehhajntoneoehciwdxneepttrcaetsoonhflasronmdaoofvtmeeRUisRrniNte1cioabt.orcolNnmhecRoRaloiwunl0it2dhfscRoeuheodrrca1nm.hssbsBiptydhRyareoassr2Thpt.Rtooe;RwryOitta00iiy(bnm2iivgsUai=To'cNtsueoh1r.snta;(lhyt(R2ePu)1tot.er;;rnotetMto00mRfaaoa2snrrr()keee1deo.s2aatvuhc.llecss2ahrhoo)s:,

22 J. W. Klop normal forms in R01 R02. Hence t t0, and R1 R2 is UN.)
Examples 1.2.13. 1. Consider CL fD(x; x) ! Eg, Combinatory Logic with binary test
for syntactic equality as in Table 1.6. Note that this is indeed a disjoint sum. As we shall see in Section 2.1, CL is con uent. Trivially,
the one rule TRS fD(x; x) ! Eg is con uent. Hence, by Toyama's
theorem (1.2.2) the disjoint sum is con uent.
2. By contrast, the union CL fDxx ! Eg, Combinatory Logic with
`varyadic' test for syntactic equality as in Table 1.7, is not con uent. (See Klop 80a].) Note that this combined TRS is merely a union
and not a disjoint sum, since CL and fDxx ! Eg have the func-
tion symbol Ap in common, even though hidden by the applicative notation. 3. Another application of Toyama's theorem (1.2.2): let R consist of the
rules if true then x else y ! x if false then x else y ! y if z then x else x ! x
(Here true; false are constants and if ? then ? else is a ternary
function symbol.) Then CL R is con uent. Analogous to the
situation in (2), it is essential here that the if ?then?else construct
is a ternary operator. For the corresponding varyadic operator, the resulting TRS would not be con uent.

Remark 1.2.14. A di erent approach to modularity is taken by Kurihara

&aispptKhraoeajiochb8lti8go]a.ptieIorfnfoRrtm1o auansrdebitRarsa2rlyaorniegntdeairssljeopaiovnsitnsigTblRoefStR'hs1,e-sirttueiplsessnaoontfdtaRhlle2o-wsstaeedmpsei;nTtthRhearSet.

Thus, if a rule of say R1 is applied to term t, we must rst normalize t with
rrtKeeiuslsaprtaieihconatnrostaromI&Ria1lK(,ifaob=jreimf1o8;ro82ef])aRpfporipro:lvtFyeeiurntrmghthesreusfrlo;metlsloo2orwfeTi,RneIgr2(,tRiahsn1etdohreveRmiuc2en:)ivboeynrssoafI. IFi 1otriamfnsadl!lIy:+i2.dteNaonnwde

1. Let R1; R2 be disjoint TRS's. Then the relation I is terminating
(SN).

2. Let R1; R2 be disjoint complete TRS's. Then the relation I is com-
plete.

Note that Assuming

(i1n),(1p)arRt1(;2R)2onf etehde

not be SN. We theorem follows

will sketch a in some easy

proof of (2). steps: First

observe that for I we have UN , CR, using UN & SN ) CR, a general

fact for ARS's. So to prove UN for I. Consider reductions s I I t1

Term Rewriting Systems

23

and s I I reductions !i with respect to

(t!i2,=, wth1he;e2rue)niiton1n;Rto2if

are are
!i

I-normal forms. Because the original SN, the terms t1; t2 are normal forms (i = 1; 2). Hence by Toyama's theorem

1.2.2: t1 t2.

Exercises 1.2.15. (Middeldorp)
1. Show that the modularity of WN (Exercise 1.2.9) is a corollary of the theorem in Remark 1.2.14.
2. Give an example of disjoint con uent TRS's such that I is not con uent. (faFSFn(ode(l(xuFB;tix()oB;)nB;!bB)y)IFAa2(r.xeFM;d(xiBid)d;;eAeBrled)n!otarpnIBdo-ngfF;ot(rhRemi(s2Aaql)=uf;eoAsrft)meio(Isnx.)2)inF!K(Aux;rgiAh. )a:rNaTo&hweKFtae(rjemi(As88)F;]:A(AR) ;1IA=1)

In this introduction to TRS's we will not consider termination proper-

itniesthoaftcaormeabisneeedDTerRshSo'swRit1z 8R1,28w7]h, iBchacahrme aniort&dDisjeorisnhtowsuimtzs.86F]o,rTroeysaumltas

88] and, for heterogeneous TRS's, Ganzinger & Giegerich 87]. As to con-

uence properties of we include two facts

icnotmhbeifnoeldlowTiRnSg'esxRer1ciseRs2,

which which

are not require

disjoint sums, some concepts

from the sequel (namely, the notion of overlapping reduction rules, critical

pairs, and -calculus).

Exercise
TRS's. De

1.2.16. (Raoult &
ne: R1?R2 (R1 and

Vuillemin 80], Toyama R2 are orthogonal to each

88]) Let R1; R2
other) if there is

be no

overlap between a rule of R1 and one of R2. (There may be critical pairs due to

overlap between R1-rules, or between R2-rules.) Prove:

Theorem. Let R1; R2 be left-linear and con uent TRS's such that R1?R2. Then
R1 R2 is con uent.

(Proof sketch. Prove that in R1 R2 we have: (1) R1-reductions commute; (2) R2-reductions commute; (3) R1-reductions commute with R2-reductions. In order to prove (3), it is su cient to prove (4) as in Figure 1.8. To prove (4), we need the left-linearity and the orthogonality requirements. The result now follows by an application of the Hindley-Rosen lemma in Exercise 1.0.17(3). The orthogonality is obviously necessary. Note that also the left-linearity cannot be dropped|see Example 1.2.13(2).)

Figure 1.8

24 J. W. Klop
Exercises 1.2.17. Prove: Theorem. Let R be a left-linear, con uent TRS. Let the signature of R be dis-
joint from that of -calculus, i.e. R does not contain the application operator. Then R, the disjoint sum of -calculus and R, is con uent.

Proof sketch: by the same strategy as used for Exercise 1.2.16.

Semantics of Term Rewriting Systems
Although we do not enter the subject of semantics of TRS's (see e.g. Boudol 85], Guessarian 81]), there is one simple remark that should be made. It concerns a semantical consideration that can be of great help in a proof of UN or CR:
nTohrmeoarlefmorm1s.2t.;1t80 .ofLRe:t A be an algebra `for' the TRS R such that for all A t = t0 ) t t0:
Then R has the property UN (uniqueness of normal forms).
Here the phrase `A is an algebra for the TRS R' means that A has the same signature as R, and that reduction in R is sound with respect to A, i.e. t R s implies A t = s. The terms t; s need not be ground terms.
More `semantic con uence tests' can be found in Plaisted 85], in the setting of equational TRS's (not treated here).

Decidability of properties in Term Rewriting Systems

We adopt the restriction in this subsection to TRS's R with nite alphabet

and nitely many reduction rules. It is undecidable whether for such TRS's

the property con uence (CR) holds. (This is so both for R, the TRS of all

termFso,ragnrdou(nRd)0T, RthSe'sT, Ri.Se.reTstRriSct'sedwthoergeroiunndevteerrymrsu.)le t ! s the terms

t; s are ground terms decidable (Dauchet &

(not to Tison

be confused 84], Dauchet

wetitahl.(R8)70],aObyoavme),agcuonchiue8n7c]e).

is

For the termination property (SN) the situation is the same. It is

undecidable for general TRS's, even for TRS's with only one rule (see for

a proof Dauchet 89]). For ground TRS's termination is decidable (Huet &

Lankford 78]).

For particular TRS's it may also be undecidable whether two terms

are convertible, whether a term has a normal form, whether a term has

an in nite reduction. A TRS where all these properties are undecidable is

Combinatory Logic (CL), in Table 1.4.

Exercise
reduction t

1!.2t.01!9.t00

!If

t

2
.

Ter(R), Prove:

we say \t If R is not

is SN" if t admits SN, then there is a

no in redex

nite of R

Term Rewriting Systems

25

which is not SN. In fact, then there is a redex whose contractum is not SN.

Exercises 1.2.20. (Huet & Lankford 78])

1.

Let R be
1; : : : ; ng.

a ground Prove: If

TRS R is

with nitely not SN, then

many rules, R =
for some i 2 f1; :

:f:t;in!g ansid

ji=
some

context C ] we have ti !+ C ti]: (Hint: Use the previous exercise and use

induction on n.)

2. Conclude: SN is decidable for nite ground TRS's.

Exercise 1.2.21. (Undecidability of SN) In this exercise we will outline a

proof that SN is an undecidable property for ( nite) TRS's, via a translation of

the problem to the (uniform) halting problem for Turing machines. The proof is

a slight simpli cation of the one in Huet & Lankford 78]. (However, that proof

employs only constants and unary function symbols; below we use also binary

function symbols.) We will not be concerned with the number of reduction rules

employed in the translation of a Turing machine to a TRS; for an undecidability

proof using a TRS of only two reduction rules, thus establishing that SN is

undecidable even for TRS's with only two rules, see Dershowitz 87]. For a

(complicated) proof that even for one rule TRS's the property SN is undecidable,

see Dauchet 89]. (Even more, for orthogonal one rule TRS's SN is undecidable,

as shown in Dauchet 89]. The property `orthogonal' is de ned in Chapter 2.)

A (deterministic) Turing machine M consists of a triple hQ; S; i where Q is a

set fq0; : : : ; qng of states, S = f2; s1; : : : ; smg is the set of tape symbols (2 being

the empty symbol or `blank'), and is a partial function (the transition function)

from Q S to Q S fL; Rg. Here L represents a move to the left, R to the

right.

An instantaneous description or con guration is an element of S QS (in

the well-known notation of regular expressions). E.g. in Figure 1.9(a) the con-

guration 2aqba2a is pictured; the understanding is that in the con guration

ww12q. wF2utrhtheehrmeaodrei,s

in state q and scans the in nite portions

the rst of tape

symbol to which are

the right of it, i.e. of to the left of w1 and

to the right of w2, are supposed to be blank. Equivalent con gurations arise by

appending to the left or to the right of the con guration nite portions of empty

tape, i.e. elements of f2g :

The transition function determines transition rules, of the form

qst s0q0t (for all t 2 S) whenever (q; s) = (q0; s0; R)

and tqs q0ts0 for all t 2 S) whenever (q; s) = (q0; s0; L):
A transition rule of the rst type (`R-type') is a move to the right (see Figure 1.9(b)), and of the second type (`L-type') a move to the left. A rule of the rst type can also be rendered as
qs s0q0 whenever (q; s) = (q0; s0; R):

Transition rules may be applied in a `context', giving rise to transitions between
con gurations, by appending words w1; w2 2 S to the left and the right. Thus

26 J. W. Klop

Figure 1.9

the all

transition
w1; w2 2 S

rule qst . Note

s0q0tR generates transitions w1qstw2 w1s0q0tw2 for that transitions operate in fact on equivalence classes of

con gurations.

We will now translate all this in the terminology of TRS's. That is, we

associate to the
q 2 Q there is

Turing machine M = hQ;
a binary function symbol

S; i a
which

TRS RM as follows. we will denote with

For the

each same

letter. Each s 2 S corresponds to a unary function symbol, also denoted with

the same letter.
A word w 2 S

Furthermore, the is translated into

alphabet the term

of Rm contains a (w) as follows:

constant

symbol

.

(") = (sw) =

s(

(("wi)s)thefoermspt2y Sw; owrd2)

S

:

E.g. the translation of ba a is b(a( (a( )))). In the sequel of this exercise we will suppress parentheses by association to the right, thus rendering b(a( (a( )))) as ba a .

Term Rewriting Systems

27

A con reversed.

Tghuerarteioansown1fqowr 2thwisillrbeveetrrsaanlswlaitlledbetocqle(ar(wla1?te1r).;

(w2)). Here E.g. the con

wg1?u1raistiwon1

aqba a is translated to q(a ; ba a ).

ruleWs oefwRilMl n.owTodetrannestithieontrarunlselastioofnRo-ftythpee,trqasnsitiosn0qr0u,lewseolfeMt coinrtroesrpeodnudcttiohne

reduction rule

q(x; sy) ! q0(s0x; y):

In the case that s is , so that the rule reads q s0q0, we add moreover the reduction rule

q(x; ) ! q0(s0x; ):

In some sense, the second rule is a degenerate case of the rst one; conceiving

as a potentially in nite portion of tape, satisfying the equation = , it is

clear how this rule arises from To a rule of L-type, tqs

tqh0tes0,rwsteolnete.correspond

the

reduction

rule

q(tx; sy) ! q0(x; ts0y):

Again we fact qs

haqv0etss0omwee

extra rules for add moreover

the

`degenerate'

cases.

If

tqs

q( ; sy) ! q0( ; s0y):

q0ts0 is in

If tqs q0ts0 is in fact tq q0ts0 we add moreover
q(tx; ) ! q0(x; ts0 ):
If tqs q0ts0 is q q0 s0 we add moreover
q( ; ) ! q0( ; s0 ):
(So the transition rule q q0 s0 corresponds to four reduction rules.) 1. Now it is not hard to prove that for con gurations ; we have:

, ( ) ! ( ):

2. Prove that, given a TRS R and a term t in R, the problem to determine

whether t has an in nite reduction in R, is undecidable. This means: there

is no nite

algorithm that accepts as set of rewrite rules) and a

inputs term t

2paTiresr((RR);,t)anodf

a TRS R (given by a that yields as output

the answer `yes' if t has an in nite reduction in R, and `no' otherwise.

(Using (1), reduce this problem to the well-known undecidable halting

problem for Turing machines with empty tape as initial con guration.)

3.

Twohiecahchnogrqo0 u2ndQ

term in RM occurs (call

of the such a

form term

q(t1; t2) where t1; t2 are terms in `restricted'), there corresponds a

28 J. W. Klop

con guration of M; but this is not so without that restriction. Prove that

if a

rseosmtreictteerdmgrtoiunndRMterhmast0anin

in nite reduction RM having an in

in RM, then there is nite reduction, and

also thus

yielding a corresponding in nite run of the Turing machine M.

4. Prove, using (3) and referring to the well-known undecidable uniform halting problem for Turing machines, that the problem to determine whether a given TRS is SN (strongly normalizing) is undecidable. The uniform halting problem for Turing machines is the problem to decide whether a given Turing machine halts on every input as initial con guration.

1.3 A termination proof technique

As Newman's Lemma (WCR & SN ) CR) shows, termination (SN) is a
useful property. In general, as noted in Exercise 1.2.21, it is undecidable whether a TRS is SN; but in many instances SN can be proved and various techniques have been developed to do so. (See Huet & Oppen 80], Dershowitz 87].) We will present in this section one of the most powerful of such termination proof techniques: the method of recursive path orderings, as developed by Dershowitz on the basis of a beautiful theorem of Kruskal. (See also the similar concept of `path of subterm ordering' in Plaisted 78], discussed in Rusinowitch 87b].) In fact we will use the presentation of Bergstra & Klop 85], where the rather complicated inductive de nitions of the usual presentation are replaced by a reduction procedure which is to our taste easier to grasp.
De nition 1.3.1. 1. Let T be the set of commutative nite trees with nodes labeled by
natural numbers. Example: see Figure 1.10(a). This tree will also be denoted by: 3(5; 7(9); 8(0(1; 5))). Commutativity means that the `arguments' may be permuted; thus 3(8(0(5; 1)); 5; 7(9)) denotes the same commutative tree. 2. Let T be the set of such trees where some of the nodes may be marked with (a single) . So T T . Example: see Figure 1.10(b); this tree will be denoted by 3 (5; 7(9 ); 8 (0(1; 5))):

Notation 1.3.2.
are elements of

Tn(.t1;

F: :u:r;tthke)r,wiilfl

be t

written as n(~t ). n(t1; : : :; tk)

Tthheenti

(i t

= 1; : : : stands

; k) for

n (t1; : : :; tk):

De nition 1.3.3. On T we de ne a reduction relation ) as follows.
1. place marker at the top:
n(~t ) ) n (~t ) (~t = t1; : : :; tk; k 0)

Term Rewriting Systems

29

Figure 1.10
2. mif ank>e cmop,itehsebnelnow(~tle)s)sermto(np: (~t ); : : :; n (~t )) (j 0 copies of n (~t )) 3. pnus(hs;~mt )a)rkenr(dso;w:n:::; s ;~t ) (j 0 copies of s )
4. select argument:
n (t1; : : :; tk) ) ti (i 2 f1; : : :; kg; k 1)
It is understood that these reductions may take place in a context, i.e. if
t ) s, then n(|; t; |) ) n(|; s; |) We write )+ for the transitive (but not re exive) closure of ).
Example 1.3.4. Figure 1.11 displays a reduction in T . Clearly, the reduction ) is not SN in T ; for, consider the second step
in Figure 1.11: there the right hand side contains a copy of the left-hand side. However:
Theorem 1.3.5. The relation )+, restricted to T, is a well-founded partial ordering. Or, rephrased, the relation )+, restricted to T, is SN.
So there is no in nite sequence t0 )+ t1 )+ t2 )+ of terms ti
(i 0) without markers. The proof of Theorem 1.3.5 is based on Kruskal's Tree Theorem; we will give the main argument.
In order to introduce the next notion of `embedding', we must make
the de nition of trees t 2 Tsomewhat more precise. An element t 2 Tis a pair (hD; ; 0i; L) where D is a nite set f 0; ; ; : : :g with distinguished
element 0, called the root or the top of t, and partially ordered by . We require that:
1. 0 for all 2 D, 2. and ) or , for all ; ; 2 D.

30 J. W. Klop

Figure 1.11

The set D is also called Nodes(t). Furthermore, L: D ! N is a map
assigning labels (natural numbers) to the nodes of t. Finally, we use the
notation ^ for the supremum (least upper bound) of ; 2 D. (The
actual names ; ; : : : of the nodes are not important, which is why they
were suppressed in the pictorial representation of t 2 Tabove.)

De nition
embedded in

t10.,3n.o6t.atLioent

t; t

t0

t02,

T. We say that if there is a map ':

tNisod(heosm(t)eo!moNrpohdiecasl(lty0))

such that:

1. ' is injective,

2. ' is monotonic ( ) '( ) '( )),

3. ' is sup preserving ('( ^ ) = '( ) ^ '( )),

4.

'maispslaobfelt;itn0crreesapseinctgiv(eLly(;

)

L0('( )), where L; L0 are the labeling
is the ordering on natural numbers).

Actually, (2) is super uous as it follows from (3).

Example 1.3.7.
1. 2(9; 7(0; 4)) 1(3(8(0(5; 1)); 9; 5(9)); 2) as the embedding in Figure 1.12 shows.
2. Note that we do not have 1(0; 0) 1(0(0; 0)).

Term Rewriting Systems

31

Figure 1.12

Clearly, is a partial order on T: Moreover it satis es the following remarkable property:

Theorem 1.3.8. (Kruskal's of trees in T. Then for some

Tree Theorem) i < j: ti tj.

Let

t0; t1; t2; : : : be

a

sequence

The proof of this theorem, as given in Kruskal 60], is extremely complicated. Proofs are given in Dershowitz 79] and Dershowitz & Jouannaud 90]. See also Exercise 1.3.12 for a detailed proof sketch of a restricted case which is su cient for the present purpose.
Now we have the following proposition (of which (1) is nontrivial to prove):

Proposition 1.3.9. 1. )+ is a strict partial order on T, 2. if s t, then t ) s:

(Here ) is the transitive-re exive closure of ).) Combining 1.3.8 and
1.3.9, we have Theorem 1.3.5. For, suppose there is an in nite sequence

t0 )+ t1 )+ t2 )+ )+ ti )+ )+ tj )+

then for some i <
impossible as )+

j is

we have a strict

ti tj partial

, hence order.

tj

)

ti, so ti )+ ti, which is

Application 1.3.10 (Dershowitz 87]). Let a TRS R as in Table 1.9 be given. To prove that R is SN. Choose a `weight' assignment _ 7! 1, ^ 7! 2,

32 J. W. Klop
::x ! x :(x _ y) ! (:x ^ :y) :(x ^ y) ! (:x _ :y) x ^ (y _ z) ! (x ^ y) _ (x ^ z) (y _ z) ^ x ! (y ^ x) _ (z ^ x)
Table 1.9
: 7! 3. Now a reduction in R corresponds to a )+ reduction in T(and
hence it is also SN) as follows:
3(3(t)) )+ t 3(1(t; s)) )+ 2(3(t); 3(s)) 3(2(t; s)) )+ 1(3(t); 3(s)) 2(t; 1(s; r)) )+ 1(2(t; s); 2(t; r)) 2(1(s; r); t) )+ 1(2(s; t); 2(r; t))
E.g. the second rule:
3(1(t; s)) ) 3 (1(t; s)) ) 2(3 (1(t; s)); 3 (1(t; s))) )+ 2(3(1 (t; s)); 3(1 (t; s))) )+ 2(3(t); 3(s)):
Remark 1.3.11.
1. The termination proof method above does not work when a rule is present of which the left-hand side is embedded (in the sense of De ni-
tion 1.3.6) in the right-hand side, as in f(s(x)) ! g(s(x); f(p(s(x)))).
For an extension of Kruskal's Theorem, leading to a method which also can deal with this case, see Kamin & Levy 80] and Puel 86]. 2. Another example where the method above does not work directly, is found in the TRS's corresponding to process algebra axiomatizations as in Bergstra & Klop 84, 85]. For instance in the axiom system PA there are the rewrite rules
xky ! (x k y) + (y k x) (x + y) k z ! (x k z) + (y k z) (a x) k y ! a (xky): Here one wants to order the operators as follows: k > k > ; +,
but then we get stuck at the third rule with the re-emergence of the
`heavy' operator k. In Bergstra & Klop 85] the solution was adopted

Term Rewriting Systems

33

to introduce in nitely many operators k
some complexity measure of the actual

naragnudmkennt,s

where n refers to of the operators

in a reduction. In fact, the operator + does not contribute to the

problem, and forgetting about it and writing xky as g(x; y); x k y as

h(x; y); a x as f(x), we have Example 16 in Dershowitz 87] where this

problem takes the following form and is solved by a lexicographical

combination of recursive path orderings:

g(x; y) ! h(x; y) h(f(x); y) ! f(g(x; y)):

The termination proof as in Bergstra & Klop 85] amounts to the
following for the present example. De ne a norm j j on terms by: j t j
irhfsoenprt(hlngae(cslee;nir2ng)).t;ahoNtroeodfrwemtritntthheesevyremoerpcybeuorsrlausstib;votterehsrepmtnahtiuhhns(t:sor;orgrddn)eur>bcieynhgnhnojasr>sjm+bjfered;jf(hosonr;pe+re)1risaa>tnaodpgrspnlli.gikcnTeawahbnielsende. Caution is required here: the norm must be chosen such that the norm of a term t is not increased by reduction of a subterm of t. (For
this reason, taking j t j as the length of t in symbols would not work
for the process algebra example above.) 3. A third example were the proof method above does not work, is when
an associativity rule

(x y) z ! x (y z)

is present. The same problem occurs in the TRS for Ackermann's

function: A(0; x)

! S(x)

A(S(x); 0) ! A(x; S(0))

A(S(x); S(y)) ! A(x; A(S(x); y))

What we need here is the lexicographic path ordering of Kamin & Levy 80], see Dershowitz 87]. Essentially this says that a reduction in complexity in the rst argument of A outweighs an increase (strictly bounded by the complexity of the original term) in the second argument. In fact, an ordering with the same e ect can easily be described in the framework of reduction with markers as explained above: all one has to do is give up the commutativity of the trees in Tand T and require that an embedding (De nition 1.3.6) respects also the left-right ordering; Kruskal's Tree Theorem works also for this case of noncommutative trees. Next, the rules in De nition 1.3.3 are restricted such that the arities of the operators are respected; in De nition 1.3.3 the operators
were treated `varyadic'. So rule (3) becomes: n (t1; : : :; ti; : : :; tk) )

34 J. W. Klop

nD(et1n; :it:i:o;nti1;.:3:.:3;(twk)it(h1(3)

i k). Further, amended) the rule

we

add

to

the

rules

in

5. simplify left argument:

n(~t

(~t =

))
t1; :

:n:(;tt1k;

n (~t (k

); : : 1);

:; k

n
?

(~t )) 1 copies

of

n

(~t ))

Example:

A(S(x); S(y)) ) A (S(x); S(y)) ) A(S (x); A (S(x); S(y))) ) A(x; A (S(x); S(y))) ) A(x; A(S(x); S (y))) ) A(x; A(S(x); y)):

Exercise 1.3.12. In this exercise we outline a short proof of a restricted
version of Kruskal's Tree Theorem 1.3.8, which is su cient for termination proofs of TRS's where the function symbols have arities uniformly bounded by some natural number N. (There may be in nitely many function symbols, as e.g. the gn; hn in the preceding Remark 1.3.11.) A fortiori this is the case for TRS's with nite alphabet.
The proof below is similar to that in Dershowitz 79]; the proof in Dershowitz & Jouannaud 90] is similar but for a short-cut there appealing to a special case of the Tree Theorem known as Higman's Lemma. These proofs are originally due to Nash-Williams 63]. First we de ne:

1. The branching degree of a node s in t 2 T is the number of immediate
successor nodes of s.

2.

TN is
degree

the subset of Tconsisting of trees N. Likewise we de ne TN:

where

all

nodes

have

branching

WtoeTwNil:l now outline a proof of Kruskal's Tree Theorem 1.3.8 where Tis restricted

1. CLAIM. Each in nite sequence of natural numbers n0; n1; n2; : : : has a

weakly ascending in nite subsequence.

This f (1)

means that < f(2) < :

:t:hesurechistahastubnsfe(q0u) encenfn(1f)(0);

nnff((12));

nf(:2:);:

:: .

: with f(0) The proof

< is

simple.

2. DEFINITION.

(a) (b)
(c) (d)

LFNLboTDfuueehott(trttestrat(Dh)eitsnne2ei)osirnt=mnTif+a:ro1(NolTtram.6=se)n!Nen,TgT.(iw)mnhtN)eeTenjnnsn+hisaisttje1nyenTt.tj0tjsT!N;htei:h:ahqs:jetiu:tsteh;ssnint,eenncqjtd?neu:u2u1eocmnfeiTscsbte!N(reatert)ehmnosa2f.evtten0TrD;oidhtcd1iesei;ostss:nae:mont:Tfciwoent!Nf.ii.2lmiln?abnleniiifwtne(rsDist)etnqeifnu=e8an(sstc)et2ns.

Term Rewriting Systems

35

3.

CLAIM. Then D

Let D
contains

Ta !Nmbineinmoanl-eemlempteynatn(dwcitlohsreedswpe.cr.tt.tothDe )m. etric

just

de

ned.

The proof of Claim 3 is easy.

4. NOTATION.

(a) (b)

LLssueectthst;ttt=haa2tnt0Tdf;ot!Ncr1a.;al:lTl:ls:hieaa;nsnsfdus(bil)seutitsbssmae=qepaursneofnsp(ce0ter)h;aosstuffb(st1t.)ir;se(:Sea:e:osebufFbetisfgae(uiq)sru.ueebnT1sc.eh1eqe3uno.)efnwtc.ee

of t,
write

Figure 1.13

5. DEFINITION. s = s0; s1; s2; : : : is a chain if s0 s1 s2 : : : , where
is the embedding relation as in Kruskal's Tree Theorem.

We will now suppose, for a proof by contradiction, that there is a counterexample

spseirqouvee.nscjTe, hitsaotstuihsp,eptorhesesetdsreictttoeCdbevenTrosn!Nio-neomfopsfetKyq.ureuNnskcoeatsle'ssthTsaurtecehCTthhisaetocrlfoeomsredntohinait<twheje

want to we have sense of

De nition 2(d).

6. CLAIM. Let t be a minimal element from C. Suppose s t.

(a) (b)

Then Even

for some stronger,

si

< j: si
contains

sj:
a subsequence

which

is

a

chain.

PbCtfyR(6=0sO). ?O=BFytaknom.dfiCCnboiylmaniCsamildliate6iyrm(aot)hf3.et.),(sNteLhqoeiutsteessnet,hcqteautbetn0ea;ca:mes: ii:sin;nintmkoC?tal1ali;niemslC0e;m6.s.He1n;Lestne2ctt;e:sei:0xt:ibc;stoetsnhatabatypinritsosh,pea(entra)sekssmuufbobmtlelrpodetwdeioeeonddf

pair of elements (the earlier one embedded in the later one). The embedded pair

cannot occur in the ti sj, since then embedded pair must

potrcecwuoxrui(lndt)tkchoebnetpcaoaisnutsetxhtes.2emCb.edIdtecdanpaailrsotinot

be of tf(j).

the form So, the

As to part (b) of the claim, suppose s does not contain an in nite chain as

subsequence. Then s contains an in nite number of nite chains, each starting

to the right of the end of the previous nite chain and each maximal in the sense

36 J. W. Klop

that it cannot be prolonged by an element occurring to the right of it in s. Now

caonnsinidenrittehesulabsstubesleemqueenntcseofofthte,seconntiatienicnhgainbys.

These (a) of

last the

elements claim an

constitute embedded

pair. But that means that one of the maximal nite chains can be prolonged, a

contradiction.

7. CLAIM. Let t be minimal in C and suppose s r t. Then s contains
an in nite chain as subsequence.

The mal

cporuonotfeorfexCalmaipmle7seisqutreinvciael.t

W2 eCw. iBllynCowlaiampp1lywae

t such that the root labels are weakly ascending. Of

sctia0envweteaptkraeokcaeedsauusbruesbetqsoeuqetunhecenemctei0ntoi-f

with the property that the branching degrees of the roots are a weakly ascend-

ing sequence. By Claim 6 every subsubsequence of t still contains an in nite

embedding chain. Let us `freeze' the
cessors of each node in

elements in t0,
some arbitrary

that way.

is, So

we impose the frozen

tarneeosridnerti0nagreofntohleonsguecr-

commutative trees, and we can speak of the rst, second etc. `arguments' of a

node. (An argument of a node is the subtree with as root a successor node

of .)

The next step in the sieve procedure is done by considering the sequence of

rst arguments of (the roots of) the elements in t . As this is a subsubsequence,

it contains an in nite chain. Accordingly, we thin t out, to the subsequence

t . This sequence has the property that its rst arguments form a chain. Next,

t is thinned out by considering the sequence of the second arguments of t .

Again, this sequence contains a chain, and thinning t accordingly yields the

subsequence t .

Figure 1.14

After at most N steps of the last kind, we are through. The result is then a chain,

since the roots already satis ed the embedding condition (they form a weakly

ascending chain), and the arguments are also related 1.14.) However, this contradicts the assumption that

tascocnhtaaiinnss.

(See Figure no embedded

pair. Hence C is empty, and the restricted version of Kruskal's Tree Theorem is

proved.

Exercise 1.3.13. (Kruskal 60]) In this exercise we introduce the terminol-
ogy of well-quasi-orders which is often used to formulate Kruskal's Tree Theorem.

Term Rewriting Systems

37

1. DEFINITION. The binary relation is a quasi-order (qo) if it is re exive

and transitive. (So the relation in a TRS is a qo.) If in addition is
anti-symmetric (i.e. x y & y x ) x = y for all x; y) then is a partial

order (po).

2.

Dx E2FYIN&ITxIONy. L)etyh2X;Y

i be a
for all

qo. x; y

2AXsu. bTsehte

Y cone

X is called a cone if generated by Y X,

notation Y ", is the set fx 2 X j 9y 2 Y y xg. (It is the intersection of

all cones containing Y .) A cone Z is nitely generated if Z = Y " for some

nite Y .

3. DEFINITION. Let hX; i be a qo (po, respectively). Then hX; i is a well-

quasi-order (wqo) or well-partial-order (wpo) respectively, if every cone of

X is nitely generated.

4.

DEFINITION. the elements of

Let hX; i be
Y are pairwise

a qo. A subset Y incomparable, i.e.

for

X all

is x;

yan2aYntsi-ucchhatinhaitf

x 6= y we have neither x y nor y x:

Prove the following lemma:

5. LEMMA. Let hX; i be a qo. Then the following conditions are equivalent:

(a) hX; i is a wqo;

(b)

X contains
anti-chains

no in nite descending
of X are nite;

chains

x0

>

x1

>

x2

>

and all

(c) for every in nite sequence of elements x0; x1; x2; : : : in X there are i; j such that i < j and xi xj:

ShKTor,u; sKkirauli'ssskatahl'eswoerTlelrm-eqeusaTtsahit-eeoosrrdtehemra.tahsPTrs;otavteieidtsheianvte1nh.T3a.;8wcieallni-spabinretirfaael-cfootrrmdaeurpl.aatretidalasorfdoellro;wsso:

Exercise 1.3.14. 1. Show that the well-partial-order hT; i is not a linear order.
2. Show that )+ is a linear order. As it is well-founded (Theorem 1.3.5),
it corresponds to an ordinal. For connections with the ordinal ?0, the rst impredicative ordinal, see Dershowitz 87]. For more about Kruskal's Tree Theorem and the connection with large ordinals, as well as a version of the Tree Theorem which is independent from Peano's Arithmetic, see Smorynski 82] and Gallier 87].

Exercise 1.3.15. (Multiset orderings) Very useful for termination proofs

(used in some of the Exercises 1.0.8) are ticular cases of the well-founded ordering

thhTe ;m)u+ltiisdeitscoursdseerdinagbs ;ovteh,esneamareelypabry-

restricting the domain T:

1. Multisets. Let hX;<i be a strict partial order. Then the p.o. of multisets

over X, or the multiset extension of X, notation hX ; < i, is obtained as

follows. The elements of X are nite \sets" of elements from X with the

understanding that multiplicity of occurrences is taken into account, other

than in ordinary sets. A multiset will be denoted by square brackets ].

38 J. W. Klop

E.g. if a; b 2 X then a; a; b] and a; b] are di erent multisets; but a; a; b]
and a; b; a] denote the same multiset. Stated di erently, a multiset is a

nite sequence of elements where the order of occurrences in the sequence is disregarded. Giving a more formal de nition is left to the reader. A multiset is also known as a bag. We use in this exercise ; ; : : : as variables

for multisets. Now we de ne the following relation >1 between elements of X by the two clauses:

(a) a] >1 b1; : : : ; bn] for all a; b1; : : : ; bn 2 X (n 0) such that a > bi
(i = 1; : : : ; n);
(b) >1 ) >1 . Here denotes multiset union, de ned in
the obvious way as a union where the multiplicities of the elements are respected. E.g. a; a; b] a;b; c] = a; a; a; b; b; c]. Thus, a multiset

gets smaller by replacing an element in it by arbitrarily many (possibly 0) elements which are less in the original ordering. The converse of >1 is <1.

Furthermore, we de ne:

(c) < is the transitive closure of <1.

Now prove the following statements:

(a) If hX;<i is a strict partial order, then so is its multiset extension

hX ; < i. If hX;<i is moreover a linear order, then so is hX ; < i:

(b) (Dershowitz & Manna 79]) hX;<i is a well-founded p.o. , hX ; < i

is a well-founded p.o. (The p.o. hX; <i is well-founded if there are

(c)

LnoetinhXn;i<tei

descending chains x0 > x1 > : : : .) be a well-founded linear order with

order

type

. Then

hX ; < i has order type ! :

2. Nested multisets. Let hX;<i be a p.o. Then the p.o. of nested multisets over X, notation: hX ; < i, is de ned as follows. The domain X is
the least set Y such that X Y and Y = Y . Or, inductively:

(a) X0 = X;

(b) Xn+1 = (X0

Xn) ;

(c) X = n 0Xn.

Note that the elements of X can be represented as nite commutative

trees, nodes

with with

terminal nodes labeled by elements from X, a label representing the multiset-operator.

and The

ndeopnt-hteormf ina2l

X is the stage of the inductive de nition in which it is generated, or in

the tree representation, the maximum of the lengths of the branches of the

tree corresponding to :

Furthermore, the ordering < is the least relation R extending < and

satisfying:

(a) x R for all x 2 X and multisets 2 X ? X;

(b)

(i

]R = 1;

:1:;::;:n: ;);

n]

for

all

; 1;:::;

n2X

(n

0) such that i R i

(c) R ) R for all multisets ; ; 2 X ? X.

Now:

Term Rewriting Systems

39

(a) Let hX; <i be a p.o. Prove that hX ; < i is a p.o. If moreover

hX; <i is a linear order, then so is hX ; < i.

(b) Let ; 2 hX ; < i. Prove that if the depth of is greater than

the depth of , we have < .

(c) (Dershowitz & Manna 79])

(d)

hX;
Let

<hNi ;is<wi eblle-ftohuendneadtu,ralhXnum;b<ers

i is well-founded.
with the usual ordering.

Prove

that hN ; > i, the nested multisets over the natural numbers, is in

(e) tSfi0isnae.hcroTmtt0wh.haienatNarhtlealoaissttsntte,rtoihfodtcoehctericasooutrnord;hfreNoetrfnh2tcteyehNp;te<roeefroeef<crituehrpiTessriweviiwssseeoeeltmnlph-ttafoehaotretuhprinnoehosndhitrceardodivtecfeortli:iinnohefng2a0>rhgNoTfor;<d); a<errt+,ieonigtifia.f0hkgNHt)ehne(e+wrt;eno<ho`i:<bcnhe-'i

in fact is multisets

the ;

eomveprtyf0rge,lastuicohn)t.haFtigur>e

1.15 ;

gives an example or equivalently,

of

two

)+ . All labels at the nodes can be taken 0, and are omitted in

the gure. Note that the procedure using the markers may employ

all clauses in De nition 1.3.3 except clause (2).

Figure 1.15
1.4 Completion of equational speci cations
In this section we will give an introduction to Knuth-Bendix completion of equational speci cations. First we will introduce the latter concept.
Equational speci cations: syntax and semantics
We can be short about introducing the syntax of equational speci cations: an equational speci cation is just a TRS \without orientation". More precisely, an equational speci cation is a pair ( ; E) where the signature

40 J. W. Klop

(or alphabet) is as in Section 1.1 for TRS's ( ; R), and where E is a set

of equations s = t between terms s; t 2 Ter( ):

If an equation s = t is derivable from the equations in E, we write

( ;E) `
inference

s = t or system

s of

=TEabtl.e

Formally, 1.10.

derivability

is

de

ned

by

means

of

the

( ;E) ` s = t
( ;E) ` s = t ( ;E) ` s = t
( ; E) ` s1 = t1; : : :; ( ; E) ` sn = tn ( ; E) ` F (s1; : : :; sn) = F (t1; : : :; tn)
( ;E) ` t = t
( ; E) ` t1 = t2; ( ; E) ` t2 = t3 ( ; E) ` t1 = t3
( ;E) ` s = t ( ;E) ` t = s

if s = t 2 E
for every substitution
for every n-ary F 2

Table 1.10

Exercise 1.4.1. (Equational deduction systems) Often the inference sys-

tem in Table 1.10 is presented slightly di erent, as follows. Prove the equivalence of the two versions below with the system above. Axioms (in addition to the equations in E):
t = t re exivity

Rules:

t1 = t2 t2 = t2

symmetry

t1 = t2; t2 = t3 t1 = t3

transitivity

t1 = t2 t1 x := t] = t2 x := t]

substitution(1)

t1 = t2 t x := t1] = t x := t2]

substitution(2)

Term Rewriting Systems

41

Here x := notation is

t] denotes chosen to

substitution of t avoid the usual

for all occurrences confusion between

of x. x=t];

(The t=x];

axsnsti]g;ntmnxen].t)

An equivalent formulation is to combine the two substitution rules in one:

t1 = t2; t = t0 t1 x := t] = t2 x := t0]

substitution

F AIf: i.e. F

is a signature, a
An ! A for every
is a constant, then

-algebra A is

nF-Aary2

function A.) An

a set A symbol

Ftog2ethe.r

with functions (If F is 0-ary,

equation s = t (s; t 2 Ter( )) is

assigned a meaning in A by interpreting the function symbols in s; t via the

corresponding functions in A. Variables in s = t are (implicitly) universally

quanti ed. If the universally quanti ed statement corresponding to s = t

(s; t 2 Ter( )) is true in A, we write A j= s = t and say that s = t is valid

in A. A is called a model of a set of equations E if every equation in E

is valid in A. Abbreviation: A j= E. The variety of -algebras de ned

by an equational speci cation ( ; E); notation Alg( ; E), is the class of all

-algebras A such that A j= E. Instead of 8A 2Alg( ; E) A j= F, where

F is a set of equations between -terms, we will write ( ; E) j= F. There is

the well-known completeness theorem for equational logic of Birkho 35]:

Theorem 1.4.2. Let ( ; E) be an equational speci cation. Then for all s; t 2 Ter( ) :

( ; E) ` s = t , ( ; E) j= s = t:

Now the validity problem or uniform word problem for ( ; E) is: Given an equation s = t between -terms, decide whether or
not ( ; E) j= s = t:
According to Birkho 's completeness theorem for equational logic this
amounts to deciding ( ; E) ` s = t. Now we can state why complete
TRS's (i.e. TRS's which are SN and CR) are important. Suppose for the equational speci cation ( ; E) we can nd a complete TRS ( ; R) such
that for all terms s; t 2 Ter( ) :

t =R s , E ` t = s

()

Then (if R has nitely many rewrite rules only) we have a positive solution

of the validity problem. The decision algorithm is simple:

1. Reduce s and t to their respective normal forms s0; t0 2. Compare s0 and t0: s =R t i s0 t0:

We are now faced with the question how to nd a complete TRS R for a

given set of equations E such that ( ) holds. In general this is not possible,

42 J. W. Klop since not every E (even if nite) has a solvable validity problem. The most famous example of such an E with unsolvable validity problem is the set of equations obtained from CL, Combinatory Logic, in Tables 1.3, 1.4 above
after replacing `!' by `=': see Table 1.11.

Sxyz = xz(yz) Kxy = x Ix = x

Table 1.11

(For a proof of the unsolvability see Barendregt 81].) So the validity problem of ( ; E) can be solved by providing a complete TRS ( ; R) for ( ; E). Note however, that there are equational speci cations ( ; E) with decidable validity problem but without a complete TRS ( ; R) satisfying ( ): see the following Exercise.

Exercise 1.4.3. Let ( ;E) be the speci cation given by the equations

x+0 = x x + S(y) = S(x + y) x+y = y+x

Prove that there is no complete TRS R `for' E, i.e. such that for all terms s; t 2

Ter( forms

): of

s =R t ,
the open

s =E terms

t. x

(Consider + y and y

in +

a supposed x.)

complete

TRS

R,

the

normal

It is important to realize that we have considered up to now equations s = t between possibly open -terms (i.e. possibly containing variables). If we restrict attention to equations s = t between ground terms s; t, we are considering the word problem for ( ; E), which is the following decidability problem:

Given an equation s = t between ground terms s; t 2 Ter( ), decide whether or not ( ; E) j= s = t (or equivalently, ( ; E) `
s = t).

Also for the word problem, complete TRS's provide a positive solution. In fact, we require less than completeness (SN and CR) for all terms, but only for ground terms. (See Example 1.1.3 for an example where this makes a di erence.) It may be (as in Exercise 1.4.3) that a complete TRS for E cannot be found with respect to all terms, while there does exist a TRS which is complete for the restriction to ground terms.

Exercise 1.4.4. Consider the speci cation as in the previous exercise and
nd a TRS ( ; R) such that ( ;R)0 (i.e. the restriction of ( ; R) to ground terms) is complete.

Term Rewriting Systems

43

Remark 1.4.5. Note that there are nite equational speci cations ( ; E)
which have a decidable word problem (so for ground terms) for which no complete TRS R (complete with respect to ground terms) exists. This strengthens the observation in Exercise 1.4.3. The simplest such ( ; E) is the speci cation consisting of a single binary commutative operator + and
a constant 0, and equations E = fx + y = y + xg. According to Exercise
1.4.3 (which also works for the present simpler speci cation) no complete
TRS R can be found such that for all (open) s; t we have s =R t , s =E t.
According to the next exercise, we also have the stronger result that no TRS R exists which is complete for ground terms and such that for ground
terms s; t we have s =R t , s =E t:

Exercise 1.4.6. (Bergstra & Klop) Prove the following fact:

THEOREM. Let ( ; E) be the speci cation with = f0; +g and E = fx + y = y + xg. Then there is no nite TRS R such that the restriction to ground terms,

(R)0, is complete and such that =R and =E coincide on ground terms.

PROOF SKETCH. De ne terms t0 0, tn+1 tn + tn (n 0). Suppose R is a TRS with nitely many rewrite rules such that =R and =E coincide on ground terms. Let N be the maximum of the depths of the LHS's of the rewrite rules in R. (Here `depth' refers to the height of the corresponding term formation tree.)

In

Consider the
fact, ft ; t g

terms t tN + t2N and is an E-equivalence class,

t hence

t2N also

+ tN. Clearly, t =E t . an R-convertibility class.

Therefore there must be a rewrite rule r such that t is an r-redex or t is an r-

redex (since there are only two elements in the convertibility class) and such that

t !r
Hence

t R

. is

Say not

t is even

an r-redex. Now one SN on ground terms.

can

easily

show

that

t

!r t

!r t .

Term rewriting and initial algebra semantics

We will now make more explicit the connection between term rewriting and

initial algebra semantics. We suppose familiarity with the concept of an

initial algebra in the class of models of an equational speci cation ( ; E),

i.e. the variety Alg( ; E), as de ned by universal properties in terms of

homomorphisms. (See e.g. Meinke & Tucker 91], Goguen & Meseguer

85].) Although the initial algebra is only determined up to isomorphism,

we will speak of `the' initial algebra and use the notation I( ; E) for it. It

is well-known that I( ; E) can be obtained from the set of ground terms

tTheer0i(nit)iablyaldgievbidrainIg(ou;tEt)hwe ictohntghreueqnucoetireenlattaiolgneb=rEa.TTerh0u(s

we can )= =E .

equate

Now suppose that ( ; R) is a =E. (So the initial algebra of ( If R is a complete TRS, then I(

TRS `for' ( ; E), ; E) van also be ; E) is in fact a

ctwohrmaittptiuesnt,a=balRseTcaoelirgn0ec(birda)e=.s

with =R.) This

is merely a rephrasing of: the word problem (for ground terms) for ( ; E)

is solvable. As noted in Exercise 1.4.6, the reverse is not necessarily the

case; for some ( ; E) with computable initial algebra there does not exist a

44 J. W. Klop complete TRS|at least not in the same signature. However, a remarkable theorem of Bergstra and Tucker states that if we allow an extension of the signature with some functions and constants (no new sorts), then a complete TRS can always be found. (This result also follows from the simulation of Turing Machines by a TRS|consisting of two rules|as in Dershowitz 87].) More precisely:
De nition 1.4.7. 1. The algebra A 2 Alg( ; E) is minimal, if it is (isomorphic to) a
quotient algebra Ter( )= for some congruence . In particular, I( ; E) is a minimal algebra. In other words, an algebra is minimal if its elements are generated by functions and constants in the signature.
2. A minimal algebra A is computable, if its equality is decidable, i.e. if the relation A j= t = s for ground terms t; s 2 Ter( ) is decidable.

Theorem 1.4.8. (Bergstra & Tucker 80]) Let A be a minimal -algebra,

a nite signature. Then the following are equivalent:

1. A is a computable algebra;

2.

there is an extension function and constant

of to a nite 0, symbols, and there

obtained by adding is a complete TRS (

s0o;mRe)

such that

A I( 0; R=) j :

Here R= is the equational speci cation obtained by viewing the reduc-
tion rules in R as equations, and j is the restriction to the signature . So A is a `reduct' (see Meinke & Tucker 91]) of an initial algebra given by
a complete TRS. (The TRS R as in the theorem is not only ground complete, but complete with respect to all terms. Actually, it is an orthogonal TRS as de ned in the next chapter; and for orthogonal TRS's possessing at least one ground term, ground completeness implies completeness.) The functions (including the constants as 0-ary functions) to be added to are sometimes referred to as `hidden functions'. Note that according to the statement in the theorem no new sorts are needed, thus the present theorem has also a bearing on the homogeneous (i.e. one-sorted) case that we are considering in this chapter.
For more information concerning the connection between term rewriting and computability aspects of initial algebra semantics (and ` nal' algebra semantics), also for the heterogeneous (many-sorted) case, we refer to the very complete survey Goguen & Meseguer 85].

Critical pair completion
We resume the question how to nd a complete TRS (for the case of open terms, henceforth) for an equational speci cation ( ; E). This is in fact

Term Rewriting Systems

45

what the Knuth-Bendix completion algorithm is trying to do. We will now explain the essential features of the completion algorithm rst by an informal, \intuition-guided" completion of the equational speci cation E of groups:

ex = x I(x) x = e (x y) z = x (y z)

Table 1.12

First we give these equations a `sensible' orientation:

1. e x ! x

2. I(x) x ! e

3. (x y) z ! x (y z)

(Note that the orientation in rules 1, 2 is forced, by the restrictions on

rewrite rules in Section 1.1. As to the orientation of rule 3, the other

direction is just as `sensible'.) These rules are not con uent, as can be seen

by superposition of e.g. 2 and 3. Redex I(x) x can be uni ed with a non-

variable subterm of redex (x y) z (the underlined subterm), with result

(I(x) x) z. This e z and (I(x) x)

term is subject to
z !3 I(x) (x z).

two possible reductions: (I(x)
The pair of reducts he z; I(x)

x) (x

zz)!i i2s

called a critical pair, since the con uence property depends on the reduction

possibilities of the terms in this pair. Formally, we have the following

de nition which at a rst reading is not easily digested. For the concept of

a `most general uni er' we refer to Section 1.6 below.

De nition 1.4.9. Let ! and ! be two rewrite rules such that
is uni able (after renaming of variables) with a subterm of which is not a variable (a non-variable subterm). This means that there is a context C ], a non-variable term t and a `most general uni er' such that C t] and t . The term C t] can be reduced in two possible ways:
C t] ! C ] and ! : Now the pair of reducts hC ] ; i is called a critical pair obtained by the superposition of ! on ! : If ! and ! are the same rewrite rule, we furthermore require that is uni able with a proper (i.e. 6 ) non-variable subterm of :

De nition 1.4.10. A critical pair hs; ti is called convergent if s and t have
a common reduct.
Our last critical pair he z; I(x) (x z)i is not convergent: I(x) (x z) is

46 J. W. Klop

a normal form and e z only reduces to the normal form z. So we have the

problematic pair of terms z; I(x) (x z); problematic because their equality

is derivable from E, but they have no common reduct with respect to the

reduction available so far. Therefore we adopt a new rule

4. I(x) (x z) ! z

Now we I(I(y))

have (I(y)

a superposition
y) !2 I(I(y))

of e.

rule 2 and 4: I(I(y)) (I(y) This yields the critical pair

hyy;)I!(I(4yy))anedi

which cannot further be reduced. Adopt new rule:

5. I(I(y)) e ! y

cancelled later

As it will turn out, in a later stage this last rule will become super uous.

We go on and I(e)

searching for critical pairs. Superposition
(e z) !1 I(e) z: Adopt new rule:

of

4,1:

I(e)

(e

z)

!4

z

6. I(e) z ! z

cancelled later

Superposition of 3, 5: (I(Iy)) e) x !3 I(I(y)) (e x) and (I(Iy)) e) x !5
y x: Adopt new rule:

7. I(Iy)) x ! y x

cancelled later

Superposition of 5, 7: I(I(y)) rule:

e !7 y:e and I(I(y))

e !5 y: Adopt new

8. y e ! y

Superposition of 5, 8: I(I(y)) new rule

e !5 y and I(I(y))

e !8 I(I(y)): Adopt

9. I(I(y)) ! y

cancel 5 and 7

(Rule 5 is now no longer necessary to ensure that the critical pair hy; I(I(y))

ei has a
rule 7.) new rule

common reduct, Superposition of

because: I(I(y))
6, 8: I(e) e !6

e e

!9
and

ye I(e)

!e8!y.8

Likewise for I(e): Adopt

10. I(e) ! e

cancel 6

Superposition of 2, 9: I(I(y)) Adopt new rule

I(y) !2 eand I(I(y))

I(y) !9 y

I(y):

11. y I(y) ! e

Superposition of 3, 11: (y I(y)) x !3 y (I(y) x) and (y I(y)) x !11 e x:
Adopt new rule

12. y (I(y) x) ! x

Superposition (again) of 3, 11: (x y) I(x y) !11 e and (x y) I(x y) !3
x (y I(x y)): Adopt new rule

13. x (y (y I(x y)) ! e

cancelled later

Superposition of 13, 4:
(y I(x y))) !13 I(x)

I(x) (x (y I e: Adopt new

(x y))) rule

!4

y

I(x

y) and I(x)

(x

Term Rewriting Systems

47

14. y I(x y) ! I(x)

cancelled later cancel 13

Superposition of 4, 14: I(y) (y I(x y)) !4 I(x y) and I(y) (y I(x y)) !14
I(y) I(x): Adopt new rule

15. I(x y) ! I(y) I(x)

cancel 14

At this moment the TRS has only convergent critical pairs. The signi cance

of this fact is stated in the following lemma.

Lemma 1.4.11. (Critical Pair Lemma; Knuth & Bendix 70], Huet 80])
A TRS R is WCR i all critical pairs are convergent.

Exercise 1.4.12. Prove the Critical Pair Lemma. (The proof is not hard,
after distinguishing cases as in Figure 1.16, after Le Chenadec 86] where the proof also can be found. Some care has to be taken to deal with repeated variables in left-hand sides of reduction rules.)

Exercise 1.4.13. Prove, using the Critical Pair Lemma: if the TRS R has
nitely many rules and is SN, then WCR and CR are decidable.
So the TRS Rc with rewrite rules as in Table 1.13 is WCR.

1: e x

!x

2: I(x) x ! e

3: 4:

(x y) z I(x) (x z)

! !

x z

(y

z)

8: y e

!y

9: I(I(y)) ! y

10: I(e)

!e

11: y I(y) ! e

12: y (I(y) x) ! x

15: I(x y) ! I(y) I(x)

Table 1.13 Furthermore, one can prove SN for Rc by a `Knuth-Bendix ordering' (not treated here) or by the recursive path ordering explained in Section 1.3. (In fact we need the extended lexicographic version of Remark 1.3.11(3), due to the presence of the associativity rule.) According to Newman's Lemma (1.0.7(2)) Rc is therefore CR and hence complete. We conclude that the validity problem for the equational speci cation of groups is solvable.
The following theorem of Knuth and Bendix is an immediate corollary of the Critical Pair Lemma 1.4.11 and Newman's Lemma:
Corollary 1.4.14. (Knuth & Bendix 70]) Let R be a TRS which is SN.
Then R is CR i all critical pairs of R are convergent.

48 J. W. Klop
Figure 1.16 The completion procedure above by hand was naive, since we were not very systematic in searching for critical pairs, and especially since we were guided by an intuitive sense only of what direction to adopt when generating a new rule. In most cases there was no other possibility (e.g. at
4: z ! I(x) (x z) is not a reduction rule due to the restriction that the
LHS is not a single variable), but in case 15 the other direction was at least as plausible, as it is even length-decreasing. However, the other direction
I(y) I(x) ! I(x y) would have led to disastrous complications (described
in Knuth & Bendix 70]). The problem of what direction to choose is solved in the actual Knuth-
Bendix algorithm and its variants by preordaining a `reduction ordering' on the terms.

Term Rewriting Systems

49

De nition 1.4.15. A reduction ordering > is a well-founded partial or-
dering on terms, which is closed under substitutions and contexts, i.e. if s > t then s > t for all substitutions ; and if s > t then C s] > C t] for all contexts C ].

thenW!e n+Roswathisavees

immediately the the requirements

following fact (noting of De nition 1.4.15):

that

if

R

is

SN,

Proposition 1.4.16. A TRS R is SN i there is a reduction ordering > such that > for every rewrite rule ! of R.

Simple version of the Knuth-Bendix completion algorithm

Input: Output:

{ an equational speci cation ( ; E) { a reduction ordering > on Ter( ) (i.e. a program which computes >) - a complete TRS R such that for all
s; t 2 Ter( ) : s =R t , ( ;E) ` s = t

Rwh:=ile?E; 6= ? do

choose reduce

an equation s = t 2 E;
s and t to respective normal

forms

s0

and

t0

wifitsh0 rets0petchtetno R;

E := E ? fs = tg

else if

s0

else

>i::f==tt00stt>00;h; es0n::t==hset00n

else

failure

;

CP := fP = Q j hP; Qi is a critical pair between the rules in R and ! g;

R := R f ! g;

E := E CP ? fs = tg

od;
success

Figure 1.17

50 J. W. Klop In Figure 1.17 a simple version of the Knuth-Bendix completion algo-
rithm is presented. As to the reduction ordering > on Ter( ) which is an input to the algorithm: nding this is a matter of ingenuity, or experimentation. (Also without reduction ordering, computer systems for KnuthBendix completion equipped with an interactive question for orientation of equations into rewrite rules are of great help.)
The program of Figure 1.17 has three possibilities: it may (1) terminate successfully, (2) loop in nitely, or (3) fail because a pair of terms s; t cannot be oriented (i.e. neither s > t nor t > s). The third case gives the most important restriction of the Knuth-Bendix algorithm: equational speci cations with commutative operators cannot be completed.
Exercise 1.4.17. Show that there exists no complete TRS for the speci ca-
tion of abelian groups as in Table 1.14. (Consider in a supposed complete TRS the normal forms of the open terms x + y and y + x.)

0+x = x
(?x) + x = 0
(x + y) + z = x + (y + z) x+y = y+x

Table 1.14

If one still wants to deal with equational speci cations having commutative/associative operators as in Exercise 1.4.17, one has to work modulo the equations of associativity and commutativity. For completion modulo such equations we refer to Peterson & Stickel 81] and Jouannaud & Kirchner 86].
In case (1) the resulting TRS is complete. To show this requires a non-trivial proof, see e.g. Huet 81]. In the next section we will give an abstract formulation of Knuth-Bendix completion, following Bachmair, Dershowitz & Hsiang 86], which streamlines considerably this kind of correctness proofs.
The completion program of Figure 1.17 does not `simplify' the rewrite rules themselves. Such an optimization can be performed after termination of the program, as follows.

De !

nition
of R

1.4.18. A TRS R is
the following holds:

called

irreducible

if

for

every

rewrite

rule

1. is a normal form with respect to R,

2. is a normal form with respect to R ? f ! g:

Exercise 1.4.19. Prove that every irreducible ground TRS is complete.
(Hint: use Exercise 1.2.19 and Corollary 1.4.14.)

Term Rewriting Systems

51

Theorem
can nd an

1ir.4re.d2u0c.ib(lMe ectoimviperlet8e3T])RSLRet0

R be such

a complete TRS. Then that the convertibilities

we =R

and =R0 coincide.

wanElirnoixetrehme.arrarLceelesinftspoaeerRmcm1t1in.wtb4goie.to2Rhft1hgra.ee.nsoWTptAeRheceStpmrtrfraooeyoRwfa!r1osi?tfseuTfmr0hujee!leot.rhe!Famgutgr1R.t.h41N2e.2droR,0wodectaseahnnnednobepterRco0goo0iinsfv=ttetahnhfianeatlrn!soeonw=rgmrRitta2hteleR,rffou1orlslemjlso=wtoRhiifsn0agatt
follows from the (easy) proofs of the sequence of statements:

1. if s !R1 t then s !+R t;
2. R and R1 de ne the same set of normal forms;

3. R1 is SN;

4. if s R t and t is a normal form then s R1 t;
5. s =R t , s =R1 t;
6. R1 is CR;

7. 8.

if s R1

!R0 t then s
and R0 de ne

!R1 t;
the same

set

of

normal

forms;

9. R0 is SN;

10. if s R1 t and t is a normal form then s R0 t;

11. 12.

Rs =0 iRs1CtR,; s =R0 t;

13. R0 is irreducible.

Instead of optimizing the TRS which is the output of the above simple completion algorithm after the completion, it is more e cient to do this during the completion. Figure 1.18 contains a more e cient Knuth-Bendix completion algorithm, which upon successful termination yields irreducible TRS's as output.
We conclude this section with a theorem stating that the Knuth-Bendix completion algorithm, given an equational speci cation and a reduction ordering, cannot generate two di erent complete irreducible TRS's. According to Dershowitz, Marcus & Tarlecki 88] the theorem is originally due to M. Ballantyne, but rst proved in Metivier 83].

De nition 1.4.22. Let > be a reduction ordering. We call a TRS R compatible with > if for every rewrite rule ! of R we have > :

52 J. W. Klop More e cient version of the Knuth-Bendix completion algorithm

Input: { an equational speci cation ( ;E)

{ a reduction ordering > on Ter( )

Output:

-

a s;

cto2mTpelert(e

)ir:resd=ucRibtle,TR(S

;REs)u`chs

that =t

for

all

Rwh:=ile?E; 6= ? do choose an equation s = t 2 E;
reduce s and t to respective normal forms

while E 6= ? do

choose reduce

an equation s = t 2 E;
s and t to respective normal

forms

s0

and

t0

wifisth0 rets0petchtetno R;

E := E ? fs = tg

elseif s0 else else

>i:f=:=tt00stt>00h;; es0n:t:==hets0n0

failure

;
R := f

! 0j

!

2 R and ' is a normal form of

with respect to R f ! gg;

CP := fP = Q j hP; Qi is a critical pair between the rules in R and ! g;

E := E CP f = j ! 2 R and is reducible by

! g ? fs = tg;

R := R f ! g ? f ! j is reducible by ! g

od;
success

Figure 1.18

TduhceibolreeTmRS1'.s4.c2o3m.p(aMtibetleivwieirth8a3]g)ivLenetreRd1ucatniodnRo2rdbeerintwgo>c.omSupplpetoeseirRre1-

aanrdenRa2mdineg

ne of

the same convertibility. variables).

Then

R1

and

R2

are

equal

(modulo

Exercise 1.4.24. (Huet 80]) In this exercise we collect some criteria for
con uence in terms of properties of critical pairs, as well as some counterexamples,

Term Rewriting Systems

53

from Huet 80]. Also some questions are listed which are, as far as we know, open. See Table 1.15.

Table 1.15

1.

In row critical

1 of pair

htth;esitaisblceonthveergCernittic(anlotPaatiironL:emt #msa),1t.4h.e1n1

is stated: if WCR holds.

every How-

ever, CR need not to hold; a counterexample is given by the TRS with four

constants a; b; c; d and rules as in Figure 1.3.

2. Row 2 of the table is Theorem 1.4.14 of Knuth and Bendix.

3. In row 3, LL means that the TRS is left-linear, RL right-linear (i.e. no right-hand side of a reduction rule contains repetitions of a variable). Strongly con uent is de ned in Exercise 1.0.8(10).

We furthermore de ne:

DarEeFtI0N, ItT00 IsOuNch.

A TRS that t

is

strto0 ngly

closed if for s and s

evte0r0 y

every t.

critical pair ht; si there
Prove that `strongly

closed' is not su cient to guarantee CR, by considering the non-left-linear TRS

fF(x; x) ! A; F(x; G(x)) ! B; C ! G(C)g. However, if the TRS is left-linear,

right-linear and strongly closed, then CR holds (for a proof see Huet 80]); in

fact, we then have strong con uence.

4. In 3, RL cannot be dropped. A nice counterexample is in Huet 80], given by J.-J. Levy: it contains the following eight left-linear rules. See also Figure 1.19.

F(A; A) FAF((Ax;0A; x0))

! ! !!

GA0(B; B) F(x; x) F(x; x)

G(B; B) GGB((Bx;0B; x0))

! ! !!

FB(0 A; A) G(x; x) G(x; x)

Check that CR does not hold, and that the TRS is strongly closed.

54 J. W. Klop

Figure 1.19

5. This is a remarkable fact: if the TRS is left-linear, and for every critical
pair ht; si we have t !jj s, then WCR 1 holds, and hence CR. Here !k
(parallel reduction) denotes a sequence of redex contractions at disjoint

occurrences.

6,7,8.

If in 5
Loriksew!ise

we (7) t".

replace
if t !k

t s

i!s rkepslabcyedsby!sk !t,

then the t, or (8)

CR question replaced by:

is \t

!opens.

Exercise 1.4.25. Knuth & Bendix 70] contains completions of two speci -
cations which closely resemble the speci cation of groups (see Table 1.16), called `L-R theory' and `R-L theory'. Prove, using the completions, that x e = x is not derivable in L-R theory and that in R-L theory the equations e x = x and x I(x) = e are not derivable. Furthermore, in L-R theory the equation x e = x is not derivable. Hence the three theories are di erent, i.e. determine di erent varieties of algebras. In fact, note that the variety of groups is a proper subset of both the variety of L-R algebras and that of R-L algebras, and that the latter two varieties are incomparable with respect to set inclusion.

1.5 An abstract formulation of completion
(This section is taken from Klop & Middeldorp 88].) There are many completion algorithms such as the two above (in Figures
1.17 and 1.18), di ering in order of execution or ways of optimization. The question is, how to prove that these algorithms are correct, i.e. deliver upon successful termination indeed a TRS R with the same equality as the one generated by the original set of equations E. As there is a whole family of completion algorithms, one needs to extract the `abstract principles' of such algorithms; and this is done indeed by Bachmair, Dershowitz & Hsiang 86]. Their method for proving correctness of completion algorithms starts with the introduction of a derivation system where the objects are pairs

Term Rewriting Systems

55

group theory

L-R theory:

R-L theory:

e x=x

e x=x

x e=x

I(x) x = e

x I(x) = e

I(x) x = e

(x y) z = x (y z) (x y) z = x (y z) (x y) z = x (y z)

completion:

completion:

completion:

e x!x

e x!x

x e!x

x e!x

I(x) x ! e

I(x) x ! e

x I(x) ! e

x I(x) ! e

(x y) z ! x (y z) (x y) z ! x (y z) (x y) z ! x (y z)

I(e) ! e

I(e) ! e

I(e) ! e

I(x y) ! I(y) I(x) I(x y) ! I(y) I(x) I(x y) ! I(y) I(x)

x (I(x) y) ! y x (I(x) y) ! y

e x ! I(I(x))

I(x) (x y) ! y I(x) (x y) ! y

x I(I(y)) ! x y

I(I(x)) ! x

x e ! I(I(x))

I(I(I(x))) ! I(x) I(I(I(x))) ! I(x)

x (y I(y)) ! x

I(I(x)) y ! x y

x (I(I(y)) z) ! x (y z)

x (y (I(y) z)) ! x z

I(x) (x y) ! I(I(y))

Table 1.16

(E; R); each derivation step from (E; R) to (E0; R0) preserves equality:

=E R coincides with =E0 R0; and moreover, along a sequence of derivations

the actual proofs of equations s = t will be getting `better and better', with

as optimal proof format that of a \rewrite proof". See Figure 1.20, where

iptaiirsss(hEow0;nR0h)otwo

E (that is the a TRS R (that

pair (E; ?)) is gradually is the pair (?; R)); along

transformed the way the

via two

example proofs in Figure 1.20 get more and more oriented until they are

in rewrite form. (Here direction is downward; horizontal steps are without

direction.)

There are two crucial ideas in this recent approach. One is the concept

of a derivation system on pairs (E; R) as discussed above. The other is the

concept of ordering the proofs of equations s = t according to their degree

of orientation. We will now proceed to a more formal explanation.

56 J. W. Klop

Figure 1.20

De nition
application there exists

1.5.1. Let (
of exactly one a context C

; E) be an equational speci cation. If s

equation in E we ], a substitution

write and

asn$eqEuta.tioSno

s u

$==EEvtt(boiyr

v = u) in E such that s C u ] and t C v ]:

De nition 1.5.2. Let ( ; E) be an equational speci cation and R a TRS

with signature :

1. A proof in E R of an equation s = t between terms s; t 2 Ter( ) is

2.

a0Ai <sseuqijbupernonconefw:ooeTffhhtPaeevrmenoss(tis?(a0st1;0io:;$n:: ::E;:Ps;snsPin), )0s]isis?mua1cehpa!rntoRshoatfsthiPasot00r

s; sn t, and for all si?1 R si: P 0(sisi;a: :s:u; sbjp)rowoifthof0P .

(Actually, as occurrence of a subproof of P.)

3. A proof of the form s0 R sk R sn is called a rewrite proof.

By de nition, P (s) is a proof of s = s. Figure 1.21 contains an example of a proof.
Knuth-Bendix completion aims at transforming every proof (s0; : : :; sn)

Term Rewriting Systems

57

Figure 1.21

ifnotroKanurtehw-rBiteendpirxoocof ms0pletiotn.

Tshne.obWjeectnsoowf

present an this system

inference are pairs

system (E; R).

The inference system BC (basic completion) has the following rules (see

Table 1.17); > is a reduction ordering.

(C1) o(Erien0tfinsg=a0ntge;qRua)tio)n (E; R fs ! tg) if s > t

(C2)

adding an equation
(E; R) ) (E

fs = tg; R)

if s

R u !R t

(C3) (C4)

s(Eimpl0iffysin=g0

an equation
tg; R) )

(E

fu = tg; R)

d(Eeleti0nfgs

a trivial equation
= sg; R) ) (E;

R)

if s !R u

Table 1.17

The notation s =0 t means s = t or t = s; the symbol 0 denotes

pd(SEriNso1joIo;ttfRhisnei1tsin)nue)sanEosiio0i(lsnyE.R2sR;eA00eRanaB2nr)Ctdeh)-daifnute,rrgtigvheiane.vtreeWimrnoanoelar`wiesdsire=mairtEiepvlna)eRtirti'+oectnoohfiorsantrncienitpdihneen(sEEittwr;eaRitsnheR)sqi).t=uievFEn(eo0EcrceR0le;o0(xR.sEauH0m0r)e;,opRwiofl0efeR),v)eb)riy.s,

adding can be

equations to E by
replaced by s $E0

inference rule C2 some subproofs t. To formalize this reduction in

csompRleuxit!y Rwet

introduce orderings on proofs.

De nition 1.5.3.
implies P Q] P

QA0]bfionraaryll

relation proofs P;

QoanndprQoo0.fsTishemroenlaottoionnic

if

Q is

Q0 stable

if

P (s; : : : ; ui; : : :; t) (s; : : : ; vj; : : :; t) Q

implies that

58 J. W. Klop

(C s ]; : : :; C ui ]; : : :; C t ]) (C s ]; : : :; C vj ]; : : :; C t ]) for all proofs P and Q, contexts C ] and substitutions . A proof ordering is a stable, monotonic, well-founded partial ordering on proofs.

Exercise 1.5.4. To illustrate the concept of proof ordering we will give an
alternative proof of Newman's Lemma 1.0.7(2) using this notion. (`Alternative'

with respect to the proofs that we have seen in the literature. The present proof

is nevertheless well-known.) See also Exercise 1.3.15 for our multiset notations.

of

Let R be a TRS the conversion s0

which = sn.

is SN and We de ne

WCR. Let P the complexity

j(Ps0;j

::: of

; sn) the

be a proof

proof P as

the multiset s0; : : multiset extension

:o;fs!n]+R. ,Tnhoetaotriodne:rin(!g +R)

which . So

we

will

use

is

induced

by

the

P P0 i j P j (!+R) j P0 j :

(This means that P P0 if the multiset j P0 j arises from the multiset j P j

by repeatedly replacing an element of the multiset by arbitrarily many elements

which are less in replacing a term

the t in

sense of the the multiset

well-founded ordering of terms by a number

!( +R0.)Io.ef.

by repeatedly proper reducts

of t.)

1. Prove that is a proof ordering.

2.

IecfqonuPvaetriosni(osn0s;0P: :=,:a;nssdnn)rseiuspclnhaoctethaiattrbePywrait`evaplPlreo0y.o'f,,(uHtshiinnentg:

there is a proof P0 of the consider a `peak' in the WCR. See Figure 1.22.)

3. Conclude that R is CR.

Figure 1.22 The proof ordering which we use for completion is based on the given
reduction ordering and on the elementary steps (!R; R or $E) in a
proof.

Term Rewriting Systems

59

De nition 1.5.5.

1. The complexity j P j of a proof P (s0; : : :; sn) is the multiset

mc(esn0t;asr1y);p:r:o:o;fc(sstnep?,1;issnd)e]

wn8<hedersebiy?c1(s] i?1;

si), the if si?1

complexity
!R si

of

an

ele-

c(si?1; si) = :

ssii?] 1; si]

if if

ssii??11

$RE

ssii

2. To compare the complexities of the elementary proof steps we use the multiset extension > of the reduction ordering >. (See Exercise 1.3.15.) To compare proof complexities we use the multiset extension of > ; notation: > : Now we de ne:
P BC P0 , jP j> jP0j :

D(eExei0s;tRsn0ia)tipiomrnopo1lfi.e5Ps.0t6ho.aftAsf=oprrtoeovinferoEyrd0perroiRnogf0

is compatible with BC if

P in such

E R of that P

an P

e0 qouraPtion

(E;

s P

0=:

R) )+
t there

The following proposition has a straightforward proof, which follows from considering Figure 1.23 and applying stability and monotonicity of
ccaasts]B;ieoCson.]f]FoCwfig2ahu(itrcsreheaen1d.sFe2fico3grruesmauresagetg1sie.o2stnto3ss)tththehopewecacocpomcrmoopropdlfelisexnxaigtirtyetyooroeCffdt1tuh;hce:ee:sds:uu;biCbnpp4rc:roooFomooffrpttilne$xstiRRtaynuscb,e!yn, aaiRnmpuptehlliiyes-
t; u]]. This is indeed a decrease since s] > t; u].

Proposition 1.5.7. The ordering over is compatible with BC.

!BC

is

a

proof

ordering,

which

more-

in

So Ej

in a Rj

BaCre-dneorivmaotiroend(iE0c;uRlt0t)h)an(Eco1r;rRes1p)o)ndi(nEg2;pRro2o)f)s in

the proofs Ei Ri; for

all j > i. The following fairness property of BC-derivations implies that

moreover every proof in Ei Ri of an equation s = t which is not yet a

rewrite proof, can be simpli ed to a rewrite proof of s = t in Ej Rj for

some j > i:

Di12s..ecalnlTi(eifCdtjhiP>cfoa;jinidErii1sji.2ft5=h.T8e?.jsefAtoi CroBfaPClaj-lldlifeocrrriivst0aoi,ctmaaiolnendpi(aEir0s0;bRteh0t)ewn)eecn(=Eth1de; R2re1Ew) k)ritfeo(rErus2ol;emRs 2eo)fk)Rj.0).

So, according to (2) every critical pair which arises will be (or was) an equation at some time, and by (1) every equation will be `considered'

60 J. W. Klop

Figure 1.23

eventually, that is, oriented in a rewrite rule, simpli ed, or deleted. The following fact can now be proved routinely.

Proposition 1.5.9.

BC-derivation and let

rewrite proof such that P

thBeCnPfo0r.

LsPoemtb(eeEja0;pRri0ot)ohf)eoref(Eesx1=i;sRtts1ia)np)Eroi(oEf 2PR; R0i.i2n)IfE)Pj

be a fair is not yet a Rj of s = t

By a completion procedure we mean a strategy for applying the inference

rules of BC to inputs ( ; E) and reduction ordering >, in order to generate

caaBusCe-dfoerrivsoamtioenin(pEu0t;sRa0)fa)ir d(eEri1v;aRti1o)n)may

nwotitbhe(pEo0s;sRib0l)e,=we(Eal;l?ow).

Befor a

completion procedure to fail. We say that a completion procedure is fair if

it generates only fair derivations unless it fails. We now have:

Theorem 1.5.10. (Bachmair, Dershowitz & Hsiang 86]) Let C be a fair
completion procedure that does not fail on input ( ; E) and > :
1. If s =E t then C will generate a pair (Ei; Ri) such that s and t have

Term Rewriting Systems

2.

Ra 1com(=mSonn

reduct Rn) is

in Ri: a complete

TRS.

61

1.6 Uni cation

In the preceding sections about completion algorithms, we have used as a `subroutine' the determination of a most general uni er of two terms. In the present section we will describe a version of a uni cation algorithm, due to Martelli & Montanari 82]; this nondeterministic algorithm to compute mgu's is itself phrased in the terminology of rewriting. We start with presenting the rewrite rules for `syntactic uni cation', and afterwards extend these rules to include `semantic uni cation' or `E-uni cation'.

Syntactic uni cation

Before presenting the syntactic uni cation algorithm, we introduce some

more concepts about substitutions, which were de ned in Section 1.1 as

homomorphisms (with respect to term formation) from the set of terms

Ter(R) of the the usual one

TRS R to Ter(R). for functions: (

The )(t)

composition of = ( (t)) for t

s2ubTsetrit(uRt)i;onhsowe; veris,

will be written as , and in accordance with our earlier notation

convention, (t) as t . Note that this notation is unambiguous: (t ) = t( ):

The support of substitution is the restriction of to the set of those

variables this case

wxei

fworritwehich(bxyis6omxei

. Usually, the support will be nite, and in `abus de langage') as its support, which is a

nite list of `bindings' of terms to variables:

fxi1 := ti; : : :; xin := tng:

A renaming substitution is a bijective substitution. This implies that a

rtreaenntiaaommn iionnfgg,,Vraaenrsdt.ritNchtoaettdettthoheatithnetvheserestceoofm?vpa1orosiaiftbiaolenrseVnaamrofi=nrgefnxaimejxiiinsgtss0agn;, disiissa

permuagain a again a

renaming. Terms s; t di ering a renaming, i.e. t s for some renaming

; are called variants (of each other).

If t; s are terms such that t s for some substitution ; we write

t s. The relation is not yet a partial ordering; it is a quasi-ordering,

also called the subsumption relation. One easily proves for all s; t 2 Ter(R):

s t & t s , s; t are variants. For substitutions ; we write if

= for some substitution . In this case is called more general than

. (The `overloading' of the symbol will cause no confusion.) Analogous

to the case of terms, one easily proves: & , ; di er a

renaming ( = for some renaming ).

62 J. W. Klop

We call most general

a uni er of a uni er (mgu)

soeftTofiftefromr sevTery=ufnt1i;

:::; er

tonfgTif

wt1e

hatvne.

It

is

a .

Each nite set of terms which can be uni ed (has a uni er) has a mgu; it

is unique modulo renamings.

wFs1a(;ss:T1:g;h:i:;ve:te:tnn;ass=bkny)osMcnfagan.nrdbtAeielnlvgiv-ieMearwymoenedotlsaeatgnsgaatenrhniteea8rtala2gls]o.kurnIoittifhcsmeoornlvoesiixfnspttgwslotooihtfteienrsrugemltetssohFfiwse(hqtri1uecp;ah:rt:eitos:re;nantsnntsfa)fttoa1irnom=nd

one set of equations into another one. To conform with the notation in

`equational logic programming' as in Holldobler 89], we write instead of

ft1 = s1; : : :; tn = sng :

( t1 = s1; : : :; tn = sn;

called also an equational goal. The empty goal (empty set of equations) will be denoted as . The algorithm to be presented transforms, nondeterministically, goals into goals; just as in logic programming we intend to end a sequence of transformations in the empty goal:

G0 G1

:

Here denotes an elementary `derivation' step; G0; G1; : : : are equa-

tional goals. Actually, at some of the -steps we may obtain as a `side-

e ect' a substitution step has the form G

;

iGt 0w. iSllobae

denoted as a subscript, derivation may have the

so that such form, e.g.:

a

G0 G1 1 G2 2 G3 G4 G5 5 G6

:

Derivation sequences ending in are successful; it will also be possible that a derivation is stuck and cannot be prolonged to reach , because no transformation rule applies. In that case we conclude the sequence after the goal where the sequence got stuck, with the symbol (for `failure'):

G0 G1

:

In the case of a successful derivation, we can obtain the `harvest' by com-

posing all the substitutions that are found, in their order of appearance; in

sthubesetixtaumtiopnleoafbtohvee:suc1ces2sf5ul

. This substitution is the computed derivation that we are considering.

answer

We will now present the four derivation rules for equational goals that

together constitute a uni cation algorithm. With some adaptations, these

`Martelli-Montanari rules' (MM-rules) are as follows. Here ( t = s; E

stands for an equational goal containing the equation t = s; with E we

denote the remaining equations in the goal.

Term Rewriting Systems
1. Term decomposition

63

( F (t1; : : :; tn) = F (s1; : : :; sn); E
( t1 = s1; : : :; tn = sn; E 2. Removal of trivial equations

( x = x; E ( E

3. Swap

( t = x; E ( x = t; E
if t is not a variable

4. Variable elimination

( x = t; E if x 62 t

fx:=tg ( Efx:=tg

(`2If'

Ewe ias btb1re=viast1e;

: : :; tn = sn; then E `occurs in'. Note that

oinslyt1in=trsa1n;s:fo:r:m; tanti=on

srnu.le

With (4) a

substitution is delivered.)

We have the following well-known `completeness' theorem:

Theorem 1.6.1. (Uni cation Theorem) Let G be an equational goal ( t1 = s1; : : :; tn = sn. Then the following are equivalent:
1. the equations in G can be uni ed; 2. there is a mgu such that t1 s1 ; : : :; tn sn; 3. the derivation tree with root G and constructed with the MM rules
is nite and has only success branches, all yielding an mgu of the equations in G as computed answer substitution. Furthermore, if the equations in G cannot be uni ed, the MM-derivation tree with root G is also nite, but now with all branches ending unsuccessfully.
(It will be clear what is meant in the statement of the theorem above with derivation tree; it arises because the rules can be applied nondeterministically.) In the original presentation of Martelli and Montanari, the following two rules are also included; they enhance e ciency, by pruning the MM-derivation tree of some unsuccessful subtrees. But we don't need them for the completeness of this (nondeterministic) uni cation algorithm. (Also, when extending the set of rules to deal with E-uni cation, as we will do below, (5) and (6) must be omitted.)

64
5. Failure rule

J. W. Klop

( F (t1; : : :; tn) = G(s1; : : :; sm); E 6. Occur check

( x = t; E if x 6 t and x 2 t
It is not hard to prove that the MM rules are indeed terminating, as stated by the Uni cation Theorem. (See Martelli-Montanari 82], Apt 90], or Dershowitz & Jouannaud 90].)
If t; s are uni able terms we will denote with mgu(s; t) a particular
mgu of fs; tg, obtained by performing the MM transformations according
to some xed strategy.

Example 1.6.2.
1. We want to determine `the' mgu of the terms F(G(x); H(x; u)) and F(z; H(F(y; y); z)). The MM rules yield the following successful derivation:

( F(G(x); H(x; u)) = F(z; H(F(y; y); z)) ( G(x) = z; H(x; u) = H(F(y; y); z) ( z = G(x); H(x; u) = H(F(y; y); z) ( H(x; u) = H(F(y; y); G(x)) ( x = F(y; y); u = G(x) ( u = G(F(y; y))

(1)
(3)
(4);fz:=G(x)g
(1)
(4);fx:=F (y;y)g (4);fu:=G(F (y;y))g

with computed answer substitution fz := G(x)gfx := F(y; y)gfu := G(F(y; y))g = fz := G(F(y; y)); x := F(y; y); u := G(F(y; y))g. In-
deed this is a mgu of the original pair of terms. 2. A failing uni cation attempt:

( F(x; y) = F(y; G(x)) ( x = y; y = G(x) ( y = G(y)

(1)
(2);fx:=yg
(6)

Semantic uni cation

In the previous section we have presented an algorithm to solve equations

tt1o

=soltv2e`seyqnutaatciotincsal`lsye'm; tahnitsiciaslaly'p,air.tei.cumlaordcualsoe

of the important problem some equational theory E

(for this reason semantic uni cation is also called E-uni cation). More

Term Rewriting Systems

65

precisely, in the presence of an equational theory E, and given an equa-

teEiqo-uuninvtia1lce=anttiltoy2n,(swweieethTwehamneotprtteyomE1n..d4.2s)ubEst`itutt1io=nst2

.

such that E So syntactic

unti1

c=atito2n

or is

The situation is now much more complicated than for the case of syn-

tactic uni cation, since in general there will not be a most general uni er

Siefokrmta1n; tn2.

We will not really enter the vast area of uni cation theory (see 84]), but will mention two algorithms for E-uni cation which

are pertinent to term rewriting. Both algorithms operate under the as-

sumption that E, the underlying equational theory, is a complete TRS (or

rather corresponds to one after orienting the equality axioms of E into

rewrite rules). So here we have another important application of Knuth-

Bendix completion: it prepares the way for equation solving over E, by

delivering a complete TRS for E (if possible).

Narrowing

A well-known technique equational theory E uses

ttoheso`nlvaerreoqwuinatgi'otnrsants1fo=rmt2atiinonthone

presence of an terms. We will

give an `intuitive' explanation rst, which also explains why narrowing is

called `narrowing'.

of

If ( the

; E) is an equational theory, we write
equation t = s in E, i.e. f j E `

t t

==s]Es

for the set of solutions
g. A solution is a

substitution as de ned earlier, i.e. a map from V ar, the set of variables,

to Ter( ). Let Sub be the set of all substitutions, and if X Sub, let

X denote f j 2 Xg. Now noting that for every we have t = s]E

t of t rst

= = is

ssa]sE]E.ju,Tstthhiedsreesstcierspibiwneidpse:ridngecutiepesrlsemtaihnceaotpmioopsnsoicnboeinlnisttiystosfooaff

stepwise determination two kind of steps. The a solution and narrow

tthe=ssid]Eestoof

t the

e=qusat]iEon.

The t=

second s under

is: apply an equation of E in consideration. Clearly, a step

one of of the

second kind preserves equality of the solution set. By an iteration of such

steps, alternating between steps of the rst kind and steps of the second

kind, we may reach the solution set of a trivial equation r = r (which is
Sub):

t = s]E

t = s ]E = r = s ]E 1 r 1 = s 1 ]E =

1 n r = r]E:

The last solution set a most general element

1
the

subnstritu=tior]nE

of this
1

`narrowing' chain has as n. The word `narrowing'

has been given a formal content: it denotes a certain method, based on

66 J. W. Klop

term rewriting, to perform a stepwise determination scribed. A narrowing step combines a step of the rst

koifndta=ndso]nEe

as of

dethe

second. Actually, the narrowing relation is rst de ned on terms rather

than equations, as in the following de nition, where we suppose that R is

a TRS equivalent to E (i.e. =R coincides with =E). Note that narrowing

is a generalization of reduction: any reductions step in a TRS is also a

narrowing step. Formally:

De nition 1.6.3. Let term
context C ]. In the presence

t contain the subterm u, of a TRS R we say that

so t t is

C u] for narrowable

stoomte0

at=thme g(nuo(unv; ta1r)ia, biflet)0

subterm C t2]

u .

t using Notation:

rewrite t ;u;r;

rutl0e.

r(S:otm1 e!timt2es2wRe,wviilal

drop mention of u; r; but not of .)

Figure 1.24

tsweo=rmrWdts0n,eaatrnoreroeowsqwauiiednaxtgttieooanncbdtseu: atnihflaletyrr;nroeawfreirrntos0gw,ttoishntteeghpnesttrs(ao=onlnussfteoi;qormunasatteti0tioos=n:ns,si)f.watAnh=dsicshwlik;ewehwaasitvs0eed=esse=snenetd,t;htohenne

dte=tersm]Rining

tthe=soslu]tRio.nNsoett,e

how rst

narrowing cuts down the search space for by using the directional aspect of a TRS,

and second by performing substitutions which are as `small' (as general)

as possible. However, there is a price to be paid: to ensure completeness

Term Rewriting Systems

67

of the narrowing method for solving equations, we must require that the uosttpthornoadasdaretsetiricrbtnlotnlygoemianfssprnoogoldllevTmutetteRi0ntaoTShnnaeRisresegSqo.iuf.vsRy.aetc,tnhnoitewoemanqeecpquttciula1aceatatn=iteloil.conyto01Mnnuu.isnonnWtrtiraeiulenapcabwrtenelqieacleu.lilqslameuItpnlaiyaootksfni(asoeaaicnbsltthlt,stehtinwsaen=toemaerrdayotr0nrroiEeenwi,spsHiuncrouoergbecrltlrdioasteeetiosrn,pie8vvod0anina]tdds)iu:otinahcnihlngesl following de nition.

De nition 1.6.4. Let ; be substitutions and E an equational theory.

Then
E`x

E if for some = x for all x.)

we have

=E . (Here

=E means:

Now we have the following completeness theorem for narrowing plus syntactic uni cation. (See Martelli, Moiso & Rossi 86], Theorem 2. See also Holldobler 89] for a proof of this theorem and many related facts.) The formulation of the theorem refers to a slightly more general setting than in our discussion of narrowing above: the narrowing procedure may be applied
not only to single equations, but to equational goals ( t1 = s1; : : :; tn = sn.

Tsasteehqspouesleoun(rt1cieoe{mn4s)to,1afs.ru6ttchi.nh5eg.tehqwLaueitatthttRhioe(nbceott1m1a=pc=uottm2et)d2p. laeaTntnehsdweTneuRrstiSshnu.egbrSesuntpiaitspruroatosiwoseunitnc1cge=osssftRfetuphtlsi2sda(seienr.qiedvu.aeMtniocMines
`improves' , i.e. R :

Remark 1.6.6.

1.

Note that the subscript R in
ff(b) ! g(b); a ! bg. Now

=

Rfx=aigs

necessary. (Example: R
is a solution for ( f(x)

= =

g(x), but as computed answer substitution we only nd = fx=bg:)

2. Also completeness of R is necessary.

(a) To see that con uence of R is necessary, consider the TRS R =
fa ! b; a ! cg (so R is not con uent). Now the equation ( b =
c cannot be solved, i.e. we do not nd the expected computed

answer substitution (the identity substitution). However, if we turn R into a con uent system, e.g. by adding the rewrite
rules b ! d and c ! d, then narrowing (together with syntactic uni cation) gives a refutation of ( b = c:

( b=c ; ( d=c ; (d=d 1 :

(b) To see that termination of R is necessary, consider the con u-
ent but nonterminating TRS with one rule: c ! f(c). Now
narrowing plus syntactic uni cation is not complete: the equa-
tion x = f(x) has a solution, fx := cg, but cannot be resolved,

68 J. W. Klop
because the only subterm where narrowing may be applied is f(x) (narrowing may not be performed on a variable) and this does not unify with c. (Also syntactic uni cation does not help, since x occurs in f(x).) So we do not nd a computed answer substitution. 3. Theorem 1.6.5 can be improved in the following sense: we can drop the termination requirement on R, thus only requiring R to be con uent, if we consider only normalizable solutions (as in the statement of the theorem above). Here is called normalizable if all terms x
(x a variable) have a normal form. (Note that the solution fx := cg
in 2(b) was not normalizable.) If moreover we consider not only normalizable solutions ; but normal (meaning that every x is in normal form), then we can even drop the subscript R in R , in the statement of the theorem above.

Lazy term rewriting as a complete E-uni cation algorithm
An interesting complete E-uni cation algorithm is given by Martelli, Moiso & Rossi 86], also for the case where E corresponds after orienting the equations to a complete TRS R. The nondeterministic algorithm consists of the four derivation rules (1){(4) for syntactic uni cation as given above together with a single rule called `term rewriting' in Martelli e.a. 86]. Of course derivation rules 5 (failure rule) and 6 (occur check) are not included now. Actually, this rule does not resemble what is usually called term rewriting. Here we will call the present rule `lazy term rewriting'.
7. Lazy term rewriting

( C F (t1; : : :; tn)] = s; E

(

C

t] = if

s; t1 = s1; : : : F (s1; : : :; sn)

!; tnt=

sn;

E

and C t]

likewise with the reverse of the equations = s. Here C ] is some context, and F (s1; : :

:C; sFn)(t!1;

:::; t is

tanr)e]w=ritse

and rule

from the complete TRS R.

Note how amazingly little is `done' in a lazy term rewriting step, as

compared to the rather complicated narrowing procedure.

2 Orthogonal Term Rewriting Systems
In the preceding sections we have considered general properties of TRS's and how these properties are related; among them the most important property, con uence, with its consequence of uniqueness of normal forms.

Term Rewriting Systems

69

We will now consider a special class of TRS's, the orthogonal ones (in the literature mostly known as non-ambiguous and left-linear TRS's), which all have the con uence property as well as various other desirable properties concerned with reduction strategies.
A remark concerning the choice of the word `orthogonal': to avoid the cumbersome phrase `non-ambiguous and left-linear', Klop 80a] introduced the abbreviation `regular'. This terminology is also used in e.g. O'Donnell 85], Kennaway 89], Klop 87], and in early versions of Dershowitz & Jouannaud 90]. On a proposal of Dershowitz and Jouannaud the word `regular' has been replaced in the present paper by `orthogonal'; this in view of the fact that many authors found the terminology `regular' objectionable. Indeed, the word `orthogonal' has the right intuitive connotations.

2.1 Basic theory of orthogonal TRS's

De nition 2.1.1.
1. A TRS R is orthogonal if the reduction rules of R are left-linear (R is left-linear) and there are no critical pairs.
2. R is weakly orthogonal if R is left-linear and R contains only trivial
critical pairs, i.e. ht; si is a critical pair then t s.

We recall that a reduction rule t ! s is left-linear if t is linear, i.e. no variable occurs twice or more in t. E.g. the rule D(x; x) ! E is not left-linear; nor is the rule if x then y else y ! y. A TRS R without critical
pairs is also called non-ambiguous or non-overlapping. One problem with non-left-linear rules is that their application requires a test for syntactic equality of the arguments substituted for the variables occurring more than once. As terms may be very large, this may be very laborious. Another problem is that the presence of non-left-linear rules may destroy the CR property.

Exercise 2.1.2. Let R consist of the rules D(x; x) ! E, C(x) ! D(x;C(x)),

A ! C(A). To show: R is WCR, but not CR; for, we have reductions C(A) E

and C(A) C(E) but C(E), E have no common reduct. There are no critical

pairs in R. Hence, in view of our later theorem con uent, the non-con uence of R is caused by

stthaetinnognt-hleaftt-olirntehaorgrounlael DT(RxS; 'xs)a!re

E.

In the preceding section (De nition 1.4.9) we have already de ned the notion of `critical pair'. Since that de nition is often found di cult, we will now explain the absence of critical pairs in a more `intuitive' way. Let R be the TRS as in Table 2.1:

70 J. W. Klop

rrr321

F(G(x; S(0)); y; H(z)) G(x; S(S(0))) P(G(x; S(0)))

! ! !

x 0 S(0)

Table 2.1 Call the context F (G( ; S(0)); ; H( )) the pattern of rule r1. (Earlier, we de ned a context as a term with exactly one hole , but it is clear what a context with more holes is.) In tree form the pattern is the shaded area as in Figure 2.1. For a left-linear rule it is only its pattern that `counts'.

Figure 2.1

Figure 2.2 The TRS R in Table 2.1 has the property that in no term patterns can overlap, i.e. R has the non-overlapping or non-ambiguity property. Figure 2.2 shows a term in R with all patterns indicated, and indeed they do not overlap.

Term Rewriting Systems

71

Overlap can already occur in one rule, e.g. in the rule L(L(x)) ! 0;
see Figure 2.3(a). An overlap at the root (of the tree corresponding to a
term), arising from the rules F(0; x; y) ! 0, F(x; 1; y) ! 1, is shown in
Figure 2.3(b). Another overlap at the root, arising from the rules for the
non-deterministic or: or(x; y) ! x, or(x; y) ! y, is shown in Figure 2.3(c).

Figure 2.3

We will now formulate and sketch the proofs of the basic theorems for

orthogonal TRS's. To that end, we need the notion of `descendant' in a

reduction. Somewhat informally, this notion can be introduced as follows:

Let t be a term in a orthogonal TRS R, and let s t be a redex whose head

symbol we will give a marking, say by underlining it, to be able to `trace' it

during a sequence ibsymcaornkterdacatsioFn(to1f;

of reduction (rewrite) steps. Thus if s

:re: d: ;etxn)s.0

First in t.

consider the rewrite step We wish to know what

t !F (st0 1t;0,: :o:b;ttani)n,eidt
has happened in

tddCtCChheiaaasiepsassseeeempsnpt231daee...irpanksTrTget0ehdohdioeestrniheonaodtecchceptcm0uxeru;orrarstrpre0r,eeelkndraunecotncdseieeauvsssrlebetotnoedpeforferoestxmssd0ica,stonoai.inonfndTntdtatsshhi00sen.oecfmifoanosinalnlatrcounkiwaneddrddieenes.rgr0deTliidicsnnhaejeesxotdeni:ssnstt(cy.hsameonTbmshbo0eaelin.rsdkwaiesdetsiurnebgndtudeeirxsbmhahecadoksf,

one of the arguments of s). Then we nd back the marked redex, with some

oCampffoatusReslserti;ibtp4olhle.tieehcsd`ehirniafwsotneiragsreenspoaitrmnlho'epeoceonmnrneatsorurafkb0cettte;dhireoimrfneandroogeff=xussm0c00..o)e,unTstldshi.sehn(eaHrvtaehesreeesdtmwoipeanprnketee0d.eddbTretehihdneeegxroearsdtruhiescodtgneoxtn0tiainmnloitewtys0

contains n copies of the marked

Now the marked the reduction step t

r!edse0 xte0s.

in It

rte0 daerxe,

all of called

them still marked. the descendants of

is obvious how to extend this

s de

t in nition

72 J. W. Klop
bt(yn?t1r)an!sist(inv)itty(n)t:o sequences of rewrite steps t !s0 t0 !s00 t00 ! !
Proposition 2.1.3. Let R be a orthogonal TRS, t 2 Ter(R). Let t con-
tain, possibly among others, the mutually disjoint redexes s1; : : :; sn. Let
(rcosttweuhiobodnpethnusatpiercciooanhtsrfceeettdsadi0tt0olei0hlflnxrlaoroeteofasmdfrttbee0ac;xelmotel0nms0dtut0ectarsisuaairsckcnae(ttelnihlidbnyndeegabdssnyofierostmqejsuuduoenneioenddxnfotecrs)srbed.l.yiieonnTr(fci)Sthno,n0eegnaeartnrtferFethdawediecrrguitlirueicttntehrthgeieotesatn2ir!ende.p4tds0(sstuay00oct)mt0b.a0i)tboltbal0noT0ie0mln.htceaaeodFnrnrukbesreatwiyt0ds.htrccsieorotremenomdtfmesroxttareohecepnse-,

Figure 2.4

The proof is a matter of easy casuistics, left to the reader. An immediate corollary is the `Parallel Moves Lemma':

ccoLooretnnmhttorrmaagccoattniiooa2nnl.T1oin.fR4rtS.e00.d(oeLPfxeaatsrlla.tldTleehlsceMten0n0o,davaaecnnsotdmsLlmeoemftormntedr!aee)dxsusWtc,0twebthe0c00iocanohfsoiatnd0r;eeetr0sm0treceupadtnuuracebtldeliyoufncodtsuiisonijnnodinabbtnyy.
(See Figure 2.4(b).)

By repeated application of the Parallel Moves Lemma we now have:

Theorem 2.1.5. Every orthogonal TRS is con uent.

Theorem 2.1.5 also holds for weakly orthogonal TRS's. The earliest proof of Theorem 2.1.5 is probably that of Rosen 73]; but earlier proofs of the con uence of CL (Combinatory Logic), work just as well for orthogonal TRS's in general. The con uence theorem for (weakly) orthogonal TRS's is also a special case of a theorem of Huet (mentioned already in Exercise 1.4.24), stated here without proof. We need a de nition rst:

De nition 2.1.6.
disjoint redexes.

(Parallel

reduction)

t

!k

s

if

t

s via a reduction of

Term Rewriting Systems

73

Theorem 2.1.7. (Huet 80]) Let R be a left-linear TRS. Suppose for every critical pair ht; si we have t !k s. Then !k is strongly con uent,
hence R is con uent.

(For the de nition of `strongly con uent' see Exercise 1.0.8(10). In

fact, the proof in Huet De nition 1.0.1(5).)

80] yields

more:

!k

is

even

subcommutative|see

Exercises 2.1.8.
1. Combinatory Logic (Table 1.4) has rule patterns as in Figure 2.5; they cannot overlap. As CL is left-linear, it is therefore orthogonal and hence con uent.

Figure 2.5

2. SKIM, in Table 1.5, is orthogonal. Likewise for the TRS's CL with test for equality, binary or applicative, in Tables 1.6, 1.7 respectively. Also Weak Categorical Combinatory Logic in Table 1.8 is orthogonal.

3. A Recursive Program Scheme (RPS) is a TRS with

(a) (b)

aafjuoinnncnttiititfoerenosmsse)et,tFwGo,hf=wefrhufeenGrFce1ti;iGoh: n:aj:sh;saGyarmskitgabyro(imlttsyhieFpj`k0=no(0wifF=(nj1' 1;=o:;r::1::`;b;::F;a:nsn:i)g;c,k' a()ftn,uhdnect`iuonnks)n,odwins-'

(c) reduction rules of the form

Fi(x1 : : : ; xmi) ! ti (i = 1; : : : ; n)

where all the displayed variables are pairwise di erent
is an arbitrary term built from operators in F;G and

and where ti the displayed

variables. For each Fi (i = 1; : : : ; n) there is exactly one rule.

Every RPS is orthogonal, hence con uent. For an extensive treatise on semantical aspects of Recursive Program Schemes, see Courcelle 90].

Exercise 2.1.9. For a deterministic Turing machine M, the TRS RM as
de ned in Exercise 1.2.21 is orthogonal.

Apart from con uence, many interesting facts can be proved for orthogonal TRS's.

74 J. W. Klop

De nition 2.1.10. 1. A TRS is non-erasing if in every rule t ! s the same variables occur
in t and in s. (E.g. CL is not non-erasing, due to the rule Kxy ! x.)
2. A TRS is weakly innermost normalizing (WIN) if every term has a normal form which can be reached by an innermost reduction. (In an innermost reduction a redex may only be `contracted' if it contains no proper subredexes.)

The next theorem was proved in Church 41] for the case of the nonerasing version of -calculus, the I-calculus, where the restriction on term formation is adopted saying that in every abstraction term x:M the variable x must have a free occurrence in M.

Theorem 2.1.11. Let R be orthogonal and non-erasing. Then: R is WN
i R is SN. Another useful theorem, which also reduces the burden of a termination
(SN) proof for orthogonal TRS's, is:

Theorem 2.1.12. (O'Donnell 77]) Let R be an orthogonal TRS. Then:
R is WIN i R is SN. The last two theorems can be re ned to terms: call a term WN if it has a
normal form, SN if it has no in nite reductions, WIN if it has a normal form reachable by an innermost reduction. The `local' version of Theorem 2.1.11 then says that for a term in an orthogonal, non-erasing TRS the properties WN and SN coincide. Likewise there is a local version of Theorem 2.1.12. Thus, if in CL a term can be normalized via an innermost reduction, all its reductions are nite.

Exercise 2.1.13. In this exercise we sketch a proof of Theorem 2.1.11 and
O'Donnell's Theorem 2.1.12.

1. The following proposition has an easy proof:

PtrSueuRdapuOlplcyoPtsidOoeinSssjIooThbinIatOatsiNrnaeef.dtdeeLxrbeeyttshcteso1bnre;te:rdaa:u:cc;tteistoirnomn,n,aiitnnndsaoanmtr0oeerndoteohrxdodegsero.s,ncoLaefenl ttdThatRenSrtse,ditcen0oxnebtets0.astihn1T;eihn:en:g:n-;msstfeounpr-.
some i 2 f1; : : : ; ng: s si. This means that either s coincides with some
si, or is contained in an argument of some si.

2. We write `1(t)' if the term t has an in nite reduction t !! . So 1(t)
i t is not SN. Using the proposition in (1) one can now prove (the proof is non-trivial):

LEMMA. Let t
be a reduction proper subterm

bspetewapittsehurcm1h(itnph)aattnh:aotr1tihs(oteg0)ro.ansaeTldhTieRnnStthsheuecsrhteetdpheatxt!s1sm(ttu0).s(tiL.ceeo.tntht!aasinsntao0

Term Rewriting Systems

75

descendants in t0).

3.

Ut !sintg0

the Lemma it
in which 1(t)

ibsunto:w1ea(ts0y),tcoapnrnoovteoTcchuerorinema

2.1.11: `critical' steps non-erasing TRS.

4. Theorem 2.1.12 follows from the Lemma in (2) by observing that an innermost contraction cannot erase a proper subterm which admits an in nite reduction, since otherwise the contracted redex would not have been innermost.

Exercise 2.1.14. STS's (Semi-Thue Systems), viewed as TRS's as explained
in Section 1.1, are always non-erasing (since left-hand side and right-hand side of every rule end in x, in their TRS version). Also, if there are no critical pairs in the STS, it is orthogonal. So if a STS has no critical pairs, the properties SN and WN coincide.
This rather trivial observation could have been more easily made by noting that for a STS without critical pairs the property WCR1 holds, as de ned in
Exercise 1.0.8(15), whence WN , SN.

Exercise
Suppose t0

2.1.15. (Klop
has a normal form,

80a]) Let t0 be
but has also an in

a term in an orthogonal TRS.
nite reduction t0 ! t1 ! t2 !

. Show that
! t?2 ! t?1

t!0 hta0s:

also an (Hint:

in use

nite the

`expansion' (the reverse of a reduction) lemma in Exercise 2.1.13, and note that

an `erasing redex' can be used to `pump' an in nite expansion.)

Exercise 2.1.16. (Klop 85])

1. Let R be orthogonal, and suppose R is WN (i.e. every term has a normal

Tfohrmen),Gb(ut)t,

not the

SN. Let t reduction

2 Ter(R)
graph of

be t,

a term with an in contains an in nite

nite reduction. expansion (by

con uence, there must then also be an in nite expansion of the normal
form t0 of t inside G(t)). In fact, G(t) contains reductions as follows:

t t1 t2

and t0 t01 t02

such that tn distinct, and

! t0n for all
likewise the

tn0j

1 (n

and 1)

such that the ti (n are pairwise distinct.

1) are pairwise

2. Let t be a term in an orthogonal TRS. Prove: if G(t) contains an in nite

reduction but contains no in nite acyclic expansion, then t reduces to a

context C ] of a term s without normal form. (The set of s such that

t C s] for some C ], is called in Barendregt 81] the family of t.) (In

particular the conclusion holds if G(t) is nite but contains a reduction cy-

cle. Curiously, in CL as in Table 1.4 this is impossible, i.e. nite reduction graphs in CL based on S; K;I are acyclic; see Klop 80b].)

3. The following gure displays the reduction graph of a term t in an orthogonal TRS R. Give an example of such t, R. Conclude, using (2), that t

must have a term without normal form in its family. A fortiori, such a

reduction graph cannot occur in an orthogonal TRS which is WN.

76 J. W. Klop

Figure 2.6

Exercise 2.1.17. (Klop 80a]) Prove for all orthogonal TRS's R with nite

alphabet and nitely many rules:

1. FRBis?1n.o)n-erasing , R has the property FB?1. (See De nition 1.0.3(8) for

2.

R(&HhSinaNts:?t1Pher)opvreIonpSceN;rst?ey1eS)FNig?nu1oren,-1e.Rr2a.sh)iansg,thuesepr(o1p)eartnyd

Inc. use

(See De nition the implication

1F.0B.3?.1)

2.2 Reduction strategies for orthogonal TRS's

Terms in a TRS may have a normal form as well as admitting in nite reductions. So, if we are interested in nding normal forms, we should have some strategy at our disposal telling us what redex to contract in order to achieve that desired result. We will in this section present some strategies which are guaranteed to nd the normal form of a term whenever such a normal form exists. We will adopt the restriction to orthogonal TRS's; for general TRS's there does not seem to be any result about the existence of `good' reduction strategies.
The strategies below will be of two kinds: one step or sequential strategies (which point in each reduction step to just one redex as the one to contract) and many step strategies (in which a set of redexes is contracted simultaneously). Of course all strategies must be computable.
Apart from the objective of nding a normal form, we will consider the objective of nding a `best possible' reduction even if the term at hand does not have a normal form.

Term Rewriting Systems

77

De nition 2.2.1. Let R be a TRS. 1. A one step reduction strategy F for R is a map F: Ter(R) ! Ter(R)
such that (a) t F(t) if t is a normal form,
(b) t ! F(t) otherwise. 2. A many step reduction strategy F for R is a map F: Ter(R) ! Ter(R)
such that (a) t F(t) if t is a normal form,
(b) t !+ F(t) otherwise. Here !+ is the transitive (but not re exive) closure of !. Instead of `one
step strategy' we will also say `sequential strategy'.

De nition 2.2.2.

1.

A if

reduction strategy (one step for each term t in R having

or many a normal

sfoterpm),FthfeorseRquiesnncoermfFalni(ztin) gj

n 0g contains a normal form.

2. F is co nal if for each t the sequence fF n(t) j n 0g is co nal in G(t), the reduction graph of t. (See Exercise 1.0.8(13) for `co nal'

and see Figure 2.7.)

Figure 2.7

A normalizing reduction strategy is good, but a co nal one is even bet-

ter: it nds, when applied on term t, the best possible reduction sequence

starting from t (or rather, a best possible) in the following sense. Consider

a reduction t ! s as a gain in information; thus normal forms have max-

imum information. In case there is no normal form in G(t), one can still

consider in the co nal

rendituecrteiodnuscttionst0as!detv1e!lopti2n!g moreaarendopmtiomreailnsfionrcme afotrioenv.eNryowt0

78 J. W. Klop

(insinGc(et)t0theytncofnotrasinomaetntnw; bityh

information de nition of

content no less `co nal'). In a

than that of t0 sense, a co nal

reduction plays the role of a kind of `in nite normal form'. See e.g. Berry

& Levy 79] and Boudol 85], where spaces of nite and in nite reductions

modulo the so-called permutation equivalence are studied; this give rise

to cpo's or even complete lattices where the bottom point corresponds to

the empty reduction of t, i.e. to t itself, and the top point corresponds

to the normal form (or rather the equivalence class of reductions to the

normal form), if it exists, and otherwise to the equivalence class of co nal

reductions.

We now present some well-known reduction strategies.

De nition 2.2.3.
1. The leftmost-innermost (one step) strategy is the strategy in which in each step the leftmost of the minimal or innermost redexes is contracted (reduced).
2. The parallel-innermost (many step) strategy reduces simultaneously all innermost redexes. Since these are pairwise disjoint, this is no problem.
3. The leftmost-outermost (one step) strategy: in each step the leftmost redex of the maximal (or outermost) redexes is reduced. Notation: Flm.
4. The parallel-outermost (many step) strategy reduces simultaneously all maximal redexes; since these are pairwise disjoint, this is no problem. Notation: Fpo.
5. The full substitution rule (or Kleene reduction, or Gross-Knuth reduction): this is a many step strategy in which all redexes are simultaneously reduced. Notation: FGK.

Strategies (1){(4) are well-de ned for general TRS's. Strategy (5) is only de ned for orthogonal TRS's, since for a general TRS it is not possible to de ne an unequivocal result of simultaneous reduction of a set of possibly nested redexes. The ve strategies are illustrated in Figure 2.8 (taken from Bergstra, Heering & Klint 89]), for the following TRS:

and(true; x) ! x and(false; x) ! false or(true; x) ! true or(false; x) ! true

We will be mainly interested here in the strategies (3){(5), for a reason that will be clear by inspection of Table 2.2 below. We have the following facts (for proofs see O'Donnell 77] or Klop 80a]):

Term Rewriting Systems

79

Figure 2.8 (after Bergstra, Heering & Klint 89])

Theorem 2.2.4. For orthogonal TRS's: 1. FGK is a co nal reduction strategy. 2. Fpo is a normalizing reduction strategy.

Remark 2.2.5. For -calculus this
is there also a normalizing strategy,

theorem just as it

ailssofohr otlhdes.orMthoorgeoonvaerl ,TFRlmS

CL (Combinatory Logic). However, in general Flm is not a normalizing

strategy for orthogonal TRS's (see Exercise 2.2.6).

Exercise 2.2.6.
1. An example showing that the leftmost-outermost strategy is not normalizing in general, is given in Huet & Levy 79]: take the orthogonal TRS
fF(x; B) ! D; A ! B; C ! Cg and consider the term F(C; A). Check
that this term has a normal form which is not found by the leftmostoutermost strategy.

80 J. W. Klop

2.

An example need not be

(by N. co nal

Dershowitz) showing that can be found in the TRS

fpAar!alleFl-(oAut)e;rGm(oxs)t

!redGuc(xti)ogn.

therEeviesnatlhaorugeghclFaslms

is in general of orthogonal

for orthogonal TRS's TRS's for which it is:

not

normalizing,

De nition 2.2.7. (O'Donnell 77]) An orthogonal TRS is left-normal if in every reduction rule t ! s the constant and function symbols in the
left-hand side t precede (in the linear term notation) the variables.

Example 2.2.8.
1. CL (Combinatory Logic) is left-normal. 2. RPS's (Recursive Program Schemes) as de ned in Exercise 2.1.8(3)
are all left-normal.
3. F(x; B) ! D is not left-normal; F(B; x) ! D is left-normal.

Exercise 2.2.9. functions from N to

N(ParreimdeitinveedRbeyctuhresifvoelloFwuinngctiinodnusc)tivTehdeepnriimtioitniv(eShreoceunrseivlde

67]):

1. The constant functions Cn;k, the projection functions Pn;i and the successor function S are primitive recursive. (Here Cn;k(x1; : : : ; xn) = k, Pn;i(x1; : : : ; xn) = xi, S(x) = x + 1.)

2. If G; H1; : : : ; Hk are primitive recursive, then F de ned by

F(~x ) = G(H1(~x ); : : : ; Hk(~x ))

(where ~x = x1; : : : ; xn) is primitive recursive. 3. If G and H are primitive recursive, then F de ned by

F(0; x~ ) = G(~x ) F(S(y); x~ ) = H(F(y; ~x ); y; ~x )

is primitive recursive.
Show that, by replacing every `=' by `!' in the de ning equations, every primitive
recursive function is de ned by a terminating, left-normal, orthogonal constructor TRS. (For the de nition of `constructor TRS', see the end of Section 2.3.)

Theorem 2.2.10. (O'Donnell 77], Klop 80a]) Let R be a left-normal orthogonal TRS. Then Flm is a normalizing reduction strategy for R.

Exercise 2.2.11. (Hindley)

1. Consider CL extended with Recursor, where Recursor = fRxy0 ! x, Rxy(Sz) ! yz(Rxyz)g. Note that this applicative TRS is not left-normal, and show that Flm is not normalizing.

2.

However, for x; R (Sz)xy

!theyzT(RRzSxyC)Lg

Recursor the strategy

FwlmheisrenoRremcaulriszoinrg. =

fR

0xy

!

Term Rewriting Systems

81

as

In the soon as

rietdaurcisteiosn, asntdrattheigsyreFpGeKate(fdulyll.

substitution) every redex is `killed' Suppose we relax this requirement,

and allow ourselves some time (i.e. some number of reduction steps) before

getting rid of a particular redex|but with the obligation to deal with it

eventually. The reductions arising in this way are all co nal.

De nition 2.2.12.

1.

Let R =
Consider

sto0m!e retd1e!x s

in

be a some

in R if eventually there are no

nite or in nite
term tn of R. We
descendants of s

reduction say that s left, i.e.

sequence. is secured

9m > n (tm contains no descendants s0; s00; : : : of s tn):

2. R is fair if every redex in R is secured.

Theorem 2.2.13. For reductions R in orthogonal TRS's: R is fair ) R
is co nal.

Note that Theorem 2.2.4(1) is a corollary of the present theorem, since

evidently reductions obtained ation of constraints applies to

by the

aopthpelyrintwgoFsGtKrataergeiefsaiFr.poAansdimFillmar:relax-

De nition 2.2.14. 1. A reduction R is leftmost-fair if R ends in a normal form or in nitely
many times the leftmost outermost redex is contracted in R. 2. R = t0 ! t1 ! is outermost-fair if R does not contain a term
tn with an outermost redex which in nitely long stays an outermost redex but which is never contracted.

Theorem 2.2.15. Let R be an orthogonal TRS. Then:
1. Outermost-fair reductions are normalizing. 2. If R is moreover left-normal, then leftmost-fair reductions are nor-
malizing.

We will now summarize some of the main properties of the various reduction strategies (and their `relaxed' versions) in Table 2.2. Before doing so, we introduce one more property of strategies:

De nition 2.2.16. A reduction strategy F for R is perpetual, if for all t: 1(t) ) 1(F(t)):
Here 1(t) means that t has an in nite reduction, i.e. not SN(t). So
a perpetual strategy is the opposite of a normalizing one; it tries to avoid normal forms whenever possible, and could therefore also be called `antinormalizing'.

82 J. W. Klop In Table 2.2 p; n; c stand for perpetual, normalizing, co nal respectively.
In case a property is not mentioned, it does not hold generally. Note that for the leftmost-outermost strategy, when applied to orthogonal TRS's in general, none of the three properties holds generally. Proofs that leftmostoutermost reduction is normalizing for left-normal orthogonal TRS's and that parallel-outermost reduction is normalizing for all orthogonal TRS's can be found in O'Donnell 77]. The latter fact is also proved in Bergstra & Klop 86] (Appendix).
Table 2.2
Computable reduction strategies
A strategy is recursive or computable if it is, after a coding of the terms into natural numbers, a recursive function. Obviously we are primarily interested in computable strategies; and indeed all ve strategies in De nition 2.2.3 are computable. We may now ask whether there is always for an orthogonal TRS a computable one-step normalizing reduction strategy. A priori this is not at all clear, in view of TRS's such as the one given by G. Berry: CL extended with rules
FABx ! C FBxA ! C FxAB ! C
which is an orthogonal TRS. This TRS seems to require a parallel reduction strategy (so, not a one-step or sequential strategy), because in a term of the form FMNL we have no way to see the `right' argument for computation: a step in the third argument may be unnecessary, namely if the rst and second argument evaluate to A and B respectively (which is undecidable due to the presence of CL); likewise a step in the other arguments may be unnecessary. In the next section about sequential TRS's this problem will be analyzed extensively.
When we want to be more liberal, we can consider the same problem for the weakly orthogonal TRS obtained by extending CL with Parallel-or:

Term Rewriting Systems
or(true; x) ! true or(x; true) ! true

83

It has been claimed by some authors that such TRS's require a parallel evaluation. However, there is the following surprising fact.

Theorem 2.2.17. (Kennaway 89]) For every weakly orthogonal TRS
there exists a computable sequential normalizing reduction strategy.

The algorithm involved is however too complicated to be of more than theoretical interest.

Standard reductions in orthogonal TRS's
For -calculus and CL there is a very convenient tool: the Standardization Theorem (see Barendregt 81], Klop 80a]). For orthogonal TRS's there is unfortunately not a straightforward generalization of this theorem (however, see Huet & Levy 79] for a generalization). The obstacle is the same as for the normalizing property of the leftmost reduction strategy, discussed in the previous section. When we restrict ourselves again to left-normal orthogonal TRS's, there is a straightforward generalization.

De nition 2.2.18. (Standard Reductions) Let R be a TRS and R = t0 ! t1 ! be a reduction in R. Mark in every step of R all redex head
symbols to the left of the head symbol of the contracted redex, with ` '. Furthermore, markers are persistent in subsequent steps.
Then R is a standard reduction if in no step a redex is contracted with
a marked head operator.

Exercise 2.2.19.
x; D1(Dxy) ! yg:

Consider CL

Pairing, where Pairing = fD0(Dxy) !

1. Show that the reduction D0(D(KII)I) ! D0(DII) ! I is not standard.

2. Show that D0(D(KII)I) ! KII ! I is standard.

Exercise 2.2.20. (Hindley) Consider in the applicative TRS R = fPxQ !
xx; R ! S; Ix ! xg the reduction R = PR(IQ) ! PRQ ! RR ! SR
and show that there is no standard reduction for R (i.e. a reduction PR(IQ)
SR which is standard).

Theorem 2.2.21. (Standardization theorem for left-normal orthogonal
TRS's) Let R be a left-normal orthogonal TRS. Then: if t s there is a standard reduction in R from t to s.
For a proof see Klop 80a]. A corollary is our earlier theorem stating that Flm is a normalizing strategy for left-normal orthogonal TRS's; this

84 J. W. Klop

fact is in -calculus and CL literature also known as the Normalization Theorem.

Exercise 2.2.22. Prove the Normalization Theorem for left-normal orthog-

onal TRS's from the Standardization Theorem. (Hint: suppose t has a normal

ftoormt0.t0T.hBisyisthine

Standardization Theorem, fact the reduction as given

tbhyerFelmis.)a

standard

reduction

from

t

2.3 Sequential orthogonal Term Rewriting Systems

An important feature of orthogonal TRS's is whether they are `sequential'. The property of sequentiality is relevant both for the existence of normalizing reduction strategies and for the de nability (implementability) in -calculus or CL.
That a TRS is sequential, does of course not mean that it is impossible to rewrite redexes in a parallel way. It means that there are also adequate sequential reduction strategies, i.e. it is not necessary to rewrite in a parallel way in order to nd normal forms. Sequentiality is a desirable property, but unfortunately it is an undecidable property. However, there is a stronger version, `strong sequentiality', which is decidable and which guarantees the existence of a recursive one-step normalizing reduction strategy. This was shown in Huet & Levy 79]. In this section we follow this paper, as well as Klop & Middeldorp 89]. We note that here we are primarily interested in `mathematical' properties of strong sequentiality, and are not concerned with e ciency of decision algorithms; for the latter see Huet & Levy 79].
As remarked in Kennaway 89], one can ask whether `sequential' is the right terminology, in view of his theorem (2.2.17) stating that every orthogonal TRS has a computable, sequential, normalizing strategy. Yet we feel that the terminology is right, if we are interested in `feasibly sequential' (admitting a sequential normalizing strategy that is computable in a `feasible' way).

De nition 2.3.1. Let t 2 TerR), R orthogonal. Let s t be a redex.

Then s is a if it exists)

needed redex (needed for
i in all reductions t !

th!e cto0msupcuhtatthioant

to0f

the is a

normal normal

form, form,

some descendant of s is contracted. (So, trivially, any redex in a term

without normal form is needed.)

Exercise 2.3.2. Show that the leftmost outermost redex in t 2 TerR) where
R is a left-normal orthogonal TRS, is a needed redex.

Theorem 2.3.3. (Huet & Levy 79]) Let t be a term in an orthogonal
TRS R.

Term Rewriting Systems

85

1. If t is not in normal form, t contains a needed redex. 2. Repeated contraction of a needed redex leads to the normal form, if
it exists. (So, needed reduction is normalizing.)

The proof involves quite some e ort and is not included here. (For a proof di erent from the one of Huet and Levy, see Kennaway & Sleep 89].)

Exercise 2.3.4.

1. The present theory about needed reductions in orthogonal TRS's trivializes for non-erasing TRS's: Show that in a non-erasing orthogonal TRS every redex in a term is needed.

2. (Kennaway 89]) Furthermore the present theory does not have a straight-

forward generalization to weakly orthogonal TRS's: Show that Theorem

2.3.3 does not hold for weakly orthogonal TRS's, by considering
! true, or(x; true) ! trueg. (However, see O'Donnell 85].)

for (true;

x)

Thus, Theorem 2.3.3 gives us a normalizing reduction strategy: just contract some needed redex. However, the de nition of `needed' refers to all reductions to normal form, so in order to determine what the needed redexes are, we have to inspect the normalizing reductions rst, which is not a very good recipe for a normalizing reduction strategy. In other words, the determination of needed redexes involves look-ahead, and it is this necessity for look-ahead that we wish to eliminate. Before we do so, rst the following observation, which is easy to prove:

Proposition
in t such that

2s.3.5s.0.

LTehtetn:2sTiesrRne)e,dRedor)thosg0 oisnanle.eLdeetd.s

and

s0

be

redexes

Corollary 2.3.6. Let t be a term not in normal form. Then some outer-
most redex of t is needed. Now let C ; : : :; ] denote a context with n holes. Denote by a sub-
stitution of redexes s1; : : :; sn in the holes 1; : : :; n. Then the last corollary states:

8C ; : : :; ] in normal form 8 9i si is needed in C s1; : : :; sn]:

So, which si is needed, may depend on , i.e. from the other sj. A more pleasant state of a airs would be when the TRS R would satisfy the following property:

De nition 2.3.7. Let R be an orthogonal TRS. Then R is sequential if

8C ; : : :; ] in normal form 9i 8 ; si is needed in C s1; : : :; sn]:

86 J. W. Klop

Exercise 2.3.8. (Middeldorp)
1. Show that the orthogonal TRS (where CL is Combinatory Logic)

CL fF(A;B; x) ! C; F(B; x; A) ! C; F(x; A; B) ! Cg

(due to G. Berry) is not sequential .
2. Show that the TRS fF(A; B; x) ! C; F(B; x;A) ! C; F(x; A;B) ! Cg
is sequential . 3. Conclude that `sequential ' is not a modular property.

The concept `sequential ' is only introduced for expository purposes. It is not a satisfactory property as it is undecidable. As it will turn out, a more satisfactory property is `strongly sequential ', de ned as follows.

De nition 2.3.9.

1. Let R be an orthogonal TRS and C ] a context. Then a reduction
relation !? (possible reduction) is de ned as follows. For every redex
s and every term t:
C s] !? C t]

As usual, scendant'

is

d? eisntehde

transitive
for !? in

re the

exive closure. obvious way.

The

concept

of

`de-

2.

Let s be a
ctioonntrtac!te?d.:

:rCe:dl!eeax?rliytn0:

wt.heTrehetn0

s is

is a

s is strongly

strongly needed if in every normal form, a descendant
needed ) s is needed.

reducof s is

3. R is strongly sequential if 8C ; : : :; ] in normal form 9i 8 si is
strongly needed in C s1; : : :; sn].

This property of `strong sequentiality ' may be rather subtle, as the following example of Huet & Levy 79] in Exercise 2.3.10 shows.

Exercise 2.3.10. Let R have rewrite rules, written in tree notation, as in
Figure 2.9(a) (the RHS's are irrelevant). Show that R is not strongly sequential , by considering the context as in Figure 2.9(b).

Now the situation takes a pleasant turn, since as we will prove, it is decidable whether a orthogonal TRS is strongly sequential , and moreover, there is a simple algorithm to compute an i as in the de nition. Actually, Huet & Levy de ne concepts `sequential' and `strongly sequential' in a di erent way; our `sequential ' does not exactly coincide with `sequential' but `strongly sequential ' is equivalent with `strongly sequential'. We will de ne these concepts now. We need some preliminary de nitions:

De nition 2.3.11.
1. Let R be a orthogonal TRS. Then the set Ter (R) of -terms of R consists of those terms that can be built from function and constant

Term Rewriting Systems

87

Figure 2.9

symbols from R together with a new constant . Reduction relations

!
we

and say

!?
that

are t is

extended to Ter a normal form if

(R)
t2

in the obvious way. Ter (R), t contains

As no

before, and t

contains no redexes. Further, t is an -normal form if t contains no

redexes (but t may contain occurrences of ).

2. On Ter (R) we de ne a partial order by:

(a) (b) ti

tt0i

for (i

all t 2 Ter
= 1; : : :; n)

(R),
)F

(t1;

:

:

:

;

tn)

F (t01; : : :; t0n).

Clearly, t context C

si ;:::;

t C ;:::; ] ] not containing

and s , and

C some

tt1i;

::
2

:; tn] Ter

for (R)

some (i =

1; : : :; n; n 0):

3. A predicate P on Ter (R) is monotone if t t0 implies P (t) ) P (t0):

4. The predicate nf is de ned on Ter (R) as follows:

nf(t) holds if t n where n is a normal form (so without ):

5. The predicate nf? is de ned on Ter (R) as follows: nf?(t) holds if t ? n where n is a normal form:
6. Let P be a monotone predicate on Ter (R). Let t C ; : : :; ; : : :; ] where all 's in t are displayed. Then the underlined occurrence of is an index with respect to P (or P -index) if for all s such that t s,
where s C t1; : : :; ti; : : :; tn]; we have: P (s) ) ti 6= : (Note that
in particular, if t has a P-index, then P(t) does not hold.)

It is easily proved that the predicates nf and nf? are monotone. Now we de ne (after Huet & Levy 79]):

88 J. W. Klop
De nition 2.3.12. 1. The orthogonal TRS R is sequential if every t 2 Ter (R) in -normal
form, but not in normal form, has a nf-index.
2. The orthogonal TRS R is strongly sequential if every t 2 Ter (R) in
-normal form, but not in normal form, has a nf?-index.

Exercise 2.3.13. (Middeldorp)
1. Show that: R is sequential ) R is sequential , but not vice versa. Hint:
consider the TRS as in Exercise 2.3.8(2), with the term F( ; ; ):
2. Show that: R is strongly sequential , R is strongly sequential .

Exercise 2.3.14. Let t C ; : : : ; ; : : : ; ] 2 Ter (R), R not necessarily
strongly sequential. The i-th occurrence of in t is underlined. Suppose that this underlined occurrence is a nf?-index of t. Show then that in C s1; : : : ; si; : : : ; sn], where si is a redex and the other sj are arbitrary terms, the redex si is strongly needed.
To link the beginning of this section, which used the terminology of contexts, with the present set-up via -terms, we note that a context in normal form, containing at least one hole, corresponds with an -term in
-normal form, but not in normal form. Before devoting the rest of this section to an exposition of the long proof that strong sequentiality is a decidable property, we will rst show how to nd a nf?-index. First, we need some de nitions.

De nition 2.3.15. Let t 2 Ter (R):

1.

t is for

saormedeerxedcoemx pta0)t.ible

-term if t can be re ned to a redex (i.e. t

t0

2. -reduction replaces a redex compatible subterm 6 by , notation: ! . So, C t] ! C ] if t is redex compatible and t 6 :

3. The xed part !(t) of an -term t is the result of maximal application

of -reductions. (In other words, the normal form with respect to

-reduction.)

Exercise 2.3.16. Show that !(t) is well-de ned, by proving that -reduction
is con uent and terminating.

Now let t C ; : : :; ; : : :; ] be an -normal form containing at least

one . We wish to test whether the i-th occurrence of , the underlined

soynme,biosl,ap.nRf?e-siunldte:xt0of

t. C

To this end ; : : :; p; : : :;

we ]:

replace

it

by

a

fresh

constant

Claim 2.3.17.
2.10.)

is a nf?-index in t , p occurs in !(t0). (See Figure

Term Rewriting Systems

89

Figure 2.10

The sistence

proof of the claim of the test symbol

is p

irnou!t(itn0e)

and we omit it. Intuitively, the permeans that whatever the redexes (or

even general terms, cf. Exercise 2.3.14) in the other places are, and what-

ever their reducts might be, the p does not vanish, is not erasable by the

action of the other redexes (or general terms). So if instead of p an actual

rreeddeuxcessi iwitasselpf,reesveenntt,utahlley.onHlyuewt a&y

to normalize the term at hand is to Levy 79] gives an e cient algorithm

for executing the `p-test', i.e. for nding needed redexes, cf. Exercise 2.3.14).

nf?-indexes

(and

hence,

strongly

The decision procedure for the strong sequentiality property itself is

much more di cult. We will now present a proof (in a slightly informal

way) which is a simpli cation of the one in Huet & Levy 79], but where

we do not pay any attention to the e ciency of the decision procedure.

In the following we -occurrence which is

will refer to a not an index,

wnifl?l-binedceaxllaesda`nfre`ein'.deAx'tfeorrmshinorwt.hAichn

all 's are free, is called free.

The main `problem' is that we do not have the following transitivity

property for indexes, which on rst sight one might expect to hold: if in

the is

a-nteirnmdsexC(1the]r;eCm2 ay];

where in be other

both terms the 's occurring),

displayed occurrence then the displayed

of in

C1 C2 ]] is again an index.

Example 2.3.18. Counterexample to transitivity for indexes. Consider
the TRS as in Exercise 2.3.10, and the term F(G( ; ); ): The underlined occurrence is an index, as is easily seen by applying the `p-test': !(F(G( ; ); p)) = F( ; p): However, substituting the same term in the index position, with result F(G( ; ); F(G( ; ); )); we have the `context' in Figure 3.12(b), which is as shown, essentially, in Exercise 2.3.10, a free term.

However, some `partial' transitivity properties for the propagation of indexes do hold, notably the one in Proposition 2.3.21 below. We will now

90 J. W. Klop make explicit some properties of index propagation. To this end we employ the following notational convention: instead of \the displayed occurrence of in C ] is an index "(here the -term C ] may contain other 's)
we will just write \C #]". However, the absence of an arrow as e.g. in C ; #] does not mean that (in this case) the rst is not an index.
Furthermore we stipulate that in C ; : : :; ] (or a version with arrow annotations) more occurrences of may occur than the ones displayed, unless speci ed explicitly otherwise. Finally, the notations s; t; C ; : : :; ] (possibly with arrow annotations) will refer to -terms, which we sometimes call just `terms'.
Proposition 2.3.19. 1. C1 C2 #]] ) C1 #] and C2 #]:
2. The reverse implication does not hold generally.
Figure 2.11
Proof. See Figure 2.11, where an arrow points to an index- . Part (2) is
the counterexample in 2.3.18. Part (1) follows by an easy argument using the p-test criterion for indexes.
Proposition 2.3.20. 1. Let !(t) = : Then C t; #] ) ; #]: 2. The reverse implication holds for all t: C t; #] ( C ; #]: Proof. (See Figure 2.12.) Simple applications of the p-test.
The following proposition (from Klop & Middeldorp 89]) states the `partial transitivity' for index propagation mentioned before. Here refers to the maximal height of the trees corresponding to the redex schemes (i.e., the left-hand-sides of reduction rules) of R. Furthermore, the depth of an occurrence in a term is the length of the branch leading from the root symbol to that occurrence.
Proposition 2.3.21. Let the depth of in C2 ] be at least . Then: C1 C2 #]] and C2 C3 #]] ) C1 C2 C3 #]]]:

Term Rewriting Systems

91

Figure 2.12

Figure 2.13

Proof sketch. Suppose contexts Ci ] (i = 1; 2; 3) as in the proposition

are given. Consider !(C1 C2 C3 p]]]). We claim that p is still present in

this and

term. For especially

if not, consider an -reduction the -reduction step in which

ltehaedisnygmtbool!(pCi1s

Clo2stC.3

p]]]) The

redex compatible subterm which is removed in this step, has a root symbol

ser.wNisoewpswcoaunlndontootcocuccruirninth!e (sCu2btCer3mp]]C).2

BCu3tps]]

coafnCa1lsCo2nCot3

p]]]; for othoccur in the

tCh1e-paasrstumofpCti1onC2reCfe3rrpi]n]]g,

for to

then .

p

would

not

occur

in

!(C1

C2

p]])

due

to

In the following propositions, a rigid term t is a term t such that !(t) = t. Terms t such that !(t) = ; will be called soft; they `melt away' completely by -reduction. It is not hard to prove that every term has a unique decomposition in a top part which is rigid and some subterms which are soft. (The top context may be trivial, i.e. equal to :)

92 J. W. Klop

Proposition 2.3.22. Every term t 2 Ter (R) can be written, uniquely,
as C t1; : : :; tn] such that C ; : : :; ] is rigid and the ti (i = 1; : : :; n) are soft.

Proposition 2.3.23. Suppose
is rigid and tk is soft for k = 1;

C ::

t1; : :; n.

:L:;ettnt]iis

aCte0rm].suTchhetnh:at

C

;:::;

]

C0 #] ) C t1; : : :; ti?1; C0 #]; ti+1; : : :; tn]:

Proof. (See Figure 2.14.) By routine arguments involving the p-test.

Figure 2.14
In an attempt to decide whether the TRS R is strongly sequential, we
will try to construct a term t 2 Ter (R) in -normal form but not in
normal form, which is free, i.e. has no indexes. If such a free term exists, then and only then R is not strongly sequential. Especially we will look for a minimal free term, minimal with respect to the length. According to the last proposition, we may suppose that a minimal free term, if it exists, is soft. So, such a minimal free term is built from redex compatible terms (i.e. originates, starting from a redex compatible term, by repeatedly substituting redex compatible terms for 's)|this follows at once from the de nition of `soft' and -reduction. (See Figure 2.15(a).) However, this observation is not yet su cient for a sensible attempt to construct a minimal free term, for there are in general in nitely many redex compatible terms which may be the building blocks of the minimal free term we are looking for. Fortunately, we may even suppose that a minimal free term is built from a special kind of redex compatible terms, the preredexes, of which only nitely many exist if the TRS R has nitely many reduction rules as was our assumption. (See Figure 2.15(b).)
De nition 2.3.24.
1. A redex scheme (or redex pattern) is a left-hand side of a reduction rule where all variables are replaced by :
2. A preredex is a term which can be re ned to a redex scheme. (See Figure 2.16.)

Term Rewriting Systems

93

Figure 2.15
Figure 2.16 So, a redex scheme itself is a preredex; every preredex is also a redex compatible term. If the TRS R has nitely many rules, there are only nitely many preredexes. The 's in a redex scheme are all free; the 's arising by `truncating' a redex scheme and thus forming a preredex, may be free or an index depending on other redex schemes. The `old' 's in the truncation, if there are any, remain free. All this follows immediately from the de nitions and the p-test. We have already noted that a minimal free term t may be supposed to be built from redex compatible terms, as in Figure 2.15(a). This `partition' in redex compatible terms need not be unique, but that does not matter.

94 J. W. Klop Suppose a certain partition of t is given, corresponding to some -reduction from t to : Each redex compatible term from which t is built, and which is removed in this -reduction, consists of a preredex re ned with some `extra' subterms. (The subterms that make the di erence between Figure 2.15(a) and (b).) Now we remove from t all these extra subterms. (See Figure 2.17.)
Figure 2.17 We claim that the term t0, originating after removing all `extra' subterms, is again free. Namely, consider the example in Figure 2.16, and remove the two extra subterms of the redex compatible subterm s. The 's that arise after this removal are free in s; this follows easily by applying the p-test and noting that subterm r is soft. But then these 's are also free in t; this follows from Proposition 2.3.19(1). Furthermore, the present removal of the extra subterms of s also does not turn free 's at other places into indexes, by Proposition 2.3.20(2). We will now try to construct a minimal free term t in a tree-like procedure, as suggested in Figure 2.18. Of course, we want t to be in -normalform|cf. De nition 2.3.12(2). We start, therefore, with the nitely many proper preredexes, where a preredex is `proper' if it is not a redex scheme. Now at every index , we attach in the next construction step, again a proper preredex. This nondeterministic procedure is repeated. A branch in the thus originating tree of construction terminates `successfully' if a free term is reached. In that case the TRS R is not strongly sequential. However, there may arise in nite branches in the construction tree. But these we may `close', eventually, by some form of `loop checking' in the following way. First a de nition.
De nition 2.3.25.
1. Let Ci ] be preredexes (i = 1; : : :; n). Then the term C1 C2 : : : Cn ]] : : :]]

Term Rewriting Systems

95

Figure 2.18

is called contains

athteowsuebrtoofwperrere0dexCesi.CIfi+11

:

:

i :

<j Cj

n, we say that tower ]] : : :]]:

2. Let be the maximal height of redex schemes of R. A tower

C1 : : : Cn ]] : : :] of preredexes is su ciently high if the depth of the

displayed in is at least :

96 J. W. Klop

3. Let t be a term built from preredexes. A main tower in is a tower (arising after removing some subterms of t) containing a complete branch in the tree corresponding to t (so, from root to some ` nal' symbol).

Now if in the construction tree we observe at some construction branch

the arising of a term which has a main tower containing two disjoint suf-

ciently high identical subtowers, that construction branch is stopped un-

successfully.

So every branch of the construction tree terminates, either successfully

in a free term, or unsuccessfully. Because the construction tree is nitely

branching, the result is a nite construction tree. Now if all construc-

tion branches terminate unsuccessfully, the TRS R is strongly sequential;

otherwise the presence of a free term at the end of a successful branch re-

veals that TRS R is not strongly sequential. Hence strong sequentiality is

decidable.

We still have to prove that our decision procedure is correct, in partic-

ular we have to justify the correctness of the `loop check' for unsuccessfully

closing branches at which a repetition of subtowers occurs. To this end,

consider consider

the term s a successor

sa0tobsotmaineepdobinyta(dnjooidnei)ngina

the construction proper preredex

tree, and at some

index position of s. In general, will contain some free 's as well as

stdooe?mtteThermehinewiyndheemodxlaebyyt'sebtre(hmwceoimtsmh0ea(rifPenrsreptoeoepwicontesristto0io.ofnNp).o2row.T3p.hwe1re9h(pfa1rrte)ee)hr.eadpW'epsxheernaesstminwaabiisnto0huflrtteehaetedhmwienigitinshtdoerenexttsheiprseeecloytf

in s where will be adjoined. This follows from Proposition 2.3.20 stating

that removal of soft terms does not a ect the index or non-index status of

other 's.

In fact, what happens with the indexes of is already determined by

the subtower of height immediately above the adherence point : This

follows from Proposition 2.3.21. But then it is easy to see that in a minimal

free term there will not be a repetition of two identical su ciently large

disjoint subtowers (see Figure 2.19). For, if such a repetition occurs in a

minimal free term, we can construct a smaller one by cutting away part

of the term as in Figure 2.19, contradicting the minimality. This ends the

proof of decidability of strong sequentiality.

Many TRS's arising in `practice' are constructor TRS's. For such TRS's

it is easy to decide strong sequentiality. A constructor TRS is a TRS

in which the set of function symbols can be partitioned into a set D of

de ned function symbols and a set C of constructors, such that for every

rewrite rule t
Fcon2stDruacntodrst.1;

!
:::

s, ; tn

t2heTeler(ftC-;hVa)n,dthseidseett

has the of terms

form built

fFro(mt1;v:a:r:i;atbnl)eswaintdh

Term Rewriting Systems

97

Figure 2.19

The reason that for constructor TRS's deciding strong sequentiality is easy, is that we do have transitivity of indexes now, in contrast with the case of general TRS's (cf. Counterexample 2.3.18).

Proposition 2.3.26. Let R be an orthogonal
start with a de ned function symbol. Then:
C1 C2 #]]:

constructor
C1 #] and

TRS. C2

#L]etimCp2lies]

Proof. Straightforward, using the p-test for nding indexes.

Corollary 2.3.27. A constructor TRS is strongly sequential i every
proper preredex has an index.

So, in order to decide whether a constructor TRS R is strongly sequential, we only have to compute the indexes of its nitely many proper preredexes. (R is supposed to have only nitely many rewrite rules.) Also, the computation of these indexes is very easy: Let C ; : : :; ; : : :; ] be
a preredex of R. Now it is not di cult to see that C ; : : :; #; : : :; ] i
C ; : : :; p; : : :; ] is not redex compatible.

Exercise 2.3.28. Let R be an orthogonal constructor TRS. Show that R is
strongly sequential if every proper preredex P has an -occurrence which is inall

98 J. W. Klop
r6 ede)x: schemes S such that P S, more de ned (i.e. replaced by an -term
Exercise 2.3.29. (Huet & Levy 79]) Let R be a left-normal orthogonal
TRS. Show that R is strongly sequential. Show that, in fact, in C ; : : : ; ] (where C ; : : : ; ] is an -free context in normal form) the leftmost occurrence of
is an index.
Exercise 2.3.30. (Klop & Middeldorp 89]) Show that strong sequentiality
is a modular property of orthogonal TRS's, i.e. if R1; R2 are orthogonal TRS's with disjoint alphabet, then:
R1 R2 is strongly sequential , R1 and R2 are strongly sequential.

Exercise 2.3.31. (Thatte 87]) Let R1; R2 be orthogonal TRS's. De ne
R1; R2 to be left-equivalent if the rewrite rules of R1; R2 have identical left-hand sides. An orthogonal TRS R is called left-sequential if all TRS's which are leftequivalent with R, are sequential (De nition 2.3.12(1)).
Let R be an orthogonal TRS and C ; : : : ; ] a context in -normal form. The i-th occurrence of is called an index with respect to left-sequentiality if this
is an index with respect to sequentiality for all TRS's left-equivalent with R.

1.

L!etxR;

Gbe(Ath)e!TRASg.wSithhowrutlhesatfFth(eAt;hBir;dxo)c!curxr;enFc(exo;fA;

B) ! x;
in F(G(

F (B; ); G(

x; A) ); )

is an index with respect to left-sequentiality, but not with respect to strong

sequentiality.

2. Prove that strong sequentiality implies left-sequentiality.

3. (Open problem.) Does the reverse of (2) also hold, i.e. is every leftsequential TRS strongly sequential?

3 Conditional Term Rewriting Systems

Of growing importance in the eld of term rewriting are the conditional Term Rewriting Systems (CTRS's). CTRS's have originally arisen from Universal Algebra (see Meinke & Tucker 91]) and in the theory of Abstract Data Types, as implementations of speci cations containing positive conditional equations

t1(~x ) = s1(~x ) ^ : : : ^ tn(~x ) = sn(~x ) ) t0(~x ) = s0(~x ) ( )

(If n = 0, the equation is called every ti; si needs to contain all

unconditional.) those variables.

Here In (

~x )

=wexi1m; :p:l:ic;ixtlky;

not use

universal quanti cation over ~x, i.e. ( ) is meant to be

8~x ( ^ ti(~x ) = si(~x ) ) t0(~x ) = s0(~x )):

i=1;::;n

Term Rewriting Systems

99

Hence the but not in

variables appearing the consequent t0(~x

i)n=thse0(c~xon)dhitaivoenasnti`(e~xx)is=tenstii(a~xl'),mie=an1in; :g:;:e;.ng,.

E(x; y) = true ^ E(y; z) = true ) E(x; z) = true

is by elementary predicate logic equivalent to

9y (E(x; y) = true ^ E(y; z) = true) ) E(x; z) = true:

Henceforth we will, conform the notation often used in `equational logic programming', write instead of ( ):

t0(~x ) = s0(~x ) ( t1(~x ) = s1(~x ); : : :; tn(~x ) = sn(~x ):

Example 3.0.1. A speci cation of gcd on natural numbers with 0 and
successor S, using conditional equations:

0<0 = 0

S(x) ? S(y) = x ? y

0 < S(x) = S(0)

0?x = 0

S(x) < 0 = 0

x?0 = x

S(x) < S(y) = x < y

gcd(x; y) = gcd(x ? y; y) ( y < x = S(0)

gcd(x; y) = gcd(x; y ? x) ( x < y = S(0)

gcd(x; x) = x

(To keep the speci cation one-sorted, 0 and S(0) are used as booleans false
and true respectively. Furthermore, `?' is cut-o subtraction.) The satisfaction relation A j= ', for an equational implication or as we
will call them henceforth, conditional equation '; is clear; see also Meinke & Tucker 91], where it is also shown that analogous to the equational case we can develop initial algebra semantics for conditional equations. Conditional equations not only facilitate some speci cations, they also are a strictly stronger speci cation mechanism. In Bergstra & Meyer 84] a conditional speci cation is given with an initial algebra that cannot be speci ed (in the same signature) by means of equations.
Again we can ask whether there exists a deduction system and a corresponding completeness theorem, in analogy with Birkho 's theorem 1.4.2 for equational logic.

Conditional equational deduction
Selman 72] presents a sound and complete deduction system for, as they are called there, equation conjunction implication (ECI) languages, or as we will say, for conditional equational logic. We state this deduction system in a considerably simpli ed way, by considering in a conditional equation

100 J. W. Klop

t=s (
conditions

E E

awshaerseetErat=hert1th=ans1a;n:

:o:r;dtenre=d

tsunp(len

as

0), the sequence of in Selman 72], and

by admitting empty E. (See Table 3.1.) Adapting the inference system to

the case where E is a multiset or even an ordered tuple is straightforward.

axioms t = s ( t = s; t0 = s0

t=t (

t = s ( t = r; s = r

Ffo(rte1v; :e:ry:;

ntn-a)r=y

F F

(s1;

:

:

:

;

sn)

(

t1

= s1; : : :; tn

=

sn

rules t = s ( t0 = s0; E; t0 = s0 ( F

t = s ( E; F

t=s ( E t =s ( E

for every substitution

Table 3.1

Here (m

E0);=Eft1==ft1s1=; :

: :; tn s1 ; : :

:=; tnsn=gs(nng.

0), F = ft01 = s01; : : :; t0m = s0mg

Operational semantics of conditional equations

In the unconditional case, there is no problem in the transition from equa-

tions to by t0(~x )

directed
! s0(~x

equations, ), provided

i.e. the

rewrite rules: left-hand side

ist0n(o~xt)

a=sisn0g(l~xe

) is replaced variable and

variables occurring in the right-hand side do also occur in the left-hand

side. (Of course, choosing the `right' direction may be a problem|see our

discussion of Knuth-Bendix completion.)

In the conditional case the transition from conditional equations to con-

ditional rewrite rules does present a problem, or at least some choices. Der-

showitz, Okada & Sivakumar 88] make the following distinctions, thereby

extending a classi cation introduced in Bergstra & Klop 86]. First we

introduce some notation.

Term Rewriting Systems

101

De nition 3.0.2. Let ! be a rewrite relation.

1. t # s (t; s are joinable) if t u and s u for some term u. (So ! is con uent if = (convertibility) and # coincide.)
2. s ! t if s t and t is a ground normal form.

Now there are several choices for evaluating the conditions of CTRS's. In the terminology of Dershowitz, Okada & Sivakumar 88] we can distinguish (among others) the following types of CTRS's: 1. semi-equational systems

t0 ! s0 ( t1 = s1; : : :; tn = sn

2. join systems
t0 ! s0 ( t1 # s1; : : :; tn # sn
3. normal systems

t0 ! s0 ( t1 ! s1; : : :; tn ! sn

4. generalized systems

t0 ! s0 ( P1; : : :; Pn:

In the last type of CTRS's, the Pi (i = 1; : : :; n) are conditions formulated

in a general mathematical framework, e.g. in some rst order language,

involving the variables occurring in the consequent (and possibly others).

In Bergstra & Klop 86] semi-equational systems were called to be of

Type I, join systems of Type Bergstra & Klop 86] de ne:

II, t

and !s

normal if s is a

systems ground

noofrTmyaplefoIIrImn:eAvecntuwaliltyh,

respect to the unconditional part from the CTRS R (obtained by removing

all conditions). This is necessary since otherwise the reduction relation

may not be well-de ned.

Note that in the cases (1){(3), the de nition of ! is circular since it

depends from conditions involving in some way or another a reference to !;

but it is not hard to see that in fact ! is well-de ned since all conditions

of type (1){(3) are positive. Hence the rewrite rules constitute a positive

induction de nition of !. In the case of generalized CTRS's we have to

take care in formulating the conditions, in order to ensure that ! is well-

de ned.

Remark 3.0.3. In a rewrite rule t ! s one requires that in s no new
variables appear with respect to t. The same requirement is made for
conditional rewrite rules t ! s ( C. But, as observed in Dershowitz,
Okada & Sivakumar 88], for CTRS's it would make good sense to lift this

102 J. W. Klop requirement, as e.g. in the following perfectly natural conditional rewrite speci cation of the Fibonacci numbers:

Fib(0) ! h0; 1i Fib(x + 1) ! hz; y + zi ( Fib(x) # hy; zi:

We will not study this more liberal format here, since it introduces a considerable complication of the theory.

We will now discuss several con uence criteria for CTRS's. The rst one is a generalization due to Middeldorp 91] (also in Middeldorp 90]) of Toyama's theorem 1.2.2, stating that con uence is a modular property of TRS's, to CTRS's:

Theorem
CTRS's or

3b.o0t.h4.noLremtaRl1C;TRR2 Sb'es

both with

semi-equational CTRS's or disjoint alphabet. Then:

both

join

R1; R2 are con uent , R1 R2 is con uent.

(sTimhpeldyijsojoinintthseumsetRs 1of

rRew2 riistdeerunleesd.)anTahleogporuosolfy

to the unconditional case: is a nontrivial application

of Toyama's theorem 1.2.2.

Orthogonal Conditional Term Rewriting Systems
We will now state some con uence criteria for orthogonal CTRS's.

De nition 3.0.5.

1. Let R be a CTRS (of any type, semi-equational, join, : : :). Then Ru; the unconditional version of R, is the TRS which arises from R by deleting all conditions.

2.

TorhtehoCgTonRaSl.R(SiseecaSlleecdti(onno2n.-1)lefoftr-loirntehaorgiofnRaul

is so; likewise TRS's.)

for

(weakly)

De nition 3.0.6.

1. Let R be a CTRS with rewrite relation !; and let P be an n-ary

predicate on the set
! if for all terms ti;

ot0if

terms of R. such that ti

Thte0in(iP=is1;c:l:o:s;end)w: ith

respect

to

P (t1; : : :; tn) ) P (t01; : : :; t0n):

2. Let R be a CTRS with rewrite relation !. Then R is closed if all
conditions (appearing in some conditional rewrite rule of R), viewed

Term Rewriting Systems

103

as predicates with the variables ranging over R-terms, are closed with
respect to !.

Theorem 3.0.7. (O'Donnell 77]) Let R be a generalized, weakly orthog-
onal CTRS which is closed. Then R is con uent.

The proof is a rather straightforward generalization of the con uence proof

for weakly orthogonal TRS's.

Obviously, rewrite rule of

the convertibility a semi-equational

CcoTnRdSitiaornescltoise=d.

sHi e(nice=:

1; : : :; n)

in

a

Corollary 3.0.8. Weakly orthogonal semi-equational CTRS's are con u-
ent.

Example 3.0.9. Let R be the orthogonal, semi-equational CTRS obtained
by extending Combinatory Logic with a `test for convertibility':

Sxyz ! xz(yz) Kxy ! x Ix ! x Dxy ! E ( x = y:

Then R is con uent. The question now arises whether analogous facts hold for the other types
of CTRS's. Indeed, this is the case for normal conditions. The following theorem is a slight generalization of a result in Bergstra & Klop 86]:
Theorem 3.0.10. Weakly orthogonal normal CTRS's are con uent. Remark 3.0.11.
1. Orthogonal join CTRS's are in general not con uent, and even in general not weakly con uent. In Bergstra & Klop 86] the following counterexample is given:
C(x) ! E ( x # C(x) B ! C(B):

SCe(eEF) i!gurEe,

3.1. i.e.

CC((EE))##EE:

does

not

hold,

since

this

would

require

2. The counterexample in (1) exhibits an interesting phenomenon, or rather, makes a pitfall explicit. According to Corollary 3.0.8 above,

the semi-equational CTRS with rules

C(x) ! E ( x = C(x) B ! C(B)

104 J. W. Klop
Figure 3.1 is con uent. Hence its convertibility, =, coincides with the joinability
relation, #. So x = C(x) i x # C(x). Yet the join CTRS obtained by replacing the condition x = C(x) by x # C(x), is according to (1)
of this remark not con uent.
The complexity of normal forms
Whereas in the unconditional case, being in `normal form' is an easily decidable property, this needs no longer to be so in the case of CTRS's. In fact, there are semi-equational orthogonal CTRS's for which the set of normal forms is undecidable (and hence not even r.e., since the complement of the set of normal forms is r.e.). The same holds for normal orthogonal CTRS's, and for join CTRS's. The proof is short and instructive enough to be included:
Consider CL (Combinatory Logic); it is well-known (cf. Barendregt 81]) that there is a representation n, a ground CL-term in normal form, of the natural number n for each n 0; together with a computable coding # from the set of ground CL-terms into natural numbers, and an `enumerator' E (also a ground CL-term in normal form) such that E#(M) M for every ground CL-term M. Now let R be the normal CTRS obtained by extending CL with a new constant symbol F and the rule
Fx ! 1 ( Ex 0: (Note that the reduction relation ! of R satis es Fx ! 1 , Ex 0.) If R had decidable normal forms, then in particular the set fn j Fn 1g would be decidable, i.e. the set fn j En 0g would be so. However, then
the set
X = fM a ground CL-term j M 0g
is decidable; for, given M we compute #(M) and decide whether E(#(M)) 0 or not. (By con uence for R it follows from E(#(M)) 0 and E#(M)
M that M 0.) But this contradicts the fact that X is undecidable;
this follows from a theorem of Scott stating that any nonempty proper subset of the set of ground CL-terms which is closed under convertibility in CL, must be undecidable.

Term Rewriting Systems

105

For a condition guaranteeing decidability of normal forms, we refer to the notion `decreasing' below.

Exercise 3.0.12. Adapt the proof above such that it holds for normal
CTRS's, and for join CTRS's.

Exercise 3.0.13. (Bergstra & Klop 86]) In this exercise we give a crite-

rion for decidability of normal forms which does not imply termination (as the

criterion `decreasing' does).
Let R be a normal CTRS. If r: t ! s ( t1 n1; : : : ; tk nk is a rule of
R, then an instance t ( some substitution) is called a candidate r-redex of R.

(Of course whether t

it depends on the validity of is an actual r-redex or not.)

the

instantiated

conditions

ti

ni of r

aRcas.nfdWoSilduleoapwtdpeseo:rsne-rNeeNFdinFe0dxiuits(cittihveeMlynse),ttrhheoaafvsseenatbobroNemveFena,nltdohfeofernmlneoefsrdtm-.ohafalTnRfdhouers,nmidtseMheooffu2oonnrcNdeoeFnornfdn+itth1ifoeonirfcaoalfnolldrpinaterivotenrosy0,f

tNoirFd; ee?rvaSlunnat.0esNFuFtornthaceor`nmwtraooirnnes,g'tNhnFeornimsoratmhl eafolsrefmotrmomfsia,ollfi.nieno. rmnmiatiel

6 ni,
forms order.

such of R.

that We

mi say

is of that

1. Show that if NF is undecidable, then there must be some normal form of

in nite order.

2.

Suppose subterm

for every of t), i =

rule 1; : :

r :;

(as above) of R k. Then we say

twhaethRavehatsi

t (ti
subterm

is a proper conditions.

Show that if R has subterm conditions, there are no normal forms of in nite

order. Hence NF is decidable.

Non-orthogonal conditional rewriting
Following Dershowitz, Okada & Sivakumar 88] (see also Dershowitz & Okada 90]), we will now consider CTRS's which are not orthogonal (i.e. may have `critical pairs') and formulate some conditions ensuring con uence.
De nition 3.0.14. (Critical Pairs)
1. Let R be a CTRS containing the two conditional rewrite rules
ti ! si ( Ei (i = 1; 2):
(Suppose these are `standardized apart', i.e. have no variables in common.) Suppose t2 can be uni ed with the nonvariable subterm u in t1 C u], via = mgu(t2; u). Then the conditional equation(!)
s1 = C t2] ( (E1; E2)
is a critical pair of the two rules.

106 J. W. Klop

2.

A t1

critical u:

pair

is

an

overlay

if

in

(1),

t1

and

t2

unify

at

the

root,

i.e.

3. A CTRS is non-overlapping (or non-ambiguous) if it has no critical

pairs.

4. A critical pair s = t ( E is joinable if for all substitutions such

that E is true, we have s # t :

Theorem 3.0.15. (Dershowitz, Okada & Sivakumar 88])
1. Let R be a semi-equational CTRS. Then: If R is terminating and all critical pairs are joinable, R is con uent.
2. Let R be a join system. Then: If R is decreasing and all critical pairs are joinable, R is con uent.
3. Let R be a join system. If R is terminating and all critical pairs are overlays and joinable, R is con uent.

This theorem contains the unexplained notion of a `decreasing' CTRS:

De nition 3.0.16. (Dershowitz, Okada & Sivakumar 88]) Let R be a

CTRS.

1. > is a decreasing ordering for R if

(a) > is a well-founded ordering on the set of terms of R (i.e. there

(b)

are t

nso)destce<ndsin(hgecrehainsistt0h>e

pt1ro>petr2

> ); subterm

ordering);

(c) t ! s ) t > s;

(d)

for each rewrite rule t and each substitution

!s
we

h(avet:1

#
t

(Likewise for other CTRS's than join

Cs>T1;R:tiS: :;'s;s.ti)n

#
(i

sn =

(n 1; :

:

:;

0) n).

2. A CTRS is decreasing if it has a decreasing ordering.

A consequence of `decreasing' is termination. Moreover, the notions
!; ; #, and normal form are decidable.

Remark 3.0.17. Related notions are fair or simplifying CTRS's (Kaplan
84, 87]) and reductive CTRS's (Jouannaud & Waldmann 86]). In fact:
reductive ) simplifying ) decreasing; see also Dershowitz & Okada 90].
We conclude this section by mentioning a useful fact:

Theorem
decreasing

s3e.m0.i1-e8q.ua(tDioenrsahl oCwTitRz,S.OLkeatdRa #&beSitvhaekcuomrraersp8o8n]d)inLgejtoiRn=CTbeRSa

(where conditions ti = si are changed into ti # si). Then:

R= is con uent ) R# is con uent.

Term Rewriting Systems

107

Acknowledgements
I am grateful to several persons for their support in writing this chapter. In particular I like to thank Henk Barendregt, Nachum Dershowitz, Ronan Sleep, Roel de Vrijer, as well as editors and co-authors of this Handbook. Special thanks to Aart Middeldorp for several contributions, and to JeanJacques Levy for his close scrutiny of a previous version including many helpful comments. Finally, many thanks to Aart Middeldorp, Vincent van Oostrom, Jane Spurr and Fer-Jan de Vries for the heroic struggle to transform an early Macintosh version into LATEX.

4 References

Apt, K.R. (1990). Logic Programming. In: Formal models and semantics, Handbook of Theoretical Computer Science, Vol. B (ed. J. van Leeuwen), 495-574.

Bachmair, L. (1988). Proof by consistency in equational theories. In: Proceedings

of the 3rd IEEE Symposium on Logic in Computer Science, Edinburgh, 228-233.

Bachmair, L. (1989). Canonical Equational Proofs. Birkhauser, Boston, 1991.

Bachmair, L. & Dershowitz, N. (1986). Commutation, transformation, and ter-

mination. Proceedings of the 8th Conference on Automated Deduction (ed. J.H.

Siekmann), Oxford, Springer LNCS 230, 5-20.

Bachmair, L., Dershowitz, N. & Hsiang, J. (1986). Orderings for equational

proofs. In: Proceedings of the 1st IEEE Symposium on Logic in Computer Sci-

ence, Cambridge, Massachusetts, 346-357.

Bachmair, L. & Plaisted, D.A. (1985). Associative path orderings. In: Proceed-

ings of the 1st International Conference on Rewriting Techniques and Applica-

tions (ed. J.-P. Jouannaud), Dijon, Springer LNCS 202, 241-254.

Barendregt, H.P. (1981). The Lambda Calculus, its Syntax and Semantics (1st

edn. 1981, 2nd edn. 1984). North-Holland, Amsterdam.

Barendregt, H.P. (1989). Functional programming and lambda calculus. In:

Handbook of Theoretical Computer Science (ed. J. van Leeuwen), North-Holland,

Amsterdam.

Barendregt, H.P., van Eekelen, M.C.J.D., Glauert, J.R.W., Kennaway, J.R., Plas-

meijer, M.J. & Sleep, M.R. (1987). Term graph rewriting. In: Proceedings of

the 1st Conference on Parallel Architectures and Languages Europe (PARLE),

Eindhoven, Vol. II, Springer LNCS 259, 141-158.

Bergstra, J.A., Heering, J. & Klint, P. (eds.) (1989). Algebraic speci cation.

Addison-Wesley, Reading, Massachusetts.

cBaetrigosnt.raI,nfJo.rAm.a&tioKnloapn,dJC.Won.t(r1o9l8640).(1P/r3o)c,es1s09a-l1g3e7b.ra for synchronous communi-

Bergstra, J.A. & abstraction. TCS

3K7lo(p1,),J1.W71.-1(9199.85).

Algebra of communicating processes with

Bergstra, J.A. & Klop, J.W. (1986). Conditional rewrite rules: con uence and
termination. JCSS 32 (3), 323-362.

108 J. W. Klop

Bergstra, J.A. (Elektronische

& Meyer, J.-J.Ch. (1984). On specifying Informationsverarbeitung und Kybernetik)

s2e0ts(1o0f/i1n1t)e,ge5r3s1.-5E41IK.

Bergstra, J.A. & Tucker, J.V. (1980). A characterisation of computable data

types by means of a nite equational speci cation method. In: Proceedings of of

the 7th International Colloquium on Automata, Languages and Programming,

(eds. J.W. de Bakker & J. van Leeuwen), Amsterdam, Springer LNCS 85, 76-90.

Berry, G. programs.

& Levy, J.-J. (1979).
JACM 26, 148-175.

Minimal

and

optimal

computations

of

recursive

BCiarmkhborid,gGe .P(h1i9lo3s5o)p. hOicnalthSeosctireutyct3u1re,

of abstract 433-454.

algebras.

In:

Proceedings

of

the

Boudol, G. (1985). Computational semantics of term rewriting systems. In: Al-

gebraic methods in semantics (eds. M. Nivat and J.C. Reynolds), Cambridge

University Press, 169-236.

Courcelle, B. (1990). Recursive application schemes. In: Formal models and

semantics, Handbook of Theoretical Computer Science, Vol. B, (ed. J. van

Leeuwen), Elsevier - The MIT Press, Amsterdam, 459-492.

Church, A. (1941). The calculi of lambda conversion. Annals of Mathematics

Studies, Vol. 6, Princeton University Press.

Curien, P.-L. (1986). Categorical combinators, sequential algorithms and func-

tional programming. Research Notes in Theoretical Computer Science, Pitman,

London.

Dauchet, M. (1989). Simulation of Turing machines by a left-linear rewrite rule.

In: Proceedings of the 3rd International Conference on Rewriting Techniques and

Applications, Chapel Hill, Springer LNCS 355, 109-120.

Dauchet, M. & Tison, S. (1984). Decidability of con uence for ground term

rewriting systems. Report, Universite de Lille I.

Dauchet, M., Tison, S., Heuillard, T. & Lescanne, P. (1987). Decidability of the

con uence of ground term rewriting systems. In: Proceedings of the 2nd Sympo-

sium on Logic in Computer Science, Ithaca, NY, 353-359.

DinegrsLheotwteirtsz,9N(.5()1, 927192)-.21A5.note on simpli cation orderings. Information Process-

Dershowitz, N. (1981). Termination of linear rewriting systems. Proceedings of

the 8th International Colloquium on Automata, Languages and Programming,

(Eds. S. Even and O. Kariv), Springer LNCS 115, 448-458.

tDreorls6h5ow, 1it2z2,-1N5.7(.1985). Computing with rewrite systems. Information and Con-

Dershowitz, (1), 69-116.

CNo. r(r1i9g8en7)d.umTe:rm4 i(n3a)t,i4o0n9o-4f1r0e.writing.

J.

of

Symbolic

Computation

3

Dershowitz, N. & Jouannaud, J.-P. (1990). Rewrite systems. In: Formal models

and semantics, Handbook of Theoretical Computer Science, Vol. B, (ed. J. van

Leeuwen), Elsevier - The MIT Press, Amsterdam, 243-320.

Dershowitz, N. & Manna, Z. (1979). Proving termination with multiset orderings.
Comm. of the ACM 22 (8), 465-476.

Dershowitz, N., Marcus, L. & Tarlecki, A. (1988). Existence, uniqueness, and

Term Rewriting Systems

109

construction of rewrite systems. SIAM J. Comput. 17 (4), 629-639.

Dershowitz, N. & Okada, M. (1990). A rationale for conditional equational pro-
gramming. TCS 75, 111-138.

Dershowitz, N., Okada, M. & Sivakumar, G. (1987). Con uence of Conditional

Rewrite Systems. In: Proceedings of the 1st International Workshop on Condi-

tional Term Rewrite Systems, Orsay, Springer LNCS 308, 31-44.

Dershowitz, N., Okada, M. & Sivakumar, G. (1988). Canonical Conditional

Rewrite Systems. In: Proceedings of the 9th Conference on Automated Deduc-

tion, Argonne, Springer LNCS 310, 538-549.

Drosten, K. (1989). Termersetzungssysteme. Informatik-Fachberichte 210,

Springer. (In German.)

Ehrig, H. & Mahr, B. (1985). Fundamentals of Algebraic Speci cation 1. Equa-

tions and Initial Semantics. Springer-Verlag, Berlin.

Gallier, J.H. (1987). What's so special about Kruskal's Theorem and the ordinal

?0. Technical report MS-CIS-87-27, University of Pennsylvania, Philadelphia.

Ganzinger, H. & Giegerich, R. (1987). A note on termination in combinations of heterogeneous term rewriting systems. Bulletin of the EATCS (European Asso-
ciation for Theoretical Computer Science) 31, 22-28.

Geser, A. (1990). Relative Termination. Ph.D. Thesis, University of Passau,

1990.

Goguen, J.A. & Meseguer, J. (1985). Initiality, induction, and computability. In:

Algebraic methods in semantics (eds. M. Nivat & J.C. Reynolds), Cambridge

University Press 1985, 459-542.

Guessarian, I. (1981). Algebraic semantics. Springer LNCS 99.

Hardin, T. (1989). Con -calculi as subsystems

ouf eCnCceLr.eTsuCltSs,foFrunthdeampuernetaSltrSotnugdiCesat6eg5o(r3ic)a, l2L9o1g-3ic42C.CL;

Hindley, J.R. (1964). The Church-Rosser property and a result in combinatory

logic. Ph.D. Thesis, University of Newcastle-upon-Tyne.

Hindley, J.R. & Seldin, London Mathematical

SJo.Pci.e(t1y9S8t6u).deInnttrTodeuxtcsti1on, CtoamCobmridbgineaUtonrisvaernsdity-PCraelcssu.lus.

Holldobler, S. (1989). Foundations of Equational Logic Programming. Springer

LNCS 353.

tHeurmet,reGw.r(it1i9n8g0s)y. stCeomns.uJeAnCt rMed2u7cti(o4n),s:79A7b-8st2r1a.ct properties and applications to

Huet, G. (1981). algorithm. JCSS

A23c,o1m1-p2le1t.e

proof

of

correctness

of

the

Knuth-Bendix

completion

Huet, G. & Lankford, D.S. (1978). On the uniform halting problem for term

rewriting systems. Rapport Laboria 283, IRIA, 1978.

Huet, G. & Levy, J.-J. (1979). Call-by-need computations in non-ambiguous lin-

ear term rewriting systems. Rapport INRIA 359. To appear as: Computations

in orthogonal term rewriting systems in: Computational logic, essays in honour

of Alan Robinson (eds. J.-L. Lassez & G. Plotkin), MIT Press, Cambridge, Mas-

sachusetts.

Huet, G. & Oppen, D.C. (1980). Equations and rewrite rules: A survey. In:

110 J. W. Klop

Formal Language Theory: Perspectives and Open Problems (ed. R.V. Book),

Academic Press, London, 349-405.

Hullot, J.M. (1980) Canonical forms and uni cation. In: Proceedings 5th Con-

ference on Automated Deduction, Les Arcs, France, 318-334.

Jantzen, M. (1988). Con uent string rewriting and congruences. EATCS (Euro-

pCeoamnpAustseorcSiactieionncefo1r4T, hSeporrinetgiecra-lVCerolmagp,uBteerrlSinc.ience) Monographs on Theoretical

Jouannaud, J.-P. & Kirchner, H. set of equations. SIAM J. Comp.

(11598(64)).,

Completion 1155-1194.

of

a

set

of

rules

modulo

a

Jouannaud, J.-P. & Waldmann, B. (1986). Reductive conditional Term Rewrit-

ing Systems. In: Proceedings of the 3rd IFIP Working Conference on Formal

Description of Programming Concepts, Ebberup, 223-244.

Kamin, S. & Levy, J.-J. (1980). Two generalizations of the recursive path order-

ing. Unpublished manuscript, University of Illinois.

Kaplan, S. (1984). Conditional Rewrite Rules. TCS 33 (2,3).

Kaplan, S. (1987). Simplifying termination and con uence. J.

conditional of Symbolic

tCerommpruewtartiitoinng4sy(3st)e,m29s5: -U33n4i.

cation,

Kennaway, J.R. (1989). lated reduction systems.

ASnenquaelsnotifaPl euvraeluanatdioAnpsptlriaedtegLioesgifco4r3p,a3r1a-l5le6l.-or

and

re-

Kennaway, J.R. & Sleep, M.R. (1989). Neededness is hypernormalizing in regular

combinatory reduction systems. Preprint, School of Information Systems, Uni-

versity of East Anglia, Norwich.

Klop, J.W. (1980a). Combinatory Reduction Systems. Mathematical Centre

Tracts 127, CWI, Amsterdam.

Klop, J.W. (1980b). Reduction cycles in Combinatory Logic. In: Festschrift `To

H.B. Curry, Essays on Combinatory Logic, Lambda Calculus and Formalism'

(eds. J.P. Seldin & J.R. Hindley), Academic Press, London, 193-214.

Klop, J.W. (1985). Term Rewriting Systems. Notes for the Seminar on Reduc-

tion Machines, Ustica. Unpublished.

Klop, J.W. (1987)
32, 143-182.

Term

rewriting

systems:

a

tutorial,

Bulletin

of

the

EATCS

Klop, J.W. & pletion. CWI

QMuidadrteeldrloyrp1,(3A),.

(1988). Centre

An Introduction for Mathematics

to Knuth-Bendix Comand Computer Science,

Amsterdam, 31-52.

Klop, J.W. & Middeldorp, A. (1989). Sequentiality in Orthogonal Term Rewrit-

ing Systems. Report CS-R8932, CWI, Centre for Mathematics and Computer

Science, Amsterdam. To appear in J. of Symbolic Computation.

Knuth, D.E. & Bendix, P.B. (1970). Simple word problems in universal algebras.

In: Computational Problems in Abstract Algebra (ed. J. Leech), Pergamon

Press, 263-297.

CKorunsjekcatlu, rJe..BT. r(a1n9s6a0c)t.ionWseollf-QthueaAsiM-OSrd9e5ri,n2g1,0t-h2e25T. ree Theorem, and Vazsonyi's

Kurihara, M. & Kaji, I. (1988). Modular Term Rewriting Systems: Termina-

tion, Con uence and Strategies. Report, Hokkaido University. Abridged version:

Term Rewriting Systems

111

LMeotdteurlsar34te3rm4,

rewriting 1-4.

systems

and

the

termination.

Information Processing

Lankford, D.S. (1979). On proving term rewriting systems are Noetherian. Memo

MTP-3, Mathematical Department, Louisiana Technical University, Ruston,

Louisiana.

Le Chenadec, P. (1986). Canonical forms in nitely presented algebras. Research

Notes in Theoretical Computer Science, Pitman, London.

Macatirotnelslio, nAP. r&ogMraomntmainnagriL, aUn.g(u1a9g8e2s).anAdnSeystecmiens t4u(2n)i,

cation algorithm. 258-282.

Trans-

Martelli, A., Moiso, C. & Rossi C.F. (1986). An Algorithm for Uni cation in

Equational Theories. In: Proceedings Symposium on Logic Programming, 180-

186.

Meinke, K. & Tucker, J.V. (1991). Universal algebra. In: Handbook of Logic

in Computer Science (eds. S. Abramsky, D. Gabbay & T. Maibaum), Oxford

University Press, this volume.

Metivier, Y. (1983). About the rewriting systems produced by the Knuth-Bendix
completion algorithm. Information Processing Letters 16, 31-34.

Middeldorp, A. (1989a). Modular aspects of properties of term rewriting systems

related to normal forms. In: Proceedings of 3rd International Conference on

Rewriting Techniques and Applications, Chapel Hill, Springer LNCS 355, 263-

277.

Middeldorp, A. (1989b). A su cient condition for the termination of the direct

sum of term rewriting systems. In: Proceedings of the 4th IEEE Symposium on

Logic in Computer Science, Paci c Grove, 396-401.

Middeldorp, A. (1990). Modular properties of term rewriting systems. Ph.D.

Thesis, Vrije Universiteit, Amsterdam.

Middeldorp, A. (1991). Modular properties of conditional term rewriting proper-

ties. To appear in Information and Computation.

Nash-Williams, ceedings of the

CCa.mStb.Jri.dAg.e(P19h6il3o)s.opOhnicawl eSllo-qciueatysi-5o9rd(4e)r,in8g33-n8i3t5e.

trees.

In:

Pro-

Nederpelt, R.P. (1973). Strong normalization for a typed lambda calculus with

lambda structured types. Ph.D. Thesis, Technische Hogeschool, Eindhoven, the

Netherlands.

Newman, M.H.A. (1942). alence". Annals of Math.

4O3n(2t)h,e2o2ri3e-s24w3i.th

a

combinatorial de

nition of

\equiv-

O'Donnell, M.J. (1977). Computing in systems described by equations. Springer

LNCS 58.

O'Donnell, M.J. (1985). Equational logic as a programming language. The MIT

Press, Cambridge, Massachusetts.

Osyysatemmasguischdie,cMid.ab(1le9.8T7)C. ST4h9e(C1)h,u4r3c-h7-9R.osser property for ground term rewriting

Peterson, G.E. & Stickel, M.E. (1981). Complete sets of reductions for some
equational theories. J. of the ACM, 28(2), 233-264.

Plaisted, D.A. (1978). A recursively de ned ordering for proving termination of

112 J. W. Klop

term rewriting systems. Report R-78-943, University of Illinois, Urbana, Illinois.

Plaisted, D.A. (1985). Semantic con uence tests and completion methods. Infor-

mation and Control, bf 65, 182-215.

PJ.uoefl,SLy.m(b19o8li6c).CUomsipnugtautniaonvo8id(a4b),le3s3e5t-s38o2f.trees to generalize Kruskal's theorem.

Raoult, J.-C. & Vuillemin, J. (1980). Operational and semantic equivalence be-
tween recursive programs. Journal of the ACM 27(4),772-796.

Rosen, Journal

B.K. (1973). of the ACM

20T(r1e)e,-m16a0n-i1p8u7l.ating

systems

and

Church-Rosser

theorems.

Rusinowitch, M. (1987a). On termination of the direct sum of term rewriting
systems Information Processing Letters 26, 65-70.

Rorudseirnionwgitrcehvi,sMite.d(.19J8o7ubrn).alPoafthSyomf sbuoblitcerCmosmoprduetaritniogna3n,d1r1ec7u-1r3s1iv.e decomposition

Selman, A. (1972). Completeness of calculii for axiomatically de ned classes of
algebras. Algebra Universalis 2, 20-32.

Shoen eld, J.R. (1967). Mathematical Logic. Addison-Wesley, Reading, Mas-

sachusetts.

Siekmann, J. (1984). Universal uni cation. In: Proceedings of the 7th Interna-

tional Conference on Automated Deduction (ed. R.E. Shostak), Napa, California,

Springer LNCS 170, 1-42.

Smorynski, C. (1982). The variety of arboreal experience. The Mathematical
Intelligencer, 4(4), 182-189.

Staples, J. (1975). Church-Rosser theorems for replacement systems. In: Algebra

and Logic (ed. J. Crosley), Springer Lecture Notes in Mathematics 450, 291-307.

cTohnastttreu,cSto.r(s1.9I8n7f)o.rmAatrieonnaenmdenCtomofpsuttraotnigonse7q2u,en46ti-a6l5it.y for term rewriting with

RToeywarmitian,gYS.y(s1t9e8m7sa.).InCfoorumntaetrieoxnaPmrpolceesstsointgerLmeitnteartsio2n5f,o1r4t1h-e14d3ir.ect sum of Term

Toyama, rewriting

Y. (1987b). On the systems. Journal of

CthheurAcCh-MRo3ss4e(r1)p,r1o2p8e-r1ty43f.or

the

direct

sum

of

term

Toyama, Y. (1988). Commutativity of Term Rewriting Systems. In: Program-

ming of Future Generation Computer II (eds. K. Fuchi and L. Kott), North-

Holland, Amsterdam, 393-407.

Toyama, Y., Klop, J.W. & Barendregt, H.P. (1989). Termination for the di-

rect sum of left-linear term rewriting systems. In: Proceedings of the 3rd In-

ternational Conference on Rewriting Techniques and Applications, Chapel Hill,

Springer LNCS 355, 477-491. Extended version: Report CS-R8923, CWI, Ams-

terdam.

Turner, D.A. (1979). A new implementation technique for applicative languages.
Software Practice and Experience, 9, 31-49.

Winkler, F. & Buchberger, B. (1983). A criterion for eliminating unnecessary

reductions in the Knuth-Bendix algorithm. In: Proceedings of the Colloquium on

Algebra, Combinatorics and Logic in Computer Science, Gyor, Hungary.

