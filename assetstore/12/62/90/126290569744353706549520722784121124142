Positive/Negative-Conditional
Equations:
A Constructor-Based Framework
for Specification and
Inductive Theorem Proving
Vom Fachbereich Informatik
der Universität Kaiserslautern
zur Verleihung des akademischen Grades
Doktor der Naturwissenschaften (Dr. rer. nat.)
genehmigte Dissertation von
Claus-Peter Wirth
This version incorporates the following revisions:
July 23, 1998 (Lots of typos corrected, pp. 97–100 rewritten)
Feb. 1, 2003 (Typos corrected, remark added at end of § 12.7)
Aug. 22, 2004 (Foundedness renamed to Groundedness. In § B,
∀ renamed to δ+, and ∃ to γ+)
Datum der wissenschaftlichen Aussprache: 11. Oktober 1996
Dekan: Prof. Dr. Hans Hagen
Promotionskommission:
Vorsitzender: Prof. Dr. Theo Härder
Berichterstatter: Prof. Dr. Jürgen Avenhaus
Prof. Dr. Klaus Madlener
D 386
Abstract
In this thesis we study algebraic specifications given by positive/negative-conditional equations,
i.e. universally quantified first-order implications with a single equation in the succedent and a
conjunction of positive and negative (i.e. negated) equations in the antecedent. In general, the
class of models of such a specification does not contain a minimum model in the sense that it
can be mapped to any other model by some homomorphism. We present a constructor-based
approach for assigning appropriate semantics to such specifications by introducing two syntactic
restrictions: firstly, for each term of a negative equation in a condition, this condition also has
to contain a literal requiring the “definedness” of this term; secondly, we restrict the rules whose
left-hand sides are constructor terms to have “Horn”-form and to be “constructor-preserving”. A
reduction relation for positive/negative-conditional rules is defined, for which the fundamental
results for positive-conditional rewrite systems can be sustained. Under the assumption of con-
fluence, the factor algebra of the term algebra modulo the congruence induced by this reduction
relation is a minimal model which is — beyond that — the minimum of all models that do not
identify more constructor terms than necessary. We define several kinds of compatibility with
wellfounded orderings for achieving decidability of reducibility, and present sufficient criteria for
the confluence of our reduction relation.
Furthermore, various conceivable notions of inductive validity for first-order equational clauses
w.r.t. constructor-based positive/negative-conditional equational specifications are defined and
discussed. Monotonicity of validity w.r.t. consistent extension of the specification admits an
incremental construction of specifications without destroying the validity of already proved pro-
positions. For inductive validities, monotonicity is essential because — contrary to deductive
theorem proving — such extensions are required by the inductive proofs themselves. Therefore
it is important that — just like our reduction relation — our notions of inductive validity are
monotonic w.r.t. consistent extension of the specification.
Finally, we present an inference system for clausal theorem proving w.r.t. various kinds of in-
ductive validity in theories specified by constructor-based positive/negative-conditional rule sys-
tems that have to be (ground) confluent, but need not be terminating. Our constructor-based
approach is well-suited for inductive theorem proving even in the presence of partially defined
functions. The proposed inference system provides explicit induction hypotheses and can be in-
stantiated with various wellfounded induction orderings. The soundness proof for the inference
system is developed systematically by presenting an abstract frame inference system a priori and
then designing each concrete inference rule locally as a sub-rule of some abstract frame infer-
ence rule. While this emphasizes a well structured clear design of the concrete inference system,
our fundamental design goal is user-orientation and practical usefulness rather than theoretical
elegance. The resulting inference system is comprehensive and quite powerful, but requires a
sophisticated concept of proof guidance.
Zusammenfassung
Grundlage dieser Dissertation sind algebraische Spezifikationen mit positiv/negativ bedingten
Gleichungen, also mit universell quantifizierten Implikationen der ersten Stufe, deren Sukze-
dens aus einer einzigen Gleichung und deren Antezedens aus einer Konjunktion positiver und
negativer (d. h. negierter) Gleichungen besteht. Die Modellklasse einer solchen Spezifikation er-
mangelt im allgemeinen eines Minimummodells in dem Sinne, daß sich dieses auf alle anderen
Modelle homomorph abbilden ließe. Es gelingt uns jedoch, solchen Spezifikationen mit Hilfe
eines konstruktorbasierten Ansatzes eine ihnen gemäße Semantik zu geben. Hierzu führen wir
zwei syntaktische Einschränkungen ein. Und zwar verlangen wir zum einen, daß für jeden der
beiden Terme einer in einer Bedingung vorkommenden negativen Gleichung diese Bedingung
auch ein Literal enthalten muß, welches die
”
Definiertheit“ dieses Termes fordert. Zum anderen
darf eine jede Regel, deren linke Seite ein Konstruktorterm ist, nur Konstruktorterme und in ihrer
Bedingung nur positive Literale enthalten. Des weiteren wird die Reduktion mit positiv/negativ
bedingten Regeln in solcher Weise definiert, daß die grundlegenden Ergebnisse für positiv bed-
ingte Termersetzungssysteme ihre Gültigkeit behalten. Unter der Voraussetzung der Konfluenz
dieser Reduktionsrelation ist die Faktoralgebra der Termalgebra modulo der von der Reduktions-
relation induzierten Kongruenz ein Modell, welches nicht nur in obigem Sinne minimal, sondern
darüberhinaus das Minimum all derjenigen Modelle ist, welche nicht mehr Konstruktorterme
einander gleichsetzen als unbedingt nötig. Ergänzend definieren wir verschiedene Formen der
Verträglichkeit mit wohlfundierten Ordnungen, die auf die Entscheidbarkeit der Reduzibilität
abzielen und auch bei einigen der anschließend dargestellten, hinreichenden Kriterien für die
Konfluenz unserer Reduktionsrelation von Nutzen sind.
Alsdann bieten sich mehrere verschiedene Möglichkeiten, den Begriff der induktiven Gültigkeit
von Gleichungsklauseln erster Stufe bezüglich konstruktorbasierter, positiv/negativ bedingter Gle-
ichungsspezifikationen zu fassen. Ist ein monotones Verhalten gegenüber konsistenter Spezifika-
tionserweiterung bereits bei deduktiver Gültigkeit von Nutzen, weil es den stückweisen Aufbau
von Spezifikationen unter Beibehaltung der Gültigkeit der bereits bewiesenen Aussagen erlaubt,
so erreicht diese Monotonie doch erst für induktive Gültigkeiten ihre unverzichtbare Bedeutung,
weil die induktiven Beweise selbst nach derartigen Erweiterungen verlangen. Es ist daher von
besonderer Wichtigkeit, daß unsere Begriffe induktiver Gültigkeit, wie übrigens auch unsere
Reduktionsrelation, gegenüber konsistenter Spezifikationserweiterung ein monotones Verhalten
aufweisen.
Auf dieser Grundlage ist es uns nun möglich, ein Inferenzsystem zum Nachweis verschiedener
induktiver Gültigkeiten von Gleichungsklauseln zu entwickeln, wobei für die zugrundeliegen-
den Theorien vorausgesetzt wird, daß sie sich durch konstruktorbasierte, positiv/negativ bedingte
Regelsysteme spezifizieren lassen, die außerdem (grund-) konfluent, aber nicht notwendigerweise
terminierend sein müssen. Unser konstruktorbasierter Ansatz erweist sich für ein derartiges In-
duktionsbeweisen als gut geeignet, und auch das Auftreten von partiell definierten Funktionen
bereitet keine zusätzlichen Schwierigkeiten. Das von uns vorgestellte Inferenzsystem stellt In-
duktionshypothesen explizit bereit und erlaubt den Einsatz der verschiedensten wohlfundierten
Induktionsordnungen. Einen systematischen Aufbau des Korrektheitsbeweises für unser Inferenz-
system erreichen wir, indem wir zunächst ein abstraktes Rahmeninferenzsystem vorstellen und
anschließend jede unserer konkreten Inferenzregeln als Unterregel einer der abstrakten Rah-
meninferenzregeln eigenständig entwerfen. Obschon dieses Vorgehen die klare Strukturierung
der Entwicklung unseres konkreten Inferenzsystems betont, so liegt doch unser eigentlicher Ent-
wicklungsschwerpunkt eher auf der Benutzerorientierung und praktischen Verwendbarkeit. Das
sich ergebende Inferenzsystem ist recht umfangreich und mächtig, verlangt jedoch nach einem
hochentwickelten Beweissteuerungskonzept.
Contents
1 Overall Motivation 1
2 Introduction 3
3 Overview of the Thesis 6
4 Motivation for Constructor-Based
Positive/Negative-Conditional Equational
Specification and Rewriting 11
4.1 Stéphane Kaplan’s Approach . . . . . . . . . . . . . . . . . . . . . . . . . . 13
4.2 The Importance of Confluence . . . . . . . . . . . . . . . . . . . . . . . . . 13
4.3 Problematic Aspects of Kaplan’s Approach . . . . . . . . . . . . . . . . . . 14
4.4 Looking for Remedy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
4.5 Our Solution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
4.6 Concluding Comparison with Other Approaches . . . . . . . . . . . . . . . 19
4.7 Two Types of Variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
5 Basic Notions and Notation 23
5.1 Terms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
5.2 Substitutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
5.3 Relations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26
5.4 Orderings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27
5.5 Confluence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28
5.6 Algebras . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
5.7 Atoms and Literals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31
5.8 Syntax of Rules and Formulas . . . . . . . . . . . . . . . . . . . . . . . . . 33
6 Semantics of Rules and Formulas 37
7 The Reduction Relation 41
8 Compatible Rule Systems 47
8.1 Undecidability of Reducibility . . . . . . . . . . . . . . . . . . . . . . . . . 47
8.2 How To Use Orderings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48
8.3 Decidability for Compatible Rule Systems . . . . . . . . . . . . . . . . . . 53
9 Confluence Criteria 54
9.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54
9.2 The Semantic Approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57
9.3 The Syntactic Approach: Critical Peaks . . . . . . . . . . . . . . . . . . . . 58
9.4 Basic Forms of Joinability of Critical Peaks . . . . . . . . . . . . . . . . . . 59
9.5 Compatible Rule Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . 60
9.6 Terminating Rule Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . 63
9.7 Complementary Critical Peaks . . . . . . . . . . . . . . . . . . . . . . . . . 67
10 Notions of Inductive Validity 71
10.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71
10.2 The Seven Cases . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73
10.3 The Seven Notions of Inductive Validity . . . . . . . . . . . . . . . . . . . . 74
10.4 The Operational View on the Notions: Counterexamples . . . . . . . . . . . 76
10.5 The Interrelation of the Notions . . . . . . . . . . . . . . . . . . . . . . . . 79
10.6 Monotonicity w.r.t. Consistent Extension . . . . . . . . . . . . . . . . . . . 83
10.7 Coincidences in Special Cases . . . . . . . . . . . . . . . . . . . . . . . . . 86
10.8 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88
10.9 Comparison of the Notions . . . . . . . . . . . . . . . . . . . . . . . . . . . 89
11 Introduction to Inductive Theorem Proving 93
11.1 What is Inductive Theorem Proving? . . . . . . . . . . . . . . . . . . . . . 93
11.2 Explicit versus Implicit Induction . . . . . . . . . . . . . . . . . . . . . . . 94
11.3 Our Approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96
12 The Abstract Inference System 101
12.1 Proof States . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104
12.2 Counterexamples and Validity . . . . . . . . . . . . . . . . . . . . . . . . . 108
12.3 Groundedness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109
12.4 The Frame Inference System . . . . . . . . . . . . . . . . . . . . . . . . . . 112
12.5 The Analytic Approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114
12.6 The Backwards Approach . . . . . . . . . . . . . . . . . . . . . . . . . . . 116
12.7 Results of the Two Approaches . . . . . . . . . . . . . . . . . . . . . . . . 117
12.8 The “Switched” Frame Inference System . . . . . . . . . . . . . . . . . . . 118
12.9 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120
12.10 Safe Steps and Failure Recognition . . . . . . . . . . . . . . . . . . . . . . 121
13 Towards the Concrete Inference System 122
13.1 The Induction Ordering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124
13.2 Generalized Substitutions . . . . . . . . . . . . . . . . . . . . . . . . . . . 129
13.3 Superposition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131
14 Contextual Rewriting 133
14.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133
14.2 Decomposition and Tautology Removal . . . . . . . . . . . . . . . . . . . . 134
14.3 Removal of Redundant Literals . . . . . . . . . . . . . . . . . . . . . . . . 136
14.4 Constant Rewriting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139
14.5 Application of Rules and Lemmas . . . . . . . . . . . . . . . . . . . . . . . 140
14.6 Completeness Result . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147
15 More Deductive Rules 149
15.1 Adding Context . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149
15.2 Removing and Adding Variables . . . . . . . . . . . . . . . . . . . . . . . . 151
16 Inductive Rules 153
16.1 Covering Sets of Substitutions . . . . . . . . . . . . . . . . . . . . . . . . . 153
16.2 Application of Hypotheses . . . . . . . . . . . . . . . . . . . . . . . . . . . 157
16.3 Solving Negative Literals . . . . . . . . . . . . . . . . . . . . . . . . . . . . 165
16.4 Generalization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 172
17 A Concrete Failure Predicate 177
18 Summarizing the Concrete Inference System 179
19 Outlook 180
20 Conclusion 182
A Refutational Completeness 183
B A Sequent Calculus for Deductive Validity 185
C The Proofs 191
References 235
Index 243
Acknowledgments
I would like to thank Klaus Madlener and Jürgen Avenhaus for giving me the opportunity to
work in their group and for promoting and refereeing this thesis, and Theo Härder for chairing its
defense.
Furthermore, I would like to thank my teachers Jürgen Avenhaus, Juliana Bruggaier, Bern-
hard Gramlich, Theo Härder, Klaus Madlener, Gerlinde Morlang, Albrecht Schneider, and Horst
Weller for all I have learned from them. Moreover, I would like to thank Detlev Boenert, Thomas
Deiß, Horst Prote, and Birgit and Joachim Reinert for their patience and love, and Klaus Becker,
Bernhard Gramlich, Ulrich Kühler, Rüdiger Lunde, and Horst Prote for their contributions to this
thesis. Finally, I would like to thank Martin Anlauf, Mauricio Ayala-Rincon, Stefan Bode, Robert
Bookhade, Arnim Buch, Ornette Coleman, John Coltrane, Jörg Denzinger, Robert Eschbach, Ro-
land Fettig-Vogt, Dirk Fuchs, Matthias Fuchs, Alfons Geser, Jürgen Giesl, Frank Hauptmann,
Thomas Hillenbrand, Dieter Hutter, Franz Kammermeier, Christoph Kögl, Martin Kronenburg,
Thomas Külz, Wolfgang Lindner, Bernd Löchner, Carlos A. Loría-Sáenz, David Oistrakh, Mar-
tin Protzen, Rodrigo Readi-Nasser, Michaël Rusinowitch, Andrea Sattler-Klein, Steffen Schuler,
Michael Schwarz, Inger Sonntag, Joachim Steinbach, Jürgen Stuber, Paul Taylor (for his support
with his diagram typesetting TEX-package), Uwe Waldmann, Uwe Wolter, Dirk Zeckzer, and the
readers, esp. those whose names I forgot to mention.
I am so much indebted to my parents Ellinor and Friedhelm Wirth, my grandmothers Else
Wirth and Toni Enders, and my sister Daniela Wirtz that I would like to dedicate this thesis to
them, in gratefulness.
Anweisung
Lade die Toten zu Ga
die Trne fllt aufwrt
sie kommen
die du lieb wie Lebende.
Niemal
den Lebenden
den du lieb
wie einen Toten.
Hilde Domin. Gesammelte Gedichte. S. Fischer Verlag, Frankfurt am Main, 1987.
Curriculum Vitae
Personalien
Name Claus-Peter Wirth
Anschrift Brandenburger Str. 42
D-65582 Diez
Geburtsdatum 18. April 1963
Geburtsort Diez an der Lahn
Familienstand Ledig
Staatsangehörigkeit Deutsch
Vater Friedrich-Wilhelm Wirth, Richter
Mutter Ellinor Wirth, geb. Enders, Hausfrau
Ausbildung und Wehrdienst
Grundschule 1969 - 1973 Pestalozzi-Schule, Diez
Gymnasium 1973 - 1982 Staatl. Gymnasium Diez
Abschluß: Abitur
Grundwehrdienst 10/82 - 12/83 1. Fernmeldebatallion 5, Diez
Studium WS 83/84 - SS 84 Chemie
Johannes Gutenberg Universität Mainz
WS 84/85 - SS 91 Informatik
Universität Kaiserslautern
Nebenfach: Wirtschaftswissenschaften
Abschluß: Diplom-Informatiker
Berufstätigkeit
Seit 01.11.1991 Wissenschaftlicher Mitarbeiter
Fachbereich Informatik
Universität Kaiserslautern
11 Overall Motivation
The subject of this thesis is clausal inductive theorem proving on the basis of specifications with
constructor-based positive/negative-conditional equations.1 Proving inductive theorems of posi-
tive/negative-conditional equational specifications is crucial for reasoning about computer pro-
grams. Since formal methods are indispensable to verifying safety-critical algorithms, it is to be
expected that more or less automated inductive theorem proving will gain economic significance
in the nearer future.
Positive/negative-conditional equations are universally quantified first-order implications with
a single equation in the succedent and a conjunction of positive and negative (i.e. negated) equa-
tions in the antecedent. Positive/negative-conditional equations are convenient2 for writing first-
order functional specifications, which can also be seen as programs because reduction to normal
form provides a straightforward and powerful computation formalism.
Being functional programs as opposed to imperative programs is no limitation because it-
erative loops and local variable introduction and value assignment can be easily replaced with
function calls and function definitions.3 Furthermore, the lack of higher-order features (like func-
tions occurring as arguments of functions) is not a serious limitation in our context.4
Instead of positive/negative-conditional equational specifications we could restrict ourselves
to a simpler framework for specification like positive conditional or unconditional equations.
Since conditions and “else”-cases (or negative conditions) with special control structure, however,
are essential to most specification and programming approaches, it is not adequate to first exclude
them and then try to simulate them in a poorer specification framework.5 Indeed, the problems
resulting from the restriction to pure equations were our main reason for discontinuing the further
refinement of the equational inductive theorem prover UNICOM.6
Since, from the point of view of pure classical logic, positive/negative-conditional equations
are nothing but equational clauses (i.e. implicitly universally quantified disjunctions of equality
literals) with one or more positive literals, and since the defining positive/negative-conditional
equations have to be representable as object formulas in our inductive theorem prover, it should
be obvious that we have to admit equational clauses as prover formulas.
That we do not allow general first-order formulas but only clauses as our prover formulas has
the following reasons: The clauses form a subset of the first-order formulas that is closed under
many interesting inference steps and furthers normalization of representation because finite sets
of clauses can be seen as a formula in conjunctive normal form. Moreover, clauses admit pow-
erful contextual reasoning. They are better suited for automation as well as for user interaction
than more general logical formulas. Furthermore, in inductive theorem proving, a prover for-
1Please do try not to read the footnotes on a first reading!
2Cf. Wirth & Lunde (1994) and Lunde & Wirth (1994).
3Cf. Boyer & Moore (1979).
4Cf. Boyer & Moore (1989).
5Cf. § 4 for more discussion on this.
6Cf. Gramlich & Lindner (1991).
2mula represents not only a proving task (as induction conclusion) but also a tool for this proof
(as induction hypothesis). Such a hypothesis is especially useful when it consists of a prefix of
universal quantifiers followed by a quantifier-free matrix.7 And clauses are of this form. More-
over, note that the addition of conjunction to our clauses is not necessary because we can move
all conjunctions to the outside (or top level) of our formulas and then remove the conjunctions,
yielding a set of formulas which can8 be used for induction as if it were a single formula.
Our inference system for proving clausal theorems w.r.t. constructor-based positive/negative-
conditional equational specifications can be used to show various conceivable kinds of inductive
validity. Regarding the semantics of our specifications two aspects are important:
• By practically reasonable restrictions on the syntax of our rules, we can guarantee the
existence of an initial model (or abstract data type) for each specification.
• By choosing notions of inductive validity properly, we can guarantee their monotonicity
w.r.t. consistent extension of the specification.
Monotonicity of validity w.r.t. consistent extension of the specification (i.e. w.r.t. the definition of
new non-constructor functions &c.) admits an incremental construction of specifications without
destroying the validity of already proved formulas. For inductive validity, monotonicity is es-
sential because — contrary to deductive theorem proving — such extensions are required by the
inductive proofs themselves.
Our inference system provides explicit induction hypotheses and can be instantiated with
various wellfounded induction orderings. The resulting inference system is comprehensive and
quite powerful, but requires a sophisticated concept of proof guidance.
An important property of our specification and inductive theorem proving approach is that it is
constructor-based in the following sense: For each sort, some of the function symbols are declared
to be the constructors for this sort. Data objects are denoted by terms that consist of constructor
function symbols. The non-constructor function symbols operate on these data objects according
to the defining positive/negative-conditional rules. With the help of constructor variables ranging
over the constructor terms (or data objects) only, we are able to overcome two serious limitations
from which many other approaches suffer: We do not have to require the termination nor the
completeness of our specifications, which means that we can reason about non-terminating and
partially specified functions. This is important in practice: The input-independent termination
of a program is usually not known a priori and sometimes (for interpreters or other program
executing programs) even impossible to achieve. Moreover, we can avoid the serious conceptual
and practical problem of over-specification resulting from arbitrary and meaningless completions
of partial function definitions.
7While ∀∗x¯∃∗y¯-formulas (having a prefix of universal quantifiers followed by existential quantifiers) are an inter-
esting extension when the formulas play the role of proof tasks, for applying formulas as hypotheses a constructive
description for the existential variables is far more useful than existential quantification. Finally, ∀∗x¯∃∗y¯∀∗z¯-formulas
are even less useful for inductive theorem proving because only the variables of the outermost universal quantifier
list ∀∗x¯ may occur in a weight for measuring the formula in the induction ordering of an inductive proof.
8Note that, due to our powerful mutual induction abilities, our situation is different from the one described in
footnote 14 on p. 90 of Boyer & Moore (1979).
32 Introduction
The aim of this section is to make the subject of this thesis accessible to the non-expert reader. To
this end, we are going to exemplify the essential ideas behind equational specification, inductive
validity, and inductive theorem proving.
Natural numbers and lists are omnipresent in mathematics, computer science, and everyday life.
Without them we could not write this sentence, because sentences are lists of characters. And even
very young children can represent natural numbers by listing bars. Before any teacher is able to
introduce natural numbers and lists as objects to our thinking, we have to have the concepts of
natural numbers and lists already to our disposal on the meta-level. Just as elementary is the
concept of equality,9 and after learning to write ‘=’ for it it is not difficult to understand things
like
0+0 = 0
0+1 = 1
.
.
.
0+9 = 9
1+0 = 1
1+1 = 2
.
.
.
1+9 = 10
. . .
9+0 = 9
9+1 = 10
.
.
.
9+9 = 18
This is nothing but an equational specification,10 and the idea of rules, i.e. of using an equation
to replace its left-hand side with its simpler right-hand side is also immediate. Watching chil-
dren doing addition with their fingers, it seems to be more straightforward to use the following
specification, where “s(x)” stands for “successor of x” or “x+1”:
x+0 = x
x+s(y) = s(x+y)
Note that this also uses the elementary concept of variables. Computation can now be seen as
reducing terms to normal form, i.e. applying the rules until none of them is applicable anymore.
Since computing the value of
s(0)+s(s(s(s(s(0)))))
takes more steps than computing the value of
s(s(s(s(s(0)))))+s(0)
it turns out to be rather useful to know that addition is commutative:
x+y = y+x
Does the validity of this formula follow from the above two equations defining ‘+’?
For answering this question we have to solve three tasks:
9Cf. Tarski (1986).
10It is also a very interesting one. Cf. Walters & Zantema (1995).
41. We have to make precise what kind of validity we are referring to.
Note that the formula is not a deductive theorem in the sense that it is valid in all models of
the defining equations. Deductive validity is equivalent to the possibility to connect the two
terms of the equation in a finite number of rewrite steps with the defining equations in any
direction. Since the defining rules result in a terminating and confluent reduction relation,
we can decide deductive validity of an equation “ s = t ” by testing syntactic equality of
arbitrary normal forms of s and t. Thus, since x+y and y+x are already in normal form
and syntactically unequal, their equality is not deductively valid.
Nevertheless, the formula is inductively valid in the sense that it holds in the algebra of
natural numbers with ‘0’, ‘s’, and ‘+’.
2. We have to explain what steps are allowed for proving this validity.
Since informal proofs tend to contain mistakes, and to ensure that a formula is really valid,
the proof has to be formal in the sense that it is a finite sequence of proof steps whose
soundness can be decided mechanically.
3. We have to find a proof for our theorem.
While intuitive use of equational specifications and inductively valid formulas is usually taught at
school, this is not always the case for the concept of proof — and especially not for the concept
of inductive proof. This indicates that — although necessary — proofs and especially inductive
proofs are difficult. The latter is mirrored by the fact that any inductive theorem prover necessarily
lacks the ability to prove some of the inductively valid formulas. In other words, for all “real-life”
problem domains, the inductively valid formulas — contrary to the deductively valid first-order
formulas — are not enumerable.11 To show that inductive validity and inductive proofs can
nevertheless be easily understood, let us now define inductive validity ad hoc and then prove the
inductive validity of the formula x+y = y+x from above by rewriting.
11This means that we have no way of describing mechanically or syntactically what inductive validity really
is. Also semantic approaches to notions of validity have little epistemological value because we cannot define
more validity on the object level than we have previously put into our meta-level. Actually, the situation is even
worse: Namely, a semantic definition of validity requires variables of strictly higher order than those occurring in the
language for which the validity is defined, cf. Tarski (1935). Also consistency proofs for inductive theories require
more inductive theory than they can show to be consistent.12 More precisely, if we can prove the consistency of
arithmetic of natural numbers in a sub-theory of arithmetic, then arithmetic is inconsistent, cf. Gödel (1931).
All in all, from a sceptic point of view, we could argue that inductive validity is meaningless since the consistency
of the inductive theories will be never known. Nevertheless, as long as we do not know them to be inconsistent, we
should go on believing in the consistency of our inductive theories and close our eyes just as most of the “working
mathematicians” do. Moreover, some less interesting notions of inductive validity (like our type-A and type-B′) are
known to be consistent because the trivial algebra is a model for their theory.
12Cf. Gentzen (1938) and Gentzen (1943) for very interesting examples of such consistency proofs for arithmetic
of natural numbers (i.e. the ordinal number ω) and for arithmetic of the ordinal number ε0, resp..
5We define an equation to be inductively valid if all the equations resulting from substituting
all its variables with natural numbers, i.e. terms of the form 0, s(0), s(s(0)), s(s(s(0))), &c., are
deductively valid.
The straightforward way to prove inductive validity of x+y = y+x is then to compute the
value of both sides of the equation for all possible instantiations of x and y with natural num-
bers and then to check that they are (syntactically) equal. While this procedure is refutationally
complete in the sense that any inductively invalid formula is recognized sometime by computing
different values for both sides of the equation, the proof procedure never terminates when the for-
mula is inductively valid. Since this is of course no practicable solution to the problem of finding
a proof for our inductive theorem, we had better look for some proof of finite length.
First case: “x is 0 and y is 0.” This case is trivial because both sides of the equation are
syntactically equal.
Second case: “x is 0 and y is of the form s(y′).” If we suppose that the equation has already
been shown for the smaller y′ instead of the bigger y, i.e. if we take 0+y′ = y′+0 as induction
hypothesis, then we get the following proof: 0+s(y′) = s(0+y′) = s(y′+0) = s(y′) = s(y′)+0.
The equations we have applied are the second defining equation, the induction hypothesis, and
then the first defining equation twice.
Third case: “x is of the form s(x′) and y is 0.” This case is symmetric to the second case.
Fourth and last case: “x is of the form s(x′) and y is of the form s(y′).” If we suppose that
the equation has already been shown for the smaller x′ instead of the bigger x and for the smaller
y′ instead of the bigger y, then we can prove the equation in the following way: s(x′)+s(y′) =
s(s(x′)+y′) = s(y′+s(x′))= s(s(y′+x′)) = s(s(x′+y′))= s(x′+s(y′)) = s(s(y′)+x′)= s(y′)+s(x′).
The first, third, fifth, and seventh step apply the second defining equation. The second step
applies the induction hypothesis s(x′)+y′ = y′+s(x′). The fourth the induction hypothesis
x′+y′ = y′+x′, and the sixth step applies the induction hypothesis x′+s(y′) = s(y′)+x′.
To complete the proof we now have to show that it was sound to suppose inductive validity
of the applied induction hypotheses. Of course, each of the hypotheses falls again into one of the
four cases and can be proved by assuming the induction hypotheses for this case, each of which
falls again into one of the four cases and can be proved by assuming the induction hypotheses for
this case, and so on. For the whole proof to be sound this elimination procedure has to terminate
for each instantiation of the theorem with natural numbers. For showing this termination property
we should find an induction ordering for the proof. Such an induction ordering has to be a
wellfounded ordering, which is nothing but a terminating and transitive binary relation. Moreover,
in any case of the proof, the instances of the theorem used as hypotheses have to be smaller in the
induction ordering than the theorem itself. In the case of our example proof we may choose the
lexicographic extension of the usual wellfounded ordering on natural numbers to pairs of natural
numbers. Since in all our hypothesis applications one variable gets strictly smaller while the other
does not get bigger in the wellfounded ordering on natural numbers, the required termination
property is certainly given — which completes the inductive proof of our inductive theorem.
63 Overview of the Thesis
We started our work on positive/negative-conditional equational specification and clausal induc-
tive theorem proving with the master’s thesis Wirth (1991). In Wirth & Gramlich (1992 & 1993)
we were able to free our framework from the severe restriction that the defining positive/negative-
conditional rules had to be terminating or, more precisely, to be decreasing. In Wirth (1995) (and
also in Gramlich & Wirth (1996)) we answered the question how to guarantee the confluence of
our reduction relation, especially in the difficult case that the defining positive/negative-condi-
tional rules are not known to be terminating or decreasing. Constructor variables (besides the
usual general variables of many-sorted logic) were added to our specification approach in Wirth
& Gramlich (1994a). In Wirth &al. (1993) and Wirth & Gramlich (1994b) we addressed the
problem of how to choose adequate notions of inductive validity. In Wirth & Becker (1995) we
explained how to develop inference systems for mathematical induction in a structured way and
why certain approaches in the literature are not to be recommended. Finally, in Wirth & Kühler
(1995) we presented an inference system for clausal inductive theorem proving in theories speci-
fied by constructor-based positive/negative-conditional equational specifications. In this thesis
we combine these results into a unified, refined, and extended presentation, and only some of the
complex results of Wirth (1995) have been left out due to their enormous length and doubtful
practical relevance for our inductive theorem proving approach. The syntactic sugar for writing
positive/negative-conditional equations conveniently of Wirth & Lunde (1994) is not covered in
this thesis, either. The thesis organizes as follows.
In § 4 we motivate and (after an interlude presenting our basic notions and notation for the whole
thesis in § 5) in sections 6 and 7 we formally develop our constructor-based approach for posi-
tive/negative-conditional term rewriting and for assigning semantics to algebraic specifications
with positive/negative-conditional equations. In our approach, the non-constructor function sym-
bols can be used for (possibly partially) specifying functions on a domain of discourse supplied
by the constructor ground terms and called the constructor sub-universe. For such specifications,
variables ranging over the constructor terms (or the constructor sub-universe) are usually more
convenient than variables ranging over all terms (including “junk” terms) (or the whole universe),
because the specifier usually (unless he wants to specify error-recovery or non-strict functions)
does not intend to tell how the functions behave on objects that are “undefined” in the sense that
they do not belong to the domain of discourse. Therefore we generalize unconditional equations
not only by adding positive and negative conditions but also by explicitly declaring some func-
tion symbols to be constructors and by introducing constructor variables in addition to the usual
general variables.
In general, specifications with positive/negative-conditional equations lack an initial model.
This becomes relevant when a unique “computational model” (abstract data type) or appropriate
notions of inductive validity are to be chosen. A very promising attempt to overcome this problem
has been that in Kaplan (1988). There, one of the quasi-initial models is distinguished by means
of control information extracted from the rules, which have to be compatible with a wellfounded
ordering. In addition, Kaplan gives a straightforward ground term reduction relation. However,
7the distinction of his quasi-initial model cannot be expressed without the control part of the speci-
fication. Furthermore, his reduction relation is not monotonic w.r.t. consistent extension of the
specification.
For these reasons, we choose a new different approach. Instead of using control information
we introduce two syntactically expressible restrictions:
(A) For a condition to be true, the terms of its negative equations have to be “defined” in
the sense that their evaluations fall into the constructor sub-universe. This requirement
is achieved by adding condition literals expressing this property and goes well with our
intention of taking the constructor sub-universe as the domain of discourse.
(B) We restrict the constructor rules (which express equalities among the constructor terms) to
have “Horn”-form and to be “constructor-preserving”.
We can then define our reduction relation, which does not need to be terminating, without using
wellfounded orderings anymore. Contrary to Kaplan, we are able to show the monotonicity of
this reduction relation w.r.t. consistent extension of the specification. As in Kaplan’s approach,
assuming confluence of our reduction relation, the factor algebra of the ground term algebra
modulo the congruence of our reduction relation is a quasi-initial model for our specification.
Unlike Kaplan, however, it is also initial in the class of all models which do not identify more
objects of the constructor sub-universe than necessary. Thus, the distinction of our intended
computational model is not based on control information, but on homomorphisms between the
models of (the logical part of) the specification.
In § 8 we then discuss compatibility restrictions on rule systems w.r.t. wellfounded orderings. In
essence, these restrictions say that each rule is decreasing, i.e., roughly speaking, that the left-
hand side has to be bigger than the condition terms and the right-hand side of the rule. This
section may help to understand the decidability problems for reducibility and confluence of con-
ditional rule systems. Moreover, for compatible rule systems it is much easier to find criteria
that are sufficient for confluence. Therefore our notions of termination-pair and compatibility
with a termination-pair are also useful in the following § 9 in which we treat the problem of how
confluence can be guaranteed.
Guaranteeing confluence is essential for our specification approach for inductive validity and
inductive theorem proving because without confluence we do not know that a defining set of
positive/negative-conditional rules is consistent in the sense that it has a “computational model”
or “abstract data type”, which is closely related to notions of inductive validity and their mono-
tonicity. Contrary to most other approaches for specification and inductive theorem proving,
our approach neither requires decreasingness nor termination of the set of defining rules. Since
our approach does require confluence, however, to be able to use it for non-decreasing or non-
terminating rule systems, we also present confluence criteria that do not require decreasingness
and a confluence criterion that even does not require termination. The proofs of these criteria are
not that simple.
8The confluence criterion that does not require termination requires the critical pairs to be com-
plementary, i.e. to contain complementary literals in their conditions. While this is not the weak-
est known condition guaranteeing confluence without requiring termination, it is in our opinion
the weakest one that can be effectively used in practice.13 Moreover, the condition of comple-
mentary critical pairs is not too restrictive in practice because it is satisfied for the usual function
definition style using nested “if-then-else”- or “case”-constructs. Finally, this simple decidable14
criterion simplifies our theorem proving task considerably because now only the problem of prov-
ing inductive validity remains. Otherwise we would also have the obligation of proving conflu-
ence in advance, and thereby may be caught in the following vicious circle: Certain inference
steps for proving confluence may require some termination properties w.r.t. some semantic order-
ing; proving termination w.r.t. some semantic ordering requires the specification to be consistent;
consistency of the specification is only known in case of confluence.
After these two technical sections on termination and confluence issues, in § 10 we discuss notions
of inductive validity. It is obvious that inductive theorem proving is meaningless without precisely
saying what an inductive theorem should be. Some readers, however, may be surprised to find
their intuitive notion of inductive validity split into seven different formal notions. While most
of these seven notions of inductive validity match the intuition somehow, they nevertheless differ
in substantial details, mainly caused by partially defined functions or the occurrence of negative
literals in the formulas. Although it may be difficult to split into seven what one used to consider
to be one (or two), we do not think that the discussion of these seven notions can be avoided
because different authors use different notions and it makes little sense to single out one of them
and claim it to be the proper or superior one.
When discussing notions of inductive validity it should become clear why we were so much
interested in monotonicity of our reduction relation w.r.t. consistent extension of the specification;
i.e. w.r.t. the definition of new sorts with new constructors, the definition of new non-constructor
functions, and possibly the completion of partial definitions of non-constructor functions. While
monotonicity of deductive validity (i.e. validity in all models) w.r.t. consistent extension of the
specification is a useful property because the already proved theorems are known to stay true
also after such an extension, monotonicity of inductive validity is an essential property because
inductive theorem proving itself recurrently requires consistent extension of the specification to
gain sufficient expressibility for capturing those induction hypotheses (or — in the language of
program verification — “loop invariants”) without that a proof of an inductive theorem cannot be
achieved.
Fortunately — contrary to several notions occurring in the literature — all our seven notions
of inductive validity are monotonic w.r.t. consistent extension of the specification.15
13Maybe one could allow weaker conditions if one has a sophisticated interactive system for proving confluence,
but the possibility for and the usefulness of such a system seems doubtful (unless decreasingness is required).
14For achieving decidability we actually have to replace the requirement for irreducibility of some ground condi-
tion terms t with some decidable sufficient property like the one that no left-hand side of any rule matches (a sub-
term of) t.
15under reasonable assumptions
9Now that we have completed the technical and conceptual description of our specification ap-
proach, in the second half of this thesis we will present our ideas on inductive theorem proving.
§ 11 introduces these ideas on a high level of conceptual abstraction. After illustrating our
view on inductive theorem proving and explaining the two paradigms of explicit versus implicit
induction, we state our basic design goals for an inference system for inductive theorem proving.
After refining these design goals we are able to explain why we integrate our implicit induction
approach into a sequent calculus and not into another deductive first-order calculus.
In § 12 we formally develop an abstract view on mathematical induction, disregarding the
property to be shown and how this is done. We present an abstract frame inference system and
explain its soundness with two independent approaches. The advantage of this abstract frame
inference system is the following: Instead of showing the soundness of our concrete inference
system of the following sections in a huge and clumsy proof running through our two dozens of
concrete inference rules, we now only have to prove that each of our concrete rules is a sub-rule
of one of the few rules of our abstract frame inference system. The global soundness proof as well
as the sub-rule proofs are small and easy to understand and maintain. Note that this localization
of the soundness proof for an inductive inference system is not trivial because the proof graph
usually contains cycles. This is completely different from a deductive inference system where the
proof graphs can be restricted to be trees and it is trivial that the soundness of an inference system
is implied by the soundness of each of its inference rules.
In § 13 ff. we describe a concrete inference system for clausal theorem proving w.r.t. various
kinds of inductive validity in theories specified by constructor-based positive/negative-condi-
tional equations. The proposed inference system provides explicit induction hypotheses and can
be instantiated with various wellfounded induction orderings. The fundamental design goal is
user-orientation and practical usefulness rather than theoretical elegance. The resulting infer-
ence system is comprehensive and quite powerful, but requires a sophisticated concept of proof
guidance, which is not treated in this thesis.
In § 13 we concretize the abstract inference system for mathematical induction of § 12 by in-
stantiating the abstract notions with the concrete notions for clausal theorem proving w.r.t. various
kinds of inductive validity in theories specified by constructor-based positive/negative-conditional
equations.
In § 14 we present a set of inference rules that is complete for deductive first-order validity
of clauses with equality and definedness. This set of inference rules captures an equality-based
reasoning on clauses that is usually called “contextual rewriting”.
In § 15 we complete the presentation of our deductive inference rules with a rule for an explicit
Cut and some rules for removing and adding variables to a clause.
Inference rules whose soundness relies on the additional assumptions resulting from consid-
ering inductive instead of deductive consequence are found in § 16:
The application of covering sets of substitutions (described in § 16.1) makes use of the term-
generatedness of the models establishing inductive validity. Since the set of terms generating such
10
a model is usually infinite, drawing consequences from term-generatedness usually requires some
cyclic reasoning which is made possible via the application of induction hypotheses as discussed
in § 16.2.
Narrowing techniques for solving negative literals (described in § 16.3) exploit the initiality
or freeness given for the models establishing some of the notions of inductive validity.
In § 16.4 we close the inductive part of our concrete inference system with the discussion of
another difference between inductive and deductive reasoning: Inductive reasoning often is only
successful when one tries to show stronger theorems than the ones one initially intended to show.
This is because an inductive theorem is not only a task (as goal) but also a tool (as induction
hypothesis) for the inductive argumentation. Therefore, before starting the proof of a theorem, it
may be necessary to generalize the theorem to have a stronger induction hypothesis available in
the proof. Contrarily, for deductive reasoning such a generalization is never necessary.16
After demonstrating the usefulness of a simple failure predicate in § 17, we summarize our
concrete inference system in § 18.
Before concluding in § 20, we give an outlook on future work in § 19.
The less important subject of refutational completeness of inference systems is dealt with in A.
A lengthy description of a sequent calculus for establishing the deductive completeness results of
§ 14 can be found in B. The proofs of all the non-trivial lemmas and theorems are given in C.17
In each section we number the definitions, lemmas, theorems, corollaries, global requirements,
and examples with one single counter which is preceded by the section number. E.g., “Defini-
tion 5.2” is the label of the second numbered item in § 5 which happens to be the first numbered
definition in that section.
While we give names to the defining rules and lemmas, in formal proofs we precede our
formulas with labels consisting of a list of numbers to indicate their position in the proof forest.
E.g., “(1)” is the label of the first root while “(1.3.2)” is the label of the second child (or branch)
of the third child of the first root.
16While analytic proofs of deductive theorems get harder after generalization, synthetic proofs may become easier,
cf. Baaz & Leitsch (1995).
17With the exception of the proofs of two confluence criteria. These proofs are of enormous length and instead of
actually presenting the proofs we give a pointer to Wirth (1995) where these proofs can be found.
11
4 Motivation for Constructor-Based
Positive/Negative-Conditional Equational
Specification and Rewriting
That positive/negative-conditional equations are necessary for convenient specification is illus-
trated by the definition of the membership predicate ‘mbp’ in Example 4.1.
Example 4.1
Let X and Y denote variables for the sort ‘nat’ of natural numbers and K and L denote variables
for the sort ‘list’ of lists of natural numbers. Let ‘true’ and ‘false’ be constructor constants of
the sort ‘bool’ of truth values, ‘0’ a constructor constant and ‘s’ a singulary constructor function
for the sort ‘nat’, and ‘nil’ a constructor constant and ‘cons’ a constructor function symbol (with
arity nat list→ list) for the sort ‘list’. We define a subtraction operation ‘−’ and a membership
predicate ‘mbp’ with the following conditional equations, where ‘←−’ precedes the non-empty
conditions of the equations.
R4.1:
(−1) X−0 = X
(−2) s(X)−s(Y ) = X−Y
(mbp1) mbp(X ,nil) = false
(mbp2) mbp(X ,cons(Y ,L)) = true ←− X=Y
(mbp3) mbp(X ,cons(Y ,L)) = mbp(X ,L) ←− X 6=Y
Note that the negative condition “X 6=Y ” in Example 4.1 could be replaced with
“eqnat(X ,Y )=false” for an equality predicate ‘eqnat’ with the arity nat nat→ bool.
eqnat(0,0) = true
eqnat(0,s(Y )) = false
eqnat(s(X),0) = false
eqnat(s(X), s(Y )) = true ←− eqnat(X ,Y )=true
eqnat(s(X), s(Y )) = false ←− eqnat(X ,Y )=false
For the sorts ‘list’ and ‘bool’ we can proceed similarly:
eqlist(nil,nil) = true
eqlist(nil,cons(Y ,L)) = false
eqlist(cons(X ,K),nil) = false
eqlist(cons(X ,K),cons(Y ,L)) = true ←− eqnat(X ,Y )=true, eqlist(K,L)=true
eqlist(cons(X ,K),cons(Y ,L)) = false ←− eqnat(X ,Y )=false
eqlist(cons(X ,K),cons(Y ,L)) = false ←− eqlist(K,L)=false
eqbool(true, true) = true
eqbool(true, false) = false
eqbool(false, true) = false
eqbool(false, false) = true
12
In the case of “free constructors” (i.e. in the absence of constructor rules) such transformations
can always remove the negative equations in the conditions. This transformation, however, is
not possible in general. Moreover, syntax and semantics of specifications with a single built-in
equality predicate are much clearer than those of specifications with several different equality
predicates (i.e. one built-in and several specified ones). Finally, if the terms t and t ′ are known to
be irreducible, the evaluation of condition literals like t=t ′ and t 6=t ′ can be done by a simple
check for syntactic equality, whereas the evaluation of eq(t,t ′)=true and eq(t, t ′)=false is less
efficient because it requires several reduction steps.
In a second step we could remove the conditions of the equations (resulting in unconditional
specifications) with the help of IfThenElse-functions:
IfThenElsenat(true,X ,Y ) = X
IfThenElsenat(false,X ,Y ) = Y
IfThenElselist(true,K,L) = K
IfThenElselist(false,K,L) = L
IfThenElsebool(true,B,B′) = B
IfThenElsebool(false,B,B′) = B′
The definition of the mbp -function of Example 4.1 would be transformed into:
(mbp1) mbp(X ,nil) = false
(mbp2+3) mbp(X ,cons(Y ,L)) = IfThenElsebool(eqnat(X ,Y ), true,mbp(X ,L))
In case of conditional rules without complementary “else”-rules we also need IfThen-functions
for the transformation.
IfThennat(true,X) = X
IfThenlist(true,K) = K
IfThenbool(true,B) = B
In general, this kind of transformation destroys the termination of the reduction relation (even for
decreasing systems) because instead of having to evaluate the condition first, we now may start
with infinite reductions in the former right-hand side of a rule with unfulfilled condition. More-
over, in general, this kind of transformation also destroys confluence of the reduction relation
when the first argument of the IfThen-function does not evaluate to true or the first argument of
the IfThenElse-function neither evaluates to true nor false. There are other possibilities to trans-
form conditional rewrite systems to unconditional rewrite systems, cf. Bergstra & Klop (1986),
which dissect the term language even more. Nevertheless, none of them is convincing because
they all destroy important properties like termination, confluence, left-linearity, &c.. The real
difficulty of the transformation can best be learned from Hintermeier (1995), where decreas-
ing conditional rule systems are transformed into unconditional rule systems in an order-sorted
framework.
An additional important argument against all these transformations is that they render the term
language much more difficult to read for human beings. Note that it is not reasonable for an
interactive theorem prover, e.g., to hide the ugly eq-, IfThenElse-, and IfThen-function symbols
from the user because many proof steps depend on the exact term representation and a huge
number of lemmas will be needed only for rewriting eq-, IfThenElse-, and IfThen-terms.
13
All in all, to look for an adequate treatment of the difficulties of positive/negative-conditional
equations seems more reasonable than to camouflage these difficulties by transforming the posi-
tive/negative-conditional equational specifications into a simpler formalism.
4.1 Stéphane Kaplan’s Approach
Kaplan (1988) defines a [negated] equation in the condition of a positive/negative-conditional rule
to hold if its terms [do not] have a common reduct (w.r.t. ∗−→). If the resulting reduction relation
is confluent and the rules are decreasing w.r.t. some wellfounded ordering  (cf. Dershowitz &al.
(1988a)), then its congruence closure is minimal (but not a minimum!) w.r.t. set-inclusion among
the congruence relations whose factor algebras (w.r.t. the ground term algebra) are models of the
set of rules R. Therefore, the factor algebra of the ground term algebra modulo the congruence
closure of the reduction relation is only quasi-initial in the class of models of R instead of initial
(as is the case for merely positive conditional equations).
Before going on with our discussion of Kaplan’s approach we should make clear why the
confluence requirement is essential.
4.2 The Importance of Confluence
Why is confluence essential for reduction with positive/negative-conditional rules?
Firstly (even without negative conditions), confluence is needed for the completeness of test-
ing semantic equality of two condition terms by looking for a common reduct. This means: We
need confluence for the congruence defined in Kaplan (1988) to yield a model of R.
Secondly, it is needed for guaranteeing the congruence to be minimal:
Example 4.2
Let a,b,c,d,e be constants of the same sort.
Let R4.2: c = d
c = e
a = b ←− e 6=d
Note that R4.2 is decreasing w.r.t. the wellfounded ordering indicated by ab cd e.
Kaplan’s reduction relation is
−→R4.2 = { (c,d), (c,e), (a,b) }
Thus, its congruence closure ∗←→R4.2 is not minimal among the congruences satisfying R4.2 be-
cause it properly contains the congruence closure of { (c,d), (c,e) }.
14
While confluence can be dropped for merely positive conditional equations by testing for congru-
ence (i.e. u ∗←→v) instead of testing for the existence of a common reduct (i.e. ∃w. u ∗−→w ∗←−v)
of two condition terms in a condition literal (u=v), the situation is worse for positive/negative-
conditional equations: It does not suffice to test non-congruence for inequality of two condition
terms if confluence is not provided:
Example 4.3
Let the signature and the ordering be as in the previous example.
Let R4.3: a = d
a = e ←− b6=c
b = c ←− d=e
Any congruence yielding a model of R4.3 contains the pair (b,c): If it did not, it would contain
(a,e) by the second rule, then by the first rule (d,e), and hence by the last rule (b,c). Therefore,
no matter which congruence we actually use for condition-testing, the test of b6=c with such a
(model-yielding) congruence will always fail, such that we cannot establish a ∗←→R4.3 e by testing
the condition of the second rule, and hence cannot establish b ∗←→R4.3 c by testing the condition
of the last rule. But R4.3 has the minimum model “a=d; b=c”, which cannot be obtained by the
simple method of condition-testing anymore, but only by paramodulation and factoring instead,
which in our opinion are too complicated for establishing just a simple reduction step.
By this we conclude that in case of negative equations in the condition, confluence is required for
computing a correct reduct by the method of condition-testing.
4.3 Problematic Aspects of Kaplan’s Approach
The major shortcoming of the reduction relation in Kaplan (1988), however, is (as noted above)
that its congruence closure is not a minimum (i.e. being smaller than anything else) but only
minimal (i.e. there is nothing smaller) among the congruences yielding a model of R. Thus,
contrary to the case of merely positive conditional specifications, there might be reductions s−→t
with s=t not holding in all models logically specified by R.
Kaplan correctly argues as follows: By writing “c=d ←− d6=e” instead of the logically equi-
valent “c=d∨ d=e” the specifier adds some “operational” information to the logical part of the
specification. This “operational” information may therefore be used to control the choice of the
intended minimal congruence in such a way that “c=d” is distinguished from the model yielding
congruences, namely “c=d”, “d=e”, and “c=d=e”.
But if the ordering context given by other rules does not allow “ce” without extending ‘’ to
a non-terminating relation, then the specifier is not at all allowed to write “c=d∨d=e” in the form
of “c=d←− d6=e”. And even if he actually is allowed to specify his intended control information,
he is likely to be unable to keep track of the consequences of all his pieces of “operational”
information, especially because he is forced to include some operational information into each
rule he writes.
15
All this would not be crucial if the operational information were used only for admissibility
of a specification, as is the case with our approach. We use the operational information given
by writing first-order clauses in the form of positive/negative-conditional rules for our reduction
relation only, which again must be confluent for the specification to be admissible. The distinction
of our computational model for an admissible specification, however, does not depend on the
operational information of the rules anymore; but only on homomorphisms between the models
of the logical part of the specification. Therefore our computational semantics (of a specification
which has passed the admissibility test depending on its operational information) can be grasped
on a more abstract level in terms of models and homomorphisms without any knowledge of
rewriting, confluence, orderings on terms, termination, &c.. Contrariwise, in Kaplan’s approach
not only admissibility of a specification but also its computational model semantics itself depends
on the operational information of the rules and is not expressible without.
This loss of the pure logic view on an admissible specification goes with the loss of a property
which is very important in practice (cf. Theorem 7.18 and the discussion which precedes it): As
can be seen from the following example, the monotonicity of logic is lost.
Example 4.4 (continuing Example 4.1)
mbp(0,cons((0−s(0)),nil))
∗
−→R4.1 false
no longer holds after adding the rule
0−s(X)=0
This shows that completing the definition of a partially specified function (here: ‘−’) (even in a
way that does not confuse different constructor terms) might destroy some reductions and con-
gruences which were possible before.
Similarly, reduction of non-ground terms is of no use because the reduction relation is not stable:
Example 4.5 (continuing Example 4.1)
As the variable X does not reduce to 0, one might say
mbp(0,cons(X ,nil)) ∗−→R4.1 false.
But for X 7→ 0 this does not make sense.
16
4.4 Looking for Remedy
One could think that in practice the problem of a minimal congruence not being a minimum
hardly arises or can be avoided by convenient purely syntactic restrictions on the defining rules.
Using the specification of Example 4.1 above (which is not a sophisticated but a really standard
specification and therefore essential in practice), the example below will on the contrary exhibit
that the problem is relevant in practice and that purely syntactic restrictions on the defining rules
cannot be reasonable because they would have to forbid even such a very restricted use of negative
conditions as in Example 4.1.
Example 4.6 (continuing Example 4.1)
For simplicity we exclude from the signature and the rule system of Example 4.1 all function
symbols besides mbp, true, false, nil, and cons and exclude all rules besides (mbp1), (mbp2),
and (mbp3). Then we enrich the signature with two constants a, b of the sort nat. The rules
are decreasing w.r.t. the lexicographic path ordering given by mbp% true, false and the reduction
relation −→ of Kaplan (1988), which is confluent because there are no feasible critical pairs.
Consider the following two congruence relations on ground terms, given by their congruence
classes for the sorts nat and bool:
∗
←→ : { a }
{ b }
{ false }∪{ mbp(x, l) | (x ∈ {a,b} ∧ (x does not occur in l)) }
{ true }∪{ mbp(x, l) | (x ∈ {a,b} ∧ (x does occur in l)) }
∼ : { a, b }
{ false, mbp(a,nil), mbp(b,nil) }
{ true }∪{ mbp(x, l) | (x ∈ {a,b} ∧ l 6=nil) }
Now, both ∗←→ and ∼ yield a model of R. By a ∼ b and a 6∗←→b we know that ∼ is no
minimum. By mbp(a,cons(b,nil)) ∗←→ false and mbp(a,cons(b,nil)) 6∼ false we know that
∗
←→ is no minimum either. But both ∗←→ and ∼ are minimal among the congruences that yield
a model of R. Hence their intersection does not yield a model of R.
Thus, we have to choose between a 6= b and mbp(a,cons(b,nil)) 6= false. As ∗←→ is some-
how more appealing than ∼ , one may argue that a 6= b is somewhat more important than
mbp(a,cons(b,nil)) 6= false by stating a, b to be constructors and thinking freeness of construc-
tors to be more important than that of non-constructors. But this treatment does not solve the
problem in general: If
(1) a or b is changed into a non-constructor term,
or
(2) mbp is stated to be a constructor symbol too,
then the very same problem arises again.
17
4.5 Our Solution
Now, while the simple attempt above fails, the intended bias towards freeness of constructor terms
can be achieved with the help of a singulary predicate ‘Def ’ (in addition to the binary predicate
‘=’). In essence, for a term t, ‘Def t’ holds if t has a congruent constructor ground term. In this
case we say that t is defined. Now our problems from above can be removed by the following two
steps:
(A) Add condition literals expressing definedness for all terms of negative equations in the
condition.
For our example above this means that the rule (mbp3) is not applicable if a or b is unde-
fined, thereby avoiding the problem of (1) above.
(B) Force each constructor rule (which is a rule whose left-hand side is a constructor term) to
have no negative equations in its condition and to be constructor-preserving (which means
that all its terms are constructor terms and all its variables occur in its left-hand side).
For our example above, this means that ‘mbp’ cannot be a constructor symbol, thereby
avoiding the problem of (2) above.
(B) is purely syntactic and not very restrictive in practice as it only limits congruences between
constructor terms (and this even less restrictively than usual). (A) is not a usage of control
information. It just means that ‘6=’ is restricted to defined terms. Since this restriction is made
syntactically explicit, the semantics of ‘6=’ remains unchanged.
Undefined terms are due to some partially specified18 function, by which we mean a function
with symbol say ‘ f ’ for which the application to some constructor ground terms t0, . . . ,tn−1 is not
congruent to any constructor ground term, i.e. for which “ f (t0, . . . , tn−1)” is an undefined term.
In the context of our specifications, functions are partially specified not because the specifier has
explicitly stated their partiality as a property of importance, but because he has partially left open
their definition, maybe due to partial information or non-termination, due to irrelevance of the
further behavior of the functions for the specification in the current state of development, or even
due to partiality being actually intended. Thus, partiality and undefinedness are not part of the
specification but a result from its incompleteness. In this line of argumentation, the undefined
terms are sometimes assumed to be equal to some unknown constructor ground terms:
E.g., Kapur & Musser (1987 & 1986) consider those congruences which are maximally en-
larged by random identification of undefined terms with constructor ground terms, as long as this
identification does not identify two distinct constructor ground terms. Their intended congruence
is then the intersection of all those maximally enlarged congruences. In Kapur & Musser (1987)
18Note that we model partiality with total algebras (i.e. algebras with total functions) (such that each ground term
evaluates to an element in the algebra) and therefore prefer to speak of “partially specified” instead of “partial”
functions. Nevertheless, the close relation of our approach to partial algebras (i.e. algebras with partial functions)
(where the values of ground terms may be undefined) is made obvious in Kreowski (1987).
18
the maximal congruences are allowed to have some undefined terms left; this causes the problem
that one cannot describe the intended congruence by monotonic model semantics.19 Therefore
in Kapur & Musser (1986) the intersection is done only over those congruences that have no
undefined terms left: These congruences can be easily described in terms of model semantics.20
Based on this tradition of thinking undefined terms to be possibly equal to constructor ground
terms, the above item (A) of our approach can be justified the following way:
Considering dynamic extension of specifications: If two terms can be shown equal by ∗←→,
they will keep being equal even if an undefined term will be identified with a defined term
later on (cf. Theorem 7.18). On the other hand might an undefined term become equal to a
previously unequal term when identifying an undefined term with a defined term. Thus, we
had better be cautious: We should not pretend to be able to distinguish something undefined
from anything else (as the former might in the sequel be defined to be the latter).
From a static point of view on the specification: Two distinct terms may be equal or unequal,
no matter whether they are defined or undefined. In particular may an undefined term
be both unequal to some distinct undefined term and equal to some other. This inequality
between undefined terms, however, differs from the inequality between defined terms in that
it is not considered sufficient for the fulfilledness of an inequality literal in the condition
of an equation. This means that we have a “closed world assumption” which is restricted
to the constructor ground terms, saying that two constructor ground terms are meant to be
unequal unless their equality is specified by the constructor rules. According to this, we
use “negation as failure” on the defined terms only, but not on the undefined terms where
the specification is allowed to be incomplete and open.
19Of course, this is tried to be done in Kapur & Musser (1987). But their “inductive model” (which is defined to
be a model with free constructors whose proper epimorphic images are no models with free constructors) is rather
peculiar: Normally, a model uses to keep being a model when one throws away some equations of the specification,
thereby establishing the monotonicity of logic. The “inductive models” do not have this property. To see this take
C = {false,true,0}; N = {s,zerop}; R = { zerop(0)= true, zerop(s(x))= false }. Now the following A is
an “inductive model” for R but not for /0 (where we need |A nat| = 1): A bool = {FALSE,TRUE}; A nat = {0,1};
trueA = TRUE; falseA = FALSE; 0A = 0; sA (x) = 1; zeropA (0) = TRUE; zeropA (1) = FALSE.
We can also see by this that we indeed have no monotonic logic here: /0 |= 0=s(0); but (as seen by A ): R 6|= 0=
s(0).
20Besides making true the universally quantified equations of R, a model A is required to satisfy the following:
Let ∗←→ denote the initial congruence of R (which exists because they consider unconditional equations only) and
k its canonical cons-epimorphism from the constructor ground term algebra G T (cons) to G T (cons)/ ∗←→. Now
the unique cons-homomorphism h from G T (cons)/ ∗←→ to A given by kh = (A |G T (cons)s)s∈S (by the Homo-
morphism-Theorem) is required to be an isomorphism. A third way of removing the undefined terms is to require
h to be epimorphic instead of isomorphic, i.e. A is required to be cons-term-generated. While the theory of the last
two approaches is beautiful, the resulting congruences may be very difficult to understand: One needs a sophisticated
way of argumentation for showing two terms equal — even for some very simple examples: Cf. Example 15.7 and
the discussion on type-D′ inductive validity below it.
19
4.6 Concluding Comparison with Other Approaches
In § 7 we will show that by the requirements (A) and (B) we get a straightforward reduction
relation −→ that has the following advantages (compared to the one of Kaplan (1988)):
1. Its congruence closure ∗←→ yields a model that is not only minimal but also the (up to
isomorphism) uniquely determined minimum among those term-generated models of R that
do not identify more constructor ground terms than necessary (provided (as also required
for Kaplan’s ∗←→ to be minimal) that −→ is confluent).
2. It is monotonic w.r.t. the addition of new rules that do not have old constructor terms as
left-hand sides.
3. It is stable when defined also on non-ground terms.
As shown in the examples above, the reduction relation of Kaplan (1988) has none of these prop-
erties. We will now revisit these examples to illustrate how our restrictions solve the problems
mentioned.
1. (Example 4.6).
If a and b are defined terms, then ∗←→ becomes the minimum among those congruences
which do not identify more constructor ground terms than necessary.
Contrariwise, if a or b is undefined, then the intersection of ∗←→ and ∼ becomes a
model of R because the rule (mbp3) now has to be written in the form of
(mbp3′) mbp(X ,cons(Y ,L)) = mbp(X ,L) ←− X 6=Y , Def X , DefY
and thus, mbp(a,cons(b,nil)) is neither true nor false , but undefined instead.
2. (Example 4.4).
We do not have mbp(0,cons((0−s(0)),nil)) ∗−→ false anymore:
mbp(0,cons((0−s(0)),nil)) is irreducible because 0−s(0) is undefined.
3. (Example 4.5).
As X is undefined: mbp(0,cons(X ,nil)) 6∗−→ false .
20
Moreover, we are not only able to give control independent semantics for admissible specifica-
tions, but are also able to remove the control aspect of requiring the rules to be decreasing for
admissibility. Thus, our reduction relation does not need to be terminating.21
For a final comparison between the reduction relation of Kaplan (1988) and the ground term
restriction of our reduction relation, suppose that R satisfies (B) from above and is decreasing
w.r.t. Kaplan’s reduction relation and some ordering  . By induction over  one can easily
show the following: The two relations do not differ on constructor terms. If the reflexive &
transitive closure of Kaplan’s relation is sufficiently complete, then ours contains Kaplan’s. If
Kaplan’s relation is confluent, then it contains ours. If the reflexive & transitive closure of one
of the relations is sufficiently complete and one of the relations is confluent, then there is no
difference between our ground reduction relation and that of Kaplan (1988). Therefore, in the
important case that all functions are totally specified and no undefined ground terms exist, we
offer control independent semantics for the reduction relation of Kaplan.
The perfect model semantics approach of Bachmair & Ganzinger (1991), which also includes
a completion procedure, generalizes Kaplan’s approach by abstracting the control information
hidden in the syntactic form of rules into a reduction ordering which must be total on ground terms
and which determines the construction process of perfect models. The perfect model semantics is
very similar to Kaplan’s in that it still does not provide control independent semantics and in that it
is still not monotonic w.r.t. consistent extensions of the specification. Cf. also Becker (1993a) for
the interrelation between the three approaches of Kaplan (1988), Bachmair & Ganzinger (1991),
and ours.
21For practical purposes, however, in particular for verifying confluence, termination of (at least some sub-relation
of) the reduction relation is sometimes indispensable.
21
4.7 Two Types of Variables
An additional feature of our presentation is our distinction between two kinds of variables. While
the distinction between constructor terms and general terms is commonly accepted and considered
fruitful, our distinction between constructor variables and general variables may require some
explanation:
General variables may be substituted by any term of the whole signature. Constructor variables,
however, may only be substituted by pure constructor terms consisting of constructor function
and constructor variable symbols.
In the field of model semantics, this distinction is mirrored by the possible valuations: While
a general variable can take the value of any object in the universe of its sort, a constructor variable
can take the value of an object of the constructor sub-universe only.
General variables are the common ones in the field of term rewriting.
Certain properties cannot be expressed with constructor variables but with general variables
only: For example, consider equations for error recovery or for non-strict functions whose mean-
ing does not depend on the definedness of all its variables, like “ or(true,Y )= true ”.
Furthermore, general variables allow a higher abstraction from evaluation strategies than con-
structor variables. For example, in case of free constructors, replacing all general variables in the
rewrite rules with constructor variables restricts the reduction relation to an innermost rewriting
strategy.
Constructor variables are convenient in the field of inductive theorem proving for expressing
important lemmas that do not hold for undefined terms. (E.g., one certainly should be able to
express a commutativity lemma for addition of rational numbers, but one cannot expect it hold
for “ 1/0 ” or other undefined terms.)
Semantically we could remove the whole constructor-based frame by considering ‘Def ’ to be
an interpreted first-order predicate, then by stating for each constructor function symbol c with
arity s0 . . .sn−1 → sn that Def c(x0, . . . ,xn−1) holds for a list x0, . . . ,xn−1 of mutually distinct
constructor variables with xi of sort si (i≺n), and finally by replacing each formula A containing
a constructor variable y with the formula “ A{y7→Y} ←− DefY ” for a new general variable Y .
While the constructor-based frame can therefore be considered to be syntactic, it is not just
syntactic sugar, since it deeply influences termination and confluence of reduction relations. E.g.,
the means to automatically show termination of the functions of classic inductive theorem prov-
ing (cf. e.g. Boyer & Moore (1979), Walther (1988)) depend on the variables in the function
definitions being bound to constructor terms only. This dependence, however, and the intended
meaning of the variables at all, are usually hidden in the formalism and not made as explicit as in
Avenhaus & Becker (1992) where it is shown that the restriction to constructor variables only, is
beneficial to confluence22 and termination23 of rewriting systems.
22Cf. also our theorems 9.1(2) and 9.15 and the theorems 68, 71, 75, 76, and 77 of Wirth (1995).
23Cf. also Walther (1988).
22
All in all, both kinds of variables have their benefits for specification with positive/negative-
conditional equations and for expressing (inductive) properties with first-order clauses, as well
as for rewriting and (inductive) theorem proving. Since the technical treatment of both kinds
of variables can be achieved by simple means, we have decided to include both of them in our
constructor-based approach for positive/negative-conditional equations here. Together with the
generalization to positive- and negative-conditional equations, the addition of constructor vari-
ables to classic term rewriting provides us with a unifying approach to the function specification
style of classic inductive theorem proving on the one hand and to term rewriting on the other.
23
5 Basic Notions and Notation
We assume the reader to be familiar with the basics of term rewriting (cf. e.g. Avenhaus & Mad-
lener (1990), Klop (1992)) and algebraic specification (cf. e.g. Ehrig & Mahr (1985)).
We use ‘⊎’ for the union of disjoint classes and ‘id’ for the identity function. ‘N’ denotes
the set of natural numbers and we define N+ := { n∈N | 0 6=n }. For a class R we define
domain, range, and image of and restriction to a class A by dom(R) := {a | ∃b. (a,b)∈R};
ran(R) := {b | ∃a. (a,b)∈R}; R[A] := {b | ∃a∈A. (a,b)∈R}; R|A := { (a,b)∈R | a∈A}.
E.g., if ‘∼’ is a (binary) relation, dom(∼)∪ ran(∼) denotes the field of the relation. If it is an
equivalence relation (cf. below), then dom(∼)= ran(∼) and and the equivalence class of some
x ∈ dom(∼) is ∼[{x}]. This use of “[. . . ]” should not be confused with our habit of stating two
definitions, lemmas, or theorems (and their proofs &c.) in one, where the parts between ‘[’ and
‘]’ are optional and are meant to be all included or all omitted. Furthermore, we use ‘ /0’ to denote
the empty set as well as the empty function or empty word.
Since our approach is based on the rigorous syntactic distinction of constructors, we have to
be quite explicit about terms, substitutions, and algebras.
5.1 Terms
We will consider terms of fixed arity over many-sorted signatures. A signature
sig = (F,S,α)
consists of an enumerable set of function symbols F, a finite set of sorts S (disjoint from F), and
a computable arity-function α : F→ S+. For f ∈ F its arity α( f ) is the list of argument sorts
augmented by the sort of the result of f ; to ease reading we will sometimes insert a ‘→’ between
a nonempty list of argument sorts and the result sort.
A constructor sub-signature of the signature (F,S,α) is a signature
cons = (C ,S,α|C )
such that the set C is a decidable subset of F. C is called the set of constructor symbols; the
complement N= F\C is called the set of non-constructor symbols.
Example 5.1 (Signature with Constructor Sub-Signature)
C = {0,s, false, true,nil,cons}
N = {dl, rc,br,+,−,ack,switch,swatch, leq, less,mbp,p,q}
S = {nat,bool, list}
α(0) = nat
α(s) = α(switch) = α(swatch) = nat → nat
α(+) = α(−) = α(ack) = nat nat → nat
α(false) = α(true) = bool
α(p) = nat → bool
α(leq) = α(less) = α(q) = nat nat → bool
α(mbp) = nat list → bool
α(nil) = list
α(cons) = α(dl) = α(rc) = nat list → list
α(br) = list list → list
24
A variable-system for a signature (F,S,α) is an S-sorted family of sets of variable symbols which
are mutually disjoint and disjoint from F. By abuse of notation we will use the symbol ‘X’ for
an S-sorted family to denote not only the family X = (Xs)s∈S itself, but also the union of its
ranges:
S
s∈SXs. As the basis for our terms throughout the whole thesis we assume two fixed
disjoint variable-systems VSIG of general variables and VC of constructor variables. We use
the following notation for S-sorted families of sets of (well-sorted) terms over sig/VSIG⊎VC :
T (sig,VSIG⊎VC ) (variable-mixed) terms
T (cons,VSIG⊎VC ) (variable-mixed) constructor terms
T (cons,VC ) pure constructor terms
G T (sig) ground terms
G T (cons) constructor ground terms
To avoid problems with empty sorts, we assume G T (cons) to have nonempty ranges only.
As exhibited in Avenhaus & Becker (1992), it is adequate to describe our terms, substitutions,
and algebras within the order-sorted framework in the style24 of Gogolla (1983) or Smolka &al.
(1989): Take {SIG,C }×S for the sorts with the sort declaration that for each s ∈ S the sort
(C ,s) is a sub-sort of the sort (SIG,s); and replace each arity declaration of the form α( f ) =
s0 . . .sn−1 → sn with the arity declaration
α( f ) ∋ (SIG,s0) . . .(SIG,sn−1)→ (SIG,sn);
moreover, for each f ∈ C add the arity declaration
α( f ) ∋ (C ,s0) . . .(C ,sn−1)→ (C ,sn).
According to this order-sorted framework we define the following.
A variable-system for a signature (F,S,α) with constructor sub-signature is a {SIG,C }×S-
sorted family X = (Xς,s)(ς,s)∈{SIG,C }×S of sets that are mutually disjoint and disjoint from F.
Note that V := (Vς,s)(ς,s)∈{SIG,C }×S provides us with such a variable-system.25 On the other
hand we can also get back to the many-sorted framework by defining XSIG := (XSIG,s)s∈S and
XC := (XC ,s)s∈S.
For our basic variable system V we will assume that, for each (ς,s)∈{SIG,C }×S, Vς,s
contains infinitely many elements. Furthermore we assume that the set V is decidable and that
the function f : V→{SIG,C }×S given by ∀x∈V. x∈Vf (x) is computable.
We use V (A) to denote the {SIG,C }×S-sorted family of variables occurring in a structure A
(e.g. a term or a set or list of terms).
We define T (X) = (T (X)ς,s)(ς,s)∈{SIG,C }×S by (s∈S): T (X)SIG,s := T (sig,X)s and
T (X)C ,s := T (cons,XC )s. To avoid confusion: Note that T (X)C ,s ⊆ T (X)SIG,s for s ∈ S,
whereas XC ,s∩XSIG,s = /0. This means that a constructor variable x ∈XC ,s is not a general vari-
able from XSIG,s but a “general” term from T (X)SIG,s. Furthermore, we use G T as a shorthand
for T ( /0) as well as T for T (V). Our custom of reusing the symbol of a family for the union of
its ranges now allows us to write T as a shorthand for T (sig,VSIG⊎VC ).
24Cf. Waldmann (1992) for an excellent comparison of different styles of semantics for order-sorted specifications.
25considering the index of VSIG,s to be (SIG,s) instead of s, &c.
25
For a term t ∈ T we denote by POS (t) the set of its positions (which are words (i.e. lists) of
positive natural numbers) and by t/p the subterm of t at position p. We partition POS (t) into
the set of variable positions VPOS (t) := { p∈POS (t) | t/p∈V } and the set of non-variable (or
function) positions FPOS (t) := { p∈POS (t) | t/p 6∈V }. By t[ p← t ′ ] we denote the result of
replacing t/p with t ′ at position p in t. p and q are called parallel, written p‖q, if neither p
is a prefix of q, nor q a prefix of p. For Π⊆ POS (t) with ∀p,q∈Π. (p=q ∨ p‖q) we denote
by t[ p← t ′p | p∈Π ] the result of replacing, for each p ∈Π, the subterm at position p in the term
t with the term t ′p. t is linear if ∀p,q∈VPOS (t). (t/p= t/q ⇒ p=q).
5.2 Substitutions
The set of substitutions from X to a {SIG,C }×S-sorted family of sets T = (Tς,s)(ς,s)∈{SIG,C }×S
is defined to be
S UB (X,T ) := { σ : X→ T | ∀(ς,s)∈{SIG,C }×S. ∀x∈Xς,s. σ(x)∈T ς,s }.
Important sets of substitutions are S UB (V,T ) and S UB (V,G T ). The definition is consistent
with the notion of substitutions in our order-sorted framework from above. A fortiori we get
∀σ∈S UB (V,T ). ∀(ς,s)∈{SIG,C }×S. ∀t∈T ς,s. tσ∈T ς,s .
Sometimes it makes sense to allow the substitution of constructor variables with non-
constructor terms: The set of generalized substitutions from X to T is defined to be
G EN S UB (X,T ) := { σ : X→ T | ∀(ς,s)∈{SIG,C }×S. ∀x∈Xς,s. σ(x)∈T SIG,s }.
In our applications we will always have ∀s∈S. T C ,s⊆T SIG,s and therefore S UB (X,T ) ⊆
G EN S UB (X,T ). Thus, the name “generalized” is justified.
Let E be a finite set of equations (i.e. pairs of terms of equal sort) and X a finite subset of V.
A substitution σ ∈ S UB (V,T ) is called a unifier for E if Eσ⊆ id. Such a unifier is called most
general on X if for each unifier µ for E there is some τ ∈ S UB (V,T ) such that (στ)|X = µ|X.
If E has a unifier, then it also has a most general unifier26 on X, denoted by mgu(E,X).
Two terms t,t ′ are unifiable if {(t,t ′)} has a unifier. They are clashing if there is some
p ∈ FPOS (t)∩FPOS (t ′) such that the head function symbols of t/p and t ′/p differ. Note that
two terms cannot be both unifiable and clashing.
26For this most general unifier σ we could, as usual, even require σσ = σ but not V (σ[V (E)]) ⊆ V (E).
To see that the latter requirement is not possible, consider x,y ∈ VC ,nat; Y ∈ VSIG,nat; a most general unifier for
{(x, s(Y ))} has to be something like { x 7→ s(y), Y 7→ y }. Note that this problem would not occur if we restricted
the variables in our terms either to be from VSIG only (cf. Wirth & Gramlich (1993)) or from VC only (cf. Avenhaus
& Becker (1992)).
26
5.3 Relations
Let ‘R’ and ‘−→’ denote binary relations.
R is said to be a relation on A if dom(R)∪ ran(R) ⊆ A. R is irreflexive if id∩R = /0. It is
A-reflexive if id|A ⊆ R. Simply speaking of a reflexive relation we refer to the biggest A that is
appropriate in the local context, and referring to this A we write R0 or 0−→ to ambiguously denote
id|A. Furthermore, we write R1 or
1
−→ to denote R or −→, resp.. For n ∈ N+ we write Rn+1 or
n+1
−→ to denote Rn◦R or n−→◦−→, such that Rn or n−→ denotes the n step relation for R or −→,
resp..
The reflexive closure of −→ is =−→ := 0−→∪−→. The transitive closure of −→ is +−→ :=
S
n∈N+
n
−→. The reflexive & transitive closure of −→ is ∗−→ := +−→= = =−→+ = Sn∈N n−→. For
a binary relation denoted with R, ≻, , >, ⊢, or ց, &c. we will use an according denotation.27
The reverse of a binary relation denoted with R, −→, ≻, , >, ⊢, or ց, &c. will be denoted
with R−1, ←−, ≺, , <, ⊣, or ւ, &c., resp.. Note that R−1 is an inverse (in the sense that
R◦R−1 = id|dom(R) and R−1◦R= id|ran(R) holds) iff R is an injective function. The symmetric
closure of −→ is ←→ :=←−∪−→.
v, w are called joinable w.r.t. −→ if v↓w, i.e. if v ∗−→◦ ∗←−w. They are strongly joinable
w.r.t. −→ if vw, i.e. if v =−→◦ ∗←−w and v ∗−→◦ =←−w.
−→ is called terminating below u if there is no s : N→ dom(−→) such that
u=s0 ∧ ∀i∈N. si−→si+1. It is terminating if it is terminating below all u.
Let X⊆ V. Let T⊆ T . A relation R on T is called:
sort-invariant if ∀n∈N. ∀(t0, . . . ,tn)∈R. ∃s∈S. ∀i∈{0, . . . ,n}. ti∈T SIG,s.
X-stable (w.r.t. substitution) if
∀n∈N. ∀(t0, . . . ,tn)∈R. ∀σ∈S UB (V,T (X)).
(t0σ, . . . ,tnσ) ∈ R.
T-monotonic if ∀(t ′,t ′′)∈R. ∀t∈T . ∀p∈POS (t).( (
∃s∈S. t/p,t ′,t ′′∈T SIG,s
∧ t[ p← t ′ ] ∈ T
)
⇒
(
(t[ p← t ′ ],t[ p← t ′′ ]) ∈ R
∧ t[ p← t ′′ ] ∈ T
) )
.
sufficiently complete (w.r.t. G T (cons)) if ∀t∈G T (sig). ∃t ′∈G T (cons). (t,t ′)∈R.
27Note that this is actually a slight abuse of notation since A+ now denotes the transitive closure of A (whereas A+
denotes the set of nonempty words over A) and since A∗ now denotes the reflexive & transitive closure of A (whereas
A∗ denotes the set of words over A).
27
5.4 Orderings
By an (irreflexive) ordering ‘<’ (on A) we mean an irreflexive and transitive binary relation (on
A), sometimes called “strict partial ordering” &c. by other authors. As with all our asymmetric
relation symbols we define a>b if b<a. A reflexive ordering ‘≤’ on A is an A-reflexive,
antisymmetric, and transitive relation on A. A quasi-ordering ‘.’ on A is an A-reflexive and
transitive relation on A. An equivalence on A is an A-reflexive, symmetric, and transitive relation
on A.
The equivalence ≈ (on A) of a quasi-ordering . (on A) is .∩&. The ordering < of a quasi-
ordering or a reflexive ordering . is .\&. The reflexive ordering on A of an ordering < is
(<∪ id)∩ (A×A). The reflexive ordering on A of a quasi-ordering . is the reflexive ordering on
A of the ordering of ..
A quasi-ordering or a reflexive ordering. is called total on A if A×A⊆.∪&. An ordering
is called total on A if its reflexive ordering on A is total on A.
An ordering < or > is called wellfounded if > is terminating. A quasi-ordering or a reflexive
ordering is called wellfounded if its ordering is wellfounded.
A reduction ordering on T is a V-stable, T -monotonic, and wellfounded ordering. The sub-
term ordering ‘ST’ on T (with reflexive ordering ‘EST’) is the V-stable and wellfounded ordering
defined by: tESTt ′ if ∃p∈POS (t ′). t = t ′/p. A simplification ordering on T is a reduction order-
ing on T containing ST . ‘≺’ denotes the ordering on the ordinal numbers. For further details
on orderings cf. Dershowitz (1987).
28
5.5 Confluence
The following notions and lemmas have become folklore, cf. e.g. Klop (1980) or Huet (1980) for
more information.
Definition 5.2 (Commutation and Confluence)
Two relations −→0 and −→1 are commuting if
∀s,t0,t1.
(
t0
∗
←−0s
∗
−→1t1 ⇒ t0
∗
−→1 ◦
∗
←−0t1
)
.
−→0 and −→1 are locally commuting if
∀s,t0,t1.
(
t0←−0s−→1t1 ⇒ t0
∗
−→1 ◦
∗
←−0t1
)
.
−→1 strongly commutes over −→0 if
∀s,t0,t1.
(
t0←−0s−→1t1 ⇒ t0
=
−→1 ◦
∗
←−0t1
)
.
s
∗
1
> t1 s 1 > t1 s 1 > t1
t0
∗
∨
0
∗
1
> ◦
∗
∨
0
t0
∨
0
∗
1
> ◦
∗
∨
0
t0
∨
0
=
1
> ◦
∗
∨
0
−→0 and −→1 are
commuting
−→0 and −→1 are
locally commuting
−→1 strongly com-
mutes over −→0
A single relation −→ is called [ locally] confluent if −→ and −→ are [locally] commuting. It is
called strongly confluent if −→ strongly commutes over −→. It is called confluent below u if
∀v,w. ( v
∗
←−u
∗
−→w ⇒ v↓w ).
Lemma 5.3
If −→0 and −→1 are commuting, then they are locally commuting, too.
Furthermore, if −→0∪−→1 is terminating or if−→0 or−→1 is transitive, then also the converse
is true, i.e. −→0 and −→1 are commuting iff they are locally commuting.
Lemma 5.4
The following three properties are logically equivalent:
1. −→1 strongly commutes over −→0 .
2. −→1 strongly commutes over
+
−→0 .
3. −→1 strongly commutes over
∗
−→0 .
Moreover, each of them implies that −→0 and −→1 are commuting.
Lemma 5.5
Assume that −→ is confluent. Now: ∗←→⊆ ↓.
29
5.6 Algebras
We define a (total) sig/cons-algebra A over the signature sig = (F,S,α) with constructor sub-
signature cons = (C ,S,α|C ) to be a function defined on F⊎ ({SIG,C }×S) with ∀s∈S.
( /0 6= A C ,s ⊆ A SIG,s ) and
f A : A SIG,s0×·· ·×A SIG,sn−1 →A SIG,sn for f ∈F with α( f )= s0 . . .sn
cA [A C ,s0 ×·· ·×A C ,sn−1 ]⊆ A C ,sn for c∈C with α(c)= s0 . . .sn.
We write f A instead of A ( f ) for f ∈F. For s ∈ S we call A SIG,s the universe of A for the sort s
and A C ,s the constructor sub-universe of A for the sort s. The sig/cons-algebras of this definition
are nothing but the order-sorted algebras over the order-sorted signature exhibited in § 5.1. A
sig/cons-algebra A is called trivial if ∀s∈S. |A SIG,s|=1.
A (total) sig/cons-homomorphism from A to B is a triple written h::A→B of an S-sorted
family h = (hs)s∈S of functions hs : A SIG,s → B SIG,s and two sig/cons-algebras A , B , such that h
is compatible with sig and cons: For f∈F; α( f )=s0 . . .sn; ∀i≺n. ai∈A SIG,si :
hsn( f A (a0, . . . ,an−1)) = f B (hs0(a0), . . . ,hsn−1(an−1)) ;
and for all s ∈ S: hs[A C ,s]⊆ B C ,s .
Taking the class of sig/cons-algebras for the class of objects and the class of sig/cons-
homomorphisms for the class of arrows, we get the (total sig/cons-homomorphism) category
of sig/cons-algebras. The composition hk::A→C of h::A→B and k::B→C is defined by hk :=
(hs ◦ ks)s∈S and the identity homomorphism for A is IdA ::A→A , where IdA := (id|A SIG,s)s∈S.
A sig/cons-homomorphism h::A→B is called a sig/cons-isomorphism if there is a sig/cons-
homomorphism h−1::B→A such that hh−1 = IdA and h−1h= IdB . Two sig/cons-algebras A
and B are sig/cons-isomorphic if there is some sig/cons-isomorphism h::A→B .
Lemma 5.6 Let h::A→B be a sig/cons-homomorphism. Now:
h::A→B is a sig/cons-isomorphism iff ∀s∈S.
(
hs : A SIG,s → B SIG,s is bijective
∧ hs[A C ,s]=B C ,s
)
.
Let X⊆ V. We enlarge the {SIG,C }×S-sorted family T (X) of § 5.1 to the term algebra over X
and sig/cons/V by defining ( f ∈F; α( f )=s0 . . .sn; ∀i≺n. ti∈T (X)SIG,si):
f T (X)(t0, . . . ,tn−1) := f (t0, . . . ,tn−1).
An A -valuation κ of X is an element of
S UB (X,A ) = S UB ( (X∩Vς,s)(ς,s)∈{SIG,C }×S , (A ς,s)(ς,s)∈{SIG,C }×S ) .
For κ∈G EN S UB (X,A ) we define the evaluation function Aκ on T (X) recursively by
Aκ(x) = κ(x) (x ∈ X);
Aκ( f (t0, . . . ,tn−1)) = f A (Aκ(t0), . . . ,Aκ(tn−1)) ( f ∈ F).
In case of κ∈S UB (X,A ) we get the evaluation homomorphism Aκ::T (X)→A . Note that here
‘Aκ’ actually denotes (Aκ|T (X)SIG,s)s∈S. Similarly, we sometimes write ‘κ’ when we actually
mean (κ|VSIG,s⊎VC ,s)s∈S.
Lemma 5.7 (Homomorphism-Lemma)
Let h::B→C be a sig/cons-homomorphism and κ ∈ G EN S UB (X,B ). Now:
Bκh=Cκh; i.e. ∀s∈S. ∀t∈T (X)SIG,s. hs(Bκ(t))=Cκh(t).
30
Lemma 5.8 (Substitution-Lemma)
Let A be a sig/cons-algebra and κ an A -valuation of X. Now:
∀t∈T . ∀µ∈G EN S UB (V,T (X)). Aκ(tµ)=A µAκ(t).
For being able to express that a sig/cons-algebra has no “junk” in its universes, we define: For
SC∈ {SIG,C }; sc∈{sig,cons}; a sig/cons-algebra A is called SC:sc-term-generated if ∀s∈S.
∀a∈A SC,s. ∃t∈G T (sc)s. a = A (t) . A is called sc-term-generated if it is SIG:sc-term-gene-
rated.
Since it is also important to compare sig/cons-algebras with respect to their “confusion”, we
define .H and .C as (proper class) relations on sig/cons-algebras by A .HB if there is a
sig/cons-homomorphism from A to B . A .C B if there is a cons-homomorphism from the
cons-algebra A |C⊎({C }×S) to B |C⊎({C }×S) . We trivially get .H ⊆ .C (by restriction of
the homomorphism); and .H , .C are quasi-orderings (by the homomorphisms exhibited for
the category above). The corresponding equivalences, orderings, and reflexive orderings will be
denoted by ≈, <, ≤, resp., with the corresponding subscript.
A sig/cons-congruence ∼ on A is an ordinary sig-congruence for A when A is considered to
be a sig-algebra, i.e. an S-sorted family ∼= (∼s)s∈S of equivalences ∼s on A SIG,s satisfying for
each non-constant function symbol f ∈ F with α( f )=s0 . . .snsn+1 and ∀in. ai∈A SIG,si : If
a j∼s j b for some j  n, then
f A (a0, . . . ,a j−1,a j,a j+1, . . . ,an) ∼sn+1 f A (a0, . . . ,a j−1,b,a j+1, . . . ,an) .
The factor algebra of A modulo ∼ is the sig/cons-algebra B (denoted by A /∼) given by:
B ς,s := { ∼s[{a}] | a∈A ς,s } ( (ς,s) ∈ {SIG,C }×S );
f B (∼s0 [{a0}], . . . ,∼sn−1 [{an−1}]) := ∼sn[{ f A (a0, . . . ,an−1)}]
( f ∈ F; α( f )=s0 . . .sn; ∀i≺n. ai∈A SIG,si).
The canonical sig/cons-epimorphism of A modulo∼ is the sig/cons-homomorphism k::A→A /∼
given by (s∈S; a∈A SIG,s): ks(a) := ∼s[{a}].
For a sig/cons-homomorphism h::A→B we define its kernel to be the sig/cons-congruence
ker(h) given by (s∈S; a,b∈A SIG,s): (a,b) ∈ ker(h)s if hs(a) = hs(b).
Theorem 5.9 (Homomorphism-Theorem)
Let h::A→C be a sig/cons-homomorphism. Let ∼ be a sig/cons-congruence on A with ∀s∈S.
∼s ⊆ ker(h)s. Define B := A /∼. Let k::A→B be the canonical sig/cons-epimorphism of A
modulo ∼. Now h=kl uniquely defines an S-sorted family of functions l = (ls)s∈S with ∀s∈S.
(ls : B SIG,s → C SIG,s). Furthermore, this l is a sig/cons-homomorphism l::B→C . Moreover, if
∼= ker(h) holds, then ls is injective for each s ∈ S.
By concretion of notions of category theory to full sub-categories of the sig/cons-homomorphism
category of sig/cons-algebras and to the forgetful functor we define for a class K of sig/cons-
algebras; a sig/cons-algebra A ; X⊆V; and ι ∈ S UB (X,A ): A is initial in K if A ∈K and for
each B ∈K there is a unique h::A→B . A is free for K over X w.r.t. ι if for each B ∈K and κ ∈
S UB (X,B ) there is a unique h::A→B with κ= ιh.
A is free in K over X w.r.t. ι if A ∈K and A is free for K over X w.r.t. ι.
31
5.7 Atoms and Literals
Let ‘=’ (binary, symmetric, sort-invariant), ‘Def ’ (singulary), and ‘<’ (binary) be predicate sym-
bols, expressing equality and definedness in algebras and a wellfounded ordering we can freely
choose during each induction proof. The elements of the field of this ordering will be called
weights. Since we denote our weights with Hebrew letters which may not be known to the reader
we introduce the beginning of the Hebrew alphabet: ℵ aleph, i beth, ג gimel, and k daleth. Let
Y be a set of variables. Each weight ℵ has associated with it a certain finite set V (ℵ) of input
variables. The set of weights over the set of variables Y is defined as
Weight(Y) := { ℵ | ℵ is a weight with V (ℵ)⊆Y }.
The set of atoms over terms from T (sig,Y) is defined as
A T (sig,Y) := { (u=v), (Def u) | ∃s∈S. u,v∈T (sig,Y)s }.
The set of generalized atoms is defined as
G EN A T (sig,Y) := A T (sig,Y) ∪ { (i<ℵ) | i,ℵ∈Weight(Y) }.
The set of literals is defined as
L I T (sig,Y) := { A, A | A ∈ A T (sig,Y) }.
The set of generalized literals is defined as
G EN L I T (sig,Y) := { A, A | A ∈ G EN A T (sig,Y) }.
The set of condition literals is defined as
CON DL I T (sig,Y) := L I T (sig,Y) \ { (Def u) | u∈T (sig,Y) }.
The condition literals are those literals that may appear in the condition of defining rules, where
Def-literals are excluded.
For “(u=v)” we also write “(u 6=v)”. For a generalized atom A let “A” denote “A”. A literal that
is an atom is called a positive literal; otherwise it is called negative.
We extend the concept of “positions” from terms to literals by (s∈S; u1,u2∈T SIG,s;
A∈G EN A T (sig,V); i,ℵ∈Weight(V); i∈{1,2}; p∈N+∗):
POS (u1=u2) := { iq | i ∈ {1,2} ∧ q ∈ POS (ui) } (u1=u2)/ip := ui/p
POS (Def u1) := { 1q | q ∈ POS (u1) } (Def u1)/1p := u1/p
POS (i<ℵ) := /0
POS (A) := POS (A) A/p := A/p
Note that for λ ∈ G EN L I T (sig,V) and p ∈ POS (λ) we have λ/p∈T . A literal λ ∈
L I T (sig,V) is called linear if ∀p,q∈VPOS (λ). (λ/p=λ/q ⇒ p=q).
32
The set T ERM S (λ0 . . .λn−1) of (top level) terms of a list of literals λ0 . . .λn−1 is recursively
defined by:
T ERM S (u1=u2) := {u1,u2}
T ERM S (Def u1) := {u1}
T ERM S (i<ℵ) := /0
T ERM S (A) := T ERM S (A)
T ERM S (λ0 . . .λn−1) :=
[
i≺n
T ERM S (λi)
Definition 5.10 (Literal Rewriting)
Let (l=r) ∈ L I T (sig,V).
We define a rewrite relation−→
(l=r) on non-generalized literals by (λ,λ′ ∈ L I T (sig,V)) λ−→(l=r)λ′
if ∃p∈POS (λ).
(
λ/p= l
∧ λ′=λ[ p← r ]
)
.
Note that the variables in (l=r) have to be treated like constants in the sense that they cannot be
instantiated for the rewrite step.
33
5.8 Syntax of Rules and Formulas
Many authors impose rather strong restrictions on constructor equations, such as “no equations
between constructors” (“free constructors”) or “unconditional equations between constructors
only”. Compared to these, our restrictions are rather weak. In the definition below we restrict
our constructor rules to contain no non-constructor function symbols or extra-variables (construc-
tor-preservation28) and to contain no negative literals (“Horn”-form). This is important for our
approach (cf. Lemma 7.10, Lemma 7.11, and Lemma 7.12) and should be kept in mind. To get
a provisional idea, the reader should think a rule l=r←−C to express that l reduces to r when,
roughly speaking, all literals in C hold.
Definition 5.11 (Syntax of CRSs)
((l,r),C) is a positive/negative-conditional rule over sig/V if (l=r) ∈ A T (sig,V) and C ∈
(CON DL I T (sig,V))∗.
A rule ((l,r), /0) with an empty condition will be written l=r. Note that l=r differs from
r=l whenever the equation is used as a rule. A rule ((l,r),C) with condition C will be writ-
ten l=r←−C. We call l the left-hand side and r the right-hand side of the rule l=r←−C.
A rule is said to be left-linear (right-linear) if its left-hand (right-hand) side is a linear term. A
rule l=r←−C is said to be extra-variable free if V ({r}∪ T ERM S (C)) ⊆ V (l).
A rule l=r←−C is called a constructor rule if its left-hand side is a constructor term, i.e.
l∈T (cons,VSIG⊎VC ). For a set of rules R we define its constructor sub-system RC to be the set
of all its constructor rules:
RC := { ((l,r),C)∈R | l∈T (cons,VSIG⊎VC ) }.
A (positive/negative-) conditional rule system (CRS) R over sig/cons/V is a finite set of rules over
sig/V satisfying the following restriction on its constructor sub-system:
∀((l,r),C)∈RC .
 {r}∪ T ERM S (C) ⊆ T (cons,VSIG⊎VC )∧ V ({r}∪ T ERM S (C)) ⊆ V (l)
∧ C ∈ (A T (sig,V))∗
.
The whole CRS R is said to have a property that is already defined for rules if each of its rules
has this property.
28The constructor-preservation is really necessary here for guaranteeing the existence of a a constructor-minimum
model as in Theorem 7.16: Let 0,1,true, false be constructor constants, let weirdp be a non-constructor constant,
and take R: 1=0←− weirdp=true ; weirdp=true←− true6=false.
Now there are sig/cons-models of R with 06=1 and models with true 6=false but no models with “06=1∧ true6=false”.
Also notice, that the constructor-preservation has some additional advantages, e.g.:
(1) The rules become sort-decreasing w.r.t. the order-sorted signature exhibited in § 5.1, i.e.
the right-hand side and the condition terms are from T (cons,VC ) if the left-hand side is.
(2) For u ∈ G T with computable and unique normal form NF(u) we can test
“ ∃uˆ ∈ G T (cons) : u
∗
−→uˆ ” by “ NF(u) ∈ G T (cons) ”.
(3) Theorem 7.18 has no reasonable analogue for CRSs which are not constructor-preserving.
34
In the following example we define a delete-function “dl(x, l)” deleting all occurrences of x in
the list l, a remove-copies-function “rc(x, l)” removing repeated occurrences of x in the list l, a
brushing function “br(k, l)” removing repeated occurrences in the list l for all elements of the list
k. Moreover, on the natural numbers, the operations of addition ‘+’ and subtraction ‘−’ (defined
only partially on the constructor ground terms of the sort nat, due to a non-complete defining
case distinction), the Ackermann function ‘ack’, the “less or equal” predicate ‘leq’ and the “less”
predicate ‘less’. The member-predicate “mbp(x, l)” tests for x occurring in the list l. That the
predicates ‘p’ and ‘q’ are also total on the constructor ground terms of the sort nat is not obvious
but will be formally proved in Example 16.25.
Example 5.12 (continuing Example 5.1)
Let x,y ∈ VC ,nat and k, l ∈ VC ,list.
R5.12:
(dl1) dl(x,nil) = nil
(dl2) dl(x,cons(y, l)) = dl(x, l) ←− x=y
(dl3) dl(x,cons(y, l)) = cons(y,dl(x, l)) ←− x 6=y
(rc1) rc(x,nil) = nil
(rc2) rc(x,cons(y, l)) = cons(y,dl(x, l)) ←− x=y
(rc3) rc(x,cons(y, l)) = cons(y, rc(x, l)) ←− x 6=y
(br1) br(nil, l) = l
(br2) br(cons(x,k), l) = br(k, rc(x, l))
(+1) x+0 = x
(+2) x+s(y) = s(x+y)
(−1) x−0 = x
(−2) s(x)−s(y) = x−y
(ack1) ack(0,y) = s(y)
(ack2) ack(s(x),0) = ack(x,s(0))
(ack3) ack(s(x),s(y)) = ack(x,ack(s(x),y))
(switch1) switch(0) = s(0)
(switch2) switch(s(0)) = 0
(switch3) switch(s(s(x))) = s(s(switch(x)))
(swatch1) swatch(s(x)) = s(switch(x))
(leq1) leq(0,y) = true
(leq2) leq(s(x),0) = false
(leq3) leq(s(x), s(y)) = leq(x,y)
(less1) less(0,s(y)) = true
(less2) less(x,0) = false
(less3) less(s(x), s(y)) = less(x,y)
(mbp1) mbp(x,nil) = false
(mbp2) mbp(x,cons(y, l)) = true ←− x=y
(mbp3) mbp(x,cons(y, l)) = mbp(x, l) ←− x 6=y
35
(p1) p(0) = true
(p2) p(s(x)) = true ←− p(x)=true, q(x,s(x))=true
(q1) q(x,0) = true
(q2) q(x,s(y)) = true ←− q(x,y)=true, p(x)=true
Formulas are implicitly universally quantified disjunctive lists of generalized literals, which in-
cludes the empty formula /0 which is always false because it is the disjunction over the empty list
of literals:
Definition 5.13 (Syntax of Formulas)
Let Y be a set of variables. The elements of the set ‘Form(sig,Y)’ of formulas (or Gentzen
clauses) over sig/Y are lists of generalized literals:
Form(sig,Y) := (G EN L I T (sig,Y))∗ .
Definition 5.14 (Equals and Contains)
We say that an atom A equals an atom B if A=B or ∃t,t ′.
(
A=(t=t ′)
∧ B=(t ′=t)
)
.
A literal λ equals a literal λ′ if the atom λ equals the atom λ′ or the atom λ equals the atom λ′.
We say that a formula Γ contains a formula Π if for each literal λ occurring in Π there is a literal
λ′ in Γ such that λ′ equals λ. We say that Γ equals Π if Γ contains Π and Π contains Γ.
E.g., the formula “ (t=t ′), (t ′=t) ” is contained in the formula “ (t=t ′), (t 6=t ′) ” (but not vice
versa) and equals the formula “ (t=t ′) ”.
Example 5.15 (continuing examples 5.1 and 5.12)
The following are formulas w.r.t. the signature of Example 5.1. Moreover, they are all type-C
inductively valid (cf. Definition 10.5) w.r.t. R5.12. Let x,y,z∈VC ,nat; k, l ∈VC ,list; and b∈VC ,bool.
The first column indicates the number of the example where the formula is proved, the second a
name of the formula which will be used in what follows.
Note that lemmas of the form “Def f (x0, . . . ,xn−1)” (the xi being different constructor vari-
ables), express that the symbol ‘ f ’ denotes a totally specified function.
36
(Tertium non datur) b= true, b= false
16.17 (0 6=s) 0 6=s(x)
16.18 (Inject s) s(x) 6=s(y), x=y
16.20 (Irrefl s) x 6=s(x)
(Defdl) Defdl(x, l)
(Def rc) Def rc(x, l)
(Defbr) Defbr(k, l)
(Def+) Def (x+y)
16.16 (Def−) Def (x−y), leq(y,x) 6= true
(Defack) Def ack(x,y)
(Def switch) Def switch(x)
(Def swatch) Def swatch(s(x))
(Def leq) Def leq(x,y)
(Def less) Def less(x,y)
(Defmbp) Defmbp(x, l)
(Del dl) dl(x, l)= l, mbp(x, l)= true
(Del rc) rc(x, l)= l, mbp(x, l)=true
(Del dl mbp) mbp(x,dl(y, l))=mbp(x, l), x=y
(Del rc mbp) mbp(x, rc(y, l))=mbp(x, l)
12.1 (Rip cons br) br(k,cons(x, l))=cons(x,br(k, l)), mbp(x, l)= true
(Del 0 +) 0+x=x
(Rip s +) s(x)+y=s(x+y)
(Comm +) x+y=y+x
(Pos ack) less(0,ack(x,y))= true
16.9 (Irrefl 2 ack) less(y,ack(x,y))= true
(Del switch switch) switch(switch(x))=x
(Del swatch swatch) swatch(swatch(s(x)))=s(x)
15.7 (Del swatch3) Def swatch(0), swatch(swatch(swatch(x)))=swatch(x)
(True leq) leq(x,x)= true
(False leq) leq(s(x),x)= false
(True less) less(x,s(x))= true
(False less) less(x,x)= false
(Strict Trans less) less(s(x),z)= true, less(x,y) 6= true, less(y,z) 6= true
16.25 (True p) p(x)= true
37
6 Semantics of Rules and Formulas
Instead of giving semantics for sets of rules directly, we define semantics of formulas and then
say which formula a rule denotes. As usual, the fixed meaning of ‘=’ is the equality in a sig/cons-
algebra A . ‘Def ’, however, is the “definedness” predicate which states that the evaluation of its
argument belongs (with invariant sort) to the constructor sub-universe of A which contains the
set of evaluation values of constructor ground terms and which is intended to supply a domain
for (possibly partially) specifying functions on it. To be able to define the semantics of ‘<’ we
assume that with each algebra A there is associated some wellfounded quasi-ordering .A , with
ordering <A and equivalence ≈A , cf. Global Requirement 13.4 for details.
Definition 6.1 (Validity of Formulas in sig/cons-algebras)
Let X and Y be sets of variables, A be a sig/cons-algebra; and κ ∈ S UB (X,A ).
An atom (u=v) ∈ A T (sig,Y) is true w.r.t. Aκ if V (u,v)⊆X and Aκ(u)=Aκ(v); and an atom
(Def u) ∈ A T (sig,Y) (with u∈T SIG,s; s∈S) is true w.r.t. Aκ if V (u)⊆X and Aκ(u)∈A C ,s.
An atom (u=v) ∈ A T (sig,Y) is false w.r.t. Aκ if V (u,v)⊆X and Aκ(u) 6=Aκ(v); and an atom
(Def u) ∈ A T (sig,Y) (with u∈T SIG,s; s∈S) is false w.r.t. Aκ if V (u)⊆X and Aκ(u) 6∈A C ,s.
A generalized atom (i<ℵ) ∈ G EN A T (sig,Y) is true w.r.t. Aκ if i,ℵ∈dom(≈A ) and
i<A ℵ.
A generalized atom (i<ℵ) ∈ G EN A T (sig,Y) is false w.r.t. Aκ if i,ℵ∈dom(≈A ) and
i≮A ℵ.
A literal A (with A∈G EN A T (sig,Y)) is true w.r.t. Aκ if A is false w.r.t. Aκ.
A literal A (with A∈G EN A T (sig,Y)) is false w.r.t. Aκ if A is true w.r.t. Aκ.
A formula Γ ∈ Form(sig,Y) is true w.r.t. Aκ if V (Γ)⊆X and there is some literal λ in Γ that is
true w.r.t. Aκ.
A formula Γ ∈ Form(sig,Y) is false w.r.t. Aκ if all literals λ in Γ are false w.r.t. Aκ.
Γ ∈ Form(sig,Y) is valid in A if ∀κ ∈ S UB (V (Γ),A ). (Γ is true w.r.t. Aκ).
As usual, these notions also apply to a set of formulas F if they apply to each formula in F . E.g.,
a set of formulas F is valid in A if ∀Γ∈F. Γ is valid in A .
38
Note that the following obvious lemma does not hold for generalized literals, whose treatment is
more difficult, cf. Lemma 13.11.
Lemma 6.2 (Substitution-Lemma for Non-Generalized Literals)
Let A be a sig/cons-algebra; λ∈ L I T (sig,V); µ∈ G EN S UB (V,T (X)); and κ∈ S UB (Y,A )
for some Y with V (ran(µ))⊆ Y.
Now the following two statements are logically equivalent:
• λµ is true w.r.t. Aκ.
• λ is true w.r.t. A µAκ .
Moreover, if 29 λ−→
(l=r)λ′ and if (l=r)µ is true w.r.t. Aκ, the following is also logically equi-
valent:
• λ′µ is true w.r.t. Aκ.
Lemma 6.3
Let Γ be a formula not containing ‘<’-literals, i.e. Γ ∈ (L I T (sig,V))∗.
Assume A and B to be sig/cons-isomorphic. Now:
Γ is valid in A iff Γ is valid in B .
29Cf. Definition 5.10.
39
As we have negative equations in the conditions of our rules, in general we cannot hope to get a
minimum model because we can express things like “a=b∨ b=c”, which has the incomparable
minimal models “a=b6=c” and “a6=b=c”. What we will get instead is a model which is the (up to
isomorphism) uniquely determined minimum of all sig-term-generated models that are minimal
w.r.t. the identification of constructor ground terms.30 For formally expressing these minimality-
properties, we need the following definition.
Definition 6.4 (Model)
When talking about semantics of rules we identify the rule
l=r←−λ0 . . .λn−1
with the formula
(l=r) λ0 . . . λn−1.
A sig/cons-algebra A is a sig/cons-model of a CRS R over sig/cons/V if all rules in R
(considered as formulas) are valid in A .
A sig/cons-algebra A will be called a minimum model (constructor-minimum model) of R if
A is a .H-minimum (.C -minimum) of the class of all sig/cons-models of R.31
Similarly, A is a minimal model (constructor-minimal model) of R if A is a sig/cons-model
of R and there is no sig/cons-model B of R with B <HA (B <C A ).
Example 6.5
Let C := {c1,c2,c3} and N := {d} be sets of constants of a single sort.
If we define R := { d=c2 ∨ d=c3 }, then the congruence given by “d=c2” as well as the
congruence given by “d=c3” yield two constructor-minimum models of R: The confusion of
the non-constructor function symbol ‘d’ is no obstacle for the required cons-homomorphism on
the cons-algebras which are too forgetful to know anything about ‘d’. Furthermore, the two
congruences yield .H-incomparable minimal models of R, which implies that a minimum model
cannot exist.
To show that a constructor-minimum model may not exist for CRSs, we redefine R to be given
by the following four rules:
d = c1 ←− c2 6=c3
d = c2 ←− c2 6=c3
d = c2 ←− c1 6=c2
d = c3 ←− c1 6=c2
Now the congruence given by “d=c2=c3” and the congruence given by “d=c1=c2” yield .C -
incomparable [constructor-] minimal models of R, which implies that a [constructor-] minimum
model cannot exist. “c1=c2=c3” yields another minimal model which, however, is not construc-
tor-minimal.
30Cf. Corollary 7.17.
31Cf. § 5.6, p. 30.
40
The following lemma tells us that, considering minimum models, we can think in terms of
sig/cons-congruences on G T instead of algebras:
Lemma 6.6 Let B be a sig/cons-model of the CRS R over sig/cons/V. Define the factor algebra
A := G T /ker(B ) . Now:
1. A is a sig/cons-model of R.
2. A .HB . Moreover, there is a unique sig/cons-homomorphism l::A→B
(which is monic in the sig/cons-homomorphism category of sig/cons-algebras).
3. A .C B . (However, we do not have A ≈C B in general, because
B |C⊎({C }×S) need not be cons-term-generated.)
The following lemma of theoretical nature ensures the existence of minimal models. It resembles
Theorem 2.1 in Kaplan (1988). Note however, that our .H and .C are reflexive and therefore
different from the relation≤ in Kaplan (1988), where the homomorphism is additionally required
to be unique.
Lemma 6.7 Let R be a CRS over sig/cons/V.
1. The trivial sig/cons-algebra is a sig/cons-model of R.
2. If B is a sig/cons-model of R, then there is a minimal model A of R with A ≤HB .
3. R has a minimal model.
41
7 The Reduction Relation
In this section we are going to define a reduction relation which is convenient for the semantics
defined in § 6 in the sense that (roughly speaking, for details cf. Corollary 7.17) the factor algebra
of the term algebra modulo the congruence induced by the reduction relation is a minimal model
of the defining set of rules. The overall idea is to reduce a left-hand side of a rule to its right-
hand side only if the condition of this rule can somehow be shown valid by means of the same
reduction relation again. The reader who is not interested in the details of our reduction relation
should read only Definition 7.15, Theorem 7.16, and Theorem 7.18 of this section.
When we are now going to define our reduction relation, please keep in mind that we intend to
require it to be confluent in what follows, whereas we do not require confluence for the definition
because we cannot prove confluence criteria if the non-confluent case is undefined. Therefore, we
have to be explicit about how we test the condition literals — even if this testing is not straightfor-
ward when confluence is not provided. Our “operational” semantics for testing condition literals
is the following: “u=v” is fulfilled if u,v have reducts uˆ, vˆ, resp., which are syntactically equal.
“Def u” is fulfilled if u has a constructor ground reduct, which means that our reduction relation
depends on the constructor sub-signature ‘cons’ beyond the signature ‘sig’ — just as our notion
of “sig/cons-model” does. Finally, “u 6=v” is fulfilled if u,v have constructor ground reducts uˆ, vˆ,
resp., which are not joinable. Thus, two terms in a condition literal are operationally equal if they
are joinable, whereas they are unequal if they are not joinable after some reduction to construc-
tor ground terms. The non-joinability alone of two terms is not sufficient for regarding them as
unequal because we are never sure about the inequality of “undefined” terms. Note that our oper-
ational logic is four-valued, i.e. “u=v” and “u 6=v” can independently be fulfilled or not. In case
of confluence, however, it is impossible that both “u=v” and “u 6=v” are fulfilled simultaneously;
in case of free or confluent constructors, such a simultaneous fulfilledness occurs only if we have
something like an ambiguous function definition.
Definition 7.1 (Fulfilledness)
A list D ∈ (CON DL I T (sig,V))∗ of condition literals is said to be fulfilled w.r.t. some relation
−→ if
∀u,v ∈ T .
 ( (( u=v ) in D) ⇒ u↓v )∧ ( ((Def u) in D) ⇒ ∃uˆ ∈ G T (cons). u ∗−→uˆ )
∧ ( (( u 6=v ) in D) ⇒ ∃uˆ, vˆ ∈ G T (cons). u ∗−→uˆ ∤↓vˆ ∗←−v )
.
Usually one gets a minimal reduction relation by taking the closure over a finitary generating
relation. This is not possible here, because we have a negative condition (uˆ ∤↓vˆ). Since our con-
structor rules have “Horn”-form and contain no non-constructor function symbols, however, this
negative condition does not influence the reduction of constructor terms; and (in Definition 7.1)
‘ ∤↓’ is applied to constructor (ground) terms only. Thus, to avoid a non-monotonic behavior due
to our negative condition, we define our intended minimal reduction relation −→R,X via a double
closure: First we define −→R,X,ω by using the constructor rules only. Then we define −→R,X,ω+ω
via a second closure including all rules, knowing the constructor reduction to remain unchanged.
42
Definition 7.2 (−→R,X)
Let R be a CRS over sig/cons/V. Let X⊆V. For β  ω+ω and a position p ∈ N+∗ the reduction
relations −→R,X,β and −→R,X,β,p on T (sig,X) are inductively defined as follows:32
Generally: −→R,X,β :=
[
p∈N+∗
−→R,X,β,p .
For a limit ordinal α ∈ {0,ω,ω+ω}: −→R,X,α,p :=
[
β≺α
−→R,X,β,p .
For for the non-limit ordinals β+1 with β≺ω+ω and for s,t ∈ T (sig,X):
s−→R,X,β+1,pt if
∃
〈
((l,r),C)∈R
σ∈S UB (V,T (X))
〉
.

s/p = lσ
∧ t = s[ p← rσ ]
∧ Cσ is fulfilled w.r.t. −→R,X,β
∧
( β≺ω ⇒ l∈T (cons,VSIG⊎VC ) )
.
−→R,X :=−→R,X,ω+ω .
We will drop “R,X” in −→R,X and −→R,X,β &c. when referring to some fixed R,X. Instantiations
of X which are important in theory and practice are at least /0, VSIG, and V. We have introduced
the parameter X since it is more convenient than triplicating statements about properties (e.g.
confluence) for “ X= /0 ” (e.g. ground confluence), “ X=VSIG ”, and “ X=V ”.
Lemma 7.3
−→R,X,ω is the minimum (w.r.t. set-inclusion) of all relations  on T satisfying for all s,t ∈
T (sig,X):
s t if ∃
〈 p∈POS (s)
((l,r),C)∈R
σ∈S UB (V,T (X))
〉
.

s/p= lσ
∧ t =s[ p← rσ ]
∧ Cσ is fulfilled w.r.t.  
∧ l∈T (cons,VSIG⊎VC )
.
Lemma 7.4 Let SR,X be the set of all relations  on T satisfying
1. ( ∩ (G T (cons)×T )) ⊆ −→R,X,ω as well as
2. for all s,t ∈ T (sig,X):
s t if ∃
〈 p∈POS (s)
((l,r),C)∈R
σ∈S UB (V,T (X))
〉
.
 s/p= lσ∧ t =s[ p← rσ ]
∧ Cσ is fulfilled w.r.t.  
.
Now −→R,X is the minimum (w.r.t. set-inclusion) in SR,X , and SR,X is closed under nonempty inter-
section.
32Note that compared to Wirth & Gramlich (1994a) &c. we have removed some redundant “ or s−→R,X,ωt ” in the
definition of −→R,X,β+1 for the case of ωβ because this makes the definition and the proofs shorter.
43
Note that the first requirement of Lemma 7.4 is really necessary: To see this, consider Example 4.6
with the additional declaration that a and b are constructor symbols, i.e. that a,b ∈ C . If we
now take  to be the relation ∼ of Example 4.6 (which does not satisfy the first requirement
of Lemma 7.4 since a ∼ b but not a−→R, /0,ωb ), then  satisfies the second requirement of
Lemma 7.4, but we do not have −→R, /0 ⊆  since mbp(a,cons(b,nil))
+
−→R, /0 false but not
mbp(a,cons(b,nil))
+
 false.
Before we go on, we want to spend some more words on the way we test fulfilledness of negative
equations in the condition of a rule. While other formulations (e.g. a universal instead of the
existential quantification) might seem to be more satisfactory, ours is the one required for a correct
definition. One might have expected “u ∤↓v” instead of “ ∃uˆ, vˆ∈G T (cons). u ∗−→uˆ ∤↓vˆ ∗←−v ” for
“u 6=v”, but this modification would not allow the conclusion that −→R,X is minimal in the sense
of Lemma 7.4, as can be seen from:
Example 7.5
Let c, d be constructor and a, b, e be non-constructor constants and take R:
a = c ←− b6=d
b = d ←− e 6=c
e = a
Now with the modified definition of fulfilledness we would get
−→
modified,R, /0 = { (a,c), (b,d), (e,a) }.
Furthermore, { (a,c), (e,a) } and { (b,d), (e,a) } would be⊆-incomparable minimal relations
satisfying the requirements of Lemma 7.4 for modified fulfilledness. Their intersection { (e,a) },
however, satisfies the requirement for our original, non-modified fulfilledness only, and is equal
to −→R, /0 .
Definition 7.6 (Parallel Reduction)
For β ω+ω we define the parallel reduction relation −→q R,X,β on T (sig,X):
s−→q R,X,βt if ∃Π⊆ POS (s). s−→q R,X,β,Πt, where
s−→q R,X,β,Πt if
 ∀p,q∈Π.
(
p=q ∨ p‖q
)
∧ t =s[ p← t/p | p∈Π ]
∧ ∀p∈Π. s/p−→R,X,βt/p
.
Corollary 7.7 ∀βω+ω.−→R,X,β ⊆−→q R,X,β ⊆ ∗−→R,X,β .
44
By induction over the construction of −→R,X,ω+ω one can easily show:
Corollary 7.8 (Monotonicity of −→ w.r.t. Replacement)
−→R,X,β (for β  ω+ω) and −→R,X are T (sig,X)-monotonic as well as ∗−→R,X[T]-monotonic for
each T⊆ T (sig,X).
Corollary 7.9 (Stability of −→)
−→R,X,β (for β ω+ω), −→R,X , and their respective fulfilledness-predicates are X-stable.
The following two technical key lemmas state the consequence of constructor-preservation and
that there is no need for a second closure for reduction of constructor terms.
Lemma 7.10 For Y⊆ X⊆ V:
∀n∈N. ∀s∈T (cons,Y). ∀t.
(
s
n
−→R,Xt ⇒ (s
n
−→R,X,ωt ∈ T (cons,Y))
)
Lemma 7.11 ↓ ∩ (T (cons,VSIG⊎VC )×T (cons,VSIG⊎VC )) ⊆ ↓ω
Lemma 7.12 (Monotonicity of −→β and of Fulfilledness w.r.t. −→β in β)
For β γ ω+ω: −→β ⊆ −→γ ⊆ −→ ; and if C is fulfilled w.r.t. −→β and(
ωβ
∨ ∀u,v. ((u 6=v) is not in C)
)
, then C is fulfilled w.r.t. −→γ and w.r.t. −→.
Note that monotonicity of fulfilledness is not given in general for β≺ω and a negative literal
which may become invalid during the growth of the reduction relation on constructor terms.
Lemma 7.13 (Fulfilledness Test may be Simple)
Let C ∈ (CON DL I T (sig,X))∗. If for each element u ∈ T ERM S (C):
(1) u has a normal form NF(u) (i.e. u ∗−→NF(u) 6∈ dom(−→) ) and
(2) −→ is confluent below u,
then C is fulfilled w.r.t. −→ iff
∀(u=v) in C. NF(u)=NF(v)
∧ ∀(Def u) in C. NF(u)∈G T (cons)
∧ ∀(u 6=v) in C.
(
NF(u),NF(v)∈G T (cons)
∧ NF(u) 6=NF(v)
)

Lemma 7.14
Let X⊆Y⊆V. Now:
For all β  ω+ω and n∈N with n 6=0: n−→R,X,β = n−→R,Y,β ∩ (T (sig,X)×T (sig,X)), and for
C ∈ (CON DL I T (sig,X))∗: C is fulfilled w.r.t. −→R,X,β iff C is fulfilled w.r.t. −→R,Y,β .
Furthermore, dom(−→R,X) = dom(−→R,Y)∩ T (sig,X).
Finally, if −→R,Y is confluent, then −→R,X is confluent, too.
45
While the following theorem in its general form is indeed necessary for establishing appropriate
notions of inductive validity (cf. § 10), its meaning is easier to grasp from its corollary below,
saying that (for Def-moderate CRSs R with confluent33 −→R, /0) the factor algebra G T /
∗
←→R, /0
is an (up to isomorphism) uniquely determined sig/cons-model being initial in the class of con-
structor-minimal models. In our opinion, this class captures the intuition behind constructor-
based specifications, cf. § 10. Furthermore, this unique model G T / ∗←→R, /0 can be constructed
by means of the congruence induced by our reduction relation. Thus G T / ∗←→R, /0 provides a
computational model for positive/negative-conditional specifications in a fashion very similar to
the initial model (or abstract data type) for unconditional or positive-conditional specifications.
The restriction that the terms of the negated equations have to be “defined” was introduced and
discussed in the sections 4.5 and 4.6. This restriction is also implicitly present in Definition 7.1,
where it is necessary for guaranteeing a minimal reduction relation, cf. Example 7.5. To make this
restriction explicit in our rules, in the following definition we specify a “well-behaved” subclass
of the class of CRSs.
Definition 7.15 (Def-Moderate Conditional Rule System (Def-MCRS))
A CRS R is a Def-moderate conditional rule system (Def-MCRS)34 if
∀((l,r),C)∈R. ∀(u0 6=u1) in C. ∀i≺2.
(
ui∈T (cons,VC )
∨ (Def ui) is in C
)
.
Theorem 7.16 (Minimal Model being Free in the Constructor-Minimal Models)
Let R be a Def-MCRS over sig/cons/V. Let X⊆V. Let K be the class of all constructor-minimal
models of R. Let ι be given by (x∈X): x 7→ ∗←→R,X[{x}].
Now, if −→R, /0 is confluent,35 then T (X)/ ∗←→R,X is free for K over X w.r.t. ι.
Furthermore, if we assume −→R,X to be confluent36 and X⊆VSIG , then:
(1) T (X)/ ∗←→R,X is a constructor-minimum model of R.
(2) T (X)/ ∗←→R,X is free in K over X w.r.t. ι.
(3) T (X)/ ∗←→R,X is a minimal model of R.
Corollary 7.17 Let R be a Def-MCRS over sig/cons/V. Furthermore, assume −→R, /0 to be con-
fluent. Now: G T / ∗←→R, /0 is a minimal model of R, initial in the class of all constructor-minimal
models of R, and the (up to isomorphism) unique (.H-) minimum of the sig-term-generated con-
structor-minimal models of R.
33Instead of requiring confluence, it suffices to require some semantic consistency property as in Avenhaus &
Madlener (1995), which is more elegant but not more useful.
34Note that for convenience we have slightly changed Definition 7.15 compared to that of Wirth & Gramlich
(1994a) &c.. Def-MCRSs are only interesting for reduction &c. based on −→R,X with X⊆VSIG. In this case,
however, it is not necessary to include (Def ui) into C when ui∈T (cons,VC ), because then each S UB (V,T (X))-
instance of (Def ui) will be fulfilled w.r.t. −→R,X anyway. Note that the Def-MCRS R5.12 of Example 5.12 was not a
Def-MCRS according to our old definition.
35The remark of footnote 36 with X := /0 is applicable here.
36The following allows to apply the confluence criterion of Theorem 9.1: If we additionally require
∀((l,r),C)∈R. ∀(u0=u1) in C. ∃i≺2.
(
ui∈T (cons,VC )
∨ (Def ui) is in C
)
, then we can weaken the confluence requirement
to confluence of −→R,X ∩ (DX×DX) for DX := { u∈T (sig,X) | ∃uˆ∈G T (cons). u
∗
←→R,X uˆ }.
46
Finally in this section, we present the second fundamental theorem for our approach, which states
that our reduction relation is monotonic w.r.t. consistent extension of the specification. Consistent
extensions play an important role for incremental refinement and modular construction of speci-
fications. For inductive theorem proving it is of major37 importance not to lose the already shown
theorems when extending the specification in a consistent manner. The following theorem can be
used to establish monotonicity of inductive validity (of first-order clauses) defined to be validity
in T (VSIG)/
∗
←→R,VSIG , cf. § 10.
Theorem 7.18
(Monotonicity of −→R,X w.r.t. Consistent Extension of the Specification)
Let R be a CRS over sig/cons/V. Let X⊆V. Let R′ be another CRS, but over sig′/cons′/V′; and
X′⊆V′ with sig′ = (F′,S′,α′)
cons′ = (C ′,S′,α′|C ′)
V′|{SIG,C }×S = V
F ⊆ F′
C ⊆ C ′ ⊆ F′
S ⊆ S′
α ⊆ α′
R ⊆ R′
X ⊆ X′
Thus, sig′/cons′/V′ is an enrichment of sig/cons/V in the most general38 sense we can think of.
Moreover, assume39: ∀((l,r),C) ∈ R′ \R. l 6∈ T (cons,VSIG⊎VC ) (:$)
Now we have:
1. ∀s∈T (cons,X). ∀t.
(
(s
∗
−→R,Xt) ⇔ (s
∗
−→R′,X′ t )
)
“no change on old constructor terms”
2. −→R,X ⊆ −→R′,X′ “monotonicity”
3. ∀β ω+ω. −→R,X,β ⊆ −→R′,X′,β “monotonicity”
When proving theorems dealing with signature enrichments, one usually has to be very careful
because a notation like ‘−→R,X’ does not indicate whether −→R,X is defined on sig/cons/V or
sig′/cons′/V′, which may be important under several aspects. For instance, it is important for
Theorem 7.18 that −→R,X tests “u 6=v” in a condition of an equation by
“ ∃uˆ, vˆ∈G T (cons). u
∗
−→R,X uˆ ∤↓R,X vˆ
∗
←−R,Xv ”
instead of
“ ∃uˆ, vˆ∈G T (cons′). u
∗
−→R,X uˆ ∤↓R,X vˆ
∗
←−R,Xv ”,
whereas this is not relevant for −→R′,X′ . With this exception, however, for the validity of the
theorem it does not matter whether −→R,X is defined on T (sig,X) or T (sig′,X′).
37Contrary to deductive first-order theorem proving, inductive theorem proving often is only successful when one
tries to show stronger theorems than one initially intended to show. This is because induction hypotheses are not only
a task but also a tool for the inductive argumentation. Sometimes the required stronger theorems are not expressible
with first-order clauses unless we extend the specification in a consistent manner.
38One may even introduce new constructor symbols for the old sorts and take them from the old non-constructor
symbols. Since all Vς,s are infinite, the restriction on V′ is not severe.
39This has to be required for keeping the negative conditions fulfilled: Having founded our inequalities on old
constructor ground terms, all we have to take care of now is not to confuse these terms.
47
8 Compatible Rule Systems
Compatibility restrictions on rule systems w.r.t. wellfounded orderings (saying, in essence, that
the left-hand side must be bigger than the condition terms and the right-hand side of the rule)
enhance our means of deciding reducibility and confluence.
While this section is not essential for the rest of the thesis, it is necessary for a deeper under-
standing of reduction with conditional rules.
To motivate the necessity of such restrictions w.r.t. wellfounded orderings for certain rule
systems we discuss the problem of decidability of reducibility in this section. The problem of
confluence is too difficult for a motivating discussion and will be discussed later.
8.1 Undecidability of Reducibility
The following lemma is similar to Theorem 3.3 of Kaplan (1984).
Lemma 8.1 (Reducibility of Ground Terms is Not Co-Semi-Decidable)
There is a left-linear, extra-variable free, merely positive conditional rule system R (without crit-
ical pairs and) with terminating and confluent reduction relation −→R,V for which reducibility of
ground terms is not co-semi-decidable40.
Lemma 8.2 (Reducibility of Ground Terms is Not Semi-Decidable)
There is a left-linear, extra-variable free, Def-moderate CRS R (without critical pairs and) with
terminating and confluent reduction relation −→R,V for which reducibility of ground terms is not
semi-decidable.
40i.e. the set of irreducible ground terms is not enumerable.
48
The following theorem generalizes Theorem 3.4 of Kaplan (1984) to negative conditions and
non-confluent and non-terminating reduction relations. We say that a −→R,X-normal form for
each term from T (sig,X) is computable if there is a computable (partial) function f that maps
each term to one of its normal forms and is undefined if it does not have any normal form, i.e.
∀s∈dom( f ). s ∗−→R,X f (s) 6∈dom(−→R,X) and dom( f ) = { s∈T (sig,X) | ∃t. (s ∗−→R,Xt 6∈dom(−→R,X)) }.
Theorem 8.3
Let R be a CRS over sig/cons/V. Let X be an enumerable subset of V.
1. −→R,X-reducibility of terms from T (sig,X) is co-semi-decidable41 if a −→R,X-normal form
for each term from T (sig,X) is computable.
2. A −→R,X-normal form for each term from T (sig,X) is computable if −→R,X-reducibility of
terms from T (sig,X) is co-semi-decidable and
∀s∈G T (cons). ∃t. s
∗
−→R,Xt 6∈dom(−→R,X).
Corollary 8.4
Let R be a CRS over sig/cons/V. Let X be an enumerable subset of V. Assume −→R,X to be
terminating. Now, co-semi-decidability of −→R,X-reducibility of terms from T (sig,X) is logically
equivalent to computability of a −→R,X-normal form for each term from T (sig,X).
8.2 How To Use Orderings
In this section we want to develop minimal reasonable compatibility requirements for achieving
additional properties for our reduction relation. We start with a discussion on how to use orderings
for reduction with conditional rules. This discussion mainly depends on the method of testing
the conditions uniformly by the same reduction relation again, where wellfounded orderings are
needed for guaranteeing termination of condition-testing and reduction. Since this method does
not depend on the concrete form of our rules, the situation under discussion does not differ from
the case of merely positive conditional equations.
As we test our conditions by reduction we must be allowed to switch from reduction to
condition-testing, and then to reduction of the condition terms, and so on. Hence we want our
compatibility requirement to imply that (at least) (−→R,X ∪։R,X) is terminating, where s։R,Xt if
s∈T (sig,X) and
∃((l,r),C)∈R. ∃σ∈S UB (V,T (X)). ∃p∈POS (s).
 s/p= lσ∧ ∃u∈T ERM S (C). t =uσ
∧ Cσ is fulfilled w.r.t. −→R,X
.
41i.e. the set of −→R,X-irreducible terms from T (sig,X) is enumerable.
49
We are now going to find out how to formulate a compatibility requirement on a CRS R in such
a way that it is guaranteed to be satisfiable for appropriate wellfounded orderings iff (−→R,X ∪
։R,X) is terminating. By Lemma 7.14 and the following lemma, the latter condition is logically
equivalent to (−→R,V ∪ (DST ◦։R,V)) being terminating.
Lemma 8.5
If (−→R,X ∪։R,X) is terminating, then (−→R,V ∪ (DST ◦։R,V)) is terminating, too.
For the sake of practical applicability, we replace ‘−→R,V’ and ‘։R,V’ with some less restricted
abstract relations ‘⇉’ and ‘→֒’: By Lemma 7.14 and the corollaries 7.8 and 7.9, the termination
of (−→R,V ∪ (DST ◦։R,V)) is logically equivalent to the existence of two relations ‘⇉’ and ‘→֒’
satisfying the following:
−→R,X ⊆ ⇉; ։R,X ⊆ →֒ ; ⇉ is sort-invariant, T -monotonic, and V-stable;
→֒ is V-stable; and (⇉ ∪ (DST◦ →֒)) is terminating.
Corollary 8.7 and Lemma 8.8 below show that the last requirement implies that even (⇉∪ST∪ →֒
) is terminating.
Lemma 8.6
Let T ⊆ T . Let DST[T] denote the set of subterms of T. Let ⇉ be a sort-invariant
(This can always be achieved by identifying all sorts.) and T-monotonic relation on T . Now:
1. id|DST [T] ◦⇉ = id|DST [T] ◦⇉ ◦ id|DST [T] ;
id|T ◦⇉ = id|T ◦⇉ ◦ id|T .
2. id|T ◦ ST ◦⇉ ⊆ id|T ◦⇉ ◦ id|T ◦ ST.
Moreover, for T=T : ST◦⇉ ⊆ ⇉ ◦ST .
3. id|DST [T] ◦ (⇉ ∪ST)
+ ⊆ EST ◦ id|T ◦ (⇉ ∪ST)
+ ;
id|DST [T] ◦ (⇉ ∪ST)
+ =
(
(id|DST [T] ◦ ⇉) ∪ (id|DST [T] ◦ ST)
)+
◦ id|DST [T] ;
id|T ◦ (⇉ ∪ST)
+ =
(
id|T ◦ ST
)
∪
(
( id|T ◦⇉ )+ ◦ id|T ◦ DST
)
.
Moreover, for T=T : (⇉ ∪ST)+ = ST ∪ (⇉+ ◦DST) .
4. If ⇉ is terminating (below all t ∈ T) [and ⇉ and T are X-stable], then
id|DST [T] ◦ (⇉ ∪ST)
+ is a wellfounded [and X-stable] ordering on DST[T] (which does
not need to be sort-invariant or T-monotonic, even not for T=T ).
5. (4) does not hold in general if one of the two conditions “⇉ sort-invariant” or
“⇉ T-monotonic” is removed, even not for T=T . Moreover, (4) does not hold in general
for (⇉ ∪ST)+ instead of id|DST [T] ◦ (⇉ ∪ST)
+.
50
Corollary 8.7
Let ⇉ be a sort-invariant (This can always be achieved by identifying all sorts.) and T -mono-
tonic relation on T . Now ST◦⇉ ⊆ ⇉ ◦ST and, if ⇉ is terminating [and V-stable], then
(⇉ ∪ST) is terminating [and V-stable].
Lemma 8.8
Assume (⇉ ∪ (DST◦ →֒)) to be terminating (cf. requirement above Lemma 8.6). Assume that
ST◦⇉ ⊆⇉ ◦ST and that (⇉ ∪ST) is terminating (cf. Corollary 8.7). [Assume⇉ and →֒
to be V-stable.] Now:
 := (⇉ ∪ →֒ ∪ST)
+ is a wellfounded [and V-stable] ordering.
Finally, writing ‘>’ for ‘⇉+’, this motivates the following definition:
Definition 8.9 (Termination-Pair)
A termination-pair over sig/V is a pair (>,) of binary relations on T with:
1. > is a T -monotonic and V-stable42 ordering43.
2.  is a V-stable42 and wellfounded ordering.
3. > ⊆
4. ST ⊆ 44
Example 8.10 The standard examples for a termination-pair (>,) are:
(1) > some sort-invariant reduction ordering;  := ST ∪ (> ◦DST), cf. Lemma 8.6(3).
(2)  some V-stable and wellfounded ordering containing ST; > :=
[
s∈S
{
(t ′,t ′′)
∣∣
t ′,t ′′∈T SIG,s ∧ ∀t∈T . ∀p∈POS (t).
(
t/p∈T SIG,s ⇒ t[ p← t ′ ] t[ p← t ′′ ]
) }
.45
(3) > some simplification ordering;  := >.
The notion of termination-pairs was introduced in Wirth (1991) and has proven its usefulness in
the meanwhile, both for capturing ordering requirements and for the development of concrete
orderings, cf. Geser (1994).
42V-stability is included because it can always be achieved (for ⇉ and →֒; and thereby for > and , too) by
restriction to ground terms—and the non-ground part of an ordering  whose V-stable closure is not terminating
anymore is of no use for showing termination anyway because then its /0-stable closure is not terminating, either.
43As discussed above, sort-invariance can be required here; but it is of no use for us and omitted for convenience.
For the benefit from this cf. Example 8.10(3).
44Notice that for proving compatibility (cf. below) in practice we only have to show ST ◦ ⊆  and then take
(∪ST)
+ instead of , because then we know by Corollary 8.7 (applied to the sort-invariant restriction of >) and
then by Lemma 8.8 that (∪ST)
+ will do the job of .
45While irreflexivity, transitivity, sort-invariance and T -monotonicity of > as well as >⊆ are trivial, V-stabi-
lity for t ′ > t ′′ ; t ′,t ′′∈T SIG,s w.r.t. a substitution σ∈S UB (V,T ) can be seen the following way: For arbitrary t∈T
and p∈POS (t) with t/p ∈ T SIG,s let ξ ∈ S UB (V,V) be a bijection with ξ[V (t)]∩V (t ′,t ′′) = /0 and then define
ρ := σ|V (t′,t′′)∪ξ−1|V\V (t′,t′′). Now by tξ[ p← t ′ ] tξ[ p← t ′′ ] we get t[ p← t ′σ ] = tξ[ p← t ′ ]ρ tξ[ p← t ′′ ]ρ =
t[ p← t ′′σ ].
51
The following kind of compatibility is a generalization to negative conditions and also a slight
weakening of the notion of “decreasingness” of Dershowitz &al. (1988a), cf. below.
Definition 8.11 (Compatibility with a Termination-Pair)
A CRS R over sig/cons/V is X-compatible with a termination-pair (>,) over sig/V if ∀((l,r),C)∈R.
∀τ∈S UB (V,T (X)). 
Cτ fulfilled w.r.t. −→R,X
⇒
(
∀u∈T ERM S (C). lτuτ
∧ lτ > rτ
) 
Lemma 8.12
Let R be a CRS over sig/cons/V; X⊆Y⊆V ; and (>,) a termination-pair over sig/V. Assume
that R is Y-compatible with (>,).
Now we have −→R,Y ⊆ > and −→R,Y∪։R,Y∪ST ⊆, which is terminating.
Furthermore, R is X-compatible with (>,) and V-compatible with the termination-pair
(
+
−→R,V , (−→R,V ∪։R,V ∪ST)
+ ) over sig/V.
X-compatibility of a CRS R guarantees the intended ordering property for an instantiated rule of
R when its condition is fulfilled. But, while this kind of compatibility is convenient for obtaining
further theoretical properties of the reduction relation, we have a problem when using this kind
of compatibility of R in practice of reduction: The terms in Cτ must be smaller than lτ only if
Cτ is fulfilled; but for easily deciding whether Cτ is fulfilled we need its terms to be smaller than
lτ and the analogous property for the other rules. That this need not be a vicious circle is shown
by the following definition, which allows us to test the literals in the condition from left to right.
Notice that the difference to Definition 8.11 is in the quantified variable i occurring as an index
which allows us to step inductively from (≺ i) to i.
Definition 8.13 (Left-Right-Compatibility)
A CRS R over sig/cons/V is X-left-right-compatible with a termination-pair (>,) over sig/V if
∀((l,r),L0 . . .Ln−1)∈R. ∀τ∈S UB (V,T (X)).
∀i≺n.
 (L0 . . .Li−1)τ fulfilled w.r.t. −→R,X⇒ ∀u∈T ERM S (Li). lτuτ

∧
 (L0 . . .Ln−1)τ fulfilled w.r.t. −→R,X⇒ lτ > rτ


Definition 8.14 (Don’t-Care-Compatibility)
A CRS R over sig/cons/V is X-don’t-care-compatible with a termination-pair (>,) over sig/V
if ∀((l,r),C)∈R. ∀τ∈S UB (V,T (X)).
∀u∈T ERM S (C). lτuτ
∧
 Cτ fulfilled w.r.t. −→R,X⇒ lτ > rτ


Having an X-left-right-compatible CRS, we can test the literals of the instantiated conditions
from left to right until one of them fails, knowing that all tested condition terms are smaller than
the left-hand side. Having an X-don’t-care-compatible CRS, we can even test the literals of the
instantiated conditions in parallel and don’t have to care for the position of these equations in the
condition list.
52
The X-compatibility of Definition 8.11 (which seems to be the least restrictive one tractable
in theory) is intended to be an interface for generating logically stronger kinds of compatibility
that are useful in practice (cf. definitions 8.13, 8.14), where the X-don’t-care-compatibility seems
to be the most important one. Cf. e.g. Example 16.6 for a rule system that is V-compatible but not
V-left-right-compatible. For restrictions of −→R,X , however, even weaker kinds of compatibility
than the one of Definition 8.11 may be sufficient.
Finally in this section, we will have a brief look into the literature. In Kaplan (1987) and Ka-
plan (1988) we find two different notions of compatibility that do not involve the reduction rela-
tion: There, an instantiated rule l=r←−C is called simplifying (reducing) if ∀u∈T ERM S (C).
l>u and l>r for some simplification ordering > (sort-invariant reduction ordering), cf. also
our Example 8.10(3) (Example 8.10(1)). Well-known are also the following compatibility no-
tions that involve −→R,X : In Jouannaud & Waldmann (1986) an instantiated rule l=r←−C is
called reductive if ∀u∈T ERM S (C). l>u and ( C fulfilled w.r.t. −→R,X ⇒ l>r ) for some
sort-invariant reduction ordering >. A less restrictive compatibility requirement which is concep-
tually the same as our X-don’t-care-compatibility can be found in Dershowitz &al. (1988a&b):
R is called decreasing if there exists a wellfounded ordering , containing ST , such that, for
each instantiated rule l=r←−C of R, ∀u∈T ERM S (C). lu and ∀s,t∈T . ( s−→R,Xt ⇒ st ).
While our additional > does not occur in this definition, it is useful both in theory and practice,
since the infinite requirement of st above can be reduced to l>r, but not to lr. Furthermore,
our discussion preceding Definition 8.9 reveals the interference of > and  with rules in practice
and how to establish the properties required.
While we require > to be a reduction ordering, we avoid the superfluous commonplace re-
striction along Example 8.10(1), restricting  to be
 := ST ∪ ((> ∩
S
s∈S(T SIG,s×T SIG,s))◦DST)
(which is also implicit in the notion of “reductive” above) because this may not be sufficient for
achieving compatibility of given rules as in the following example of Dershowitz &al. (1988b):
Example 8.15 ( := ST ∪ (> ◦DST) is Too Restrictive) (cf. Example 8.10(1))
R8.15: b = c
a = c ←− b=c
f(b) = f(a)
Compatibility of R8.15 requires a  b which we cannot achieve by the above construction of
 : a > b is impossible since compatibility of the third rule requires f(b) > f(a), which also
forbids a > fn+1(b), since then we get a > f(n+1)(a) > f2(n+1)(a) > · · · .
Nevertheless, R8.15 is X-don’t-care-compatible with the termination pair(
+
−→R8.15,X , ST ∪ (
+
−→R8.15,X ◦ DST)∪{ (f
n(a),b) | n∈N }
)
.
Thus, for theoretical treatment, the procedure of (2) of Example 8.10 is to be preferred to that of
(1) of Example 8.10, whereas (for practically guaranteeing compatibility of rules) (2) of Exam-
ple 8.10 lacks any hints on how to semi-decide > (even for decidable ).
All in all, there seems to be no proper reason for preferring one of >,  to the other and we
thus have introduced the notion of a termination-pair (>,).
53
8.3 Decidability for Compatible Rule Systems
Lemma 8.16
Let R be a CRS over sig/cons/V and (>,) a termination-pair over sig/V. Let X be an enumer-
able subset of V. Now, if (This condition is essential: Cf. Lemma 8.2.)
(1) R is X-left-right-compatible with (>,),
or
(2) R is X-compatible with (>,), ∩ (T (sig,X)×T (sig,X)) is semi-decidable, and
∩ (G T (cons)×G T (cons)) is decidable,
then the following statements hold:
(1) −→R,X-reducibility of terms from T (sig,X) is semi-decidable.
(2) { t | s +−→R,Xt } is (universally46) enumerable for all s ∈ T (sig,X).
(3) { t | s +−→R,Xt } is a finite computable set for all s ∈ G T (cons).47
The following lemma, however, shows that compatibility does not imply decidability of reduci-
bility as long as extra-variables are permitted.
Lemma 8.17 (Reducibility of Ground Terms Still Not Co-Semi-Decidable)
There is a left-linear, merely positive conditional rule system R (without critical pairs and) with
terminating and confluent reduction relation −→R,V , which is V-don’t-care-compatible with a
termination-pair (,) with decidable , and for which reducibility of ground terms is not co-
semi-decidable.
If we do not allow extra-variables, however, we get the following decidability result, which is
important because (in combination with Corollary 8.4) it says that normal forms become com-
putable.
Lemma 8.18
Let R be a CRS over sig/cons/V and (>,) a termination-pair over sig/V. Let X be an enumer-
able subset of V. Now, if R is extra-variable free (This condition is essential: Cf. Lemma 8.17.)
and if (This condition is essential: Cf. lemmas 8.1, 8.2.)
(1) R is X-left-right-compatible with (>,),
or
(2) R is X-compatible with (>,) and ∩ (T (sig,X)×T (sig,X)) is decidable
then the following statements hold:
(1) −→R,X-reducibility of terms from T (sig,X) is decidable.
(2) { t | s +−→R,Xt } is a finite computable set for all s ∈ T (sig,X).
(3) Confluence of −→R,X is co-semi-decidable.
46By this we want to express that there is not only for each s ∈ T (sig,X) some computable function which
enumerates { t | s +−→R,Xt } but even one single computable universal function which enumerates { t | s
+
−→R,Xt }
when its first argument (or index) is s.
47I.e. there is some computable function f such that, for each s ∈ G T (cons), f (s) is a list of exactly the elements
of { t | s +−→R,Xt }.
54
Confluence of −→R, /0 (i.e. ground confluence) cannot be semi-decidable for extra-variable free,
V-don’t-care-compatible Def-MCRSs R in general, because it is not semi-decidable even for
extra-variable free, terminating, left-linear, monadic, unconditional rule systems, cf. Kapur &al.
(1990). While confluence of −→R,V , however, is decidable for extra-variable free, terminating,
unconditional rule systems R (Note that each condition is essential here.), the following lemma
does not give us a chance in general to decide confluence of −→R,V for extra-variable free, don’t-
care-compatible Def-MCRSs R.
Lemma 8.19 (Confluence of −→R,V is Not Semi-Decidable)
There is a signature sig with sub-signature cons and a termination-pair (,) over sig/V with
decidable , such that confluence of −→R,V is not semi-decidable in general for left-linear, extra-
variable free, merely positive conditional rule systems R over sig/cons/V which are V-don’t-care-
compatible with (,).
9 Confluence Criteria
9.1 Introduction
Contrary to the specification and inductive theorem proving approaches of Boyer & Moore (1979),
Biundo &al. (1986), Walther (1994), Hutter & Sengler (1996), Zhang &al. (1988), Kapur &
Zhang (1989), Bachmair (1988), Gramlich & Lindner (1991), Bouhoula & Rusinowitch (1995),
Bachmair & Ganzinger (1991), and Ganzinger & Stuber (1992), our specification approach for
inductive validity and inductive theorem proving neither requires decreasingness (compatibility
with a termination-pair) nor termination. Since it does require confluence, however, to be able to
use it for non-decreasing or non-terminating rule systems, we need confluence criteria that do not
require decreasingness and confluence criteria that even do not require termination. Therefore,
after presenting a confluence test for decreasing systems in § 9.5, in § 9.6 we present a confluence
criterion for terminating but not necessarily decreasing systems, and finally in § 9.7, we present a
confluence criterion that does not even require termination of the rule system.
Note that, while semantic confluence criteria for conditional term rewriting systems (just like
those for unconditional ones) require termination only,48 several basic results on confluence of
unconditional term rewriting systems based on syntactic considerations do not hold for the con-
ditional case. In particular, in contrast to the unconditional case, local confluence of conditional
term rewriting systems is not equivalent to joinability of all critical pairs. In other words, this
means that variable overlaps may be “critical”, too. This may even happen under the assumption
of termination (plus left-linearity, plus normality),49 i.e. there are terminating positive conditional
rule systems whose critical pairs are all joinable but that are not (locally) confluent. This means
that joinability of critical pairs does not suffice anymore for inferring confluence of terminating
CRSs. When we do not require termination anymore, the situation is even more complicated:
There are left-linear positive conditional rule systems that do not have any critical pair but are not
confluent.50
48Cf. Theorem 9.1.
49Cf. Dershowitz &al. (1988a), Example B, p. 36.
50Cf. Dershowitz &al. (1988a), Example A, p. 36; taken from Bergstra & Klop (1986).
55
Therefore, reasonable syntactic criteria for confluence of CRSs have to require (besides join-
ability of the critical pairs)
• a strengthened termination assumption (which enables a justified inductive reasoning also
when recursing into the conditions, i.e. decreasingness, cf. Theorem 9.6)
or
• some strengthened forms of joinability of the critical pairs (like overlay joinability, e.g., cf.
Theorem 9.11) and possibly some syntactic restrictions on the rules (like left-linearity &c.,
cf. Theorem 9.15).
56
Besides the difficulty in principle to find criteria for confluence of conditional rule systems that
are not too restrictive on the class of rule systems that satisfy them, we have to mention that there
is another major problem with effectively applying these criteria in practice: This problem results
from the difficulty to capture (by effective means) the infinite number of substitutions that must
be tested for fulfilling the conditions of the critical pairs. Therefore in practice it is an important
step forward when one knows that critical pairs with complementary literals in the conditions
need not be considered.51 Reasoning on the form of the relevant substitutions may also become
easier when one knows that the substitutions or even the instantiated terms can be required to be
irreducible.52 Finally, it is a great help for finding out the substitutions fulfilling the conditions of
critical pairs when one knows that confluence below certain terms may be already assumed when
testing the joinability of a critical pair.53 Also assuming confluence properties for smaller depth
β in −→R,X,β may be helpful, but we do not discuss these properties involving a great number of
level and shallow joinability notions in this thesis because of their technical complexity and the
enormous length of a proper treatment. The readers who are really interested in this subject should
study Wirth (1995), which is a comprehensive survey and detailed formal treatment on how to
achieve confluence of constructor-based positive/negative-conditional rule systems by syntactic
means.
51as is the case for our theorems 9.6 and 9.15
52as is the case for our theorems 9.6 and 9.11
53as is the case for our theorems 9.6 and 9.11
57
9.2 The Semantic Approach
The most elegant but least effective way to achieve confluence of −→R,X is to use semantic con-
fluence criteria in the style of Plaisted (1985).
While this semantic approach is very powerful when one has sufficient knowledge about the
domain, it is, however, not at all obvious how to formalize or even automate such semantic con-
siderations. In essence, such a formalization would require that the specification given by the
whole rule system R has actually been modeled before in some other formalism.
Above that, the semantic confluence criteria are based on the existence of normal forms and
therefore require termination (at least in some weak form) or even compatibility with a termi-
nation-pair because otherwise irreducibility of ground terms need not be (semi-) decidable, cf.
Lemma 8.17.
The semantic confluence criterion below is taken from Wirth & Gramlich (1994a).
The first part of it may be especially useful for showing confluence of−→R,X,ω by instantiating
R with RC .
The second part, which is a slight variation of the first, is also interesting, because it allows
establishing confluence for a restriction of−→R,X that is sufficient for our model theoretic consid-
erations.54 Moreover it has two interesting properties: Firstly, the reduction relation is required
to be terminating on the defined terms only, i.e. infinite reduction sequences on terms which
do not return a result (i.e. are not congruent to some constructor ground term) are in principle
no obstacle for applying the criterion. Secondly, the evaluation homomorphism Aκ::T (X)→A
may identify some syntactically different, irreducible non-constructor terms such that some non-
congruent “undefined” terms of T (X) may be given the same “undefined” value in A .
Theorem 9.1 (Semantic Confluence Criterion)
Let R be a CRS over sig/cons/V and X⊆V.
Let A be a sig/cons-model of R and κ an A -valuation of X. Now:
1. If ∀s∈S. ∀uˆ, vˆ ∈ T (sig,X)s\dom(−→R,X).
(
Aκ(uˆ)=Aκ(vˆ) ⇒ uˆ= vˆ
)
and −→R,X is terminating, then −→R,X is confluent.
2. If ∀s∈S. ∀uˆ, vˆ ∈ T (sig,X)s\dom(−→R,X).
( (
Aκ(uˆ)=Aκ(vˆ)
∧ vˆ∈G T (cons)
)
⇒ uˆ= vˆ
)
and
−→R,X ∩ (DX×DX) is terminating for
DX := { u∈T (sig,X) | ∃uˆ∈G T (cons). u
∗
←→R,X uˆ },
then −→R,X ∩ (DX×DX) is confluent.
54Cf. footnote 36 of Theorem 7.16, footnote 70 of Lemma 10.9, footnote 73 of Lemma 10.14, and footnote 77 of
Theorem 10.15.
58
9.3 The Syntactic Approach: Critical Peaks
Critical peaks describe those possible sources of non-confluence that directly arise from the syn-
tax of the given rule system. While the so-called variable overlaps can hardly be approached via
syntactic means, the critical peaks describe the non-variable overlaps resulting from an instan-
tiated left-hand side being subterm of an instantiated left-hand side at a non-variable position.
Our critical peaks capture more information than the standard critical pairs: Besides the pair,
they contain the peak term and its overlap position. Furthermore, each element of the pair is
augmented with the condition that must be fulfilled for enabling the reduction step down from
the peak term, and with a 0 or 1 indicating whether the rule applied was a non-constructor rule or
not.
Definition 9.2 (Critical Peak)
If the left-hand side of a rule l0=r0←−C0 and
the subterm at non-variable position p ∈ FPOS (l1)
of the left-hand side of a rule l1=r1←−C1
(assuming V (l0=r0←−C0)∩V (l1=r1←−C1) = /0 w.l.o.g.55) are unifiable by
σ = mgu( {(l0, l1/p)}, V (l0=r0←−C0, l1=r1←−C1)),
if (for i≺2) Λi =
{
0 if li ∈ T (cons,VSIG⊎VC )
1 otherwise
}
,
and if the resulting critical pair is non-trivial (i.e. l1[ p← r0 ]σ 6= r1σ), then(
(l1[ p← r0 ], C0, Λ0), (r1, C1, Λ1), l1, σ, p
)
is a (non-trivial) critical peak (of the form (Λ0,Λ1)) consisting of the conditional critical pair, its
peak term l1, the most general unifier σ, and the overlap position p.
For convenience we usually identify this critical peak with its instantiated version(
(l1[ p← r0 ]σ, C0σ, Λ0), (r1σ, C1σ, Λ1), l1σ, p
)
which should not lead to confusion because the tuple is shorter.
The set of all critical peaks of a CRS R is denoted by CP(R).
Example 9.3 (continuing Example 4.1)
CP(R4.1) contains two critical peaks, namely (in the instantiated version)(
(true, (X=Y ), 1), (mbp(X ,L), (X 6=Y ), 1), mbp(X ,cons(Y ,L)), /0
)
and(
(mbp(X ,L), (X 6=Y ), 1), (true, (X=Y ), 1), mbp(X ,cons(Y ,L)), /0
)
which we would (partially) display as
mbp(X ,cons(Y ,L)) > mbp(X ,L) mbp(X ,cons(Y ,L)) > true
true
∨
..., /0
mbp(X ,L)
∨
..., /0
Note that we omit the position at the arrow to the right because it is always /0. Furthermore,
note that the two critical peaks are different although they look similar. Namely, the one is the
symmetric overlay (cf. below) of the other.
55To achieve this, let ξ ∈ S UB (V,V) be a bijection with ξ[V (l0=r0←−C0)]∩V (l1=r1←−C1) = /0 and then
replace l0=r0←−C0 with (l0=r0←−C0)ξ.
59
9.4 Basic Forms of Joinability of Critical Peaks
A critical peak
((t0,C0,Λ0), (t1,C1,Λ1), tˆ, σ, p)
is joinable w.r.t. R,X (for X⊆V) if ∀ϕ∈S UB (V,T (X)).(
((C0C1)σϕ fulfilled w.r.t. −→R,X) ⇒ t0σϕ↓R,Xt1σϕ
)
.
It is an overlay if p= /0. It is a non-overlay if p 6= /0.
It is overlay joinable w.r.t. R,X if it is joinable w.r.t. R,X and is an overlay.
In the following two definitions ‘true’ and ‘false’ denote two arbitrary irreducible ground terms.
Their special names have only been chosen to make clear the intuition behind.
The above critical peak is complementary w.r.t. R,X if
∃u,v∈T . ∃i≺2.
(
(u=v) or (v=u) occurs in Ciσ
∧ (u 6=v) occurs in C1−iσ
)
∨ ∃p∈T . ∃true, false∈G T \dom(−→R,X). ∃i≺2. (p=true) or (true=p) occurs in Ciσ∧ (p=false) or (false=p) occurs in C1−iσ
∧ true 6= false

.
It is weakly complementary w.r.t. R,X if
∃u,v∈T .
(
(u=v) or (v=u) occurs in (C0C1)σ
∧ (u 6=v) occurs in (C0C1)σ
)
∨ ∃p∈T . ∃true, false∈G T \dom(−→R,X). (p=true) or (true=p) occurs in (C0C1)σ∧ (p=false) or (false=p) occurs in (C0C1)σ
∧ true 6= false

.
It is strongly joinable w.r.t. R,X if ∀ϕ∈S UB (V,T (X)).(
((C0C1)σϕ fulfilled w.r.t. −→R,X) ⇒ t0σϕR,Xt1σϕ
)
.
In the following definition ‘A’ is an arbitrary function from positions to sets of terms.
The above critical peak is -weakly joinable w.r.t. R,X [besides A] if ∀ϕ∈S UB (V,T (X)).

(C0C1)σϕ fulfilled w.r.t. −→R,X
∧ ∀u.
(
u tˆσϕ ⇒ −→R,X is confluent below u
)
∧ ∀x∈V. xϕ 6∈dom(−→R,X)
∧
(
p 6= /0 ⇒ ∀x∈V (tˆ). xσϕ 6∈dom(−→R,X)
)[
∧ tˆσϕ 6∈A(p)
]
⇒ t0σϕ↓R,Xt1σϕ
.
Note that -weak joinability adds several useful features to the single condition of joinability,
forming a conjunctive condition list. The first new feature allows assuming confluence below all
terms that are strictly smaller than the peak term. The following features allow assuming some
irreducibilities for the joinability test, where the optional one is an interface that is to be specified
by the confluence criteria using it, cf. Theorem 9.6. For a demonstration of the usefulness of these
additional features cf. Example 9.7.
Lemma 9.4 (Joinability of Critical Peaks is Necessary for Confluence)
If −→R,X is confluent, then all critical peaks in CP(R) are joinable w.r.t. R,X.
60
9.5 Compatible Rule Systems
For compatible rule systems it is possible to show that conditions of critical peaks are not fulfilled
for any substitution by the simple syntactic criterion of weak complementarity:
Lemma 9.5
Let R be a CRS over sig/cons/V and X⊆V.
Assume that R is X-compatible with a termination-pair (>,) over sig/V.
Now, if a critical peak from CP(R) is weakly complementary,
then it is -weakly joinable w.r.t. R,X.56
Due to its fundamental importance, we repeat Theorem 73 of Wirth (1995) below, which gen-
eralizes Theorem 3 of Dershowitz &al. (1988a) by weakening decreasingness to compatibility
with a termination-pair (defined in § 8.2) as well as joinability to -weak joinability (defined in
§ 9.4) which provides us with some confluence and irreducibility assumptions when checking the
fulfilledness of the condition of a critical peak.
Note that in confluence criteria like the one below whose proof is by induction on an extension
of the reduction relation the joinability requirement can be weakened to a sub-connectedness
requirement, cf. Küchlin (1985). We here, however, present the simpler versions only, where the
connectedness is required to have the form of a single “valley”.
Theorem 9.6 (Syntactic Test for Confluence)
Let R be a CRS over sig/cons/V and X⊆V.
Assume that R is X-compatible with a termination-pair (>,) over sig/V.
[For each t ∈ T (sig,X) assume≪t to be a wellfounded ordering on POS (t). Define (p∈N+∗)
A(p) := { t∈dom(−→R,X,ω+ω,q) | /0 6=q≪t p }. ]
The following two are logically equivalent:
1. Each critical peak in CP(R) is -weakly joinable w.r.t. R,X [besides A].
2. −→R,X is confluent.
Due to a weakening of the notion of -weak joinability, Theorem 9.6 differs from Theorem 7.17
of Wirth & Gramlich (1994a) in that it provides several irreducibility assumptions intended to
restrict the number of substitutions ϕ for which for a critical peak(
(l1[ p← r0 ],C0, . . .), (r1,C1, . . .), l1, σ, p
)
resulting from two rules l0=r0←−C0 and l1=r1←−C1 (with no variables in common) we have to
show l1[ p← r0 ]σϕ↓R,Xr1σϕ in case of (C0C1)σϕ being fulfilled. This means that Theorem 9.6
provides means to tackle the problem of describing the infinite number of substitutions for that
joinability must be shown, cf. the discussion in § 9.1.
The first assumption allowed is that the substitution ϕ itself is normalized: ∀x∈V. xϕ 6∈dom(−→R,X).
56Note that it is not necessarily joinable w.r.t. R,X.
61
The second assumption allows us to assume that for non-overlays (i.e. for p 6= /0) even σϕ is
normalized on all variables occurring in the left-hand side l1.
Moreover, by weakening “-weak joinability” to “-weak joinability besides A” with A de-
fined as in the theorem via some family≫ = (≫t)t∈T (sig,X) of arbitrary wellfounded orderings
≫t on POS (t), we have added a new feature which allows us to assume that the instantiated
peak term (or superposition term) l1σϕ is irreducible at all nonempty positions which are≪l1σϕ-
smaller than the overlap position p. Generally, beyond our first two assumptions, we may use≪
to further reduce the number of instantiations for which the joinability test must succeed in the
following way: If we can choose≪l1σϕ such that
p= /0 ⇒ ∀x∈V (l1).
 xσ 6=x ⇒
∃q∈POS (l1).
(
l1/q=x
∧ ∀q′∈POS (xσϕ). qq′≪l1σϕ p
) 
as well as ∀x∈V (l0).
 xσ 6=x ⇒
∃q∈POS (l0).
(
l0/q=x
∧ ∀q′∈POS (xσϕ). pqq′≪l1σϕ p
) ,
then we may assume σϕ to be normalized: ∀x∈V. xσϕ 6∈dom(−→R,X). This can be a consid-
erable help for showing that (C0C1)σϕ is not fulfilled when we have a certain knowledge on the
normal forms of the terms of the sorts of the variables occurring in C0C1. E.g., when we define the
depth of a term t ∈ T by depth(t) := max{ |p′| | p′∈POS (t) } and then define (p,q∈POS (t))
q≪t p if depth(t)− |q| ≺ depth(t)− |p| , then we can forget about all critical peaks which
are called “composite” in § 2.3 of Kapur &al. (1988)—and even some more, namely all those
whose peak term is reducible at some position that is longer than the overlap position of the
critical peak. Kapur &al. (1988) already states in Corollary 5 that (unless l0∈V, which some
authors generally disallow) the irreducibility of these positions implies the irreducibility of all
terms introduced by the unifying substitution σ; more precisely, the joinability test may assume:
∀x∈V.
(
xσ 6=x ⇒ xσϕ 6∈dom(−→R,X)
)
, which, by our first irreducibility assumption can be
simplified to ∀x∈V. xσϕ 6∈dom(−→R,X). If we, however, revert ≪ by defining q≪t p if
|q| ≺ |p| , then we can forget about all critical peaks which are called “composite” in § 4.1 of
Kapur &al. (1988)—and even some more, namely all those whose peak term is reducible at some
nonempty position that is shorter than the overlap position of the critical peak.
The power of the combination of the two weakenings of the joinability requirement, i.e. the
confluence and the irreducibility assumptions, is demonstrated by the following simple but non-
trivial example whose predicate ‘nonnegp’ checks whether an integer number is non-negative:
Example 9.7 C := {0,s,p, true, false}
N := {nonnegp}
R9.7 : s(p(y)) = y
p(s(y)) = y
nonnegp(0) = true
nonnegp(s(x)) = true ←− nonnegp(x) = true
nonnegp(p(0)) = false
nonnegp(p(x)) = false ←− nonnegp(x) = false
62
Let 0, s, p be constructor symbols of the sort int and true, false constructor symbols of the sort
bool. Let nonnegp be a non-constructor predicate with arity “ int→ bool ”. Let x, y be constructor
variables of the sort int.
Obviously, R9.7,V is V-compatible with the termination-pair (,) where  is the lexico-
graphic path ordering generated by nonnegp being bigger than true and false.
There are only the following two critical peaks which are both of the form (0,1):
nonnegp(s(x))σ > true nonnegp(p(x))σ′ > false
nonnegp(y)
∨
1,1
nonnegp(y)
∨
1,1
where σ := {x 7→ p(y)} and σ′ := {x 7→ s(y)}. Their respective condition lists are the following
two lists containing each one literal only:
nonnegp(x)σ= true nonnegp(x)σ′= false
Now the following is easy to show: The irreducible constructor terms of the sort int are exactly
the terms of the form sn(z) or pn+1(z) with n∈N and z∈VC ,int∪{0}. The irreducible constructor
terms of the sort bool are VC ,bool∪{true, false}. Furthermore, by induction on n∈N one easily
shows nonnegp(sn(0)) ∗−→R9.7, /0true and nonnegp(p
n+1(0))
∗
−→R9.7, /0false. Finally, by induction
on n∈N one easily shows that nonnegp(t) ∗−→R9.7,V,ω+ntrue ∨ nonnegp(t)
∗
−→R9.7,V,ω+nfalse im-
plies V (t)= /0, which we only need to show confluence besides ground confluence.
Define ≪ via (p,q∈POS (t)): q≪t p if depth(t)− |q| ≺ depth(t)− |p| . Now the
new combined weakening of joinability to -weak joinability w.r.t. R9.7,V besides A (with A de-
fined as in the theorem) allows showing joinability of the above critical peaks very easily. Since
the second critical peak can be treated analogously to the first, we only explain how to treat
the first one: By the new additional feature for assuming irreducibility, our weakened joinabil-
ity allows us to assume that xσϕ is irreducible for the first critical peak, which can be seen
in two different ways: First, since the critical peak is a non-overlay and x occurs in the peak
term nonnegp(s(x)). Second, since the overlap position is 1, nonnegp(s(x))/1 1 = x and
∀q′∈POS (xσϕ). 1 1 q′≪nonnegp(s(x))σϕ 1. Furthermore, we are allowed to assume that the
condition of the critical peak is fulfilled, i.e. that nonnegp(x)σϕ ∗−→R9.7,Vtrue. Together with
the irreducibility of xσϕ=p(y)ϕ this implies that yϕ is of the form pn(0). This again implies
nonnegp(x)σϕ ∗−→R9.7,Vfalse. But since we may assume confluence below the condition term
nonnegp(x)σϕ we get true↓R9.7,Vfalse, which is impossible. Thus, the properties that weak join-
ability allows us to assume for the joinability test are inconsistent and the critical pair need not be
joined at all.
All in all, Theorem 9.6 implies confluence of−→R9.7,V without solving the task of showing that
for each arbitrary (not necessarily normalized) substitution ϕ either nonnegp(p(y))ϕ ∗−→R9.7,Vtrue
does not hold or nonnegp(y)ϕ ∗−→R9.7,Vtrue holds, which is more difficult to show than our simple
properties above.
63
9.6 Terminating Rule Systems
According to Theorem 4 of Dershowitz &al. (1988a), a terminating positive conditional rule
system is confluent if it is overlay joinable. In Wirth & Gramlich (1994a) we have weakened
overlay joinability to quasi overlay joinability. In Wirth (1995), however, we reported that this
notion turned out to be never applicable when the left-hand side of the first rule generating a
non-overlay was simultaneously unifiable with another non-variable subterm of the left-hand side
of the second rule. Moreover, in Wirth (1995) we have removed this problem by developing the
weaker notion of -quasi overlay joinability and proved that it implies confluence in case of ter-
mination. In Gramlich & Wirth (1996) we have presented a simplified version of this result using
the notion of “shared parallel critical peaks”. Since here we are more interested in a powerful
practical criterion than in a beautiful presentation of the relevant ideas, in this section we repeat
the relevant parts of Wirth (1995). While we use some of the more readable notation of Gram-
lich & Wirth (1996), to allow an easy comparison with our other criteria we do not introduce the
notion of “shared parallel critical peaks”.
Definition 9.8 (-Quasi Overlay Joinability)
For a relation < we define (s,u,v∈T (sig,X)) u−→R,X,<sv if
∃p∈POS (u).
(
u−→R,X,ω+ω,pv
∧ u/p < s
)
.
A critical peak ((t0,C0,Λ0), (t1,C1,Λ1), tˆ, σ, p) is -quasi overlay joinable w.r.t. R,X if for
< := (←−R,X∪)
+, s := tˆ/p, s′ := t0/p :
∀ϕ∈S UB (V,T (X)). ∀∆.

(C0C1)σϕ fulfilled w.r.t. −→R,X
∧ ∆={ p′∈FPOS (tˆ)\{p} | (tˆ/p′)σϕ=sσϕ }
∧ ∀w < sσϕ. −→R,X is confluent below w
∧ ∀wSTsσϕ. w 6∈dom(−→R,X)

⇒ t0[ p′← s′ | p′∈∆ ]σϕ ∗−→R,X ◦
∗
←−R,X,<sσϕt1σϕ
.
For ϕ∈ S UB (V,T (X)) and ∆⊆FPOS (tˆ)\{p}with (C0C1)σϕ fulfilled w.r.t.−→R,X and ∀p′∈∆.
(tˆ/p′)σϕ=sσϕ the critical peak, the further reduction of its left part, and the required joinability
after this reduction can be depicted as follows:
tˆ[ p′← s | p′∈{p}∪∆ ]σϕ ======================= tˆσϕ > t1σϕ
tˆ[ p← s′ ][ p′← s | p′∈∆ ]σϕ
∨
ω+ω, p
===================== t0σϕ
tˆ[ p′← s′ | p′∈{p}∪∆ ]σϕ
==
∨
ω+ω,∆
=============== t0[ p′← s′ | p′∈∆ ]σϕ
∗
> ◦
∗
∨
<sσϕ
Lemma 9.9 ( Overlay Joinable ⇒ -Quasi Overlay Joinable )
W.r.t. R,X the following holds for each critical peak:
If it is overlay joinable, then it is -quasi overlay joinable.
64
The proof of the following lemma and its far more restrictive predecessors has an interesting
history. After its first occurrence in Dershowitz &al. (1988a) for overlay joinable positive con-
ditional systems, in our proof for quasi overlay joinable positive/negative-conditional systems in
Wirth & Gramlich (1994a) we changed the third component of the induction ordering from +−→R,X
to ≻, the ordering of the ordinals. This change was made because it allowed us to check for gen-
eralizations more easily but did not result in a stronger criterion at first. Later, however, this
change of the induction ordering turned out to be essential for Theorem 21 of Gramlich (1995)
saying that an innermost terminating overlay joinable positive conditional rule system is termi-
nating and confluent: Due to the mutual dependency of the termination and the confluence proof,
when proving confluence it was not possible to assume global termination but local termination
only. And it was especially impossible to assume termination for that part of −→R,X which was
necessary for the third component of the induction ordering. The following lemma (just like The-
orem 7 of Gramlich (1995)) requires local termination instead of global termination, which is not
really necessary for proving Theorem 9.11 but again allows us to check for future generalizations
more easily. Moreover, note that the form of the proof which is taken over from Wirth (1995) has
been considerably improved compared to any publication previous to Wirth (1995): Claim 0 of
the proof does not only provide us with the new irreducibility assumptions we have included into
the notion of -quasi overlay joinability but also subsumes the whole second case of the global
case distinction of the proof (as presented in Dershowitz (1987), Wirth & Gramlich (1994a), and
Gramlich (1995)). As a consequence, in the whole new proof now the second and the third com-
ponent of the induction ordering are used only once, and the whole proof is surprisingly short (in
comparison with the proofs of the other theorems in § 9).
Lemma 9.10 (Syntactic Confluence Criterion)
Let R be a CRS over sig/cons/V and X⊆V. Let sˆ ∈ T (sig,X). Define T := ∗−→R,X[{sˆ}].
Assume either that −→R,X |T is terminating and  = ST
or that −→R,X |D[T] ⊆ , ST ⊆ , and  is a wellfounded ordering on T .
Now, if all critical peaks in CP(R) are -quasi overlay joinable w.r.t. R,X,
then −→R,X|D[T] is confluent.
Theorem 9.11 (Syntactic Confluence Criterion)
Let R be a CRS over sig/cons/V and X⊆V.
Assume either that −→R,X is terminating57 and =ST or that −→R,X ⊆, ST ⊆, and 
is a wellfounded ordering on T .
Now, if all critical peaks in CP(R) are -quasi overlay joinable w.r.t. R,X,
then −→R,X is confluent.
57Actually innermost termination is enough here when we require overlay joinability instead of -quasi overlay
joinability, cf. Gramlich (1995).
65
Example 9.12
Let X⊆V. The following system is neither decreasing, nor left-linear, nor overlay joinable; but it
is terminating and ST-quasi overlay joinable w.r.t. R9.12,X. Thus Theorem 9.11 is the only one
that implies confluence of −→R9.12,X .
58
Even though it is irrelevant for Theorem 9.11, let X ,Y ∈ VSIG; 0,s,a, true, false ∈ C ; and
less,p, f,g ∈ N. Note that 0,s,a, less model the ordinal number ω+1 via 0, s(0), . . . . . . s∗(a).
R9.12:
(s1) s(a) = a
(less1) less(s(X),s(Y )) = less(X ,Y )
(less2) less(X ,X) = false
(less3) less(0,s(Y )) = true
(less4) less(X ,0) = false
(less5) less(0,a) = true
(less6) less(a, s(Y )) = less(a,Y )
(less7) less(s(X),a) = less(X ,a)
(p1) p(X) = true ←− p(s(X))=true
(p2) p(X) = true ←− less(f(X),g(X))=true
(fi) f(X) = . . .
(gi) g(X) = . . .
The critical peaks are the following:
From (s1) into (less1) we get the following two non-overlays of the form (0,1) and their shared
parallel critical peak:
less(s(a), s(Y ))
ω+1
> less(a,Y )
less(a, s(Y ))
∨
1,1
ω+1, /0
> less(a,Y )
wwwww
less(s(X),s(a))
ω+1
> less(X ,a)
less(s(X),a)
∨
1,2
ω+1, /0
> less(X ,a)
wwwww
less(s(a),s(a))
ω+1
> less(a,a)
less(a,a)
==
∨
1,{1,2}
=============== less(a,a)
wwwww
58Note that Theorem 75 of Wirth (1995) becomes applicable when we replace the non-constructor variable in (p1)
with a constructor variable. Moreover, if we additionally do the same with (p2), then Theorem 77 of Wirth (1995)
becomes applicable, too.
66
From (s1) into (less3) we get the following non-overlay of the form (0,1):
less(0,s(a))
ω+1
> true
less(0,a)
∨
1,2
ω+1, /0
> true
wwwwww
The critical peaks resulting from (s1) into (less6) and (less7) are trivial.
From (less1) into (less2) and from (less2) into (less1) we get the following symmetric overlays of
the from (1,1):
less(s(X),s(X))
ω+1
> false
less(X ,X)
∨
ω+1, /0
ω+1, /0
> false
wwwwww
less(s(X),s(X))
ω+1
> less(X ,X)
false
∨
ω+1, /0
=================== false
∨
ω+1, /0
The critical peaks resulting from (less2) into (less4), (less4) into (less2), (p1) into (p2), and (p2)
into (p1) are trivial.
67
9.7 Complementary Critical Peaks
In this section we present a confluence criterion that does not rely on termination. It is, of course,
also applicable to terminating systems, which might be very attractive if one does not know
how to show termination or if the correctness of the technique for proving termination requires
confluence.
Our positive/negative-conditional rule systems including a syntactic separation between construc-
tor and non-constructor symbols offer more expressive power than the standard positive condi-
tional rule systems and therefore allow us to model more applications naturally in such a way
that their confluence is given by the confluence criteria presented in Wirth (1995). Using the
separation into constructor and non-constructor rules (generated by the syntactic separation into
constructor and non-constructor function symbols) it is possible to divide the problem of showing
confluence of the whole rule system into three smaller sub-problems: Firstly we show confluence
of the constructor rules, secondly commutation of the constructor rules with the non-constructor
rules, and finally, under these assumptions, we show confluence of the whole reduction relation.
The important advantage of this modularization is not only the division into smaller problems,
but is due to the possibility to tackle the sub-problems with different confluence criteria. E.g.,
when confluence of the constructor rules is not trivial then their confluence often can only be
shown by sophisticated semantical considerations or by criteria that are applicable to terminating
systems only. For the whole rule system, however, neither semantic confluence criteria nor con-
fluence criteria requiring termination of the reduction relation are practically feasible in general.
This is because, on the one hand, an effective application of semantic confluence criteria requires
that the specification given by the whole rule system has actually been modeled before in some
formalism. On the other hand, termination of the whole rule system may not be given or difficult
to be shown without some confluence assumptions.59 Fortunately, without requiring termination
of the whole rule system the syntactic confluence criterion we present in this section guarantees
confluence of the non-constructor rules of a class of rule systems that is sufficient for practical
specification. This class of rule systems generalizes the function specification style used in the
framework of classic inductive theorem proving60 by allowing partial functions resulting from
incomplete specification as well as from non-termination. Together with the notions of induc-
tive validity presented in § 10 this extends the area of semantically clearly understood inductive
specification considerably.
59When termination (decreasingness) is assumed, there are approaches to prove confluence, cf. Becker (1993b),
Becker (1994), and Becker (1996).
60Cf. Walther (1994). Note that we can even keep the notation style similar to this function specification style, cf.
Wirth & Lunde (1994).
68
Since the criterion we present in this section assumes −→R,X,ω to be confluent and then suggests
how to find out that the whole system−→R,X =−→R,X,ω+ω is confluent too, we first have to discuss
how to find out that −→R,X,ω is confluent.
Denoting the constructor sub-system (i.e. the sub-system of the constructor rules) of R with
RC (cf. Definition 5.11), −→R,X,ω is nothing but −→RC ,X,ω = −→RC ,X .
The easiest way to achieve confluence of −→R,X,ω is to have no constructor rules at all, i.e.
RC = /0. While it is rather restrictive, this case of free constructors is very important in practice
since a lot of data structures can be specified this way. Moreover, it is economic to restrict to this
case because non-free constructors make a lot of trouble when working with the specification,
e.g., most techniques for proving inductive validity get into tremendous trouble with non-free
constructors — if they are able to handle them at all.
The second case where confluence of −→R,X,ω is immediate is when for each rule l=r←−C in
RC also r=l←−C is an instance of a rule of R, and then also of RC due to the restriction on the
constructor rule l=r←−C given by Definition 5.11. An example for this is the commutativity rule
c(x,y) = c(y,x) which is equal to a renamed version of the reverse of itself. In this case it may
be worthwhile to consider reduction modulo a constructor congruence as described in Avenhaus
& Becker (1992) and Avenhaus & Becker (1994).
A third way to achieve confluence of −→RC ,X is to use one of our confluence criteria of the
theorems 9.1, 9.6, or 9.11 with R replaced with RC . Note that the application of each of these
confluence criteria requires termination of −→RC ,X . Termination of the constructor sub-system,
however, of course does not mean termination of the whole rule system. We may, e.g., apply
Theorem 9.6 to infer confluence of a terminating constructor sub-system containing the asso-
ciativity rule c(c(x,y),z) = c(x,c(y,z)) (whose confluence can hardly be inferred syntactically
without termination) and then infer the confluence of the whole non-terminating rule system by
Theorem 9.15 below. This case where a terminating constructor sub-system is part of a non-
terminating rule system seems to be important in practice since confluence of non-free construc-
tors often can hardly be inferred without termination whereas termination is usually not needed
for then inferring confluence of the whole system because the non-constructor rules can be chosen
in such a way that their critical peaks are complementary. Moreover note that the reverse case,
i.e. that of a non-terminating constructor sub-system of a terminating rule system, is impossible
in our framework but not in the abovementioned one of Avenhaus & Becker (1992) and Avenhaus
& Becker (1994) where the notion of reduction is different, namely reduction via R\RC modulo
RC .
More syntactic criteria for confluence of −→R,X,ω can be found in § 15 of Wirth (1995).
Sometimes, however, confluence of−→R,X,ω can only be shown using the semantic knowledge
of the specifier, either via Theorem 9.1 or even in some tailored way.
Before we state our theorem it is convenient to introduce some further syntactic restriction. By
disallowing non-constructor variables in conditions of constructor equations we disentangle the
fulfilledness of conditions of constructor equations from the influence of non-constructor rules.
69
Definition 9.13 (Conservative Constructors)
R is said to have conservative constructors if
∀((l,r),C)∈RC . V (C)⊆ VC .
Let us consider a rule system with conservative constructors. Together with our global restric-
tions on constructor rules (cf. Definition 5.11) this means that the condition terms of constructor
rules are pure constructor terms. This has the advantage that (contrary to the general case) the
condition terms of constructor rules still are constructor terms after they have been instantiated
with some substitution. By Lemma 7.10 this means that the reducibility with constructor rules is
captured in −→R,X,ω and does not depend on the new possibilities which could be added by the
non-constructor rules for β ≻ ω in −→R,X,β , i.e. that the constructor rules are conservative w.r.t.
their decision not to reduce a given term because non-constructor rules cannot generate additional
solutions for their conditions.61
The condition of conservative constructors is very natural and not very restrictive. (Note that
even now constructor rules may have general variables in their left- and right-hand sides.) That
conservative constructors make the construction of confluence criteria much easier can be seen
from the following lemma which can treat a special case of possible divergence, namely a sub-
case of the “variable overlap case”. In this case it is important that a reduction with a certain rule
can still be done after the instantiating substitution has been reduced.
Lemma 9.14
Let µ,ν ∈ S UB (V,T (X)). Let ((l,r),C) ∈ RC .
Assume that
 R has conservative constructors∨ V (C)⊆VC
∨ T ERM S (Cµ)⊆T (cons,VSIG⊎VC )

.
Assume −→R,X,ω to be confluent.
Now, if Cµ is fulfilled w.r.t. −→R,X and ∀x∈V. xµ ∗−→R,Xxν,
then Cν is fulfilled w.r.t. −→R,X,ω and lν−→R,X,ωrν.
While the criterion for confluence without termination that we present in Theorem 9.15 below
is not the strongest one known,62 it suffices to extend the class of specifications usually allowed
for inductive theorem proving because it removes the termination requirement, and it is in our
opinion the strongest one not requiring termination that can be effectively used in practice. The
extended class consists of left-linear rule systems with conservative constructors that achieve a
weakened form of normality63 just by requiring the presence of a Def-literal for all those equa-
tions in the condition of a rule that do not contain an irreducible ground term, and satisfy the
joinability requirements due to the critical peaks being complementary, i.e. having complemen-
tary literals in their condition lists, cf. § 9.4. Note that rule systems of this class are quite useful in
61Since “conservative constructors” is actually a property not of the constructors (i.e. constructor function sym-
bols) but of the constructor rules, the notion should actually be called “conservative constructor rules”. But the
commonplace notion of “free constructors” is just the same.
62Cf. theorems 68 and 71 of Wirth (1995). Theorem 68 is the version for ω-shallow confluence, Theorem 71 for
ω-level confluence. We omit them here because the theorems, their proofs, and the notions involved are very deep
and sophisticated and would distract from the main topic of this thesis.
63Called quasi-normality in Wirth (1995).
70
practice. E.g., the rule system of Example 5.12 belongs to this class. They generalize the function
specification style that is usually required in the framework of classic inductive theorem proving
(cf. e.g. Walther (1994)) by allowing partial functions resulting from non-complete defining case
distinctions as well as resulting from non-termination.
Theorem 9.15 (Syntactic Confluence Criterion)
Let X⊆V and R be a left-linear CRS over sig/cons/V.
Assume that −→R,X,ω is confluent. Furthermore, assume that the critical peaks of the form (0,1)
or (1,0) (i.e. the ones between constructor and non-constructor rules) are complementary. Now:
(I) In case of ∀((l,r),C)∈R. V (C)⊆VC ,
if each critical peak in CP(R) of the form (1,1) (i.e. between non-constructor rules)
is weakly complementary, then −→R,X is confluent.
(II) Assume that R has conservative constructors and X⊆VSIG.
Finally, assume the following weak kind of normality
∀((l,r),C)∈R. ∀(u0=u1) in C. ∃i≺2.
 ui∈T (cons,VC )∨ (Def ui) occurs in C
∨ ui ∈ G T \dom(−→R,X)
.
Now, if each critical peak in CP(R) of the form (1,1)
is complementary, then −→R,X is confluent.
Note that both parts of the theorem are applicable to the rule system of Example 5.12 — even
though it is terminating. To illustrate the possibility of partiality due to non-termination as well as
the possibility of critical peaks with complementary predicate literals, here is another toy example
to which we can apply part II of Theorem 9.15 (but not part I).
Example 9.16 (continuing Example 5.12)
R9.16: R5.12
.
.
.
while(B,Y )=Y ←− B=false
while(B,Y )=while(. . ., . . .) ←− B=true, . . .
.
.
.
We have added two rules to the system from Example 5.12 for a function ‘while’ with arity
“ bool nat → nat ” where B is meant to be a variable from VSIG,bool and Y from VSIG,nat. The two
resulting critical peaks are symmetric overlays of the form (1,1) and complementary. Further-
more, we assume that there are no rules with true, false, or a variable of the sort bool as left-hand
sides, such that we have true, false ∈ G T \dom(−→R9.16,X).
71
10 Notions of Inductive Validity
10.1 Motivation
Given a set of first-order axioms ‘R’, one is often not only interested in propositions ‘Γ’ that are
deductive theorems of R, i.e. that hold in all models of R: “ R |= Γ ”; but also in those propositions
that only hold in some specific sub-class of the class of models of R. Besides restricting the class
of models with some required property, one may also consider those Γ where only “ R |= Γτ ”
is required for all τ taken from a specific set of (e.g. ground) substitutions. Notions of validity
resulting from combinations of restrictions of these two kinds are usually called inductive, and
the inductively valid propositions are named inductive theorems. In general, the set of inductive
theorems is a proper superset of the set of deductive theorems because inductive theorems can rely
on additional properties induced by the given notion of inductive validity. Typical such properties
are term-generatedness (“no junk”) and initiality or freeness (“no confusion”).64 Inductive theo-
rems are called “inductive” because their (finite) proofs usually require mathematical induction
to utilize term-generatedness.
Concerning the adequacy of a notion of inductive validity we think that there are at least three
important criteria.
Monotonicity behavior: Whenever we extend a specification in some consistent manner then
previously valid formulas should still be (inductively) valid w.r.t. the extended specification.
Coincidence with intuition: Notions of inductive validity should capture the intention of the
human specifier as closely as possible.
Operational feasibility: Notions of inductive validity should be operationally feasible in the
sense that there are operational characterizations or at least sufficient operational means
which provide a reasonable basis for corresponding theorem proving techniques.
For specifications with unconditional (or positive conditional) equations it is well-known how to
obtain initial semantics and (in principle) how to prove inductive theorems when these theorems
are taken to be the equations that are valid in the initial model, cf. e.g. Bachmair (1988), Bevers
& Lewi (1990).
64Note that, in general, term-generatedness (just like wellfoundedness) is not first-order axiomatizable, cf. Ender-
ton (1973), Gödel (1931). And even under the assumption of term-generatedness, in general, initiality is not finitely
first-order axiomatizable, cf. Berghammer (1993).
72
Consider for instance the following specification R over the natural numbers where addi-
tion ‘+’ is defined in terms of zero ‘0’ and successor ‘s’.
X +0 = X
X +s(Y ) = s(X +Y )
Here it is easy to show by standard techniques (cf. e.g. Boyer & Moore (1979), Bachmair (1988))
that
0+Y =Y
is an inductive theorem when inductive validity is taken to be validity in the initial model or
validity in all term-generated models of R. If we now enrich the above signature with a subtraction
operation ‘−’ and define
X−0 = X
s(X)−s(Y ) = X−Y
yielding a new specification R′, then, unfortunately, 0+Y =Y is no longer inductively valid
in the enriched specification (to wit, substitute 0−s(0) for Y ). Hence, neither validity in the
initial model nor validity in all term-generated models enjoys the above-mentioned monotonicity
property w.r.t. consistent extension. The intuitive reason for that phenomenon is that by enriching
our basic specification R as described above we have introduced new junk terms (like 0−s(0))
which should not be considered for verification purposes. Similarly, the “Tertium Non Datur” on
truth values (cf. Example 5.15) should not be destroyed by a partially specified predicate. This
intention is formally reflected in our approach by distinguishing between constructor and general
variables which permits to refine the class of (ground) instances of a theorem that are required to
be valid for considering the theorem to be inductively valid.
Another crucial problem with initial semantics has to do with the way in that negative state-
ments are interpreted. For instance, the negative equation
0−s(0) 6=0
holds in the initial model of R′. But if we now complete the partial definition of subtraction in
some consistent manner, e.g., by defining
0−s(Y ) = 0
yielding the new specification R′′, then 0−s(0) 6=0 does not hold anymore in the initial model of
R′′. Of course, also validity of conditional statements or general first-order clauses is influenced
by this phenomenon. One may argue now that in R′ we are not yet sure whether 0−s(0) 6=0 is
inductively valid because it depends on the way we might (consistently) complete the definition
of ‘−’ later on in the specification process. Note that this problem is similar to that of negative
conditions in the defining rules and can be solved with similar argumentation and by similar
means, namely by requiring definedness of the terms of negative literals.65
65Cf. the justification of item (A) in § 4 and Theorem 10.15(E).
73
Thus, the existence of partially defined function symbols as well as the occurrence of nega-
tive literals in formulas to be proved opens up — or even necessarily entails — various ways of
defining inductive validity, in particular if we want to guarantee some reasonable monotonicity
property w.r.t. consistent extension. Pioneering papers along this line of reasoning are Kapur &
Musser (1987 & 1986), Zhang (1988), and Zhang &al. (1988). But whereas in these papers the
specifications treated are systems of unconditional equations, and the formulas considered are
pure equations, here we shall permit general equational first-order clauses as formulas and, more-
over, as specifications we admit positive/negative-conditional equational systems which naturally
arise in many cases.66
10.2 The Seven Cases
As exhibited in Wirth &al. (1993), Wirth & Gramlich (1994b) and stated in Wirth & Becker
(1995) and § 10.1, it is appropriate to call a formula ‘Γ’ “inductively valid” if for all “constructor
ground substitutions” ‘τ’ and all algebras ‘A ’ belonging to some special model class ‘K’, the
instantiated formula Γτ is valid in A .
Different possible choices for the model class K result in the following seven cases.
Definition 10.1 (A-/ B-/ B′-/ C-/ D′-/ D-/ E-case)
The following cases are said to hold for sig/cons/R if their associated requirements hold:
A-case: K is the class of all sig/cons-models of R.
B-case: K is the class of all constructor-minimal models of R.
B′-case: K is the class of all C :cons-term-generated sig/cons-models of R.
C-case: K is the class of all C :cons-term-generated, constructor-minimal models of R.
D′-case: K is the class of all SIG:cons-term-generated, constructor-minimal models of R.
D-case: X := VSIG, I := T (X)/
∗
←→R,X, K := {I }, ιI is given by x 7→
∗
←→R,X[{x}] (x∈X).
E-case: X := /0, and the rest is like in the D-case, i.e., I := G T / ∗←→R, /0, K := {I }, ιI := /0.
66Cf. e.g. Example 5.12
74
10.3 The Seven Notions of Inductive Validity
The most cautious way to extend deductive validity to inductive validity is to incorporate term-
generatedness by saying that a formula is inductively valid if all its ground instances are deduc-
tively valid. In our constructor-based framework this should be refined by requiring all construc-
tor ground instances of a formula to be deductively valid where “constructor ground instance”
means instance w.r.t. a constructor ground substitution. Constructor ground substitutions replace
constructor variables with constructor ground terms and leave the general variables invariant:
Definition 10.2 (Constructor Ground Substitutions)
We define the set of constructor ground substitutions67 by:
CGSUB(V,cons) := { τ ∈ S UB (V,T ) | τ[VC ]⊆ G T (cons) ∧ τ|VSIG = id|VSIG }
Replacing a formula with all its constructor ground instances disallows the constructor variables
of the formula to range over objects of the constructor sub-universe which are not denoted by
constructor ground terms (with sort invariant). While we restrict the constructor variables in the
formula by substituting them with constructor ground terms, we do not instantiate their general
variables with (general) ground terms. This is because we do not want the general variables to
range over the junk generated by ground terms only, but possibly over additional junk, e.g. of
non-constructor symbols which might be introduced later on. Indeed, allowing this additional
junk is necessary for the monotonicity of our logic w.r.t. consistent extension, cf. Theorem 10.15.
The following definition is from Wirth &al. (1993) and Wirth & Gramlich (1994b):
Definition 10.3 (Type-A/ -B Inductive Validity)
Let Γ be a formula not containing ‘<’-literals, i.e. Γ ∈ (L I T (sig,V))∗.
Now, for T ∈ {A,B}, if the T -case holds for sig/cons/R, then Γ is (type-T inductively) valid
(w.r.t. sig/cons/R) if
∀A ∈K. ∀τ∈CGSUB(V,cons).
(
Γτ is valid in A
)
The following theorem was used in Wirth & Gramlich (1994b) to define the other types of induc-
tive validity. We present the theorem on inductive validity before the definition because it is more
intuitive, whereas the definition is more general.
Theorem 10.4 (Type-B′/ -C/ -D′/ -D/ -E Inductive Validity)
Let Γ be a formula not containing ‘<’-literals, i.e. Γ ∈ (L I T (sig,V))∗.
Now, for T ∈ {B′,C,D′,D,E}, if the T -case holds for sig/cons/R, then Γ is (type-T inductively)
valid (w.r.t. sig/cons/R) iff
∀A ∈K.
(
Γ is valid in A
)
As usual, our notions of inductive validity also apply to a set of formulas F if they apply to each
formula in F .
67In Wirth &al. (1993) and Wirth & Gramlich (1994b) the constructor ground substitutions CGSUB(V,cons)
were called “inductive substitutions” instead. Since S UB (V,T (VSIG)) (or, more generally, S UB (V,T (VSIGA )), cf.
§ 10.4) has turned out to be more important than CGSUB(V,cons) and has no special name, we did not want to give
CGSUB(V,cons) such a distinguishing name anymore.
75
Type-A formulates the idea that constructor variables are meant to denote objects denoted by
constructor ground terms. However, contrary to all other types, type-A does not restrict the models
of the specification that have to be considered, but considers only instances of formulas obtained
by constructor ground substitutions.
Type-B forbids unnecessary confusion in the constructor sub-universes, i.e. the domains of
interest.
Type-B′ forbids junk in the constructor sub-universes, by restricting each model A to be
C :cons-term-generated, i.e. ∀s∈S. A C ,s =A [G T (cons)s]. Note that this restriction makes the
application of constructor ground substitutions redundant.
Type-C combines both restrictions, which is appealing if one wants to prescribe a precise and
fixed knowledge on the basic objects for computation.
Type-D′ corresponds to the philosophy that a partially defined function is to be interpreted as
the set of all possible complete and consistent extensions.
Type-D and -E finally fix one specific unique minimal model which has neither junk nor
confusion in the constructor sub-universe and which can be described constructively in terms of
the factor algebra of the term algebra modulo the congruence induced by the reduction relation.68
Type-E uses the ground term algebra G T , which is only adequate when no general variables
occur in the formula.69 Therefore, the superior type-D uses the term algebra T (VSIG) over VSIG.
In a sense, type-D means inductive semantics for VC and free semantics for VSIG.
The basic characteristics of and the relations between these notions of inductive validity are
illustrated in the figure below where an arrow indicates that validity of the one type implies
validity of the other type, cf. Lemma 10.9. Missing arrows indicate non-implications as shown in
the examples 10.10, 10.11, 10.12, and 10.13 below.
) q
q )
)
?
q
no confusion & no junk
no confusion & and no junk for C ,
for C
no confusion for SIG, and A =G T / ∗←→R, /0
no junk for SIG, and
A SIG,s =A [G T (cons)s]
no confusion & no junk for C ,
A
B′B
C
D D′
E
no confusion
for C
no junk for C ,
no confusion &
A =T (VSIG)/
∗
←→R,VSIG
no confusion for SIG, and
no junk
for C
68provided the latter is confluent
69Cf. Theorem 10.15 and Example 10.13.
76
10.4 The Operational View on the Notions: Counterexamples
Note that the types A and B show the following “misbehavior”: Let x be an implicitly universally
quantified constructor variable and t be a non-constructor term of the same sort. According to our
intuition behind the concept of “constructor variables”, validity of the formula Γ should imply
validity of the formula
(Def t), Γ{x 7→t}
where t is substituted for x in Γ under the assumption that t is defined. This is the case with
deductive validity as well as inductive validity of the types B′, C, D′, D, and E . It is not the case
with inductive validity of types A and B, however, because they admit junk in the constructor
sub-universes, cf. Example 10.11. The misbehavior of these two types is not only intuitional
but also makes a reasonable treatment of generalized substitutions (cf. § 13.2) with our inference
rules impossible.
Therefore, by considering C :cons-term-generated sig/cons-algebras only, we exclude the types
A and B in our following discussion, which leads to the definition of inductive validity from Wirth
& Kühler (1995).
The following technical trick enables us to simplify our notions and to shorten our proofs.
Some algebras we will have to deal with are factor algebras of term algebras but others are
not. Let ∼ be some sig/cons-congruence on T (X) and define B := T (X)/∼. When we de-
fine ι ∈ S UB (X,B ) by ((ς,s)∈{SIG,C }×S; x∈Xς,s) xι :=∼s[{x}], then (since B ι::T (X)→B
is surjective and by the Axiom of Choice) each B -valuation from S UB (V,B ) can be written in
the form τB ι for some τ ∈ S UB (V,T (X)). Some of our inference rules for factor algebras of
term algebras depend on this τ. For general algebras, however, such a τ cannot exist in general.
Instead of having one set of notions for term algebras and another set for general algebras, and
instead of making a case distinction on this again and again, we prefer to assume all algebras to be
factor algebras of term algebras by the following trick: For each sig/cons-algebra A we assume
some A -valuation ιA ∈ S UB (X,A ) such that A ιA ::T (X)→A is surjective. In the case of A
being the factor algebra of a term algebra like B above, we assume this ιA to be just the ι from
above. When, for some s∈ S, the cardinality of XSIG,s is too small for the existence of a surjective
mapping of T (X)SIG,s on A SIG,s then we assume that XSIG,s is extended by new variables until
its cardinality is big enough. We could obtain A ιA [T (X)C ,s]=A C ,s by a similar extension of
XC ,s, but this is not necessary because we consider only C :cons-term-generated algebras, due to
which we even can require that X contains general variables only. To indicate this extension and
reduction of X, we write VSIGA instead of X. In the case of A being a factor algebra of the term
algebra T (X) with X⊆VSIG we require VSIGA =X. Now, due to A ιA ::T (VSIGA )→A being
surjective, A ιA [T (VSIGA )C ,s]=A [G T C ,s]=A C ,s, and due to the Homomorphism-Theorem(5.9)
and Lemma 5.6, A is sig/cons-isomorphic to T (VSIGA )/ker(A ιA ). Thus w.l.o.g. we may as-
sume that each sig/cons-algebra A is a factor algebra T (X)/∼ of a term algebra T (X) with
X⊆VSIG and that each A -valuation from S UB (V,A ) can be written in the form τA ιA for some
τ ∈ S UB (V,T (X)).
77
Definition 10.5 (Type-B′/ -C/ -D′/ -D/ -E Inductive Validity)
Let T ∈ {B′,C,D′,D,E}. Assume the T -case to hold for sig/cons/R.
A formula Γ is (type-T inductively) valid (w.r.t. sig/cons/R) if
∀A ∈K. ∀τ∈S UB (V,T (VSIGA )).
(
Γτ is true w.r.t. A ιA
)
Note that while this definition is rather technical, it is more general than Theorem 10.4 because it
includes formulas with ‘<’-literals, and it is also more feasible for operationalization because it
provides us with more syntactic information on the instantiation of the variables of Γ.
Using the definitions 6.1 and 10.1, we can restate the definition of type-D and -E validity without
using the notions of truth and algebras:
Corollary 10.6 (Type-D/ -E Inductive Validity)
Let Γ ∈ Form(sig,V). Let T ∈ {D,E}. Assume the T -case to hold w.r.t. sig/cons/R.
Now, Γ is (type-T inductively) valid (w.r.t. sig/cons/R) iff
∀τ∈S UB (V,T (X)).
∃(u=v) in Γτ. u ∗←→R,Xv
∨ ∃(u 6=v) in Γτ. u 6∗←→R,Xv
∨ ∃(Def u) in Γτ. ∃s∈S.
(
u∈T SIG,s
∧ ∃uˆ∈G T C ,s. u
∗
←→R,X uˆ
)
∨ ∃(Def u) in Γτ. ∃s∈S.
(
u∈T SIG,s
∧ ∀uˆ∈G T C ,s. u 6
∗
←→R,X uˆ
)
∨ ∃(ℵ<i) in Γτ. ℵ<I i
∨ ∃(ℵ<i) in Γτ. ℵ≮I i

Now that we are so close to operationalization we should complete the definition of our opera-
tional notions with the definition of the notion of counterexamples — even if we do not really
need them until § 13 and they will not be properly motivated before § 12:
Definition 10.7 (Counterexample)
The set of syntactic constructs (which form the basic data structure on which our inference system
will operate) is defined as SynCons := Form(sig,V)×Weight(V). A weight ‘ℵ’ in a syntactic
construct ‘(Γ,ℵ)’ is intended to describe some measure controlling the inductive application of
‘Γ’.
‘Info’, the class of extra information intended to exhibit the reason why a formula
(of a syntactic construct) is invalid, is defined to be the class of pairs (τ,A ) with
τ∈S UB (V,T (VSIGA )) and A ∈K. Note that in the D- or E-case, for (τ,A )∈ Info this
requires τ∈S UB (V,T (X)).
((Γ,ℵ),(τ,A )) ∈ SynCons×Info is a (type-T ) counterexample (w.r.t. sig/cons/R) if
Γτ is false w.r.t. A ιA .
78
Since this concrete notion of counterexamples does not depend on the weight ℵ, in the above
situation we sometimes simply speak of the “counterexample (Γ,τ,A ) (for the formula Γ)”.
The essential meaning of counterexamples is simply the following:
Corollary 10.8
Let T ∈ {B′,C,D′,D,E}. Assume the T -case to hold for sig/cons/R.
Now, w.r.t. type-T and sig/cons/R the following holds for any formula Γ ∈ Form(sig,V):
Γ is (inductively) valid iff Γ has no counterexample, i.e. there is no (τ,A ) ∈ Info such that
(Γ,τ,A ) is a counterexample.
79
10.5 The Interrelation of the Notions
Lemma 10.9 (From Type-A down to Type-E)
Let R be a CRS over sig/cons/V. Let Γ ∈ Form(sig,V).
Now w.r.t. sig/cons/R (and Γ) the following holds:
(a) If Γ does not contain ‘<’-literals, then
type-A validity of Γ implies type-B′ validity of Γ, and
type-B validity of Γ implies type-C validity of Γ.
(b) If Γ does not contain ‘<’-literals, then
type-A validity of Γ implies type-B validity of Γ.
Type-B′ validity implies type-C validity.
(c) Type-C validity of Γ implies type-D′ validity of Γ
and even of Γ′ when Γ′ results from Γ by deleting some Def-literals.
(d) If R is Def-moderate and −→R,VSIG is confluent,70 then
type-C validity implies type-D validity.
(e) If Γ does not contain ‘<’-literals, then
type-D validity of Γ implies type-E validity of Γ.
(f) If R is Def-moderate and −→R, /0 is confluent, then
type-C validity implies type-E validity.
(g) If R is Def-moderate, −→R, /0 is confluent, and
∗
−→R, /0 is sufficiently complete,71 then
type-D′ validity implies type-E validity.
70The following allows applying the confluence criterion of Theorem 9.1: If we additionally require
∀((l,r),C)∈R. ∀(u0=u1) in C. ∃i≺2.
(
ui∈T (cons,VC )
∨ (Def ui) is in C
)
,
then we can weaken the confluence requirement to confluence of −→R,VSIG ∩ (DVSIG×DVSIG ) for
DVSIG := { u∈T (sig,VSIG) | ∃uˆ∈G T (cons). u
∗
←→R,VSIG uˆ }.
71Note that this condition (which is defined in § 5.3) is rather restrictive and thus we have not included this impli-
cation into the above figure.
80
Let us return to the specification on natural numbers from § 10.1 to show that the implications of
Lemma 10.9, which are illustrated in the above figure, are all strict.
Example 10.10 (Type-B 6=Type-A and Type-C 6=Type-B′)
Let us start with F10.10 := C10.10 := {0,s} and R10.10 := /0. Then
0 6=s(0) is type-B valid but not type-A valid,
since 0 and s(0) are interpreted as distinct objects in any constructor-minimal model of R10.10,
but 0 6=s(0) does not hold for instance in the trivial model of R10.10, which identifies everything.
Furthermore, for the same reason,
0 6=s(0) is type-C valid but not type-B′ valid.
Example 10.11 (Type-C 6=Type-B and Type-B′ 6=Type-A)
Keeping C10.11 := {0,s}, let us add two non-constructor function symbols ‘+’ and ‘ω’, yielding
F10.11 := {+, ω}⊎C10.11, with the rules
R10.11: X +0 = X
X +s(Y ) = s(X +Y )
where it does not matter whether X ,Y are from VSIG,nat or VC ,nat.
Now, while, for a constructor variable x, it is obvious that 0+x=x is inductively valid (for
all our types),
Def ω, 0+ω=ω is type-C valid but not type-B valid,
since, if (Def ω) is valid in some C :cons-term-generated sig/cons-model, then ω can be denoted
by some constructor ground term si(0), but for type-B validity we also have to consider (construc-
tor-minimal) models containing constructor objects that are not denoted by any term of the form
si(0), e.g. G T ′/ ∗←→R10.11, /0 where G T
′ differs from G T only in the constructor sub-universes
given as G T ′C ,s := G T SIG,s. 72
Furthermore, for the same reason,
Def ω, 0+ω=ω is type-B′ valid but not type-A valid.
72Note that G T ′/ ∗←→R10.11, /0 is constructor-minimal indeed, due to
G T ′/
∗
←→R10.11, /0.C G T /
∗
←→R10.11, /0 ,
which again can be seen by the cons-homomorphism
c::G T ′|C10.11⊎({C }×S)→(G T /
∗
←→R10.11, /0)|C10.11⊎({C }×S)
given by cnat(ω) := cnat(0) and the Homomorphism-Theorem.
81
Example 10.12 (Type-D 6=Type-C 6=Type-D′)
Again keeping C10.12 := {0,s}, let us add a non-constructor symbol ‘−’, yielding
F10.12 := {−}⊎C10.12, with the rules
R10.12: X−0 = X
s(X)−s(Y ) = X−Y
where it does not matter whether X ,Y are from VSIG,nat or VC ,nat. Then
0−s(0) 6=0 is type-D valid but neither type-D′ nor -C valid
because 0−s(0) 6∗←→R10.12,VSIG 0 , but 0−s(0) 6=0 does not hold in the SIG:cons-term-generated
constructor-minimal model obtained by identifying 0−s(Y ) with 0.
Furthermore, while, for a constructor variable x, it is obvious that x−x=0 is inductively
valid (for all our types),
(0−s(0))−(0−s(0))=0 is type-D′ valid but neither type-E , -D, nor -C valid
because a SIG:cons-term-generated model must satisfy 0−s(0)=si(0) for some i, but
(0−s(0))−(0−s(0)) 6
∗
←→R10.12, /0
0 , i.e. (0−s(0))−(0−s(0))=0 does not hold in the C :cons-
term-generated, constructor-minimal model G T / ∗←→R10.12, /0 .
Example 10.13 (Type-E 6=Type-D)
Finally, keeping C10.13 := {0,s} and choosing F10.13 := {+}⊎C10.13 and R10.13 := R10.11,
for Z ∈ VSIG,nat
0+Z =Z is type-E valid but not type-D valid
since ∀t∈G T (sig). 0+t ∗←→R10.13, /0 t but not 0+Z
∗
←→R10.13,VSIG Z .
Similarly
Def Z is type-E valid but not type-D valid.
Note that 0+Z =Z as well as Def Z are not type-E valid anymore after the consistent extension
via F10.13 := F10.11. The resulting non-monotonicity of validity makes obvious that type-E does
not treat general variables adequately.
82
While the examples have shown that the reverse of each implication depicted in the figure above
does not hold in general, the following lemma gives sufficient conditions:
Lemma 10.14 (From Type-E up to Type-A)
Let R be a CRS over sig/cons/V.
Let Γ be a formula not containing ‘<’-literals, i.e. Γ ∈ (L I T (sig,V))∗.
Now w.r.t. sig/cons/R the following holds:
(a) If Γ does not contain variables from VSIG, then
type-E validity of Γ implies type-D validity of Γ.
(b) If R is Def-moderate, −→R, /0 is confluent,73 and
if, for all negative literals λ in Γ and all terms u ∈ T ERM S (λ),
the formula (Def u) is type-D valid, then
type-D validity of Γ implies type-C validity of Γ.
(c) If, for each negative Def-literal (Def u) occurring in Γ,
the formula (Def u) is type-C valid,74 then
type-C validity of Γ implies type-B validity of Γ.
If, for each negative Def-literal (Def u) occurring in Γ,
the formula (Def u) is type-B′ valid,74 then
type-B′ validity of Γ implies type-A validity of Γ.
(d) If no rule in R has a negative condition (like (u 6=v)),75 and
if Γ does not contain negative literals, then
type-C validity of Γ implies type-A validity of Γ.
Note that (by Lemma 10.9) Lemma 10.14 also permits to conclude from type-C to B′ (via A),
from type-B to A (via C), and from type-D′ to C (via E , D).76
73Footnote 70 is applicable here if we replace −→R,VSIG with −→R, /0 as well as DVSIG with D /0 := { u∈G T (sig) |
∃uˆ∈G T (cons). u
∗
←→R, /0 uˆ }.
74Even if this condition is not satisfied, the following equivalence transformation for type-B′, C, D′, D, and E
validity (but not for A and B) may help to apply the Lemma: Γ(Def u)∆ is equivalent to Γ(x 6=u)∆ for a fresh (i.e.
not occurring in Γ∆, u) constructor variable x.
75Note that this condition is really necessary: The formula mbp(0,cons(s(0),nil))= false is type-C (and -B)
inductively valid w.r.t. the specification of Example 5.12 where the rule (mbp3) has a negative condition. The
formula, however, is neither type-A nor type-B′ inductively valid, cf. the model given by the congruence ‘∼’ of
Example 4.6 with a replaced with 0 and b replaced with s(0), which is not constructor-minimal because it identifies
0 and s(0).
76For the latter step cf. also Lemma 10.16.
83
10.6 Monotonicity w.r.t. Consistent Extension
In this section we are going to show that — under some reasonable assumptions — all our seven
notions of inductive validity are monotonic w.r.t. consistent extension.
Note that compared to the monotonicity theorem 7.18, when enriching our signature sig/cons/V
to a new signature sig′/cons′/V′ in the following monotonicity theorem 10.15, we have to disallow
the introduction of new constructor function symbols for already existing sorts. Otherwise we
would get new constructor ground terms for old sorts and new constructor ground instances of
old formulas, which clearly destroys their inductive validity for all our types. E.g., the theorem
0+x=x of Example 10.11 loses its inductive validity (of any of our types) when we add a new
constructor constant symbol ‘1’ for the sort nat. This, however, is the only additional requirement
of Theorem 10.15 on the enrichment of the signature compared to Theorem 7.18. Therefore the
enrichment of Theorem 10.15 is still a very unrestrictive one: We may add all non-constructor
function symbols we would like to, and also new sorts with new constructor function symbols.
Moreover, for those types of inductive validity requiring the models to be constructor-minimal
(i.e. all our types but A and B′), the addition of new defining equations to R must be restricted in
two ways:
First, we are not allowed to add a rule that is a constructor rule in the sense of the old system,
i.e. that has an old constructor term as its left-hand side. This has to be required for keeping the
negative conditions of the (old) instantiated rules being fulfilled: Having founded our inequalities
on old constructor ground terms, we have to take care of not confusing these terms now.
Second, we have to require the resulting rule system to be ground confluent to guarantee that
non-congruent old constructor terms are not connected “above” by new rules for non-constructor
function symbols. Consider, e.g., the following single rule Def-MCRS:
weirdp = false ←− true 6=false
where true and false are constructor constant symbols and weirdp and ambigp are non-constructor
constant symbols. Then the formulas
true 6= false
and
weirdp= false
are inductively valid for all our types but A and B′. When adding the rules
ambigp = false
ambigp = true
yielding a new rule rule system whose ground reduction relation is not confluent, however, the
formula true 6= false loses validity of the types B, C, D′, D, and E , and the formula weirdp=
false loses validity of the types B, C, and D′.
84
Furthermore, when completing a partial definition for a non-constructor function symbol, it may
happen that type-D or -E inductive validity of negative literals gets lost. E.g., w.r.t. the specifica-
tion of Example 10.12 the type-D and -E validity of the formulas
0−s(0) 6=0
and
Def (0−s(0))
gets lost when adding the rule
0−s(Y ) = 0
We can avoid this non-monotonic behavior simply by requiring all terms of negative literals to be
defined, which was already required for type-D validity to imply type-C validity in Lemma 10.14(b).
As type-D and -E differ from the other types just in that their theorems can rely on the partiality
of function definitions due to the minimality of the their models (“no confusion for SIG”), this
partly non-monotonic behavior is not a flaw but simply natural, and those who dislike it should
choose another type (say C) of inductive validity as their favorite, cf. the discussion in § 10.9.
Finally, it should be obvious that it is not reasonable to expect monotonicity of validity for for-
mulas containing ‘<’-literals: The enrichment of the signature forces us to enlarge an algebra to
treat the new symbols, thereby getting a new algebra which (according to our definition of the
semantics of ‘<’-literals, cf. Global Requirement 13.4) may have an arbitrary induction ordering
associated with and therefore evaluate ‘<’-literals in a completely different way as compared to
the non-enlarged algebra.
85
Theorem 10.15 (Monotonicity of Inductive Validity)
Let R be a CRS over sig/cons/V. Let R′ be another CRS, but over sig′/cons′/V′; with
sig′ = (F′,S′,α′)
cons′ = (C ′,S′,α′|C ′)
V′|{SIG,C }×S = V
F ⊆ F′
C ⊆ C ′ ⊆ F′
S ⊆ S′
α ⊆ α′
R ⊆ R′
such that all new constructor symbols are for new sorts, i.e.
∀c∈C ′\C . ∃s¯∈S′ ∗. ∃s′∈S′ \S. α′(c)= s¯→s′ .
Let Γ be a formula over sig/cons/V not containing ‘<’-literals, i.e. Γ ∈ (L I T (sig,V))∗.
Now, we have:
(A) If Γ is type-A valid w.r.t. sig/cons/R,
then Γ is type-A valid w.r.t. sig′/cons′/R′.
(B′) If Γ is type-B′ valid w.r.t. sig/cons/R,
then Γ is type-B′ valid w.r.t. sig′/cons′/R′.
Moreover, let us additionally assume:
(∗:) ∀((l,r),C) ∈ R′ \R. l 6∈ T (cons,VSIG⊎VC )
(∗∗:) −→R′, /0 is confluent77
Now, we also have:
(B) If R′ is Def-moderate, and
if Γ is type-B valid w.r.t. sig/cons/R,
then Γ is type-B valid w.r.t. sig′/cons′/R′.
(C) If R′ is Def-moderate, and
if Γ is type-C valid w.r.t. sig/cons/R,
then Γ is type-C valid w.r.t. sig′/cons′/R′.
(D′) If R′ is Def-moderate, and
if Γ is type-D′ valid w.r.t. sig/cons/R,
then Γ is type-D′ valid w.r.t. sig′/cons′/R′.
(D) If for all negative literals λ in Γ and all terms u ∈ T ERM S (λ),
the formula (Def u) is type-D valid w.r.t. sig/cons/R, and
if Γ is type-D valid w.r.t. sig/cons/R,
then Γ is type-D valid w.r.t. sig′/cons′/R′.
(E) If Γ does not contain variables from VSIG, and
if for all negative literals λ in Γ and all terms u ∈ T ERM S (λ),
the formula (Def u) is type-E valid w.r.t. sig/cons/R, and
if Γ is type-E valid w.r.t. sig/cons/R,
then Γ is type-E valid w.r.t. sig′/cons′/R′.
77The following allows applying the confluence criterion of Theorem 9.1: If we additionally require
∀((l,r),C)∈R. ∀(u0=u1) in C. ∃i≺2.
(
ui∈T (cons,VC )
∨ (Def ui) is in C
)
, then we can weaken the confluence requirement
to confluence of −→R′ , /0 ∩ (D
′
/0×D
′
/0) for D
′
/0 := { u ∈ G T (sig
′) | ∃uˆ∈G T (cons′). u
∗
←→R′ , /0 uˆ }.
86
10.7 Coincidences in Special Cases
In § 10.1 we have demonstrated that a reasonable treatment of partially defined functions as well
as the presence of negative literals in formulas does not go together well with standard notions of
inductive validity like validity in the initial model or validity in all term-generated models. The
price we had to pay for solving the problems involved was the intellectually difficult process of
splitting the one or two well-known notions of inductive validity into seven different ones. For
reassuring the necessity of such a process it may be helpful to see whether the splitting is really
the result of solving the above-mentioned problems. Therefore in this section we will firstly have
a look on which of our notions of inductive validity coincide when we disallow partially defined
functions. We will do so by first considering the case of a sufficiently complete reduction relation
and then by reducing to the standard algebraic framework by considering all functions symbols
to be constructor function symbols. Secondly in this section, we show that most of our notions
coincide when we consider only positive formulas, i.e. formulas not containing negative literals.
Lemma 10.16 (Coincidences for Sufficient Completeness)
Let R be a Def-MCRS over sig/cons/V.
Assume that −→R, /0 is confluent and that ∗−→R, /0 is sufficiently complete.78
Let Γ be a formula not containing ‘<’-literals, i.e. Γ ∈ (L I T (sig,V))∗.
Now w.r.t. sig/cons/R the following holds:
(a) Γ is type-E valid iff Γ is type-D′ valid.
(b) If no general variable from VSIG occurs in Γ, then all the following are logically equivalent:
Γ is type-B valid.
Γ is type-C valid.
Γ is type-D′ valid.
Γ is type-D valid.
Γ is type-E valid.
An important special case of sufficient completeness of ∗−→R, /0 is the case that all function sym-
bols are constructor function symbols, i.e. that cons=sig. Note that, to reduce to the standard
framework of algebra, this may always be achieved by considering all symbols to be constructor
symbols.
78Note that this condition (which is defined in § 5.3) is rather restrictive.
87
Let us assume then that all symbols are constructor symbols, i.e. cons=sig and no variables
from VSIG occur in formulas. Note that in this case our restrictions on constructor equations
forbid negative conditions in the defining rules. By Lemma 10.16(b), the types B, C, D′, D, and
E now coincide with validity in the unique minimal term-generated model, i.e. the initial model.
Hence, we obtain classic initial semantics (for positive conditional equational specifications) as
a special case of our general framework. Moreover, in this case type-A and B′ validity coincide
with validity in all term-generated models, cf. Lemma 10.9(a) and Lemma 10.14(c).
The following is a corollary of the lemmas 10.9 and 10.14.
Corollary 10.17 (Coincidences for Positive Formulas)
Let R be a CRS over sig/cons/V.
Let Γ be a formula neither containing negative literals nor ‘<’-literals,
i.e. Γ ∈ (A T (sig,V))∗.
Now w.r.t. sig/cons/R the following holds:
(a) Γ is type-B′ valid iff Γ is type-A valid.
(b) Γ is type-C valid iff Γ is type-B valid.
(c) If no rule in R has a negative condition (like (u 6=v)), then
all the following are logically equivalent:
Γ is type-A valid.
Γ is type-B′ valid.
Γ is type-B valid.
Γ is type-C valid.
(d) If R is Def-moderate and −→R,VSIG is confluent, then
all the following are logically equivalent:
Γ is type-B valid.
Γ is type-C valid.
Γ is type-D valid.
88
10.8 Related Work
Let us now have a brief look at notions of inductive validity in the literature, most of which can
be described as specializations within our framework.
If we consider all symbols to be constructor symbols (and, consequently, forbid negative
conditions in the rules), then we find type-A (or -B′) in Kounalis & Rusinowitch (1990) as well
as in Bouhoula &al. (1992).
The crucial idea of requiring the values of variables in formulas to be defined, i.e., to be
substituted by constructor ground terms only, seems to explicitly appear first in Zhang (1988),
Zhang &al. (1988). The “constructor models” of Zhang (1988), Zhang &al. (1988), which are
not models in the usual algebraic sense since function symbols are allowed to be interpreted
by partial functions,79 are consistently formalized in our framework by introducing the simple
(order-sorted) notion of sig/cons-algebras. The notion of inductive validity of Zhang &al. (1988),
Zhang (1988) can be described as type-A (or -B′) by implicitly interpreting all variables in rules
as general variables and all variables in formulas as constructor variables.
In Kounalis & Rusinowitch (1988), Bevers & Lewi (1990), Padawitz (1992), and Bouhoula
& Rusinowitch (1995) we find the usual validity in the initial model which is like our type-E (or
-D), assuming again all symbols to be constructor symbols and forbidding negative conditions in
the rules.
Kapur & Musser (1987 & 1986) consider only unconditional equations and only congruences
on ground terms (i.e. term-generated models) for validity, namely those that are maximally en-
larged by random identification of undefined terms with defined ones (i.e. constructor ground
terms) as long as this identification does not identify distinct constructor ground terms. Their
intended congruence is then the intersection of all those maximally enlarged congruences. In
Kapur & Musser (1987) the maximal congruences are allowed to have some undefined terms
left, accounting for the fact that the constructor-minimality requirement may forbid any further
identification from some point on. The resulting “inductive models”, however, lack the discussed
monotonicity property.80 Therefore, in Kapur & Musser (1986) the intersection is formed only
over those congruences that have no undefined ground terms left. While we have no notion of
inductive validity corresponding to that of Kapur & Musser (1987), inductive validity in Kapur
& Musser (1986) coincides with type-D′. Furthermore, the problems due to not yet known or
incompletely specified function symbols are also discussed in Walther (1994), mainly along the
lines of Kapur & Musser (1986).
In Ganzinger & Stuber (1992) inductive validity is defined to be validity in the perfect model
as introduced in Bachmair & Ganzinger (1991). This approach has a more general specification
formalism permitting sets of first-order clauses instead of constructor-based positive/negative-
conditional rule systems. The perfect model is determined as the least term-generated model
w.r.t. some ground-total reduction ordering. The perfect model semantics, however, lacks the
discussed monotonicity property w.r.t. consistent extension.
79For such partial algebras cf. also Kreowski (1987) and Reichel (1987).
80Cf. footnote 19 in § 4 for an example.
89
10.9 Comparison of the Notions
In this section we briefly compare the notions of inductive validity according to our criteria for
their adequacy of § 10.1.
As shown and discussed in § 10.6, all our seven notions of inductive validity have the desired
monotonic behavior w.r.t. consistent extension (under reasonable assumptions).
Regarding the importance of consistent extension of the specification for being able to express
induction hypotheses, this also means that they are more feasible for inductive theorem proving
than the older notions of inductive validity that lack this monotonicity, like validity in the ini-
tial model (cf. § 10.1), validity in all term-generated models (cf. § 10.1), validity in “inductive
models” (cf. § 10.8), and validity in the perfect model (cf. § 10.8).
The coincidence of notions for inductive validity with the intuition of a human specifier is quite a
subjective matter. Nevertheless, the following hints may be helpful.
According to our discussion on a certain misbehavior of the types A and B in § 10.4, and along
the similarity of the notions (by lemmas 10.9(a), 10.14(c)), we clearly give preference to type-B′
over type-A as well as to type-C over type-B, and consequently do not treat the types A and B in
our following sections on inductive theorem proving.
That type-E inductive validity is only adequate when we do not allow general variables to occur in
the formulas is illustrated in Example 10.13. Restricting the variables of the formulas to be con-
structor variables only, however, is severe, — especially for type D and E because for these types
interesting formulas containing general variables become valid even when no general variables
occur in the defining rules:
The following formula, which is shown to be (only) type-D and -E inductively valid in Ex-
ample 16.24, expresses strictness of the function ‘+’ in the second argument (where X and Y are
from VSIG,nat and ‘+’ is defined as in Example 10.13 or in Example 5.12):
Def (X +Y ), DefY
It seems impossible to express this without general variables. Note that the defining rules of
Example 5.12 do not contain general variables — but since all of these defining rules contain at
most one non-constructor function symbol one could argue that strictness is not an interesting
property because typical specifications without general variables will obey a similar “constructor
discipline”.
Thus, as a second example, consider the following formula, which is shown to be (only) type-
D and -E inductively valid in Example 16.15 (where X and Y are from VSIG,nat and ‘−’ is defined
as in Example 10.12 or in Example 5.12):
90
X−Y 6=0, X =Y
Since this lemma can be used for rewriting terms that are not known to be defined, we lose relevant
information when we formulate it with constructor variables instead of the general variables.
Therefore, when one is interested in such inductive theorems that rely on the partiality of
the definition of function symbols on T (VSIG), type-D inductive validity is clearly to be given
preference over type-E .
Moreover, when one is not interested in inductive theorems that rely on the partiality of the
definition of function symbols, then type-C inductive validity should be chosen.
Thus, type-E should be chosen only if one really wants to disallow general variables in for-
mulas but is interested in such inductive theorems that rely on the partiality of the definition of
function symbols on G T (cons), like (where x and y are from VC ,nat)
x−y 6=0, x=y
We consider type-D′ validity to be the most problematic one under the intuitional aspect because
in general we are unable to imagine what the class of possible consistent completions of the
partial definitions of the function symbols may look like and quite unexpected theorems hold.81
Moreover, it is possible that no consistent completion of a partial definition for a non-constructor
function symbol exists: E.g. when we have a rule like s(ω)=ω or ω=s(ω) for 0 and s being
constructors and ω a non-constructor constant. In such a case the class of models establishing
type-D′ validity is empty, which means that all formulas are type-D′ valid.
Furthermore, even if consistent completions of the partial definition for a function symbol ex-
ist, it is possible that none of the total functions resulting from such a completion is computable.82
In such a case the specification cannot be implemented in such a way that the type-D′ inductively
valid theorems hold in the implementation.
The types B′, C, and D do not have obvious shortcomings like the other ones. Thus it is left to the
reader to choose his favorite. Our favorite is type-C:
Contrary to type-B′, it provides the useful and natural property of constructor-minimality (“no
confusion for C ”) and thereby makes formulas like
s(0) 6=0
or
mbp(0,cons(s(0),nil))= false
inductively valid.
81like swatch(swatch(swatch(x)))=swatch(x) for x∈VC ,nat and w.r.t. the rule system of Example 5.12, cf. also
Example 15.7 and the remark following it.
82A simple diagonalization argument shows that this is the case for the function that applies a program to itself
and adds 1 to the result.
91
Contrary to type-D, the monotonicity behavior of type-C w.r.t. consistent extension is un-
restricted, cf. Theorem 10.15, which is important since (to gain sufficient expressibility for the
formulation of induction hypotheses) a specification should be considered to be a momentary
state in a process of incremental extension.
Nevertheless, since only with type-D validity it is possible to express the fact that certain cases
of a function definition are non-terminating or left open or that a function is strict in one of its
arguments, type-D validity is sometimes useful when searching for extensions or simplifications
of the definition of a function.
Concerning operational feasibility of our seven types of inductive validity, the following can be
said.
As already indicated in § 10.4, the operationalization of type-A and -B is problematic because
the definedness of a term does not guarantee that substituting it for a constructor variable is
semantically correct, as is the case with all our other notions. Such substitutions are necessary,
however, because we must be able to apply lemmas and hypotheses instantiated with generalized
substitutions, cf. § 13.2.
For the types B′, C, and D (and also for E because it hardly differs from D) we are going to develop
inductive theorem proving techniques which are supported by a confluent reduction relation in the
following sections.
This will be done by presenting inference rules for all these types, some additional ones that do
not apply for type-B′ anymore because they depend on constructor-minimality, and finally some
set of inference rules that apply only for type-D and -E because they rely on the characterization
indicated by Corollary 10.6. Note that these additional inference rules correspond to a greater set
of theorems for the “lower” types.
This approach of proving inductive validity of the types B′, C, and D via different sets of
inference rules is more powerful than presenting an inference system for type D only and then to
approach type C (and B′) via Lemma 10.14(b) (and (d)). To see this, consider the specification of
Example 5.12. There the following formula, named ‘(Del swatch3)’ in Example 5.15, is type-C
valid which cannot be inferred from its type-D validity via Lemma 10.14(b):
Def swatch(0), swatch(swatch(swatch(x)))=swatch(x)
It is, however, easy to show its validity (cf. Example 15.7) without the inference rules reserved
for type-D (and -E), which means that its type-C validity can be proved by our approach.
From type-C validity of the above formula we can conclude by Lemma 10.9(c) that
swatch(swatch(swatch(x)))=swatch(x)
is type-D′ valid. Obviously, this is not an inductive theorem for any other type. This indicates a
possibility to use our inference system for type-C to show type-D′ validity.
92
It seems hard to effectively prove type-D′ valid formulas that do not result from type-C valid
formulas by deleting Def-atoms because this requires to capture an infinite argumentation on
SIG:cons-term-generatedness. Moreover, we are not so much interested in the additional theo-
rems of type-D′ due to the intentional problems indicated above — and we doubt that anybody is:
We suppose that the only reason for choosing type-D′ instead of type-C validity is that one can
circumvent the decision on how to model partial definedness.
93
11 Introduction to Inductive Theorem Proving
11.1 What is Inductive Theorem Proving?
Inductive reasoning can be seen as extending deductive reasoning in that infinite deductive proofs
may be represented in a finite cyclic form, as suggested in the following example, where Γ(x0,y)
is a proposition over the natural numbers, and where the formulas below each line (sub-goals)
imply the formula (goal) above: An infinite deductive proof of Γ(x0,y)
Γ(x0,y)
Γ(0,y) Γ(s(x1),y)
.
.
. Γ(s(0),y) Γ(s(s(x2)),y)
.
.
. Γ(s(s(0)),y) . . .
.
.
.
.
.
.
.
.
.
(using xi =0 ∨ ∃xi+1. xi =s(xi+1) ) should be captured in something like
Γ(x0,y)
Γ(0,y) Γ(s(x1),y)
.
.
. ∆ ⇒ Γ(s(x1),y) Π ⇒ Γ(s(x1),y)
.
.
.
.
.
.
∆′ ∨ Γ(x1,s) Π′ ∨ Γ(x1,t) Π′′
(back to top) (back to top) ...
using ∆ ∨Π. This kind of cyclic argument — namely inferring Γ(x1,s) and Γ(x1,t) from Γ(x0,y)
— is sound if for each (ground) instantiation of the theorem (here: Γ(sm(0),sn(0))) the deductive
proof terminates. This can be guaranteed by requiring that each cycle in the proof (graph) termi-
nate, i.e. its preconditions (usually called induction hypotheses — here: Γ(x1,s) and Γ(x1,t)) be
smaller than the “induction” conclusion (here: Γ(x0,y) or Γ(s(x1),y)) w.r.t. some wellfounded
ordering,83 called induction ordering (here e.g. the usual ordering on the natural numbers applied
to the first argument of Γ). Thus, while the property of being an inductive theorem depends only
on the specification (i.e. a term language and a set of axioms) and the choice of a specific notion
of inductive validity, an inductive proof of an inductive theorem also depends on an additional
parameter, namely some induction ordering which must be chosen during the proof appropriately.
83Note that this is more powerful than structural induction. Cf. Gentzen (1943).
94
11.2 Explicit versus Implicit Induction
Although there is no generally accepted characterization of the two paradigms of explicit and
implicit induction in the research community, in Walther (1994), which is a comprehensive survey
on explicit induction, the following is said:
Research on automated induction these days is based on two competing paradigms:
Implicit induction (also termed inductive completion, inductionless induction, or, less
confusingly, proof by consistency) evolved from the Knuth-Bendix Completion Pro-
cedure . . . . . . . The other research paradigm . . . is called explicit induction and re-
sembles the more familiar idea of induction theorem proving using induction axioms.
In accordance with this view, we call the latter paradigm “explicit” because, in the underlying
inference systems, every cyclic argument must be made explicit in a single inference step applying
a so-called induction rule. Besides generating induction base formulas, this step joins induction
hypotheses and conclusions in induction step formulas and explicitly guarantees the termination
of their cycles by a sub-proof or -mechanism for the wellfoundedness of the induction ordering
resulting from the step formulas. In the explicit induction proof corresponding to the example
induction proof of § 11.1 the induction base formula is Γ(0,y) and the induction step formulas
are ∆ ⇒ ( Γ(x1,s)⇒ Γ(s(x1),y) ) and Π ⇒ ( Γ(x1,t)⇒ Γ(s(x1),y) ). The explicit induction
proof then has the following form:
Γ(x0,y)
Γ(0,y) ∆ ⇒ ( Γ(x1,s)⇒ Γ(s(x1),y) ) Π ⇒ ( Γ(x1,t)⇒ Γ(s(x1),y) )
.
.
.
.
.
.
.
.
.
Note that the first inference in this proof is an application of an induction axiom in the sense of
Walther (1994).
As the example induction proof of § 11.1 illustrates, the cyclic arguments and their termination in
implicit induction proofs need not be confined to single inference steps, as is in explicit induction.
Therefore, the induction axioms corresponding to the cyclic arguments in a finite implicit induc-
tion proof can only be determined by analyzing the whole proof, whereas in the case of explicit
induction each applied induction axiom is given by an application of the induction rule.
Since Bachmair (1988), refutational completeness (cf. A) has been emphasized by various au-
thors in the field of implicit induction: In general, the set of inductively valid theorems is not enu-
merable for all significant notions of inductive validity, cf. Gödel (1931), Nourani (1994), Mac-
Queen & Sannella (1985); therefore refutational completeness is an optimal theoretical quality of
inference systems for inductive theorem proving. Moreover, non-terminating proof attempts in
95
refutationally complete inference systems could be considered successful proofs. While the abil-
ity of an inductive theorem prover to detect invalid formulas is important under a practical aspect
(cf. § 12.10), refutational completeness does not help in finding finite proofs for inductively valid
formulas.
To succeed in proving an inductive theorem in finite time, implicit inductive theorem provers have
to solve the same problems as explicit inductive theorem provers, namely to find a finite cyclic
representation for an infinite deductive proof as well as an induction ordering guaranteeing the
termination of its cycles. Therefore, if a theorem prover with sufficient deductive power fails to
show an inductive theorem, possible reasons may be a failure to construct the proper reasoning
cycles or to establish their termination. As will be shown in the following, inference systems
for implicit induction can be made powerful enough to express the appropriate cyclic arguments,
but a certain kind of bookkeeping (cf. the “weights” in § 12.1) of the ordering information for
controlling the various applications of induction hypotheses is necessary for establishing their
termination, cf. the examples 12.1, 12.2, 12.3, and 12.4 in § 12. Inference systems for explicit
induction on the other hand do not require this kind of bookkeeping since the ordering information
is used only locally within single explicit induction steps. Inference systems for explicit induction
have the disadvantage, however, that adequate instantiations of the induction hypotheses need to
be guessed when the induction step formulas are synthesized, cf. the terms s and t in our above
example. In general, it can be rather difficult to choose these instantiations before the induction
conclusion has been substantially simplified, cf. Protzen (1994) for a simple example.
All in all, we feel that, from an abstract point of view and beyond the technicalities usually
involved, most induction proofs can be expressed in either of the two paradigms with essentially
the same cyclic arguments. Moreover, we think that a combination of methods, techniques, and
heuristics from both research paradigms is possible and will be beneficial for the automation of
inductive theorem proving.
96
11.3 Our Approach
In the following sections we present an inference system for proving inductive theorems w.r.t.
constructor-based positive/negative-conditional equational specifications and various important
notions of inductive validity which have been described in the previous sections.
Based on experiences with more or less automated inductive theorem provers, such as NQTHM,
INKA, RRL, UNICOM, SPIKE, &c.,84 we have come to adopt a rather pragmatic viewpoint with
respect to inductive theorem proving: Successful use of an inductive theorem prover in “real-life”
problem domains has not been possible yet without a knowledgeable human user who can interact
with the system on various levels. Accordingly, we think that even the development of the theo-
retical concepts of a new theorem prover — including its inference system — should begin with
a clear emphasis on user interaction, whereas automatic proof guidance is seen as a long-term
goal. Therefore, the following two requirements are main design goals for our inference system:
1. We expect the inference system to comply with human (inductive) proof techniques in that
it enables users to naturally express their proof ideas in terms of the inference system.
2. Users should have no difficulties in understanding and searching for formal proofs repre-
sented with the inference system, no matter whether they try to follow them on the mere
syntactic level or try to grasp overall “strategic” aspects of the proofs.
Refining the first design goal we obtain the following requirements:
• All proof problems and sub-problems, defining equations, lemmas, and induction hypo-
theses should be represented homogeneously, such that all requirements of any inference
rule are expressed in the same language. This enables the user to utilize the full power
of the whole inference system on all problems and sub-problems and to choose freely and
flexibly between eager or lazy strategies for any proof problem.
• Another important point is that the inference system includes inference rules for most
elementary proof steps such that the user can force the prover to follow his proof ideas
as closely as possible. We consider transparency of atomic inference steps to be more
important than having (derived) higher-level inference rules. Applied in non-trivial proof
problems higher-level inference rules tend to be too restrictive, while an inference system
comprising a multitude of simple “fine-grain” inference rules can be used to (interactively)
construct even very difficult proofs.
Refining the second design goal we obtain the following requirements:
• The inference system should support a natural flow of information in the sense that a
certain decision can be delayed until the state of the proof attempt provides sufficient
information to make a successful decision. One example of unnatural flow of information is
84Cf. Boyer & Moore (1988), Biundo &al. (1986), Kapur & Zhang (1989), Gramlich & Lindner (1991), Bouhoula
& Rusinowitch (1995), resp.
97
instantiating induction hypotheses in induction step formulas of explicit induction long be-
fore the hypotheses become applicable, cf. Protzen (1994).85 Another
example of unnatural flow of information is the γ-rule of sequent calculi or semantic tableaus
(without free variables), cf. Smullyan (1968), where instantiations have to be guessed long
before it can be recognized which instantiations will make a proof attempt successful. To-
gether with the homogeneous and flexible formulation of the inference rules, the natural
flow of information should make it possible to replace a certain amount of proof planning
based on some special abstractive representation with
heuristic search based on the homogeneous representation in the inference system.
• Moreover, to enable the user to understand and manipulate the current proof state a mutual
independence of the proof sub-problems represented by the formulas at the open nodes of
the proof graph is helpful. This independence (or locality) facilitates distributed and local-
ized proof construction. Note that this kind of independence is not trivially satisfied. E.g.,
the branches of a free-variable tableau (cf. Fitting (1990), Baaz & Fermüller (1995)) need
not be mutually independent, leading to the problem of simultaneous rigid E-unification
which is undecidable in general, cf. Degtyarev & Voronkov (1995), Degtyarev & Voronkov
(1997).
• Another requirement that is very important for efficiency of automated as well as interac-
tive theorem proving is goal-directedness. Goal-directedness means that every problem in
the graph of a proof attempt is connected with the theorem to be proved. For inductive the-
orem proving this is even more important than for deductive theorem proving: The crucial
point is that we often have to invent some new literals — or, more generally, formulas — to
close the gap between the induction conclusion and the induction hypotheses. This creative
invention can be guided by the user’s knowledge of the domain or more automatically by
the applicable lemmas, the (extended) induction conclusion, and the induction hypotheses.
Without the goal-directedness given by the connection with the induction conclusion and
the induction hypotheses the missing formulas can hardly be guessed. Note that such cre-
ative steps are not necessary for deductive theorem proving because according to Gentzen’s
Hauptsatz a proof of a deductive theorem does not need to invent new formulas but can
be restricted to “sub”-formulas86 of the theorem. On the contrary, the application of hypo-
theses and lemmas inside an inductive reasoning cycle cannot generally be eliminated in
the form given by Gentzen’s Hauptsatz for deductive proofs.87
85Note that we do appreciate the heuristic knowledge in the induction rule of explicit induction systems. We just
do not accept that we have to instantiate the induction hypotheses eagerly before the proof is sufficiently developed
in the case that the instantiations are not straightforward, resulting in a failure of the proof if one of the guessed
instantiations was wrong.
86Note, however, that this notion of “sub”-formula is closed under instantiations with a usually infinite number of
terms. For inductive theorem proving, however, creativity cannot be restricted to finding the proper instantiations, but
requires the invention of new formulas, possibly in an enrichment of the term language and in a consistent extension
of the specification.
87Cf., however, Gentzen (1938). Moreover, it is possible to replace one Cut with another Cut: When the formulas
are restricted to be clauses, e.g., all Cuts can be replaced with Cuts on single atoms and all hypothesis and lemma
applications can be moved to the leaves of this tree of atomic Cuts. This means that it is theoretically not important
whether a lemma application occurs inside or outside an inductive reasoning cycle. The crucial point, however,
is how to practically find the proper atoms for the Cuts. This problem is discussed in some detail in § 16.2: In
Example 16.9 the application of the lemma (Strict Trans less) is inside the inductive reasoning cycle, whereas in
Example 16.11 (whose proof does not differ from the one of Example 16.9 when one normalizes it to atomic Cuts)
the application of the lemma (Strict Trans less) is outside the inductive reasoning cycle.
98
As a first step towards achieving the above design goals, we have an inference system in mind that
explicitly provides the concepts of induction hypothesis and induction ordering. With the latter
concept we associate means of supplying induction ordering conditions with sufficient expres-
siveness (i.e. explicit weights, cf. § 12.1) and methods of choosing adequate induction orderings
among semantic orderings (resulting in “induction on values”), syntactic orderings (resulting in
“induction on terms”) or combinations of these types of orderings. Concerning the concept of
induction hypothesis, we intend an inference system that does not “hide” (applications of) induc-
tion hypotheses in single inference steps. We rather think of an inference system that “knows”
what an induction hypothesis is, i.e. it includes inference rules that provide or apply induction
hypotheses, given that certain ordering conditions resulting from these applications can be met
by an induction ordering. Obviously, such an inference system is an inference system for implicit
induction (as explained above). Furthermore, the intended inference system supports lazy gener-
ation of induction hypotheses and mutual induction. As a consequence, we obtain the following
essential constraint for our inference system:
The formulas used by the inference system must be capable of representing an induc-
tion hypothesis as a whole and in recognizable form. Not an inference rule nor input
normalization may decompose a conjectured inductive theorem (into “sub”-formulas)
before the induction hypotheses have been extracted from it.
This constraint helps settling the following question: Which deductive inference system is best
suited for an integration of implicit induction? Note that in the more restricted framework of
explicit induction, obtaining an inference system for inductive theorem proving from a deductive
inference system is far simpler: Since induction is concentrated in a single inference rule then,
this induction rule can be just added to the given deductive inference system without affecting the
rest of the inference system. When integrating implicit induction, however, the whole inference
system is affected.
Satisfying the above indented constraint with refutational inference systems based on reso-
lution or paramodulation (cf. e.g. Bachmair & Ganzinger (1994)) or on semantic tableaus (cf.
Fitting (1990)) seems difficult. Suppose we want to prove the following inductive theorem stating
a transitivity-like property of the “less”-predicate on the natural numbers:
∀x. ∀y. ∀z.
(
less(s(x),z) ∨ less(x,y) ∨ less(y,z)
)
.
Now for a refutational proof we first have to negate this, yielding
∃x. ∃y. ∃z.
(
less(s(x),z) ∧ less(x,y) ∧ less(y,z)
)
.
Next we must Skolemize such that satisfiability is invariant. For deductive satisfiability this sim-
ply yields the three unit clauses (with new constants ‘a’, ‘b’, ‘c’)
less(s(a),c); less(a,b); less(b,c).
It is obvious that the original input theorem has been decomposed and when we want to use it
as an induction hypothesis it is not recognizable as a whole anymore. Thus, when using refuta-
tional inference systems, we have to extract the induction hypotheses before negation and input
normalization, which results in two different representations: one for the induction hypothesis
99
and another quite strange looking dual one for the induction conclusion. This makes proof guid-
ance more difficult for human users. Moreover, for inductive satisfiability we must actually refute
something like (k, l, m denoting arbitrary globally constant natural numbers)
less(s(sk(0)), sm(0)); less(sk(0),sl(0)); less(sl(0), sm(0)).
Since this is beyond our term language, we have to guarantee that the inference system is able to
apply lemmas like xi =0 ∨ ∃xi+1. xi =s(xi+1).
The two dual representations of the input theorem in the induction proof can be easily over-
come when the inference system has two types of formulas, namely prover formulas that may
occur at the nodes of proof graphs as opposed to the formulas generating inference rules like
xi =0 ∨ ∃xi+1. xi =s(xi+1) and ∆ ∨ Π in our inductive proof of § 11.1. Then the induction con-
clusions are taken as prover formulas and the induction hypotheses as non-prover formulas. Due
to the separation into two disjoint kinds we can now switch the duality of the prover formulas
when writing them down. Although links between formulas of different kind connect literals of
the same polarity then, the human user sees the input theorem only in one single form of du-
ality. Sergey Yu. Maslov’s inverse method (cf. Lifschitz (1989)) restricts prover formulas to be
clauses, whereas the formulas generating inference rules are super-clauses, which are disjunctions
of super-literals, which are conjunctions of literals. Sergey Yu. Maslov’s general idea of inver-
sion (cf. Maslov (1971)), however, seems not to be appropriate for inductive theorem proving:
How can we invert proofs of the form as presented in § 11.1? Inversion here means beginning
at the bottom.88 An infinite deductive proof on the one hand has no (finite) bottom at which to
start. An inductive proof on the other hand where the induction conclusion is a prover formula at
the top lacks goal-directedness when starting from the bottom. This lack of goal-directedness is
very similar to that of the more familiar framework of non-refutational resolution and paramod-
ulation, where the resolution rule is applied to axioms only, and the task is to infer a formula
which subsumes the theorem. Non-refutational resolution seems not very appropriate for deduc-
tive theorem proving because it is not goal-directed. In the context of inductive theorem proving,
however, non-refutational resolution could be considered goal-directed because it starts with the
axioms plus the induction hypotheses, and formulas that subsume the induction conclusions are
to be inferred. Nevertheless, the goal-directedness given by the induction hypotheses is not suffi-
cient. Since numerous lemmas may be applicable and applications of lemmas tend to be “closer”
to applications of induction hypotheses than to the conclusions, it is practically impossible to find
the appropriate ones unless the conclusion has been expanded to a large degree. Furthermore,
non-refutational resolution is not goal-directed in the base cases and in those parts of the proof
that lie below applications of induction hypotheses (cf. e.g. the right-most branch of the inductive
proof in § 11.1). Finally, since most inductive proofs follow the recursive definitions of the speci-
fication, non-refutational resolution requires to paramodulate with the defining rules from right
to left. This can result in a high branching degree for some of the non-recursive cases and make
a proper combination of the cases of the definition difficult (i.e. “unfolding” (or “expanding”) a
function definition is easier than “folding” it). All in all, we conclude that non-refutational reso-
lution and paramodulation as well as the general idea of inversion are not adequate for inductive
theorem proving. Cf. Ganzinger & Stuber (1992), however, for a first step towards the difficult
integration of implicit induction into a refined deductive paramodulation inference system. More
88We do apologize for this brute force simplification of Sergey Yu. Maslov’s fascinating idea.
100
interesting is the inference system of Padawitz (1992) for implicit induction, where the induc-
tion hypotheses (which are special super-clauses with additional existential variables) are applied
very similar to the non-prover formulas in the inverse method. Moreover, goal-directedness w.r.t.
the induction conclusion is achieved here by starting from the negated induction conclusion in
the form of a set of “goals”, i.e. clauses in dual notation. Contrary to this, the inverse method
starts from the set of tautologies, which has the advantage of deductive completeness but lacks
goal-directedness w.r.t. the induction conclusion.
Finally, Hilbert calculi are not adequate for (inductive) theorem proving because they are not
goal-directed and natural deduction calculi (cf. Gentzen (1935), Prawitz (1965)) augment the
proofs with assumptions that conflict with our concept of induction hypothesis.
Now the only remaining family of well-known first-order deductive inference systems is that
of sequent calculi, cf. Gentzen (1935), Lifschitz (1971). Fortunately, sequent calculi do admit an
integration of implicit induction in a way that is adequate in our opinion:
If provided with an inference rule for lemma application (cf. § 14.5), sequent calculi are goal-
directed w.r.t. deductive theorem proving. By adding a powerful inference rule for applying
induction hypotheses (cf. § 16.2), we obtain an inference system for inductive theorem proving
that is optimally goal-directed w.r.t. the induction conclusions and sufficiently goal-directed w.r.t.
the induction hypotheses.
Starting with the formula89 to be proved, the problem of proving a formula (goal) is re-
duced to the problem of proving another set of formulas (sub-goals), which can be considered to
be its children. Applying such reduction steps recursively results in a tree-like proof structure,
which is augmented with cyclic arguments resulting from inference rules generated by induction
hypotheses, similar to our inductive proof in § 11.1. A proof having the simple structure of a
tree is easy to understand for users and a good basis for automatic tactics and heuristic proof
search. Note that sequent calculi lie somewhere between the other two families of deductive in-
ference systems that admit comprehensible proofs, namely natural deduction calculi and semantic
tableaus: The close relation to natural deduction was already exhibited in Gentzen (1935), and
tableaus can be regarded as the dual of Gentzen’s sequent calculus, cf. Smullyan (1968).90
Concluding the discussion of the question which deductive inference system is best suited
for an integration of implicit induction, we indicate how the above indented constraint can be
satisfied with sequent calculi. Contrary to semantic tableaus (where the formulas at some an-
cestor nodes must be included), any formula in a proof tree of a sequent calculus is completely
self-descriptive. Therefore, any formula in the proof tree can be used as an induction hypothesis
without regarding its position in the tree. It is obvious then that the hypotheses can be extracted
before any inference rule or input normalization has decomposed the conjectured inductive the-
orems. Moreover, the induction hypotheses are represented as a whole and in a recognizable
form.
89We simply speak of “(prover) formulas” instead of “sequents”.
90Compared with natural deduction or tableaus, proofs in Gentzen’s sequent calculus may be a little tiresome
to write down by hand due to the many repetitions, but a computer can overcome this overhead by using a more
tableau-like hidden internal representation. For our convenience, we let the proof trees grow downwards, as is usual
with tableaus. Thus, while readers familiar with tableaus must think in the dual in this thesis, they do not have to
invert their trees. On the other hand, readers familiar with sequent calculi must invert their trees and inference rules,
whereas they do not have to think in the dual.
101
12 The Abstract Inference System
In this section we present a revised version of Wirth & Becker (1995) because it is essential for
developing and understanding the key properties of our inference system. Due to the high level
of abstraction, we now begin with a detailed concrete example to refer to it in what follows. We
do not expect the reader to understand or read this example in detail. Nevertheless, it may help to
understand the justification for the way we construct our abstract inference system.
Example 12.1 (continuing examples 5.1, 5.12, 5.15)
Let x,y,z∈VC ,nat and h,k, l ∈VC ,list. Suppose that the defining rules are given as in Example 5.12
and that we want to show the following theorem (Rip cons br) from Example 5.15, where “, ”
denotes “logical or” and “ ; ” separates the formula from its weight that controls the application
of induction hypotheses:
(1) br(k,cons(x, l))=cons(x,br(k, l)), mbp(x, l)= true ; wγ12.1(k,x, l)
The goal (1) says that x occurs in l or the wave-front cons(x, . . .) can be rippled out. Applying a
covering set of substitutions to (1) (using the Substitution Add rule of § 16.1), we get a base case
(1.1) for {k 7→nil} and the case (1.2) for {k 7→cons(y,k)}:
(1.1) br(nil,cons(x, l))=cons(x,br(nil, l)), mbp(x, l)= true ; wγ12.1(nil,x, l)
(1.2) br(cons(y,k),cons(x, l))=cons(x,br(cons(y,k), l)),
mbp(x, l)= true ; wγ12.1(cons(y,k),x, l)
A rewrite step with the defining rule (br1) of Example 5.12 in the left-hand side of the first literal
(using the Lemma Rewrite rule of § 14.5) transforms (1.1) into
(1.1.1) cons(x, l)=cons(x,br(nil, l)), mbp(x, l)= true ; wγ12.1(nil,x, l)
A second Lemma Rewrite with the defining rule (br1), now in the right-hand side of the first
literal, transforms (1.1.1) into
(1.1.1.1) cons(x, l)=cons(x, l), mbp(x, l)= true ; wγ12.1(nil,x, l)
This goal can be removed (using the =-Decompose rule of § 14.2) because the first literal is
tautological.
102
Now we return to the goal (1.2) left open above. Lemma Rewrite with (br2) in the left-hand side
of the first literal transforms (1.2) into
(1.2.1) br(k, rc(y,cons(x, l)))=cons(x,br(cons(y,k), l)),
mbp(x, l)= true ; wγ12.1(cons(y,k),x, l)
A second Lemma Rewrite with (br2), now in the right-hand side of the first literal transforms
(1.2.1) into
(1.2.1.1) br(k, rc(y,cons(x, l)))=cons(x,br(k, rc(y, l))),
mbp(x, l)= true ; wγ12.1(cons(y,k),x, l)
Lemma Rewrite with (rc3) in the left-hand side of the first equation transforms (1.2.1.1) into the
following two goals. The first goal asks us to show that the condition x 6=y of (rc3) is satisfied.
In the second we have carried out the rewrite step.
(1.2.1.1.1) x 6=y, br(k, rc(y,cons(x, l)))=cons(x,br(k, rc(y, l))),
mbp(x, l)= true ; wγ12.1(cons(y,k),x, l)
(1.2.1.1.2) x=y, br(k,cons(x, rc(y, l)))=cons(x,br(k, rc(y, l))),
mbp(x, l)= true ; wγ12.1(cons(y,k),x, l)
Lemma Rewrite with (rc2) in the left-hand side of the second equation transforms (1.2.1.1.1) into:
(1.2.1.1.1.1) x 6=y, br(k,cons(x,dl(y, l)))=cons(x,br(k, rc(y, l))),
mbp(x, l)= true ; wγ12.1(cons(y,k),x, l)
Now we can use the literal x 6=y for a rewrite step in the left-hand side of the second literal of
(1.2.1.1.1.1) (using the Constant Rewrite rule of § 14.4) to yield
(1.2.15) x 6=y, br(k,cons(x,dl(x, l)))=cons(x,br(k, rc(y, l))),
mbp(x, l)= true ; wγ12.1(cons(y,k),x, l)
A Lemma Rewrite in the first literal with (Del dl) from Example 5.15 yields
(1.2.16) x 6=y, br(k,cons(x, l))=cons(x,br(k, rc(y, l))),
mbp(x, l)= true ; wγ12.1(cons(y,k),x, l)
Another Constant Rewrite of the same kind yields
(1.2.17) x 6=y, br(k,cons(x, l))=cons(x,br(k, rc(x, l))),
mbp(x, l)= true ; wγ12.1(cons(y,k),x, l)
so that a Lemma Rewrite in the second literal with (Del rc) from Example 5.15 can transform this
into
(1.2.18) x 6=y, br(k,cons(x, l))=cons(x,br(k, l)),
mbp(x, l)= true ; wγ12.1(cons(y,k),x, l)
Now we can apply (1) as an induction hypothesis using the Hypothesis Apply rule of § 16.2. Since
(1) subsumes (1.2.18) we get only the following ordering condition for the hypothesis application:
(1.2.19) wγ12.1(k,x, l)<wγ12.1(cons(y,k),x, l),
x 6=y, br(k,cons(x, l))=cons(x,br(k, l)),
mbp(x, l)= true ; wγ12.1(cons(y,k),x, l)
103
Now we go on with the goal (1.2.1.1.2) left open above. Here we can also apply (1) as an
induction hypothesis, matching the first literal of (1) to the second literal of (1.2.1.1.2), but this
is a little more difficult. Since we have to instantiate the constructor variable l of (1) with the
non-constructor term rc(y, l) we have to show that this term is defined:
(1.2.1.1.2.1) Def rc(y, l),
x=y, br(k,cons(x, rc(y, l)))=cons(x,br(k, rc(y, l))),
mbp(x, l)= true ; wγ12.1(cons(y,k),x, l)
Moreover, since the instantiated literal mbp(x, rc(y, l))=true of (1) is not contained in (1.2.1.1.2)
we have to show its complement:
(1.2.1.1.2.2) mbp(x, rc(y, l)) 6= true,
x=y, br(k,cons(x, rc(y, l)))=cons(x,br(k, rc(y, l))),
mbp(x, l)= true ; wγ12.1(cons(y,k),x, l)
Finally we have to show that the weight of the instantiated hypothesis (1) is smaller than the
weight of the goal (1.2.1.1.2):
(1.2.1.1.2.3) wγ12.1(k,x,h)<wγ12.1(cons(y,k),x, l), h 6= rc(y, l),
x=y, br(k,cons(x, rc(y, l)))=cons(x,br(k, rc(y, l))),
mbp(x, l)= true ; wγ12.1(cons(y,k),x, l)
The lemma (Def rc) from Example 5.15 subsumes the goal (1.2.1.1.2.1), which therefore can be
removed by the Lemma Apply rule of § 14.5.
A Lemma Rewrite with the lemma (Del rc mbp) from Example 5.15 applies to the first literal of
(1.2.1.1.2.2), transforming it into
(1.2.1.1.2.2.1) mbp(x, l) 6= true,
x=y, br(k,cons(x, rc(y, l)))=cons(x,br(k, rc(y, l))),
mbp(x, l)= true ; wγ12.1(cons(y,k),x, l)
which can then be removed by an =-Decompose of the last literal because it is complementary to
the first.
Now the proof is completed when we can solve the ordering conditions of (1.2.19) and
(1.2.1.1.2.3), namely
w
γ
12.1(k,x, l)<w
γ
12.1(cons(y,k),x, l)
and
w
γ
12.1(k,x,h)<w
γ
12.1(cons(y,k),x, l)
After defining wγ12.1(k,x, l)=k this means:
k<cons(y,k)
and
k<cons(y,k)
which are satisfied when we choose ‘<’ to be the subterm ordering ‘ST’.
104
12.1 Proof States
Proof states are intended to represent the state of a proof. They record which sub-tasks of a proof
have been successfully established, which goals remain to be proved, &c.. Technically, the proof
states are the field of our inference relation ‘⊢’.
For deductive reasoning we may start with a set ‘G’ of goals which contains the theorems we
want to prove, transform them and finally delete them after they have become trivial tautologies.
Such an inference relation, starting from the theorems to be proved and reducing them until some
termination criterion is satisfied, is called analytic, cf. e.g. Bibel & Eder (1993). These theorems
have to belong to some set ‘Form’ which contains the formulas the inference system can treat. If
⊢ permits only sound transformation and deletion steps, then from “ G ∗⊢ /0 ” (where ‘ ∗⊢ ’ denotes
the reflexive and transitive closure of ⊢ ) we may conclude that G is valid. Note that ‘⊢’ has
nothing to do with logical implication ‘|=’ but with problem reduction. ‘⊢’ just denotes some
binary relation that describes an inference step.
For practical reasons, we would like to have a set ‘L’ of lemmas at hand. In this L inference
steps can store axioms of the specification, already proved lemmas or the results of any theorem
prover called for solving special tasks which might be helpful in our inference process. We can
then use L for transformations of G that are only known to be sound relative to L. Thus our proof
states should be pairs of sets ‘(L,G)’ such that, for valid L, “ (L,G) ∗⊢ (L, /0) ” implies validity of
G (and such that “ ( /0,G) ∗⊢ (L,G) ” implies validity of L).
For inductive reasoning, we additionally would like to have a set ‘H’ of induction hypotheses.
Similar to L, the set H may be built up during the inference process and used for transforma-
tions of G which are founded on H in the sense that they are only known to be sound relative
to H. Proof states for inductive theorem proving should be triples of sets ‘(L,H,G)’ such that
“ ( /0, /0,G) ∗⊢ (L,H, /0) ” implies inductive validity of G, L, and H. Unlike the lemmas in L, how-
ever, the hypotheses in H are not known to be valid before the whole induction proof is done (i.e.
“ G = /0 ”). Here is a risk of being caught in a cyclic kind of reasoning like: “The goal can be
deleted, since it is valid due to the hypothesis, which is valid, if the goal can be deleted, . . . ”,
cf. § 11.1. That this cyclic reasoning terminates can be guaranteed by equipping each formula
in H or G with a weight and allowing a hypothesis to transform a goal only if the weight of the
hypothesis is smaller than the weight of the goal w.r.t. a wellfounded quasi-ordering ‘.’ which
we will call the induction ordering in what follows.
Note that we distinguish between the weight of a formula and the actual formula itself: For
explicit induction, weights are not needed on the inference system level because each inductive
reasoning cycle is encapsulated in a single inference step which combines induction conclusions
with induction hypotheses in step formulas. In implicit induction, however, induction conclusions
and hypotheses need not be joined in the beginning. Instead, the conclusions can be taken as
goals and transformed until it becomes obvious which hypotheses will be useful for proving
them. At this point, when hypotheses are to be applied to the transformed goals, their weights are
needed to transfer ordering information from the original goals that generated the hypotheses to
the transformed goals. Roughly speaking, the goals have to store the weights of hypotheses for
which they carry the proof work. (This still permits mutual induction.)
105
A possible weight for a formula, which is so natural that there are hardly any other weights in
the literature on implicit induction, is (the value of a measure applied to) the formula itself. How-
ever, if we require the weight of a goal to be determined by the formula alone, then the chance to
transform or delete this goal by means of some fixed hypothesis (which has to be smaller w.r.t. <)
gets smaller with each transformation of the goal into other goals which are smaller w.r.t. <.
Such transformation of goals is usually called simplification. While simplification of a goal is an
important91 heuristic, the weight of the goal should not change during simplification. This can
be stated more generally: For concrete inference rules it is very important that a goal can trans-
mit its weight unchanged to the sub-goals which it is transformed into. This would be generally
impossible if the weight of a formula were restricted to be the formula itself. In our approach,
therefore, each element S of H ∪G is some syntactic construct from a set ‘SynCons’. Besides
its formula ‘form(S)’, S may have some additional contents describing its weight. Conceptually,
one can consider each syntactic construct to be a pair made up of a formula expressing some
proposition and a weight carrying the ordering information for avoiding non-terminating cycles
in the use of inductive arguments. For the description of concrete inference systems within our
abstract framework, however, it may be more convenient not to restrict the syntactic constructs
to this form because in some of these inference systems the formulas share some structure with
the weights: E.g., in Bachmair (1988) the formulas are the weights, and in Becker (1994) the
weights restrict the semantics of the formulas by the so-called “reference compatibility”. The
distinction between formulas and syntactic constructs (i.e. formulas augmented with weights) has
the following advantages compared to other inference systems for implicit induction:
No Global Ordering Restriction: Inference steps can be admitted which transform the formula
of a goal into another one which is bigger w.r.t. the induction ordering, cf. Gramlich (1989).
High Quality of Ordering Information: The loss of ordering information during simplification
of a goal (as described above) is avoided, which (as far as we know) was first described in
Wirth (1991), exemplified by a failure of a formal induction proof just caused by this loss
of ordering information. There it is also sketched how to store the weight of the goal to
avoid this information loss, — an idea which is also found in Becker (1993b) and Fraus
(1994)92.
91when the induction ordering contains the evaluation ordering of the functional definitions of the specification,
cf. Walther (1994)
92Note, however, that in Fraus (1994) the weight of a goal is not directly attached to the goal but to each hypothesis
in the set of hypotheses that is attached to this goal. Moreover, each time a goal is copied into the set of hypotheses
attached to it, the goal gets a new weight for this hypothesis, namely the identity substitution on its variables. When
a hypothesis is applied to the goal to that it is attached, then the matching substitution has to be strictly smaller than
the weight of the goal for this hypothesis. Note that this weight may be different from the identity substitution then
because the substitutions applied to the goal are also applied to the weights stored with its hypotheses.
106
Example 12.2 (continuing Example 12.1)
For the soundness of the induction proof of Example 12.1 we have to find a wellfounded
ordering in which the instance of the induction hypothesis (1) of Example 12.1 via the
substitution {l 7→rc(y, l)}, i.e. (omitting the weight)
(Inst.Hyp.) br(k,cons(x, rc(y, l)))=cons(x,br(k, rc(y, l))), mbp(x, rc(y, l))= true
is (strictly) smaller than the goal (1.2.1.1.2) of Example 12.1 to which it is applied, i.e.
(1.2.1.1.2) x=y, br(k,cons(x, rc(y, l)))=cons(x,br(k, rc(y, l))),
mbp(x, l)= true
If the weight of a formula is the formula itself (regarded as the multi-set of (its literals
considered as the multi-sets of) its terms), this cannot be achieved with a simplification
ordering, whereas the evaluation ordering of (the relevant part of) the specification is a sub-
relation of a simplification ordering, namely the lexicographic path ordering given by the
following precedence on function symbols: mbp% true, false; br % rc% dl≻ cons.
The first thing we can do is to use weight pointers to avoid the deterioration of ordering
information on the way from (1.2) to (1.2.1.1.2) of Example 12.1: Initially we set the weight
pointer of (1) to (1) itself, such that the weight of this formula is this formula itself. The
same holds for (1.2) because when applying the substitution {k 7→cons(y,k)} the weight
is instantiated as well as the formula. During the simplification steps yielding (1.2.1),
(1.2.1.1), and then (1.2.1.1.2) the weight remains unchanged, i.e. the weight of the formula
(1.2.1.1.2) is still the formula (1.2), i.e.
(1.2) br(cons(y,k),cons(x, l))=cons(x,br(cons(y,k), l)), mbp(x, l)= true
Now (Inst.Hyp.) is indeed strictly smaller than (1.2) in the lexicographic path ordering
given by the precedence from above extended with br ≻mbp.
Thus the high quality of ordering information preserved by separating the formula from its
weight when simplifying (1.2) into (1.2.1.1.2), now permits us to justify the application of
(Inst.Hyp.) to (1.2.1.1.2) with a simplification ordering.
Focus on Relevant Ordering Information: Some induction proofs are only possible if we do
not measure the whole formula (as often is the case when a clause is measured as the
multi-set of all its literals) but only some sub-formula, subterm or variable of it. Focus-
ing on certain variables is common for human beings (speaking of “induction on variable
x”, e.g.). While focusing on certain variables (called “measured variables” in Boyer &
Moore (1979) and Walther (1994)) is standard for the mechanisms usually applied inside
the induction rule of explicit induction, a marking concept for focusing in implicit induc-
tion was introduced in Wirth (1991). The more general focusing that can be achieved with
the syntactic constructs here, permits us not to measure those parts of formulas which (due
to unsatisfiable ordering conditions) block the application of useful hypotheses. Thus we
can focus on the literals (or even terms, variables) that do get smaller on their way from
the induction conclusion to the induction hypothesis. This allows additional applications of
induction hypotheses.
107
Example 12.3 (continuing Example 12.2)
The termination argument in Example 12.2 leaves room for improvement. The new pair
in the precedence (i.e. br ≻ mbp) is not at all motivated by the evaluation ordering of our
specification. After all, our proof of Example 12.1 is nothing but a structural induction and
thus should work out without such a sophisticated ordering. When we have a closer look at
the derivation from (1) (or (1.2)) to (1.2.1.1.2) in Example 12.1, then we notice that the first
literal does decrease in the evaluation ordering on the way from our original goal (via the
goal the hypothesis is applied to) to the instantiated hypothesis (Inst.Hyp.) of Example 12.2,
but the second literal does not. Thus, if we focus on the first literal by setting the weight
to it, then we only have to show that the first literal of (Inst.Hyp.) is smaller than the first
literal of (1.2) of Example 12.1 which does not require the unmotivated pair br ≻mbp in
the precedence. Going one step further and setting the weight of (1) of Example 12.1 to the
variable k, the weight of (1.2) and (1.2.1.1.2) of Example 12.1 becomes cons(y,k) which is
trivially greater than the weight k of (Inst.Hyp.).
Easier Design of Inference Rules: The design of concrete inference rules (as sub-rules of the
abstract inference rules in § 12.4 below) becomes simpler because a transformation of the
actual formula does not necessarily include a transformation of its weight (into a smaller
one) and is thus not restricted by superfluous ordering conditions.
Example 12.4 (continuing Example 12.3)
Suppose we want to apply the lemma (Del dl) of Example 5.15 in the proof of a formula
(1) Γ[dl(x, l)]
containing dl(x, l) as a subterm. A Lemma Rewrite with (Del dl) of Example 5.15 trans-
forms (1) into the following two sub-goals:
(1.1) mbp(x, l) 6= true, Γ[dl(x, l)]
(1.2) mbp(x, l)= true, Γ[l]
When we restrict the weight of a formula to be determined by the formula itself, then the
sub-goals (1.1) and (1.2) have to be smaller than (or equal to) (1) (without focusing on
Γ[dl(x, l)]). For (1.2) this might be achieved again by an unmotivated extension of the
precedence on function symbols (given by the evaluation ordering, cf. Example 12.2) with
dl ≻ mbp (additionally to mbp % true ); for (1.1), however, this does not seem to be
reasonably possible in general. Thus the design of an inference rule applying the lemma
(Del dl) in the intended form to (1) has to be very difficult without separate weights because
the step from (1) to (1.1) has to be replaced with a very big inference step bridging over
all steps following in the proof of (1.1) until all branches of this proof have reached a
smaller weight, which contradicts our design goal of § 11.3 that “inference rules should
have a fine grain”. Separating weights from formulas, however, makes the design of such
an inference rule very easy: One just sets the weight of (1.1) and (1.2) to the original weight
of formula (1).
108
All in all, the inference relation ⊢ should operate on proof states which are triples ‘(L,H,G)’ of
finite sets such that L contains formulas (from ‘Form’) and H and G contain syntactic constructs
(from ‘SynCons’) whose formulas may be accessed via the function “ form : SynCons→ Form ”.
While proof states represented by forests of syntactic constructs are more useful in practice, the
simpler data structure presented here suffices for the purposes of this thesis.
12.2 Counterexamples and Validity
For powerful inductive reasoning we have to be able to restrict the test of whether the weight of
a hypothesis is smaller than the weight of a goal (which has to be satisfied for the permission
to apply the hypothesis to the goal) to the special case semantically described by their formulas.
This can be achieved by considering only such instances of their weights that result from ground
substitutions describing invalid instances of their formulas. A syntactic construct augmented
with such a substitution providing extra information on the invalidity of its formula is called a
counterexample. Thus, a syntactic construct whose formula is valid has no counterexamples.
We assume the existence of some class ‘Info’ describing this extra information and require the
induction ordering. to be a wellfounded quasi-ordering not simply on ‘SynCons’ but actually on
‘SynCons×Info’. Furthermore, we require “being a counterexample” to be a well-defined basic
property which has to be either true or false for each (S, I) ∈ SynCons×Info. Finally, to formally
express the relation between counterexamples and our abstract notion of validity, we require the
following:
For each syntactic construct S ∈ SynCons: Its formula ‘form(S)’ is valid iff there is
no I ∈ Info such that (S, I) is a counterexample.
Note that our notion of “counterexample” is a semantic one contrary to the notion of “inconsis-
tency proof” used in Bachmair (1988). Generally speaking, an abstract frame inference system
that is to be fixed prior to the design of concrete inference rules has to be sufficiently stable and
therefore its notions should not rely on our changeable ideas on formal proofs.
Finally note that even with our emphasis on proving valid formulas “positively” (instead of
being refutationally complete), the somewhat negative kind of argumentation with counterex-
amples is handier, somewhat less operationally restricted, and more convenient for defining and
proving properties of practically useful inference systems than the less local formal proofs used
in the positive proving approach of Gramlich (1989) or Reddy (1990).
109
12.3 Groundedness
In this section we move from counterexamples to an even higher level of abstraction. We use the
notion of counterexamples to lift the induction ordering . from “SynCons×Info” to subsets of
‘SynCons’ by explaining what we mean by saying that a set H of hypotheses is founded on a set
G of goals (written HyG) or by saying that a set G of goals is strictly grounded on a set H of
hypotheses (written GցH or HւG). Roughly speaking, HyG indicates that the hypotheses are
known to be valid if a final proof state (i.e. one with an empty set of goals) can be entailed. HւG
indicates that the goals in G can be deleted by the application of smaller hypotheses from H.
On the abstract level we are going to present in this section inductive theorem proving is similar
to building a supporting frame in a swamp by the following operations:
First, we can fix a construction element H to a construction element H ′ on a strictly lower
level of the supporting frame resulting in the construction
H
ց
H ′
for which we also write HցH ′ and which expresses that if H needs some support, then it can
get it from the element H ′ below. In the world of induction this means that if an element of H
has a counterexample, then there is a counterexample for an element of the set H ′ that is strictly
smaller in our induction ordering >.
Second, we can fix a construction element H to a construction element G on the same or lower
level of the supporting frame resulting in the construction
HyG
In the world of induction this means that if an element of H has a counterexample, then there is a
counterexample for an element of G that is smaller or equal in our induction ordering &.
Finally, we can fix a construction element H partly to a construction element G on the same
or lower level and partly to a construction element H ′ on a strictly lower level of the supporting
frame resulting in the construction
HyG
ց
H ′
for which we also write Hց/y(H ′,G). More precisely this means that if H needs some support
it gets it either from G or from H ′ or from both. In the world of induction this means that if an
element of H has a counterexample, then there is a counterexample for an element of either H ′ or
G. Moreover, if this counterexample is from H ′ then it has to be strictly smaller and if it is from
G it has to be equal or smaller than the original counterexample from H in the induction ordering.
110
The basic idea now is the following: If we have a supporting frame of the form ∀i∈N.
HiցHi+1, i.e.
H0
ց
H1
ց
H2
ց
.
.
.
and we know that the swamp is wellfounded (i.e. we get to solid ground everywhere if we only
go deep enough) then we know that H0 is sufficiently supported against sinking which — in the
world of induction — means that all formulas of the elements of the set H0 are inductively valid.
Similarly, if we have a supporting frame of the form ∀i∈N. Hiց/y(Hi+1,Gi+1), i.e.
H0yG1
ց
H1yG2
ց
H2yG3
ց
.
.
.
under the assumption of wellfoundedness we know that H0 can get its support from the elements
Gi alone, i.e. H0y
S
i≻0 Gi, cf. also Corollary 12.12 below.
Returning to the world of induction we now define the relations ‘ց’, ‘y’, and ‘ց/y ’ formally
and then present a complete list of those of their properties that we will need in what follows.
Definition 12.5 (Groundedness)
Let M,H,G ⊆ SynCons. Let ‘ց/y’ be a symbol for a single relation. Now M is said to be
strict/quasi-grounded on (H,G) (denoted by Mց/y(H,G) ) if
∀S∈M. ∀I∈ Info.
((S, I) is a counterexample) ⇒
∃S′∈H ∪G. ∃I′∈ Info.

((S′, I′) is a counterexample)
∧

(
S′∈H
∧ (S, I)>(S′, I′)
)
∨
(
S′∈G
∧ (S, I)&(S′, I′)
)


.
M is said to be strictly grounded on H (denoted by MցH or HւM) if Mց/y(H, /0).
M is said to be (quasi-) founded on G (denoted by MyG) if Mց/y( /0,G).
Note that (for S ∈ SynCons) the expressive power of “ {S}ց/y . . . ” is higher than that of
“ {S}ց . . . ” and “ {S}y . . . ” together, since “ {S}ցH ∨ {S}yG ” implies “ {S}ց/y(H,G) ”,
but the converse does not hold in general.
111
Corollary 12.6 Let H ⊆ SynCons. Now each of the following seven properties is logically
equivalent to validity of form[H]:
(1) Hy /0
(2) Hց /0
(3) HցH (due to
wellfoundedness of >)
(4) ∀G⊆SynCons. HyG
(5) ∀G⊆SynCons. HցG
(6) ∃G⊆SynCons. ((form[G] is valid ) ∧ HyG)
(7) ∃G⊆SynCons. ((form[G] is valid ) ∧ HցG)
Corollary 12.7 Let H ⊆ G⊆ SynCons. Now: /0ցHyG.
Corollary 12.8 The following four inclusion-properties hold:
ց⊆y. ց◦y⊆ց. y◦ց⊆ց. Mց/y(H,G)⇒ MyH∪G.
Corollary 12.9
(1) M ց/y (H,G) ∧ M′ց/y (H ′,G′) ⇒ M∪M′ ց/y (H∪H ′,G∪G′)
(2) M∪M′ ց/y (H,G) ⇒ M ց/y (H∪H ′,G∪G′)
(3) G ց H ⇒ G ց H\G
Note that the last item of the previous as well as the first item of the following corollary rely on
the wellfoundedness of >.
Corollary 12.10
(1) Mց/y(H,G) ∧ HyG∪M ⇒ M y G
(2) Mց/y(H,G) ∧ Gց/y(H ′,G′) ⇒ Mց/y(H∪H ′,G′)
Corollary 12.11 y is a quasi-ordering on the set of all subsets of ‘SynCons’.
Note that the two situations of the following corollary were illustrated above.
Corollary 12.12
ց is a transitive relation, which is neither irreflexive nor generally reflexive.
Let ∀i∈N. Hi, Gi ⊆ SynCons. Then (by the wellfoundedness of >)
∀i∈N. HiցHi+1 implies that form[Hk] has to be valid for all k ∈ N. More generally,
∀i∈N. Hiց/y(Hi+1,Gi+1) implies Hky
S
j≻k G j for all k ∈ N. Moreover, the restriction of
ց to those H ⊆ SynCons with invalid form[H] is a wellfounded ordering.
112
12.4 The Frame Inference System
We now present four abstract inference rules defining ⊢ . Thus, in this and the following three
sections, ⊢ will be restricted to applications of one of the four following inference rules.
In what follows, let Γ ∈ Form; S ∈ SynCons; L, L′ be finite subsets of ‘Form’; and H, H ′, G,
G′, and M be finite subsets of ‘SynCons’:
Expansion: (L ,H ,G )
(L ,H ,G∪{S} )
Hypothesizing: (L ,H ,G )
(L ,H ∪{S} ,G ) if L is invalid or {S}yH∪G
Acquisition: (L ,H ,G )
(L∪{Γ} ,H ,G ) if L is invalid or Γ is valid.
Deletion: (L ,H ,G∪{S} )
(L ,H ,G ) if L is invalid or {S}ց/y(H,G)
The Expansion rule has two typical applications. The first one introduces sub-goals for a goal
that is to be deleted, cf. the Transformation rule below. The second one is the very difficult task
of introducing new conjectures that are needed for the whole induction proof to work.
The Hypothesizing rule makes a new hypothesis S available for the proof. Since forward
reasoning on hypotheses is hardly required, it can usually be restricted to the following sub-rule
(cf. Corollary 12.7) which just stores the goals in the set of hypotheses. This storing is indeed
necessary because these goals usually have been transformed before the hypotheses derived from
them become useful for inductive reasoning.
Memorizing: (L ,H ,G∪{S} )
(L ,H ∪{S} ,G∪{S} )
The Acquisition rule makes a new lemma Γ available for the proof. The rule may be used to
include axioms from the specification or formulas proved in other successful runs of the inference
system or by any other sound prover which seems appropriate for some special purposes.
113
The Deletion rule permits the deletion of a goal that is strictly grounded on some hypotheses.
While we cannot go into details here on how to find this out, the Deletion rule especially permits
us to remove a goal if its formula is implied by the formula of an instance of a hypothesis and
this instance is smaller than the goal in our induction ordering. More frequently, however, is the
Deletion rule used in the following combination with several preceding Expansion steps:
Transformation: (L ,H ,G∪{S} )
(L ,H ,G∪M ) if L is invalid or {S}ց/y(H,G∪M)
The Transformation rule replaces a goal S with a (possibly empty) set M of sub-goals whose
completeness may rely on hypotheses from H or lemmas from L. It is the most often applied rule
of the frame inference system. The intended design of concrete inference systems for specific
kinds of validity mainly consists in finding appropriate sub-rules of the Transformation rule. The
Transformation rule has the following technical property which is rather useful for constructing
new sub-rules of it from already given sub-rules of it. It is a restricted kind of transitivity of the
Transformation rule and a corollary of corollaries 12.11, 12.9(1), and 12.10(2):
Corollary 12.13
If
(L ,H ,G ∪ {S} )
(L ,H ,G ∪ G′ ∪ {S′} )
and
(L ,H ,G ∪ G′ ∪ {S′} )
(L ,H ,G ∪ G′ ∪ M )
are both applications of the Transformation rule in the sense that L is invalid or both
{S}ց/y(H,G∪G′∪{S′})
and
{S′}ց/y(H,G∪G′∪M) ,
then, due to L being invalid or
{S}ց/y(H,G∪G′∪M) ,
also the following inference is an application of the Transformation rule:
(L ,H ,G ∪ {S} )
(L ,H ,G ∪ G′ ∪ M )
In the following sections we will present two alternative approaches to explaining why the above
inference system implements the ideas presented at the beginning of § 12.1. The first is called
“analytic” because it is based on an invariance property that holds for an initial proof state and
is kept invariant by the analytic inference steps. The second is called “backwards” because it is
based solely on an invariance property which holds for a final (i.e. successful) proof state and is
kept invariant when one applies the inference rules in backward direction.
114
12.5 The Analytic Approach
The analytic approach was first formalized in Wirth (1991). In § 12.1 we indicated that if ⊢
permits sound steps only, then from “ ( /0, /0,G) ∗⊢ (L,H, /0) ” we may conclude that G is valid. This
idea is formalized in:
Definition 12.14 (Soundness of Inference Step)
The inference step “ (L,H,G) ⊢ (L′,H ′,G′) ” is called sound if validity of ‘form[G′]’ implies
validity of ‘form[G]’.
Corollary 12.15 If all inference steps in “ (L,H,G) ∗⊢ (L′,H ′, /0) ” are sound, then ‘form[G]’ is
valid.
Besides the soundness of an inference step described above, it is also useful to know about in-
variant properties of a proof state because they can be used to justify why an inference step is
sound. The following such property is most natural, stating that all lemmas are valid and that the
hypotheses are founded on the goals, i.e. that for each counterexample for a hypothesis there is a
smaller counterexample for a goal.
Definition 12.16 (Correctness of Proof State)
A proof state (L,H,G) is called correct if L is valid and HyG.
The first part “L is valid” of this definition should be immediately clear. For understanding the
idea behind the second part “ HyG ” the reader should remember the following: The goals in the
set G carry the proof work in the sense that the proof is finished when we have removed all of them
in a sequence of sound inference steps. The hypotheses in H are useful tools for transformation
and deletion of these goals. For the soundness of these hypotheses application steps, however,
we have to know that these hypotheses are not arbitrary, but chosen in such a way that the goals
do not only carry their own proof work but also the proof work for the hypotheses. This is
expressed by “ HyG ”. Since the deletion of the goals with the hypotheses essentially requires
GցH (cf. the condition of the Deletion rule), after this deletion we have GցHyG, i.e. GցG
by Corollary 12.8, and then all formulas in G are valid by Corollary 12.6(3). Using the notion
of counterexamples this idea can be explained the following way: Since the deletion of a goal
essentially requires that for each of its counterexamples there is a strictly smaller counterexample
of a hypotheses, when for each counterexample of a hypotheses there is an equal or smaller
counterexample of a goal, then minimal counterexamples of goals cannot be deleted in this way.
While “correctness of proof states” obviously formulates this idea, it is not the only possible
way to do it:
Definition 12.17 (Weak Correctness of Proof State)
A proof state (L,H,G) is called weakly correct if
L is valid and (HւG ⇒ ( form[H] is valid)) .
By the corollaries 12.8 and 12.6(3) we get:
Corollary 12.18 If a proof state is correct, then it is weakly correct, too.
115
As announced above, correctness of proof states really permits us to conclude that the inference
steps of our frame inference system are sound:
Lemma 12.19 (Soundness of Inference Steps)
If (L,H,G) is a [weakly] correct proof state, then an inference step
“ (L,H,G) ⊢ (L′,H ′,G′) ” (with the above rules) is sound.
Furthermore, correctness holds indeed for an initial state and is kept invariant by the frame infer-
ence system:
As a corollary of corollaries 12.7 and 12.18 we get:
Corollary 12.20 (Initial State is Correct)
Let L be valid and H ⊆ G. Now (L,H,G) is [weakly] correct.
Lemma 12.21 (Invariance of Correctness of Proof States)
If “ (L,H,G) ⊢ (L′,H ′,G′) ” (with the above rules) and the proof state (L,H,G) is [weakly]
correct, then ‘(L′,H ′,G′)’ is [weakly] correct, too.
Finally, “correctness of proof states” as an invariance property is not only useful to conclude
soundness of single steps, but also globally useful, which can be seen in the following corollary
stating that the lemmas and hypotheses gathered in a final proof state are valid:
As a corollary of the corollaries 12.7, 12.6(1), and 12.18 we get:
Corollary 12.22 (For Final State: Correctness means Validity)
(L′,H ′, /0) is [weakly] correct iff “ L′∪ form[H ′] ” is valid.
116
12.6 The Backwards Approach
The backwards approach was first formalized in Becker (1994).
Definition 12.23 (Inductiveness and Inductive Soundness)
A proof state (L,H,G) is called inductive if ((L is valid) ⇒ HւG).
The inference step “ (L,H,G) ⊢ (L′,H ′,G′) ” is called inductively sound93 if inductiveness of
(L′,H ′,G′) implies inductiveness of (L,H,G).
Inductiveness is a technical notion abstracted from inference systems similar to the frame infer-
ence system of § 12.4. Roughly speaking, inductiveness of a state means that an inductive proof
of it is possible in the sense that a final (i.e. successful) proof state can be entailed. This is be-
cause all goals can be deleted with the Deletion rule, since there are either false lemmas (ex falso
quodlibet) or false hypotheses below all invalid goals.
Inductive soundness can replace soundness of proof steps, by the following argument, which
(just like soundness) requires to think ⊢ backwards, starting from a final proof state (L′,H ′, /0),
which is always inductive. Now, if the steps deriving a final state are inductively sound, then all
states involved are inductive. Finally, inductiveness of an initial state implies validity of the initial
set of goals.
As a corollary of Corollary 12.7 we get:
Corollary 12.24 (Final States are Inductive) (L′,H ′, /0) is inductive.
By Corollary 12.6(5) for the forward and by the corollaries 12.7, 12.8 and 12.6(3) for the back-
ward direction we get:
Corollary 12.25 (For Initial State: Inductiveness means Validity of Goals)
Let L be valid and H ⊆ G. Now, ‘form[G]’ is valid iff (L,H,G) is inductive.
By the corollaries 12.24 and 12.25 we conclude:
Corollary 12.26 If all inference steps in “ ( /0, /0,G) ∗⊢ (L′,H ′, /0) ” are inductively sound, then
‘form[G]’ is valid.
Indeed, we have:
Lemma 12.27 (Inductive Soundness of Inference Steps)
An inference step with the above rules is inductively sound.
Unlike soundness, inductive soundness also captures the basic idea of our frame inference system
which for the analytic approach had to be expressed by some correctness property, namely the
idea that transformations of goals may make use of hypotheses which are smaller than the goal
itself since minimal counterexamples for goals can never be deleted that way. Note, however,
that “being not inductive” is no invariance property of ⊢ (like correctness is) because one never
knows whether it holds for some state or not: If all steps are inductively sound, we only know
that the property of “being not inductive” is never removed by an inference step, but this does
not mean that it ever holds. Especially for successful proofs it never does, cf. Corollary 12.24.
Instead, inductiveness (i.e. “being inductive”) is an invariance property of ⊣ .
93In Becker (1994) this is called preservation of (inductive) counterexamples, but we cannot use this name here
because the notion of “counterexample” is different there.
117
12.7 Results of the Two Approaches
While the relation between the two approaches of the previous two sections is not simple, both
seem to be equally useful in capturing the ideas presented in the beginning of § 12.1 as well as in
explaining the soundness of our inference system: The following is a
corollary of 12.15, 12.19, 12.20, & 12.21, as well as independently a corollary of 12.26 & 12.27:
Corollary 12.28 (Soundness of “ ( /0, /0,G) ∗⊢ (L′,H ′, /0) ”)
If “ ( /0, /0,G) ∗⊢ (L′,H ′, /0) ” (with the above rules), then “ form[G] ” is valid.
The analytic approach even permits a slightly stronger conclusion via Corollary 12.22:
Corollary 12.29 If “ ( /0, /0,G) ∗⊢ (L′,H ′, /0) ” (with the above rules), then
“ form[G]∪L′∪ form[H ′] ” is valid.
Considering the design of concrete inference systems by presenting sub-rules of the frame infer-
ence rules, another advantage of the analytic approach could be that the additional assumption of
correctness of the states could be essential for the sub-rule relationship.
The rest of this section is rather sophisticated and the reader should continue with the next
section unless he is really interested in the details of the comparison of the analytic and the back-
wards approach independently of our frame inference system. Here, we consider one approach
to be superior to the other when it permits additional successful proofs, whereas we do not re-
spect the fact that one notion may be more appropriate for effective concretion than the other.
Invariance of correctness cannot be superior to invariance of weak correctness or to inductive
soundness, since a step with the former and without one of the latter properties starts from an
invalid set of goals and thus the required soundness of inference steps does not permit additional
proofs. Invariance of weak correctness cannot be superior to invariance of correctness (inductive
soundness), since a step with the former and without one of the latter properties leads to (starts
from) an invalid set of goals and thus the required soundness of inference steps does not permit
additional proofs. Finally, inductive soundness is very unlikely to be superior to invariance of
[weak] correctness, since a step with the former and without one of the latter properties leads to
an invalid set of lemmas or hypotheses. Moreover, if we do not consider all proofs but only the
existence of proofs, then (on our non-effective level!) all approaches are equivalent: Using the
Deletion rule |G| -times we get:
Corollary 12.30 (Completeness of “ ( /0, /0,G) ∗⊢ (L′,H ′, /0) ”)
If “ form[G] ” is valid, then “ ( /0, /0,G) ∗⊢ ( /0, /0, /0) ” (with the above rules).
Note, however, that (as far as we know) for the construction of effective concrete inference sys-
tems based on rules which are no (effective) sub-rules of the rules of our frame inference system,
each of the three approaches (i.e.: soundness and invariance of correctness; soundness and invari-
ance of weak correctness; inductive soundness) could be superior to each of the others. The same
may be the case for generalizing them to inference systems on generalized proof states. E.g., for
Parallelization: (L,H,G∪G
′)
(L,H,G) (L,H,G′)
it is obvious how to generalize inductive soundness, whereas the two other approaches do not
seem to permit an appropriate generalization based on local properties of triples (L,H,G). To
118
achieve parallelization for the correctness approach, we have to replace G with a family of sets
Gh (initially G = ({h})h∈H) such that correctness means that L is valid and, for each h ∈ dom(G),
we have {h}yGh. Similarly, for the weak correctness approach, we have to change the defi-
nition of weak correctness to: L is valid and, for each h ∈ dom(G), we have (HւGh ⇒
( form(h) is valid )).
12.8 The “Switched” Frame Inference System
In § 12.1 we pointed out that we have to avoid non-terminating reasoning cycles between hypo-
theses and goals. In our formalization we achieved this by founding a hypothesis S′ on smaller
or equal goals from G, i.e. “ {S′}yG ” (cf. the condition of the Hypothesizing rule), and by
applying to a goal S only strictly smaller hypotheses from H, i.e. “ {S}ցH ” (cf. the condition
of the Deletion rule). From a cyclic reasoning “ HyGցH ” we immediately get “ HցH ” and
“ GցG ” by Corollary 12.8, and then ‘form[H∪G]’ is valid by Corollary 12.6(3), which means
that the reasoning cycle is sound. Now an alternative way to achieve this is the following: In-
stead of doing our quasi-decreasing step ‘y’ from hypotheses to goals “ HyG ” and our strictly
decreasing step ‘ց’ from goals to hypotheses “ GցH ”, we could go from hypotheses to goals
with a strict and from goals to hypotheses with a quasi step. More precisely: The condition of
the Hypothesizing rule would be changed into “ if L is invalid or {S}ց/y(G,H) ”, and the
condition of the Deletion rule into “ if L is invalid or {S}yG∪H ”. The Expansion and the Ac-
quisition rules remain unchanged. A Memorizing rule cannot exist and the Transformation rule
is composed of several Expansions, possibly followed by a Hypothesizing, and then a Deletion
into one of the following forms:
Memorizing Switched Transformation:
(L ,H ,G∪{S} )
(L ,H ∪{S} ,G∪M ) if L is invalid or {S}ց/y (G∪M,H)
Simple Switched Transformation:
(L ,H ,G∪{S} )
(L ,H ,G∪M ) if L is invalid or {S}yG∪M∪H
We then also have to switch ‘y’ and ‘ց’ (i.e. replace one by the other) in the definitions of
“correctness” and “inductiveness”. Finally, we have to restrict any initial state (L,H,G) not only
by requiring its lemmas L to be valid and its hypotheses H to be contained in its set of goals G
(cf. corollaries 12.20 and 12.25) but also by actually requiring H to be empty (as we already did
in corollaries 12.28 and 12.29). After these little changes and restrictions, we analogously get the
results of § 12.7 for the soundness also of the switched frame inference system.
The reasons why we prefer the non-switched version presented here are the following:
From a user’s point of view, the non-switched version may be more convenient, because
hypotheses become available earlier and easier via the Memorizing rule, which cannot exist for
the switched version.
119
From the inference system designer’s point of view, the non-switched version is more conve-
nient, due to the following argumentation: With both the switched and the non-switched version
of the inference system, a proof can be thought to consist mainly of steps of the kind that a
goal S may become available as a hypothesis and is then transformed into sub-goals M. For
the non-switched case this can be achieved by an application of the Memorizing and then of
the Transformation rule. For the switched inference system this is just a Memorizing Switched
Transformation. The shortcoming of the Memorizing Switched Transformation is that the trans-
formation of a goal into sub-goals has to be strictly decreasing instead of quasi-decreasing (as
required for the non-switched case). The design of quasi-decreasing transformations, however,
is easier than that of strictly decreasing ones, for the same reason as exhibited in § 12.1 (“Easier
Design of Inference Rules”): The solution suggested in Example 12.4 for making (1.1) smaller
than (1) (namely to set the weight of (1.1) to the weight of (1)) does not solve the problem for the
Memorizing Switched Transformation where (1.1) has to be strictly smaller than (1). Therefore,
the non-switched inference system admits fine grain inference steps (which is one of our design
goals of § 11.3), which in the switched system have to be replaced with a very big inference step
bridging over all quasi-decreasing steps until a strictly decreasing step is reached. Moreover, each
simplification step with the Memorizing Switched Transformation rule has to decrease the weight
of the goal strictly, such that the possibility to apply some fixed smaller hypothesis gets more and
more unlikely with each simplification step, cf. § 12.1 (“High Quality of Ordering Information”),
esp. Example 12.2. If we, however, use the Simple Switched Transformation instead, then the
goal is not made available as a hypothesis. Thus, not to lose the possibility to apply a hypothesis,
simplification should not be done via inference steps of the switched inference system, but in-
corporated into the hypotheses applicability test. With the non-switched version, however, the
power of the whole inference system can be homogeneously used for simplification, as required
by our design goals of § 11.3. Finally, the required decision whether to apply the Memorizing or
the Simple Switched Transformation rule does not comply with our design goal of a “natural flow
of information”, cf. § 11.3.
On the other hand, the comparison of weights for an applicability test of a hypothesis to a goal is
simpler in the switched inference system because there the weight of the hypothesis is often equal
to the weight of the goal, in which case the test is successful. While this does not allow for ad-
ditional proofs with the switched inference system, it may avoid possibly complicated reasoning
on ordering properties.
120
12.9 Related Work
In this section we give a sketch of the literature on inference systems for implicit induction and
briefly classify these inference systems according to our presentation here.
In Bachmair (1988) our sets of hypotheses and goals are not separated yet. A disadvantage of
this is that a success of a proof due to an empty set of goals is more difficult to detect and that un-
derstanding the inference system gets more difficult without the concepts of hypotheses and goals.
The missing separation into hypotheses and goals also requires both the groundedness step from
hypotheses to goals (as in our switched system of § 12.8) and the step from goals to hypotheses
(as in the non-switched system of § 12.4) to be strictly decreasing (i.e. ‘ց’), which means a com-
bination of the disadvantages of both the switched and the non-switched approach. The soundness
of Bachmair’s inference system results from the fact that a fair derivation sequence Mi ⊢Mi+1
(i∈N) always satisfies MiyMi+1 and has a sub-sequence such that ∀i∈N. M jiցM ji+1 , which
implies that ‘form[M0]’ is valid, cf. corollaries 12.12, 12.11, and 12.6(6). The groundedness re-
lations are defined by use of sizes of inconsistency proofs for the equations in Mi instead of the
counterexamples themselves. As already mentioned in § 12.2, it is in general undesirable to base
the notions of a frame inference system on formal proofs instead of semantic notions because the
latter impose no operational restrictions and are likely to change less frequently. One of the op-
erational restrictions in Bachmair (1988) is the (ground) confluence requirement for the defining
rules. That this restriction can be removed was noted in Gramlich (1989) by defining the groun-
dedness relations by use of the sizes of positive proofs measured via the applications of equations
from Mi.
The important separation between hypotheses and goals was introduced in Reddy (1990),
where a frame inference system similar to our switched one in § 12.8 is used, the argumentation
for soundness follows the analytic approach using operationally restricted versions of soundness
and (switched) correctness, and the groundedness notions are still the operationally restricted
ones of Gramlich (1989). In Wirth (1991) this operational restriction is overcome by using a
semantic groundedness notion.
In Fraus (1993) we have found the first94 argumentation for soundness following the back-
wards approach. While the inference system already is of the (superior) non-switched style, the
groundedness relations are still operationally restricted (by measuring positive proofs in the natu-
ral deduction calculus) — a restriction that is overcome in Fraus (1994). In Becker (1994) we
finally find the backwards approach based on semantic groundedness notions as presented here.
94This actually goes back to an unpublished manuscript of the year 1988 by Alfons Geser at the University of
Passau entitled “An inductive proof method based on narrowing”.
121
12.10 Safe Steps and Failure Recognition
As already mentioned in § 11.2 the ability of an inductive theorem prover to detect invalid for-
mulas is important under a practical aspect; especially for inductive theorem proving because of
the important role generalizations play in it: An invalid formula can result from a valid input
theorem due to over-generalization. The following notions are useful for the discussion of failure
recognition and refutational completeness (cf. A):
Definition 12.31 ( Validity of a State / Safeness of Inference Steps and Rules )
A proof state (L,H,G) is valid if L∪ form[H ∪G] is valid.
The inference step “ (L,H,G) ⊢ (L′,H ′,G′) ” is safe if 95
validity of (L,H,G) implies validity of (L′,H ′,G′).
An inference rule is safe if it describes only safe inference steps.
It is not reasonable to require all possible steps of an inductive theorem prover to be safe, since
this property is undecidable for generalization steps which play a major role in inductive theo-
rem proving. For concrete inference systems, however, it is usually possible to give interesting
sufficient conditions for the application of an inference rule to be safe.
The following is a corollary of Corollary 12.6(6) [and Corollary 12.8]:
Corollary 12.32 The [Switched] Hypothesizing, Acquisition, [Switched] Deletion, and Memo-
rizing rules are safe.
Note that the Expansion rule and its derivatives (i.e. the Transformation, Memorizing Switched
Transformation, and Simple Switched Transformation rule) are unsafe in general. Nevertheless,
nearly all sub-rules of the Transformation rule we will present in the following sections will be
safe.
Since it is undecidable in general whether a proof state is invalid, regarding the operationalization
of invalidity of proof states we had better content ourselves with some incomplete failure pred-
icate ‘FAIL’ defined on sets96 of formulas, which should be sound in the following sense (note
that we write “F ∈FAIL” when FAIL holds for the set F of formulas):
Definition 12.33 (Soundness of a Failure Predicate)
The failure predicate ‘FAIL’ is sound if ∀F∈FAIL. (F is invalid).
95Note that if we excluded the set L from the definition of validity of a state and from the definition of safeness,
then Corollary 12.32 and the lemmas 14.12 and 14.16 would not hold any more because all rules whose safeness is
stated there (with the exception of the Memorizing rule) would become unsafe in general. Moreover, if we excluded
the sets H and H ′ from the definition of safeness, then the Hypothesis Apply and the Hypothesis Rewrite rule would
become unsafe, contrary to what is stated in the lemmas 16.8 and 16.12.
96Note that this failure predicate is defined on sets of formulas for operational reasons, namely to be able to
recognize that one formula contradicts another one; whereas for a theoretical treatment it would be sufficient to
define it on single formulas since one of those formulas has to be invalid in a consistent specification; but to find out
which formula it is is undecidable in general.
122
Definition 12.34 (Failure State)
A proof state (L,H,G) is a failure state (w.r.t. FAIL) if 97
(L∪ form[H ∪G]) ∈ FAIL.
Corollary 12.35 If all inference steps in “ (L,H,G) ∗⊢ (L′,H ′,G′) ” are safe and (L′,H ′,G′) is a
failure state w.r.t. a sound failure predicate, then (L,H,G) is invalid.
Now, when an inductive theorem prover has realized that a proof state (L′′,H ′′,G′′) is a failure
state, the following questions arise: How far do we have to backtrack its derivation to reach a
valid state? Was our original state valid? To recover from this failure (after setting (L′,H ′,G′) to
(L′′,H ′′,G′′)) we may iterate the following:
If this (L′,H ′,G′) is the original input state (with L′ known to be valid and H ′⊆G′),
then we have refuted our original set of goals G′ and should stop proving. Other-
wise the step that yielded (L′,H ′,G′), say (L,H,G) ⊢ (L′,H ′,G′) , has to be carefully
inspected: If it is known to be safe we backtrack this step (setting (L′,H ′,G′) to
(L,H,G)) and reiterate. Otherwise it might be possible to find a (minimal) subset
of L′′ ∪ form[H ′′∪G′′] for which the failure predicate FAIL is still known to hold
and which also is (implied by) a subset of L∪ form[H ∪G]; in which case we also
backtrack this step (setting (L′,H ′,G′) to (L,H,G)) and reiterate. Otherwise, when
(L,H,G) ⊢ (L′,H ′,G′) is likely to be an unsafe step which might have caused the in-
validity, we backtrack this step and may try to go on with a hopefully safe inference
step from (L,H,G) instead.
Note that the notion of safeness becomes even more useful for detecting invalid states when
(instead of representing our goals by an unstructured set) we use the obvious structure of a forest
for our goals which is standard for sequent calculi in the style of Gentzen (1935) and which is
indicated in our examples via the labels of the goals.
13 Towards the Concrete Inference System
In this section we will concretize the abstract notions and the frame inference system of § 12 to
obtain the more concrete inference system for proving inductive validity we want to present in
this thesis. More precisely, we will concretize the classes ‘Form’, ‘SynCons’, ‘Info’, ‘form’, the
notions of “counterexample” and “validity”, and the induction ordering.
Finally in this section, we will complete our technical prerequisites by explaining how to
handle generalized substitutions and superposition of rules into terms.
97Note that we have included L and H (instead of just testing G) on the one hand to match Definition 12.31 (Why
this definition includes L and H is explained in footnote 95) and on the other hand because we want to be able to
detect an invalid lemma or hypothesis when it has just been generated and do not want to have to wait until it will
have been harmfully applied to a goal. One is tempted to argue that, in case of [weak] correctness of a proof state, an
invalid hypothesis implies the existence of an invalid goal, but this argument again does not respect the operational
aspect, i.e. that a decidable failure predicate cannot be complete in general.
123
The set ‘Form’ of formulas is instantiated to the set ‘Form(sig,V)’, cf. Definition 5.13. The set
‘SynCons’ of syntactic constructs and the class ‘Info’ of extra information are instantiated as in
Definition 10.7. The function “ form : SynCons→ Form ” is simply given by “ form((Γ,ℵ)) := Γ
”.
Counterexamples are instantiated according to Definition 10.7.
Next we have to specify what kind of validity we are going to show. While our formulas
are well-suited for proving ground confluence (cf. Becker (1993b), Becker (1994), or Becker
(1996)), we want to restrict ourselves here to the case of inductive validity, assuming that a ground
confluent rule system is given:
Global Requirement 13.1
R is a Def-MCRS over sig/cons/V.
−→R, /0 is confluent. Moreover, in the D-case, we require that even −→R,VSIG is confluent.
The exclusion of inductive validity of the types A and B as discussed in § 10.4 is captured by the
following:
Global Requirement 13.2
K is a sub-class of the class of C :cons-term-generated sig/cons-models of R.
Note that this requirement is satisfied for the B′-, C-, D′-, D-, and E-case (cf. Definition 10.1);
whereas it excludes the cases A and B. To get a feeling that this is not a severe exclusion, note
that all formulas of Example 5.15 are type-C inductively valid w.r.t. R5.12.
Finally, it is important to note that according to Corollary 10.8 the essential requirement for
the relation between validity and counterexamples of § 12.2 is indeed satisfied for the B′-, C, D′-,
D-, and E-case.
124
13.1 The Induction Ordering
The weight ℵ of a syntactic construct (Γ,ℵ) is intended to augment the formula Γ with additional
structure for expressing ordering conditions to avoid non-terminating cycles in the inductive ar-
gumentation. The connection between a formula and its weight can be established via common
(implicitly universally quantified) variables. Some of our inference steps will apply some sub-
stitution to the formula. In this case the connection between a formula and its weight can be
preserved only if the substitution is applied to the weight as well. Therefore the following is
appropriate:
Global Requirement 13.3
Let Y be a set of variables. Each weight ℵ has associated with it a certain finite set V (ℵ) of
input variables. The set of weights over the set of variables Y is defined as
Weight(Y) := { ℵ | ℵ is a weight with V (ℵ)⊆Y }.
Furthermore, there must be some function which maps each ℵ ∈ Weight(V) and µ ∈
G EN S UB (V,T ) ∪
S
A ∈KG EN S UB (V,T (VSIGA )) to a weight we just denote by ‘ℵµ’. 98
For such ℵ and µ we require that the new weight ℵµ depends only on the values of µ for the
input variables of ℵ:
µ|V (ℵ) =µ′|V (ℵ) ⇒ ℵµ=ℵµ′.
Moreover, we require that ℵµ has its input variables among the variables of the terms replaced
for the input variables of ℵ:
∀ℵ∈Weight(V). ∀µ∈G EN S UB (V,T ). V (ℵµ)⊆ V (µ[V (ℵ)]).
Since inference rules must be able to apply generalized substitutions to syntactic constructs, the
result of applying a “syntactic” generalized substitution to a syntactic construct has to be a syn-
tactic construct again. Therefore, it is important that, according to Global Requirement 13.3,
Weight(V) is closed under G EN S UB (V,T ):
∀ℵ∈Weight(V). ∀µ∈G EN S UB (V,T ). ℵµ∈Weight(V).
On the other hand, also according to Global Requirement 13.3, the application of substitutions
from G EN S UB (V,T (VSIGA )), which in our context play the “semantic” role of valuations,
results in a weight with input variables from VSIGA :
∀ℵ∈Weight(V). ∀A ∈K. ∀µ∈G EN S UB (V,T (VSIGA )). ℵµ∈Weight(VSIGA ).
This is important because (according to the following requirement) it means that the “semanti-
cally” instantiated weights are in the field of the wellfounded quasi-ordering .A associated with
each sig/cons-algebra A , which was used in § 6 to define the validity of a <-literal (i<ℵ) in A .
Global Requirement 13.4
Each sig/cons-algebra A ∈ K is associated with a wellfounded quasi-ordering .A on
Weight(VSIGA ).
98Cf. § 10.4 for the meaning of T (VSIGA ).
125
The following requirement says that the result of applying two substitutions (one after the other)
to a weight is equivalent to the result of applying the product of the two substitutions in a single
step. This is necessary for the soundness of inference steps that apply substitutions to syntactic
constructs (cf. e.g. § 16.1) or to formulas containing <-literals.
Global Requirement 13.5
For each (τ,A ) ∈ Info; µ ∈ G EN S UB (V,T ); and i ∈Weight(V); we require
(iµ)τ≈A i(µτ).
When the above requirements are satisfied, we can now concretize our induction ordering in the
following way:
Definition 13.6 (Induction Ordering)
The induction ordering ‘.’ is given as follows (for two counterexamples ((∆,i),(pi,B )) and
((Γ,ℵ),(τ,A )) ):
((∆,i),(pi,B )). ((Γ,ℵ),(τ,A )) if B =A and ipi.A ℵτ.
Now it is time to point out two important aspects of our induction ordering and the way we assign
semantics to <-literals:
• We can freely choose .A to be any binary relation as long as it only satisfies Global Re-
quirement 13.4. Thus, while the interpretation of the universes A ς,s ((ς,s)∈{SIG,C }×S)
and function symbols f A ( f ∈F) is globally fixed (for each sig/cons-algebra A ) and of uni-
versal character, the association of a wellfounded quasi-ordering .A with A is local to
each single induction proof, and thus may change from proof to proof. We only have to
guarantee that for each proof and for each A ∈K there exists a wellfounded quasi-ordering
.A on Weight(VSIGA ). Moreover, this quasi-ordering .A has to satisfy possible addi-
tional restrictions expressed in the applicability conditions of the inference rules applied
in this induction proof. E.g., an inference rule may require the induction ordering to be
semantic, cf. Definition 13.7 below.
• When the syntactic form of substitutions applied to weights remains recognizable in the
instantiated weights, the induction ordering can depend on the syntactic form of the instan-
tiations of weights. More precisely, the comparison of the two counterexamples of Defini-
tion 13.6 can depend on the syntactic form of the substitutions pi and τ, such that even in
case of equality of i and ℵ (i.e. i=ℵ) and semantic equality of pi and τ (i.e. τA ιA =piA ιA )
it is possible that ipi<A ℵτ holds. Therefore, it is possible to use syntactic orderings
as induction orderings, i.e. we can do “induction on terms”. Note that this treatment of
weights in syntactic constructs is compatible with our definition of validity of <-literals in
Definition 10.5, which enables <-literals to be different from =- and Def-literals, the valid-
ity of whose instantiations does not depend on the syntactic form but only on the semantic
values of the instantiating substitutions, cf. Lemma 6.2.
126
Although the semantics of <-literals can depend on the syntactic form of instantiating substitu-
tions, in a certain state of a proof attempt we may want to do an inference step whose soundness
(or safeness) relies on the condition that the syntactic form of the instantiating substitutions is not
relevant for the induction ordering. This special type of induction ordering is called semantic in-
duction ordering and defined below. It admits additional inference steps in our inference system.
Therefore, the meaning of some of our notions as well as the applicability conditions of some of
our inference rules will depend on the induction ordering being (required to be) semantic or not.
Definition 13.7 (Semantic Induction Ordering)
In case of
∀µ,ν∈G EN S UB (V,T ). ∀τ,pi. ∀A . ∀ℵ∈Weight(V).( (
(τ,A ),(pi,A )∈ Info
∧ (µτA ιA )|V (ℵ) =(νpiA ιA )|V (ℵ)
)
⇒ (ℵµ)τ≈A (ℵν)pi
)
we say that the induction ordering is semantic.
This means that semantic equality of µτ and νpi on the input variables of ℵ implies equivalence
of ℵµτ and ℵνpi in the induction ordering, cf. Global Requirement 13.5.
Due to its fundamental importance for understanding our inference system, we restate that the
case that the “induction ordering is semantic” has the following meaning: Suppose that a proof
contains an application of an inference rule that requires the induction ordering to be semantic.
Then the ordering we may choose for satisfying the ordering conditions represented by the order-
ing literals of the goals has to be a semantic induction ordering, which means that it has to satisfy
the requirement of Definition 13.7 (besides Global Requirement 13.4).
127
In case of a semantic induction ordering the following manipulation of weights becomes reason-
able, which allows us to extend our rewrite relation −→
(l=r) of Definition 5.10 from L I T (sig,V)
to G EN L I T (sig,V) and Form(sig,V).
Definition 13.8 (Weight Rewriting, Literal Rewriting, Formula Rewriting)
Let (l=r) ∈ L I T (sig,V).
We define −→
(l=r) on Weight(V) by (ℵ,ℵ′ ∈Weight(V)):
ℵ−→
(l=r)ℵ
′ if the induction ordering is semantic and
∃k∈Weight(V). ∃µ,µ′∈G EN S UB (V,T ).
ℵ=kµ
∧ ℵ′=kµ′
∧ ∃x∈V (k). ∃p∈POS (xµ).
 xµ/p= l∧ xµ′=xµ[ p← r ]
∧ ∀y∈V (k)\{x}. yµ′=yµ


We extend−→
(l=r) on G EN L I T (sig,V) by defining ((ℵ0<ℵ1),(ℵ′0<ℵ′1)∈G EN L I T (sig,V)):
(ℵ0<ℵ1)−→(l=r)(ℵ
′
0<ℵ′1)
(
(ℵ0<ℵ1)−→(l=r)(ℵ
′
0<ℵ′1)
)
if ∃i≺2.
(
ℵi−→(l=r)ℵ
′
i
∧ ℵ1−i =ℵ′1−i
)
.
Finally, we extend −→
(l=r) to formulas via (Γ,∆ ∈ Form(sig,V); λ,λ′ ∈ G EN L I T (sig,V)):
Γλ∆−→
(l=r)Γλ′∆ if λ−→(l=r)λ′.
As a corollary of definitions 13.7 and 13.8 and Lemma 5.10 we get:
Corollary 13.9
Let (l=r)∈ L I T (sig,V). Let ℵ,ℵ′ ∈Weight(V); and Γ,∆∈Form(sig,V). Assume ((l 6=r),τ,A )
to be a counterexample. Now:
1. If ℵ−→
(l=r)ℵ
′, then ℵτ≈A ℵ′τ.
2. If Γ−→
(l=r)∆, then (Γ,τ,A ) is a counterexample iff (∆,τ,A ) is a counterexample.
128
After completing the definition of our notions for dealing with <-literals, we will close this sec-
tion with the generalization of our Substitution-Lemma for Non-Generalized Literals (Lemma 6.2)
to formulas.
Definition 13.10 (V <(. . .))
We define V <(A), the set of variables occurring in ‘<’-literals of A, in the following way:
V <(A) := /0 for A∈A T (sig,V); V <(k<ℵ) := V (k)∪V (ℵ) for k,ℵ∈Weight(V); and
V <(A) :=V <(A) for A∈G EN A T (sig,V). For the formula λ0 . . .λn−1 we define V <(λ0 . . .λn−1) :=S
i≺nV <(λi).
Lemma 13.11 (Substitution-Lemma for Formulas)
Let µ,ν ∈ G EN S UB (V,T ); (τ,A ),(pi,A ) ∈ Info; and Π ∈ Form(sig,V).
Assume that (µτA ιA )|V (Π) =(νpiA ιA )|V (Π).
Moreover, assume either (µτ)|V <(Π) =(νpi)|V <(Π) or that the induction ordering is semantic.
Now the following two statements are logically equivalent:
• (Πµ,τ,A ) is a counterexample.
• (Πν,pi,A ) is a counterexample.
129
13.2 Generalized Substitutions
Suppose we have shown that addition on natural numbers is commutative. More precisely, that
we have proved the lemma
x+y = y+x
of Example 5.15 where x and y are constructor variables of the sort nat. Now suppose we have to
show the goal
(u+v)+y = y+(u+v)
where u and v are also constructor variables of the sort nat. This seems to be just an instance of
the lemma above, but a more careful look at it reveals that we have to instantiate the constructor
variable x of the lemma with the non-constructor term u+v of the goal which a substitution is not
allowed to do. This is a pity since we also have the lemma (cf. Example 5.15)
Def (x+y)
which means that semantically the above instantiation is sound. Fortunately, generalized substi-
tutions can do the job. To know, however, that a generalized substitution is semantically sound
we must have a careful look at the following set:
Definition 13.12
For a generalized substitution µ we define the variables generalized by µ to be
GENDOM(µ) := { x∈dom(µ) | x∈VC ∧ xµ 6∈T (cons,VC ) }.
The meaning of the following definition is given by the following lemma which shows that the
application of generalized substitutions is sound when they are justified semantically and the
weights are treated with special care. As the reader may guess from Lemma 13.11, it is not possi-
ble to apply a generalized substitution directly to a constructor variable x occurring in a ‘<’-literal
of a goal (Π,k), unless we restrict ourselves to semantic induction orderings. Therefore, instead
of applying the generalized substitution µ directly to x, we substitute x with a fresh constructor
variable y and add the semantic restriction (y6=xµ) to the formula, expressing that y and xµ can
be assumed to be semantically equal. The same has to be done when x occurs in k. The ‘Z’
in the following definition is intended to contain the variables that are already in use when the
application of µ to (Π,k) is considered.
Definition 13.13
Let µ ∈ G EN S UB (V,T ); (Π,k) ∈ SynCons; Z⊆ V. Now we define:
(Π′,k′,Y,Θ) results from application of µ to (Π,k) w.r.t. Z if
Y =
{
/0 if the induction ordering is semantic (cf. Definition 13.7)(
V <(Π)∪V (k)
)
∩ GENDOM(µ) otherwise
}
and there is some bijection ξ ∈ S UB (V,V) with
ξ[Y] ∩ ( Z∪V (µ[Y]) )= /0
such that
• (Π′,k′) differs from (Π,k)µ only in that any occurrence of a variable x ∈Y in a ‘<’-literal
of Π or in k is replaced with xξ instead of xµ.
• Θ ∈ Form lists the literals (xξ6=xµ) with x∈Y.
130
Note that in the usual case of Y= /0 we always get (Π′,k′,Y,Θ)=(Πµ,kµ, /0, /0). For x ∈ Y the
idea is to disconnect x from xµ syntactically by introducing a new constructor variable xξ for x
and then to express the equality of xξ and xµ semantically via (xξ6=xµ), cf. Example 16.9.
The following technical lemma formalizes how to apply a generalized substitution µ to syntactic
constructs and formulas in such a way that their operationality and validity (w.r.t. (τ,A )) is re-
spected (because the (generalizing) (µτ,A ) /∈ Info can be replaced with (ordinary) (pi,A ) ∈ Info
or (ρ,A ) ∈ Info).
Lemma 13.14
Let µ ∈ G EN S UB (V,T ), (Π,k) ∈ SynCons, (τ,A ) ∈ Info, Y′ ⊆ V.
Assume that ∀x ∈ Y′∩GENDOM(µ). ( ((Def xµ),τ,A ) is a counterexample ).
Now there is some pi such that:
1. (pi,A )∈ Info.
2. pi|V\GENDOM(µ) =(µτ)|V\GENDOM(µ).
3. (piA ιA )|Y′ =(µτA ιA )|Y′ .
4. If
(
GENDOM(µ)∩V <(Π)= /0
∨ the induction ordering is semantic
)
and V (Π)⊆Y′, then the following two
are logically equivalent:
• Πµτ is true w.r.t. A ιA .
• Πpi is true w.r.t. A ιA .
Additionally assume that (Π′,k′,Y,Θ) results from application of µ to (Π,k) w.r.t. Z.
5. If Y⊆Y′, then there is some τ′ such that (τ′,A )∈ Info, τ′|Z =τ|Z, and (Θ,τ′,A ) is a
counterexample.
6. If V (Π,k)⊆Y′ and if (Θ,τ,A ) and (Π′,τ,A ) are counterexamples, then there is some ρ
with (ρ,A )∈ Info such that ((Π,k),(ρ,A )) is a counterexample with ((Π,k),(ρ,A )) .
((Π′,k′),(τ,A )).
131
13.3 Superposition
In this section we lay the technical foundation for the inference rules that utilize the initiality or
freeness of those algebras that establish some specific notion of inductive validity, cf. § 10.3. The
reader who is not interested in the proofs of the soundness and safeness of these inference rules
should read the following definition only and skip the very technical rest of this section.
For a term t and a set of variables Y, ‘SUPERPOSE(t,Y)’ describes the possible reductions
of t with the set R of defining rules. For each rule from R whose left-hand side is unifiable with
some non-variable subterm of t, the set SUPERPOSE(t,Y) contains the pair (Γ,σ) of the most
general unifier σ and the negation of the condition of the rule expressed in the formula Γ. The
variables in Y are protected such that their occurrences in rules from R must be renamed before
unification.
Moreover, ‘NARROW(t,t ′,Y)’ describes the possible beginnings of reduction steps joining
the terms t and t ′. Besides the sets SUPERPOSE(t,Y) and SUPERPOSE(t ′,Y), NARROW(t,t ′,Y)
contains the pair of the empty formula and the most general unifier of t and t ′ if such a unifier
exists.
Definition 13.15
Let n ∈ N; s ∈ S; t,t ′ ∈ T SIG,s; λ0, . . . ,λn−1 ∈ CON DL I T (sig,V); Y⊆V.
Let ξ∈ S UB (V,V) be a bijection that maps all variables occurring in rules of R apart from Y (i.e.
ξ[V (R)]∩Y= /0). Now let SUPERPOSE(t,Y) be the set containing for any rule (l=r←−λ0 . . .λn−1)∈
R and any non-variable position p∈FPOS (t) such that lξ and t/p are unifiable the pair
( (λ0 . . . λn−1 )ξ , mgu({(lξ,t/p)},Y∪ξ[V (l=r←−λ0 . . .λn−1)]) ) .
Define NARROW(t,t ′,Y) :=
SUPERPOSE(t,Y) ∪
SUPERPOSE(t ′,Y) ∪
{ ( /0, mgu({(t,t ′)},Y)) | t and t ′ are unifiable }.
132
Lemma 13.16
Let X′ ∈ { /0,VSIG,VSIGA | A ∈K } and X⊆ X′. Let Y be a finite subset of V. Let t ∈ T be a
linear term with V (t)⊆Y. Let τ ∈ S UB (V,T (X′)).
Define I := T (X)/ ∗←→R,X . Define ι ∈ S UB (X, I ) by (x∈X) xι := ∗←→R,X[{x}].
Now if there is some t ′′ ∈ T such that tτ ∗−→R,Xt ′′ and
¬∃τ′∈S UB (V,T (X′)).
 t ′′= tτ′∧ ∀x∈V (t). xτ ∗−→R,Xxτ′
∧ ∀x∈V\V (t). xτ=xτ′

then there are some (Λ,σ) ∈ SUPERPOSE(t,Y) and some pi such that
1. pi∈S UB (V,T (X′)).
2. (σpi)|Y\V (t) =τ|Y\V (t).
3. (σpiIι)|V (t) =(τIι)|V (t).
4. t∈T (cons,VC ) implies that all literals in Λ are negative.
5. If t∈T (cons,VC ) or if −→R,X is confluent, then Λσpi is false w.r.t. Iι.
Lemma 13.17
Let X′ ∈ { /0,VSIG,VSIGA | A ∈K } and X ⊆ X′. Assume −→R,X to be confluent. Let Y be a
finite subset of V. Let t,t ′ ∈ T be linear terms with V (t)∩V (t ′)= /0 and V (t,t ′)⊆Y. Let
τ ∈ S UB (V,T (X′)).
Define I := T (X)/ ∗←→R,X . Define ι ∈ S UB (X, I ) by (x∈X) xι := ∗←→R,X[{x}].
Now if tτ ∗←→R,Xt ′τ, then there are some (Λ,σ) ∈ NARROW(t,t ′,Y) and some pi such that
1. pi∈S UB (V,T (X′)).
2. (σpi)|Y\V (t,t ′) =τ|Y\V (t,t ′).
3. (σpiIι)|V (t,t ′) =(τIι)|V (t,t ′).
4. t,t ′∈T (cons,VC ) implies that all literals in Λ are negative.
5. Λσpi is false w.r.t. Iι.
Lemma 13.18
Let s ∈ S and t,t ′ ∈ T SIG,s. Let (τ,A ) ∈ Info. Assume one of the following two:
• D- or E-case holds or
• t,t ′∈T (cons,VC ), X= /0, and
K is a sub-class of the class of constructor-minimal models of R.
Now −→R,X is confluent, and if A ιA (tτ)=A ιA (t ′τ) then:
1. tτ ∗←→R,Xt ′τ.
2. If t,t ′ are linear terms with V (t)∩V (t ′)= /0, V (t,t ′)⊆Y, and Y is a finite subset of V,
then NARROW(t,t ′,Y) 6= /0.
133
14 Contextual Rewriting
14.1 Introduction
Our reduction relation −→R,V (cf. § 7) is able to rewrite terms containing constructor variables.
It is, however, actually of little use at this because the condition of an instantiated rule then still
contains these constructor variables and it is very unlikely therefore that this condition is fulfilled
for all possible (inductive) instantiations. And even when this is the case, we do not know how to
find it out.99 Therefore, the appropriate way of rewriting terms containing constructor variables
with a conditional rule uses additional assumptions implying fulfilledness of the condition of the
rule.
This leads us to a species of rewriting which is called contextual rewriting in Ganzinger
(1988), Zhang & Kapur (1988), and Bevers & Lewi (1990). While these authors use a finite
set of equations for the context of their rewriting steps we generalize these contexts to negative
equations and Def-literals by taking a formula Γ instead, in which the negative equations play the
role of these authors’ finite set of equations.
The form of presentation we choose is that of sub-rules of the Transformation rule presented
in § 12.4 of this thesis. On the one hand this uniform presentation satisfies our design goal of a
“homogeneous representation” as established in § 11.3, according to which it admits to use the
power of our whole inference system inside contextual rewriting flexibly. On the other hand,
however, this presentation does not exhibit the need for a special heuristic control for successful
application of contextual rewriting in practice.
Since contextual rewriting is based on removal of trivial tautologies, we begin with that. Then,
before one really starts with contextual rewriting one should remove redundant literals. After
that, we will come to constant rewriting. Finally in this section, we treat features of contextual
rewriting that apply rules and lemmas, and then close with a completeness result for contextual
rewriting.
99Be reminded we require confluence of −→R, /0 only, or of −→R,VSIG at most, but not of −→R,V .
134
14.2 Decomposition and Tautology Removal
In this section we present inference rules that try to show that a literal of a goal is true. When they
are completely successful, they can remove the goal. When they are only partially successful,
they have to add some sub-goals to express the open tasks.
Our idea behind decomposition is to perform a top-down search on a term structure until one finds
relevant subterms and then to extract these subterms from the original term.
To apply the below =-Decompose rule we look for clashing subterms in the two terms of
an =-literal of a goal. In the special case (represented by m=n=0) that there are no clashing
subterms, the =-literal has the form (t=t) and the goal can be removed. It may be appropriate to
introduce an =-Tautology Remove rule for this important special case. Otherwise, if we find a
clashing pair of subterms (ui,vi), two possible cases arise. The first one (represented by n i) is
that the literal (ui 6=vi) is contained in the goal, which means that we can assume ui and vi to be
equal. In the contradictory case (represented by i≺n), we have to generate a new goal that asks
us to prove (ui=vi).
To apply the below Def-Decompose rule we look for non-constructor subterms in the term of
a Def-literal of a goal. If we find such a non-constructor subterm vi, two possible cases arise. The
first one (represented by n i) is that the literal (Def vi) is contained in the goal, which means
that we can assume vi to be defined. In the contradictory case (represented by i≺n), we have
to generate a new goal that asks us to prove (Def vi). In the special case (represented by n=0)
that this contradictory case does not occur, the Def-Decompose rule just removes a goal that
contains an atom of the form (Def t[ p j ← v j | j≺m ]) where t is a pure constructor term and we
can assume (Def v j) to be true because it is listed in the condition of the goal (for all j≺m). It
may be appropriate to introduce a Def-Tautology Remove rule for this important special case.
Another interesting special case (represented by m=1, n=0, p0 = /0) of the =- and Def-
Decompose rule results from stopping our search right at the top position of the terms because
there is a complementary literal in the goal which allows us to remove the goal immediately. It
may be appropriate to introduce a Complement-Tautology Remove rule for this important special
case.
For a first reading of the =- and Def-Decompose rule suppose all Λi to be the empty formula
such that the last condition of the rule is trivially satisfied.
Furthermore, note that the special case of “ m=n=1, p0 = /0 ” of the =- and Def-Decompose
rule is meaningless.
Finally, the 6=-Tautology Remove rule can remove a goal containing a literal of the form (u0 6=u1)
provided that u0 and u1 are pure constructor terms that cannot be joined.100
100Note that there indeed is nothing like a Def-Tautology Remove rule because (Def u0) cannot be tautological for
a pure constructor term u0.
The Def-Solve rule we will present in § 16.3, however, is able to remove goals due to tautological Def-literals.
Note that in § 16.3 we will also present an 6=-Solve rule, which (in combination with the Variable Add and Remove
rules of § 15.2) generalizes the 6=-Tautology Remove rule.
135
Let m,n ∈ N with nm; Γ,∆,Λ0, . . . ,Λn−1 ∈ Form; ℵ ∈Weight(V); t ∈ T .
Let p0, . . . , pm−1 ∈ POS (t) be mutually parallel and u0, . . . ,um−1,v0, . . . ,vm−1 ∈ T .
Let L be a finite subset of ‘Form’, and H, G be finite subsets of ‘SynCons’:
=-Decompose:
(L ,H ,G ∪ { (Γ(t[ p j ← u j | j≺m ]= t[ p j ← v j | j≺m ])∆ ,ℵ) } )
(L ,H ,G ∪ { ((ui =vi)ΛiΓ(t[ p j ← u j | j≺m ]= t[ p j ← v j | j≺m ])∆ ,ℵ) | i≺n } )
if
- ∀i.
(
n i≺m ⇒ (ui 6=vi) is contained in Γ∆
)
,
- ∀i≺n.
(
Λi is contained in (ui−1 6=vi−1)(ui−2 6=vi−2) . . .(u0 6=v0)
)
.
Def-Decompose:
(L ,H ,G ∪ { (Γ(Def t[ p j ← v j | j≺m ])∆ ,ℵ) } )
(L ,H ,G ∪ { ((Def vi)ΛiΓ(Def t[ p j ← v j | j≺m ])∆ ,ℵ) | i≺n } )
if
- t∈T (cons,VC ),
- ∀i.
(
n i≺m ⇒ (Def vi) is contained in Γ∆
)
,
- ∀i≺n.
(
Λi is contained in (Def vi−1) (Def vi−2) . . .(Def v0)
)
.
6=-Tautology Remove:
(L ,H ,G ∪ { (Γ(u0 6=u1)∆ ,ℵ) } )
(L ,H ,G )
if
- u0,u1∈T (cons,VC ),
- u0, u1 are clashing, and
- ∀i≺2. ∀p∈FPOS (ui). ∀((l,r),C)∈R. ( ui/p and l are clashing ).
Lemma 14.1 The =-Decompose rule is a safe sub-rule of the Transformation rule.
Lemma 14.2 The Def-Decompose rule is a safe sub-rule of the Transformation rule.
Lemma 14.3 If K is a sub-class of the class of constructor-minimal models of R, then the 6=-
Tautology Remove rule is a safe sub-rule of the Transformation rule.
136
14.3 Removal of Redundant Literals
In this section we present inference rules that try to show that a literal of a goal implies the rest of
the formula. In this case, we can remove the literal, knowing that this results in a safe inference
step. A special case of the required implication is that the literal is false.
Although removing literals is never really necessary for proving a goal, it tends to reduce the
search space and therefore should be applied before starting more complex proof search.101
Note that the above-mentioned safeness is the crucial part of these Literal Remove rules be-
cause literals can always be removed in unsafe inference steps as illustrated by the following rule,
which is not intended to be a rule of the concrete inference system that we want to present in this
thesis.102
Let Γ,∆ ∈ Form; λ ∈ G EN L I T (sig,V); ℵ ∈Weight(V).
Let L be a finite subset of ‘Form’, and H, G be finite subsets of ‘SynCons’:
Context Remove: (L ,H ,G ∪ { ( Γλ∆, ℵ) })
(L ,H ,G ∪ { ( Γ∆, ℵ) })
Corollary 14.4 The Context Remove rule is a sub-rule of the Transformation rule.
To achieve safeness of the Context Remove step, the following notion is useful:
Definition 14.5 (Subsumption)
Let L be a subset of Form(sig,V).
A formula Π is said to be subsumed by L if one of the following cases holds:
Complement-Axiom
∃A∈G EN A T (sig,V). A and A are contained in Π.
=-Axiom
∃t∈T . (t=t) is contained in Π.
Def-Axiom
∃m∈N. ∃t∈T (cons,VC ). ∃p0, . . . , pm−1∈POS (t). ∃v0, . . . ,vm−1∈T . ∀ j≺m. ∀i≺ j. pi ‖ p j∧ (Def t[ p j ← v j | j≺m ]) is contained in Π
∧ ∀i≺m. (Def vi) is contained in Π
.
101In some situations, however, some redundant literals (typically Def-literals) will later be generated again by a
Lemma Apply &c..
102Cf. § 16.4 for the reason why we do not want unsafe rules.
137
L-Axiom
∃Λ∈L. ∃µ∈G EN S UB (V,T ).
Λµ is contained in Π
∧ ∀x∈GENDOM(µ). (Def xµ) is contained in Π
∧
(
GENDOM(µ)∩V <(Λ) = /0
∨ the induction ordering is semantic
)
.
Lemma 14.6
If Π is subsumed by L and if L is valid, then Π is valid, too.
The below Subsumptive Literal Remove rule removes a literal λ from a clause Γλ∆ provided that
λ implies Γ∆ to be true, i.e. that λΓ∆ is valid. This validity is operationalized by the requirement
that λΓ∆ is subsumed by the other formulas of the proof state. Moreover, if λ is an =-literal, then
some rewriting of Γ∆ with ∗←→λ is allowed for satisfying the subsumption relation. The rewriting
of formulas is defined in definitions 5.10 and 13.8. Note that we are indeed allowed to use all the
formulas of the proof state for the subsumption test: If one of these formulas is not valid, then the
original proof state is not valid and the inference step is trivially safe, cf. Definition 12.31.
It may be appropriate to introduce a separate sub-rule of the Subsumptive Literal Remove
rule for each of the four cases of Definition 14.5. E.g., in Wirth & Kühler (1995) there are a
Multiple-Literal Remove rule for the first case, an 6=-Literal Remove rule for the second case, a
Def-Literal Remove rule for the third case, and an Applicative Literal Remove rule for the fourth
case of the definition of subsumption.103 The first case of a complement-axiom is in a certain
sense complementary to the case of “ m=1, n=0, p0 = /0 ” of the =- or Def-Decompose rules of
§ 14.2. The cases of a =-axiom and a Def-axiom are in a certain sense complementary to the
special case of “ n=0 ” of the =- and Def-Decompose rule, resp..104
Finally, the below =-Literal Remove and Def-Literal Remove rule remove literals that are known
to be false due to the freeness or initiality that can be assumed for the models of the specification
for some types of inductive validity. The =-Literal Remove and the Def-Literal Remove rule are
in a certain sense complementary to the 6=-Solve and Def-Solve rules of § 16.3, resp.. Note that
“NARROW(. . ., . . ., . . .)” is defined in Definition 13.15 and that the linearity requirement for the
literals can be removed when some termination property can be assumed.105
103Note that these four rules of Wirth & Kühler (1995) are, however, weaker than the Subsumptive Literal Remove
rule presented here because there the possibility to use Def-axioms for removing Def-literals and — more important
— the possibility to rewrite the formula for removing =-literals are missing, cf. footnote 111 of Example 14.13. This
shows that designing sufficiently powerful inference rules for simplification or inductive theorem proving is more
difficult than designing inference rules for deductive theorem proving where a completeness proof can serve as an
essential test for sufficient inference power.
104Also the case of an L-axiom has a complementary rule that removes a goal, namely the Lemma Apply rule of
§ 14.5 for the special case of “ m=0 ”.
105Cf. § 16.3 for a discussion of this.
138
Let Γ,∆ ∈ Form; ℵ ∈Weight(V); λ ∈ G EN L I T (sig,V); s ∈ S; t,t ′ ∈ T SIG,s.
Let L be a finite subset of ‘Form’, and H, G be finite subsets of ‘SynCons’:
Subsumptive Literal Remove:
(L ,H ,G ∪ { ( Γλ∆ ,ℵ) } )
(L ,H ,G ∪ { ( Γ∆ ,ℵ) } )
if there is some formula Π such that
λΠ is subsumed by L∪ form[H ∪G] and Π = Γ∆
∨ ∃l,r.
(
λ equals (l=r)
∧ Π ∗←→
(l=r)Γ∆
) .
=-Literal Remove:
(L ,H ,G ∪ { ( Γ(t=t ′)∆ ,ℵ) } )
(L ,H ,G ∪ { ( Γ∆ ,ℵ) } )
if (t=t ′) is linear and NARROW(t,t ′,V (t,t ′)) = /0.
Def-Literal Remove:
(L ,H ,G ∪ { (Γ(Def t)∆ ,ℵ) } )
(L ,H ,G ∪ { ( Γ∆ ,ℵ) } )
if t is linear and for some x ∈ VC ,s\V (t) we have NARROW(x,t,V (x,t)) = /0.
Corollary 14.7 The Subsumptive Literal Remove, =-Literal Remove, and Def-Literal Remove
rules are sub-rules of the Transformation rule.
Lemma 14.8 The Subsumptive Literal Remove rule is safe.
Lemma 14.9 Assume either that the D- or E-case holds or otherwise106 that, for the literal
(t=t ′) of the =-Literal Remove rule, t,t ′∈T (cons,VC ) and K is a sub-class of the class of
constructor-minimal models of R. Now:
The =-Literal Remove rule is safe.
Lemma 14.10 Assume that the D- or E-case holds. Now:
The Def-Literal Remove rule is safe.
106Note that in case of t∈T (cons,VC ) the Def-Literal Remove rule is never applicable (contrary to the Def-
Decompose rule for “ m=n=0 ” which should be immediately applied in this case). This makes a second case of
Lemma 14.10 according to Lemma 14.9 superfluous.
139
14.4 Constant Rewriting
An essential feature of contextual rewriting is the following Constant Rewrite rule. The word
“constant” was chosen to remind the reader that this rule does not allow instantiating the variables
of its “rewrite rule” for the rewrite step, i.e. the variables have to be treated like constants. While
the Constant Rewrite rule can implement Knuth-Bendix completion for unconditional ground
equations (cf. Zhang (1993)), in accordance with our design goal of § 11.3 to include “inference
rules for most elementary proof steps” we present the Constant Rewrite rule in the following
essential elementary form because long sequences of consecutive Constant Rewrite steps are
hardly necessary in practice. The rewriting of formulas and weights is defined in definitions 5.10
and 13.8.
Let λ′′ ∈ G EN L I T (sig,V); Γ,∆,Γ′,∆′ ∈ Form(sig,V). ℵ,ℵ′ ∈Weight(V).
Let L be a finite subset of ‘Form’, and H, G be finite subsets of ‘SynCons’:
Constant Rewrite: (L ,H ,G∪{ ( Γλ′′∆ , ℵ ) } )
(L ,H ,G∪{ ( Γ′λ′′∆′ , ℵ′ ) } )
if there are some l, r such that all the following holds:
- λ′′ equals (l 6=r).
- Γ ∗−→
(l=r)Γ
′
- ∆ ∗−→
(l=r)∆′
- ℵ ∗−→
(l=r)ℵ
′
Lemma 14.11 The Constant Rewrite rule is a safe sub-rule of the Transformation rule.
Note that we could rewrite also λ′′ with (l=r). Then the Constant Rewrite rule would still be
a sub-rule of the Transformation rule, but not safe anymore: Consider Γ := ∆ := /0; λ′′ :=
(true 6= false). Then (true 6= false)−→
(true=false)
(false 6= false), but, while (true 6= false) is likely
to be inductively valid, (false 6= false) is not.
Note that rewriting the weight or a ‘<’-literal, which is only possible if the induction ordering
is semantic, is of questionable importance: One usually can delay the rewriting of the weight until
it has generated a ‘<’-literal and the rewriting of a ‘<’-literal until it has been transformed into
an ‘=’-literal like less(t,t ′)= true by a special inference rule for ‘<’. Therefore we have omitted
this possibility in the Lemma and Hypothesis Rewrite rules for the sake of readability. Neverthe-
less, we consider the rewriting of the weight to be conceptually interesting, cf. Example 16.21.
140
14.5 Application of Rules and Lemmas
In this section we treat inference rules that allow us to apply a defining rule from R or a lemma
Π (instantiated via a generalized substitution µ) to a goal Γ.
Let m ∈ N; Γ,Π,Λ0, . . . ,Λm−1 ∈ Form; λ0, . . . ,λm−1 ∈ G EN L I T (sig,V); ℵ ∈Weight(V).
Let L be a finite subset of ‘Form’, and H, G be finite subsets of ‘SynCons’:
Lemma Apply: (L ∪ {Π} ,H ,G ∪ { ( Γ , ℵ) } )
(L ∪ {Π} ,H ,G ∪ { ( λi ΛiΓ , ℵ) | i≺m } )
if there is some µ ∈ G EN S UB (V,T ) such that all the following holds:
- ∀i≺m.
(
Λi is contained in λi−1λi−2 . . .λ0
)
,
- Πµ is contained in λm−1λm−2 . . .λ0Γ,
- ∀x∈GENDOM(µ).
(
(Def xµ) is contained in λm−1λm−2 . . .λ0Γ
)
,
-
(
GENDOM(µ)∩V <(Π)= /0
∨ the induction ordering is semantic
)
.
Lemma 14.12 The Lemma Apply rule is a safe sub-rule of the Transformation rule.
The Lemma Apply is the more attractive the smaller the variable m is:
E.g. for “ m=0 ”, an application of the rule means just to remove the goal (Γ,ℵ) by appli-
cation of a lemma that subsumes it.
For “ m=1 ”, it means to add a new literal to Γ. This is attractive if this new literal is useful
for the proof, which especially is the case if a rule becomes applicable that can remove the new
goal,107 or if the literal is of the form (l 6=r) and l is a sub-term occurring in Γ, in which case we
can use the literal for a Constant Rewrite. The latter case includes an application of a defining rule
from R, since we can always suppose R ⊆ L.108 This rewriting case is so important in practice
that, after some more motivation, we will combine a Lemma Apply with a succeeding Constant
Rewrite into a single rule.
An “ m≻1 ” results either from conditions of the applied defining rule or lemma or from
definedness conditions for the generalized variables. The resulting literals have to be added to the
goal because they are not already present. Therefore in the Lemma Apply rule we intend
∀i≺m.
 λi is not contained in Γ
∧
(
(λi is contained in Πµ)
∨ ∃x ∈ GENDOM(µ). λi =(Def xµ)
)  .
107like the Decompose or Tautology Remove rules of § 14.2 or Lemma (or Hypothesis, cf. § 16.2) Apply. Note,
however, that if it is a Decompose rule that becomes applicable for the special case of a complement-axiom, i.e.
“ m=1, n=0, p0 = /0 ”, then it would have been possible to remove the goal at once by choosing “ m=0 ” for the
original Lemma Apply instead of “ m=1 ”.
108according to Definition 6.4 by the Acquisition rule presented in § 12.4 of this thesis.
141
Thus, the application of Π is lazy with respect to the verification of the “λi ” which has to be done
later, possibly by contextual rewriting again. In this sense the application of rules or lemmas is a
recursive feature of contextual rewriting.
The laziness mentioned above is not a must. An eager tactic could, e.g., after applying the
Lemma Apply rule, verify the sub-goals expressing the fulfilledness of the conditions of the
rule or lemma first, and then, if this was not successful, undo the application of the Apply rule.
Thus (in accordance with our design goal of a “homogeneous representation” of § 11.3), the
homogeneous formulation of the sub-problem of showing satisfaction of the conditions of an
Apply rule in the form of sub-goals allows us to use the full power of our prover to verify these
conditions as well as to be lazy or not, leaving this choice to our tactical consideration.
Example 14.13 (continuing examples 5.12 and 5.15)
Let p be an arbitrary term of the sort bool. We now want to simplify the literal p= false in a
context where false as a top level term of a =- or 6=-literal is considered to be more difficult than
true.109 Thus let us start with the goal110
(1) p= false
A Lemma Apply of the lemma ‘(Tertium non datur)’ from Example 5.15 substituted with µ :=
{b 7→p}; setting m := 2; λ0 := Def p; λ1 := p= true; Λ0 := Λ1 := /0; yields:
(1.1) Def p, p= false
(1.2) p 6= true, p= false
Since (Def p)−→
(p=false)(Def false), the Subsumptive Literal Remove rule can simplify (1.1) with
a Def-axiom into111
(1.1.1) Def p
A Constant Rewrite transforms (1.2) into
(1.2.1) p 6=true, true= false
and then an =-Literal Remove yields
(1.2.1.1) p 6= true
Thus, according to our intention, we have simplified the goal (1) into the goals (1.1.1) and
(1.2.1.1) that do not contain false anymore.
109As already noted in Wirth (1991), this kind of simplification is quite useful for removing the ambiguity of
“=false” versus “ 6=true” as well as “ 6=false” versus “=true” in goals. In defining rules and lemmas, however, “ p=
false ” is sometimes more straightforwardly useful than “ p 6= true ” because the former can be used for a Lemma
Rewrite.
110Note that we omit the weights of the goals here and in the other examples of this section.
111Note that this is not possible with the less powerful Literal Remove rules of Wirth & Kühler (1995) (as explained
in footnote 103 of § 14.3) unless we have the lemma “ Def B, B 6= false ” in our set of lemmas to enable an Applicative
Literal Remove with it. Why we do not want to have such lemmas is explained in Example 15.2.
142
Example 14.14 (continuing examples 5.12 and 5.15)
Assume that we want to transform the goal
(1) mbp(s(x),cons(s(y),nil))= true
into a more concise form, using the rules of Example 5.12 as lemmas:
(mbp1) mbp(x,nil)= false
(mbp2) mbp(x,cons(y, l))= true, x 6=y
(mbp3) mbp(x,cons(y, l))=mbp(x, l), x=y
Now both (mbp2) and (mbp3) qualify for a Lemma Apply, since they both have equality literals
matching the first term of our goal via µ := { x 7→s(x), y7→s(y), l 7→nil }. Since this match extends
to the whole literal for the case of (mbp2), the application of (mbp2) is more attractive since it
admits a smaller ‘m’ in the Lemma Apply. Therefore we apply (mbp2) first and then (mbp3)
afterwards. Doing it the other way round produces the same result but with a bigger proof tree
and the difficulty whether to instantiate Λ1 to /0 or λ0 where only the latter choice brings us into
the right direction.
The Lemma Apply of (mbp2) via m := 1; λ0 := s(x) 6=s(y) results in the new goal
(1.1) s(x)=s(y), mbp(s(x),cons(s(y),nil))= true
which then is transformed with a Lemma Apply of (mbp3) via m := 1; λ0 :=
mbp(s(x),cons(s(y),nil))=mbp(s(x),nil); yielding
(1.1.1) mbp(s(x),cons(s(y),nil)) 6=mbp(s(x),nil), s(x)=s(y),
mbp(s(x),cons(s(y),nil))= true
which by Constant Rewrite can be transformed into
(1.1.1.1) mbp(s(x),cons(s(y),nil)) 6=mbp(s(x),nil), s(x)=s(y),
mbp(s(x),nil)= true
which in turn can be transformed by Lemma Apply of (mbp1) into
(15) mbp(s(x),nil) 6= false, mbp(s(x),cons(s(y),nil)) 6=mbp(s(x),nil), s(x)=s(y),
mbp(s(x),nil)= true
then by Constant Rewrite into
(16) mbp(s(x),nil) 6= false, mbp(s(x),cons(s(y),nil)) 6=mbp(s(x),nil), s(x)=s(y),
false= true
then by =-Literal Remove into
(17) mbp(s(x),nil) 6= false, mbp(s(x),cons(s(y),nil)) 6=mbp(s(x),nil), s(x)=s(y)
then by =-Decompose of s(x)=s(y) into
(18) x=y, mbp(s(x),nil) 6= false, mbp(s(x),cons(s(y),nil)) 6=mbp(s(x),nil), s(x)=s(y)
then by Subsumptive Literal Remove with (Inject s) of Example 5.15 into
(19) x=y, mbp(s(x),nil) 6= false, mbp(s(x),cons(s(y),nil)) 6=mbp(s(x),nil)
and finally by Subsumptive Literal Remove with (mbp1) into
(110) x=y, mbp(s(x),cons(s(y),nil)) 6=mbp(s(x),nil)
143
All in all, we have transformed
(1) mbp(s(x),cons(s(y),nil))= true
into
(110) x=y, mbp(s(x),cons(s(y),nil)) 6=mbp(s(x),nil)
By application of the Context Remove rule (cf. § 14.3), which, however, is unsafe in general, we
could transform this into
x=y
which is much more concise.
Note that we cannot remove the literal
mbp(s(x),cons(s(y),nil)) 6=mbp(s(x),nil)
from (110) by a Subsumptive Literal Remove with (mbp3) because this would require the presence
of the literal s(x)=s(y) which we have removed before. Of course, removing the literals in a
different order could have led us to the desired concise goal x=y. But this all seems much too
complicated for such a simple simplification problem. In general, throwing away the 6=-literals
generated by Lemma Apply and then used for intermediate Constant Rewrite steps is unsafe,
however. To see this, consider the following example:
Example 14.15 (continuing examples 5.12 and 5.15)
Let us transform the goal
(1) s(x) 6=s(y), Γ
by a Lemma Apply of (Inject s) of Example 5.15 into
(1.1) x 6=y, s(x) 6=s(y), Γ
and then by Constant Rewrite to
(1.1.1) x 6=y, s(y) 6=s(y), Γ
and finally by Subsumptive Literal Remove with the =-axiom s(y)=s(y) to
(1.1.1.1) x 6=y, Γ
If we now removed the literal generated by Lemma Apply for the intermediate Constant Rewrite
(i.e. x 6=y), we would get the formula Γ. The transformation of (1) to Γ, however, is not safe in
general.112
The reason why we are not allowed to safely remove the intermediate 6=-literal here is that we
have applied it to the literal which was needed to invent it in the Lemma Apply step.
112To see this, consider Γ := x=y. Note, however, that in this case we had better remove the original goal
directly with the lemma.
144
Instead of keeping book on which literals are used for intermediate Constant Rewrite, on which
literals their invention depends, and to which literals they have been applied, and instead of
searching for the right order in which to remove them, we prefer not to add these intermediate
literals at all:
Let m ∈ N; Γ,∆,Π,Λ0, . . . ,Λm ∈ Form; λ0, . . . ,λm ∈ G EN L I T (sig,V); ℵ ∈ Weight(V); λ′′ ∈
L I T (sig,V); p ∈ POS (λ′′)\{ /0}.
Let L be a finite subset of ‘Form’, and H, G be finite subsets of ‘SynCons’:
Lemma Rewrite: (L ∪ {Π} ,H ,G ∪ { ( Γλ′′∆ , ℵ) } )
(L ∪ {Π} ,H ,G ∪ { ( λi ΛiΓλ′′∆ , ℵ) | i≺m }
∪ { ( ΛmΓλ′′[ p← r ]∆ , ℵ) } )
if there is some µ ∈ G EN S UB (V,T ) such that all the following holds:
- λm equals (l=r) for l := λ′′/p,
- ∀im.
(
Λi is contained in λi−1λi−2 . . .λ0
)
,
- Πµ is contained in λmΛmΓ∆,
- ∀x∈GENDOM(µ).
(
(Def xµ) is contained in ΛmΓ∆
)
,
-
(
GENDOM(µ)∩V <(Π)= /0
∨ the induction ordering is semantic
)
.
Lemma 14.16 The Lemma Rewrite rule is a safe sub-rule of the Transformation rule.
Note that in the Lemma Rewrite rule we intend that Λm equals λm−1λm−2 . . .λ0.
145
Note that weakening the third condition of the Lemma Rewrite rule to
- Πµ is contained in λmΛmΓλ′′∆,
makes the Lemma Rewrite rule unsafe. This can be easily seen in the following example:
Example 14.17 (continuing Example 14.15)
If we weakened the third condition of the Lemma Rewrite rule as indicated above, we could use
a Lemma Rewrite with m := 0; λ0 := x=y; λ′′ := s(x) 6=s(y); p := 11; to transform the
goal
(1) s(x) 6=s(y), Γ
with the lemma
(Inject s) s(x) 6=s(y), x=y
of Example 5.15 into the goal
(1.1) s(y) 6=s(y), Γ
which can safely be transformed by Subsumptive Literal Remove with the =-axiom s(y)=s(y)
into
(1.1.1) Γ
The transformation of (1) into (1.1.1), however, is unsafe in general as already noted in Exam-
ple 14.15.
Furthermore, note that instead of the result of the Lemma Rewrite
(G0) ΛmΓλ′′[ p← r ]∆
a Lemma Apply with subsequent Constant Rewrite can safely yield
(G1) (l 6=r)Γλ′′[ p← r ]∆
A third possibility of a safe transformation is to yield the following instead:
(G2) λ′′Γλ′′[ p← r ]∆
Thus, to achieve safeness of the rewrite step in Γλ′′∆ we have to add to Γλ′′[ p← r ]∆ one of
Λm (as Lemma Rewrite does), (l 6=r) (as Lemma Apply does), or λ′′.
(G2) (in general strictly) implies
(G1’) (l 6=r)λ′′Γλ′′[ p← r ]∆
which is equivalent to (G1). (G1) again (in general strictly) implies
(G0’) Λm(l 6=r)Γλ′′[ p← r ]∆
which by Πµ is equivalent to (G0). Thus (G2) is possibly stronger and thus more difficult to
prove than the result of the Lemma Apply, which again is possibly stronger and more difficult to
prove than the result of Lemma Rewrite. Furthermore, (G2) is less concise and practically useful
than the result of Lemma Apply, which again may be less concise (especially for the typical
special case of m=0 where Λm = /0 ) and practically useful than the result of Lemma Rewrite.
146
Now we reconsider Example 14.14 to see whether the additional Lemma Rewrite rule admits a
simpler and more appropriate treatment of the given simplification problem:
Example 14.18 (continuing Example 14.14)
Remember that we wanted to transform the goal
(1) mbp(s(x),cons(s(y),nil))= true
into a more concise form, using the rules of Example 5.12 as lemmas.
Again, both (mbp2) (with m := 1) and (mbp3) (with m := 2) qualify for a Lemma Apply since
they both have equality literals matching the first term of our goal. Additionally, both (mbp2)
and (mbp3) qualify for a Lemma Rewrite with m := 1. Again, the Lemma Apply of (mbp2) is
the most attractive when we prefer an Apply to a Rewrite with equal ‘m’ because the Rewrite
produces an additional goal.
The Lemma Apply of (mbp2) results (as before) in the goal
(1.1) s(x)=s(y), mbp(s(x),cons(s(y),nil))= true
Now (mbp3) qualifies for a Lemma Apply with m := 1 and for a Lemma Rewrite with m := 0.
Since we consider a Rewrite with a strictly smaller ‘m’ to be more attractive than an Apply, we
choose the Rewrite here.
This Lemma Rewrite with (mbp3) via m := 0; λ0 := mbp(s(x),cons(s(y),nil))=mbp(s(x),nil);
transforms (1.1) into
(1.1.1) s(x)=s(y), mbp(s(x),nil)= true
which in turn can be transformed by Lemma Rewrite with (mbp1) into
(1.1.1.1) s(x)=s(y), false= true
then by =-Literal Remove into
(15) s(x)=s(y)
then by =-Decompose into
(16) x=y, s(x)=s(y)
and finally by Subsumptive Literal Remove with (Inject s) of Example 5.15 into
(17) x=y
Thus we really have got rid of the intermediate 6=-literals without running the risk of an unsafe
inference step, and obtained a more concise result. Moreover, the simplification took only six
instead of nine inference steps and the intermediate goals are much simpler.
147
14.6 Completeness Result
While it is obvious that, with the exception of the 6=-Tautology Remove, the =-Literal Remove
and the Def-Literal Remove rule, all rules for contextual rewriting are deductively sound in the
sense that theorems proved with them hold in all sig/cons-models of the lemmas applied, it is
more difficult to see that they are also deductively complete:
Theorem 14.19 (Deductive Completeness)
Let F denote the set of those formulas from Form that do not contain <-literals. For a finite
set L⊆ F let ‘ L̂ ’ denote a conjunction containing a universal quantifier closed version of each
formula of L.
The below subsystem of our inference system for contextual rewriting is deductively complete
in the following sense: If some formula Γ ∈ F is valid in all those sig/cons-algebras in which all
formulas from a finite set L⊆ F of lemmas are valid, i.e. if
L̂ |= Γ,
then we have
(L, /0,{(Γ,ℵ)}) ∗⊢ (L, /0, /0)
for any ℵ ∈Weight(V).
The complete subsystem contains the =-Decompose (with the restriction of m=n=0), and
the Def-Decompose rule (with the restriction of n=0). It also contains Constant Rewrite (with
the restriction that ℵ=ℵ′, that only positive literals in Γ∆ are rewritten, and that only one
occurrence of l is replaced with r). Finally, it also contains Lemma Apply (with the restrictions
Πµ=λm−1 . . .λ0, ∀x∈GENDOM(µ). ((Def xµ) is contained in Γ), ∀i≺m. Λi = /0, and that
only Lemma Applys have been applied before).
If each formula from L contains a positive =-literal, then instead of the Lemma Apply
we can also take the Lemma Rewrite (with the restrictions that the literal λ′′ is positive,
( m=0 ∨ Πµ equals λmΛm ), ∀x∈GENDOM(µ). ((Def xµ) is contained in Γ∆), ∀i≺m. Λi =
/0, Λm =λm−1 . . .λ0 ).
148
You know, for me, music is really true emotional medicine.
It makes people feel better, it makes people happy, it makes people think.
It just brings lots of joy and love to people.
The thing that I realize more and more is there isn’t any particular style or caste of
music
that really can do that better than any other music.
Ornette Coleman in an interview by Jeff McCord.
149
15 More Deductive Rules
15.1 Adding Context
While the Apply and Rewrite rules are appropriate for automatic addition of context (i.e. of new
literals) to a formula, a more intelligent tactic may want an explicit case analysis as a single rule
instead of spreading the case analysis over several Apply or Rewrite rule applications driven by
the application of defining rules, lemmas, or hypotheses. Since Gentzen’s Cut Elimination is
not possible for inductive proofs, such a rule may be really necessary for non-trivial examples.
For the same reason, such an inference rule for explicit case analysis may also be necessary for
simplification routines, cf. Example 15.2 below. Furthermore, such an inference rule, like the
Context Add rule below, is well-suited for user interaction in more difficult proofs.
Let m ∈ N; Γ,Λ0, . . . ,Λm+1 ∈ Form; λ0, . . . ,λm ∈ G EN L I T (sig,V); ℵ ∈Weight(V).
Let L be a finite subset of ‘Form’, and H, G be finite subsets of ‘SynCons’:
Context Add: (L ,H ,G ∪ { ( Γ, ℵ) } )
(L ,H ,G ∪ { ( λi ΛiΓ, ℵ) | im }
∪ { ( Λm+1Γ, ℵ) } )
if ∀im+1.
(
Λi is contained in λi−1λi−2 . . .λ0
)
.
Corollary 15.1 The Context Add rule is a safe sub-rule of the Transformation rule.
Note that our Context Add is similar to the complete case analysis used in mathematical (meta-
level) proofs: There one puts up some cases λi and does the proof of Γ for each of these single
cases, i.e., for each i  m, one shows that λi implies Γ, which means to show λiΓ. For that
proof method to be sound one has to show that the case analysis is complete, i.e. that (under the
assumptions of the state of the proof Γ) the logical disjunction of the cases holds, which means to
show λmλm−1 . . .λ0Γ, for which Λm+1Γ is sufficient. Indeed, in the Context Add rule we intend
Λm+1 to be λmλm−1 . . .λ0. Especially the case of Λm+1 being empty is not recommended
because it just provides us with new goals that are useless since the logically stronger old goal is
still present.
150
The following example shows that the Context Add rule is useful for simplification routines.
Example 15.2 (continuing examples 5.12 and 5.15)
Let p be an arbitrary term of the sort bool. We now want to simplify the literal p 6= false in a
context where false as a top level term of a =- or 6=-literal is considered to be more difficult than
true. Thus let us start with the goal
(1) p 6= false
Contrary to the complementary situation of Example 14.13 we do not have any lemma in Exam-
ple 5.15 that can help us to find the appropriate case distinction. Therefore we have to use the Con-
text Add rule for starting the intended simplification. Setting m := 1;
λ0 := Def p; λ1 := p= true; Λ0 := /0; Λ1 := Def p; Λ2 := p= true, Def p;
the Context Add rule yields the following subgoals:
(1.1) Def p, p 6= false
(1.2) p 6= true, Def p, p 6= false
(1.3) p= true, Def p, p 6= false
By a Constant Rewrite step (1.1) can be transformed into
(1.1.1) Def false, p 6= false
which can be removed by Def-Decompose.
Similarly, (1.2) can be transformed by the analogous Constant Rewrite into
(1.2.1) false 6= true, Def p, p 6= false
which can be removed by 6=-Tautology Remove.
Finally we can simplify the remaining goal (1.3) via a Subsumptive Literal Remove with the
lemma ‘(Tertium non datur)’ from Example 5.15 into the following intend form:
(1.3.1) p= true, Def p
Note that this does not contain false anymore.
Without the Context Add rule the step from (1) to (1.3) would have required the following two
lemmas (where B is a general variable of the sort bool) for two succeeding Lemma Apply steps.
Def B, B 6= false
B 6= true, B 6= false
These lemmas do not carry any reasonable information about the sort bool and hold similarly for
all (free) constructors of any sort. Without the Context Add rule we would have to inflate our set
of lemmas with lots of such silly lemmas, thereby confusing human users as well as automatic
proof search tactics.
151
15.2 Removing and Adding Variables
Let Γ,∆ ∈ Form; s ∈ S; t ∈ T SIG,s; ℵ ∈Weight(V);
p0, . . . , pn−1 ∈ POS (t) mutually parallel; v0, . . . ,vn−1 ∈ T \T (cons,VC ).
Let L be a finite subset of ‘Form’, and H, G be finite subsets of ‘SynCons’:
SIG-Variable Remove: (L ,H ,G ∪ { ( Γ(x 6=t)∆ , ℵ) } )
(L ,H ,G ∪ { ( Γ∆ , ℵ) } )
if x∈VSIG\V (t,Γ,∆).
C -Variable Remove: (L ,H ,G ∪ { ( Γ(x 6=t)∆ , ℵ) } )
(L ,H ,G ∪ { ( Γ(Def t)∆ , ℵ) } )
if x∈VC \V (t,Γ,∆).
SIG-Variable Add: (L ,H ,G ∪ { ( Γ , ℵ) } )
(L ,H ,G ∪ { ( (x 6=t)Γ , ℵ) } )
if x∈VSIG,s\V (t,Γ,ℵ).
C -Variable Add: (L ,H ,G ∪ { ( Γ , ℵ) } )
(L ,H ,G ∪ { ((x 6=t[ pi ← vi | i≺n ])Γ , ℵ) } )
if x∈VC ,s\V (t[ pi ← vi | i≺n ],Γ,ℵ) and
t ∈ T (cons,VC ) and ∀i≺n. (Def vi) is contained in Γ.
Lemma 15.3
The SIG-Variable Remove rule is a safe sub-rule of the Transformation rule.
Lemma 15.4
The C -Variable Remove rule is a safe sub-rule of the Transformation rule.
Lemma 15.5
The SIG-Variable Add rule is a safe sub-rule of the Transformation rule.
Lemma 15.6
The C -Variable Add rule is a safe sub-rule of the Transformation rule.
Note that the Variable Add rules (choosing t to be a fresh variable) enable subsequent linearization
of literals and rewriting to constructor terms as may be required before a Solve rule (cf. § 16.3)
can be applied. Moreover, as shown in the following example, the C -Variable Add rule enables a
subsequent case distinction on t[ pi ← vi | i≺n ] via application of a covering set of substitutions
to x, cf. the Substitution Add rule of § 16.1.
152
Example 15.7 (continuing examples 5.12 and 5.15)
Let us show the lemma (Del swatch3) of Example 5.15, omitting the weights of the goals:
(1) Def swatch(0), swatch(swatch(swatch(x)))=swatch(x)
A Substitution Add (cf. § 16.1) yields:
(1.1) Def swatch(0), swatch(swatch(swatch(0)))=swatch(0)
(1.2) Def swatch(0), swatch(swatch(swatch(s(x))))=swatch(s(x))
A C -Variable Add with n := 1; p0 := /0; v0 := swatch(0); transforms (1.1) into:
(1.1.1) y 6= swatch(0), Def swatch(0), swatch(swatch(swatch(0)))=swatch(0)
A Substitution Add yields:
(1.1.1.1) 0 6=swatch(0), Def swatch(0), swatch(swatch(swatch(0)))=swatch(0)
(1.1.1.2) s(y) 6=swatch(0), Def swatch(0), swatch(swatch(swatch(0)))=swatch(0)
Constant Rewrite with the first literal transforms (1.1.1.1) first into
(1.1.1.1.1) 0 6=swatch(0), Def swatch(0), swatch(swatch(0))=swatch(0)
and then into
(1.1.1.1.1.1) 0 6=swatch(0), Def swatch(0), swatch(0)=swatch(0)
which is then removed by an =-Decompose.
Moreover, Constant Rewrite with the first literal transforms (1.1.1.2) into
(1.1.1.2.1) s(y) 6=swatch(0), Def swatch(0), swatch(swatch(s(y)))=s(y)
which is then removed by a Lemma Apply with the lemma (Del swatch swatch) of Example 5.15.
Finally, we complete the proof by showing (1.2). A Lemma Rewrite with the lemma (Del swatch
swatch) of Example 5.15 transforms (1.2) into
(1.2.1) Def swatch(0), swatch(s(x))=swatch(s(x))
which is then removed by an =-Decompose.
After all, it should be mentioned that a Lemma Apply with the lemma (Del swatch3) (shown in
the example above to be type-C, -D′, &c., valid (cf. § 18)) and then a Lemma Apply with the
type-D′ valid lemma (for X ∈VSIG,nat)
Def X
proves that
swatch(swatch(swatch(x)))=swatch(x)
is type-D′ valid. It is not valid, however, for the types E , D, C, &c..
153
16 Inductive Rules
16.1 Covering Sets of Substitutions
We are now going to explain why we need a further case analysis rule. Even our rather general
form of contextual rewriting is not sufficient for inductive theorem proving. This will become
obvious by the following, where x is assumed to be a constructor variable of the sort nat and
where leq is assumed to be defined according to Example 5.12. The constructor ground instances
that are described by the goal
leq(x,0)= true, Γ ; ℵ
can all be transformed by Lemma Rewrite steps with rules from R5.12, but the goal itself does not
have to be transformable. Therefore we first have to transform this goal into the following two
goals:
leq(0,0)= true, Γσ0 ; ℵσ0
leq(s(z),0)= true, Γσ1 ; ℵσ1
by means of the covering set of substitutions σ0 := {x 7→ 0}, σ1 := {x 7→ s(z)}, where z is a
new constructor variable. Now Lemma Rewrite can transform these two goals into the following
two new goals:
true= true, Γσ0 ; ℵσ0
false= true, Γσ1 ; ℵσ1
The former can be removed by =-Decompose, the latter can be transformed by an =-Literal
Remove into
Γσ1 ; ℵσ1
All in all, this is an appropriate transformation of the original goal, since the information of the
literal leq(x,0)=true has been consumed in a way that tends to make the success of the proof
attempt more likely than before: Namely the applied σ1 carries the information that x can be
assumed to be different from 0 now.
A question one could ask is the following: “The application of a covering set of substitutions
is nothing but a complete case analysis; why don’t we then use the above Context Add rule to
generate this case analysis?”
It is true indeed that both the application of a covering set of substitutions and a Context Add
mean a complete case analysis. However, there are two reasons for our distinction:
First reason: Our Context Add is rather poor regarding the introduction of new variables: Suppose
we had introduced the variable z by Context Add to “ leq(x,0)= true, Γ ; ℵ ” via λ0 := x=0;
λ1 := x=s(z); yielding the new goals
x 6=0, leq(x,0)= true, Γ ; ℵ
x 6=s(z), leq(x,0)= true, Γ ; ℵ
x=0, x=s(z), leq(x,0)= true, Γ ; ℵ
The first two are rather fine: By Constant Rewrite they can be transformed into
x 6=0, leq(0,0)= true, Γ ; ℵ
x 6=s(z), leq(s(z),0)= true, Γ ; ℵ
and then by Lemma Rewrite into
154
x 6=0, true= true, Γ ; ℵ
x 6=s(z), false= true, Γ ; ℵ
The first can be removed by an =-Decompose, the second transformed by an =-Literal Remove
into
x 6=s(z), Γ ; ℵ
which is quite appropriate for the further proof. (But note that this semantic equality of x and
s(z) is weaker than their syntactic equality expressed by the σ1 from above.) Trouble, however,
is caused by the goal
x=0, x=s(z), leq(x,0)= true, Γ ; ℵ
we have left untransformed above: The context
x=0, x=s(z)
is likely to be of no use for the proof of “ leq(x,0)= true, Γ ; ℵ ” (since z does not occur
in “ leq(x,0)=true, Γ ; ℵ ”). Thus, if the original Context Add should bring our proof of
“ leq(x,0)= true, Γ ; ℵ ” further, then the above context itself should be valid. This is not the
case, however. The reason is, that we actually should have made our Context Add via λ0 := x=0;
λ1 := ∃z. x=s(z). Then, the above context would be
x=0, ∃z. x=s(z)
Since this is valid, the situation would be better then. But still we would not know how to prove
this without application of a covering set of substitutions to x. Moreover, as long as we do not
admit existentially quantified variables in our formulas, the new variable z is implicitly universally
quantified, which makes the above case analysis via Context Add useless for our proof.
Second reason for the introduction of a rule for applying a covering set of substitutions: If the
weight ℵ of the formula “ leq(x,0)= true, Γ ; ℵ ” from above depends on the variable x and we
apply the substitution σ1 from above, then the new weight ℵσ1 depends on the variable z instead.
This change of dependency may be necessary for successful application of induction hypotheses.
It is also sound in this case. In general, however (unless the induction ordering is semantic),
exchanging the goal “ x 6=s(z), Γ ; ℵ ” with “ x 6=s(z), Γσ1 ; ℵσ1 ” is not sound due to the
instantiation of ℵ and of possible ‘<’-literals in Γ, since the induction ordering may depend on
the syntactic form of the terms represented by x while the context x 6=s(z) only implies semantic
equality of x and s(z). Thus, we would need something like x 6≡s(z) instead of x 6= s(z), where
‘≡’ denotes syntactic equality.
All in all, to have a successful case analysis in the above situation without using a covering set
of substitutions we have to add some inference rule similar to the one saying that “ x≡0, ∃z.
x≡s(z) ” is a lemma and then to use it for a Lemma Apply via λ0 := x≡0; λ1 := ∃z. x≡s(z).
Since this requires a considerable extension of our syntax for formulas, we prefer to add another
inference rule for adding covering sets of substitutions instead.
155
Definition 16.1 (Covering Sets of Substitutions)
Let (Γ,ℵ) ∈ SynCons. A covering set of substitutions for (Γ,ℵ) is a finite sequence (n∈N)
σ0, . . . ,σn ∈ S UB (V,T )
such that
∀(τ,A )∈ Info. ∃in. ∃ϕ.

(ϕ,A )∈ Info
∧ ℵτ&A ℵ(σiϕ)
∧ (τA ιA )|V (Γ) =(σiϕA ιA )|V (Γ)
∧
(
τ|V <(Γ) =(σiϕ)|V <(Γ)
∨ the induction ordering is semantic
)
.
Let n ∈ N; Γ ∈ Form; ℵ ∈Weight(V).
Let L be a finite subset of ‘Form’, and H, G be finite subsets of ‘SynCons’:
Substitution Add: (L ,H ,G ∪ { (Γ , ℵ ) } )
(L ,H ,G ∪ { (Γσi, ℵσi) | in } )
if σ0, . . . ,σn is a covering set of substitutions for (Γ,ℵ).
Lemma 16.2 The Substitution Add rule is a safe sub-rule of the Transformation rule.
A first step towards operationalizing covering sets of substitutions is given by . . .
Corollary 16.3
Let (Γ,ℵ) ∈ SynCons. A finite sequence (n∈N) σ0, . . . ,σn ∈ S UB (V,T ) with
∀τ∈S UB (V,T (VSIG)). ∃in. ∃ϕ∈S UB (V,T (VSIG)). τ|V (Γ,ℵ) =(σiϕ)|V (Γ,ℵ)
is a covering set of substitutions for (Γ,ℵ).
The following corollary can be used to construct simple covering sets of substitutions of the form
of Corollary 16.3.
Corollary 16.4 Let (Γ,ℵ) ∈ SynCons.
1. id|V is a covering set of substitutions for (Γ,ℵ).
2. Assume that there are exactly m+1 (m∈N) constructor symbols for some sort sˆ∈ S, namely
c0, . . . ,cm ∈ C with ∀ jm. α(c j)=s j,0 . . .s j,l j−1 → sˆ. Assume x∈VC ,sˆ and ∀ jm.
∀k≺ l j. y j,k∈VC ,s j,k with ∀ jm. ∀k≺ l j. ∀k′≺k. y j,k′ 6=y j,k. Define σ′j ∈ S UB (V,T ) by
σ′j|V\{x} ⊆ id and xσ′j := c j(y j,0, . . . ,y j,l j−1).
Now, if σ0, . . . ,σn is a covering set of substitutions for (Γ,ℵ), in, and ∀ jm. ∀k≺ l j.
y j,k /∈ σi[V (Γ,ℵ)]\{x}, then σ0, . . . ,σi−1,σiσ′0, . . . ,σiσ′m,σi+1, . . . ,σn is a covering set of
substitutions for (Γ,ℵ), too.
156
Finally, we want to remark that our kind of covering sets of substitutions may not be sufficient
for successful inductive theorem proving in case of non-free constructors:
Example 16.5
Let 0, s, and p be constructor symbols for the sort int of integers. Let nonnegp be a non-
constructor predicate with arity “int → bool”. Let x, y be constructor variables of the sort int.
Let R16.5 contain the following rules:
s(p(x)) = x
p(s(x)) = x
nonnegp(0) = true
nonnegp(s(x)) = true ←− nonnegp(x) = true
nonnegp(p(0)) = false
nonnegp(p(p(x))) = false ←− nonnegp(p(x)) = false
Suppose that further non-constructor function symbols have the same definition scheme as nonnegp.
For this definition scheme one might consider covering sets of substitutions like
σ0 := { x 7→ 0 },
σ1 := { x 7→ s(x) },
σ2 := { x 7→ p(0) },
σ3 := { x 7→ p(p(x))}
to be appropriate. The experienced reader, however, may recognize that adding the substitu-
tion σ1, e.g., is likely to be of no use for most inductive proofs without also adding the context
“nonnegp(x) 6= true”. Such an adding of substitution and context has to be done in a single step be-
cause adding the context later via Context Add leaves the proof with the case (σ1,nonnegp(x)=
true) which does not fit into the definition scheme and thus is very unlikely to be easier to prove
than the original goal. This observation, however, does not lead us to the augmentation of cover-
ing sets with context (as other authors do, cf. e.g. Definition 2 in Bronsard & Reddy (1991)) and
the design of an inference rule for simultaneous adding of substitution and context. Instead, we
advise the specifier, not to use definition schemes of the above kind for non-free constructors, but
to proceed as exhibited by the following set of rules, which does not require context-augmented
covering sets of substitutions and, beyond that, has no feasible proper critical pair anymore. Its
confluence can be inferred via each of the (independent) theorems of Wirth (1995) 68, 71, 75, 76,
77, and 78, which is Theorem 9.11 of this thesis.
Example 16.6
Let R16.6 contain the following rules:
s(p(x)) = x
p(s(x)) = x
nonnegp(x) = true ←− x = 0
nonnegp(x) = true ←− nonnegp(p(x)) = true
nonnegp(x) = false ←− x = p(0)
nonnegp(x) = false ←− nonnegp(s(x)) = false
157
This does not mean that we want to forbid syntactic case distinctions for sorts with non-free
constructors in function definitions. We only want to avoid their combination with incomplete
conditions in specifications of total functions. The following extension of the above definition,
e.g., does not cause problems with covering sets of substitutions:
Example 16.7
Let R16.7 contain the following rules:
x+0 = x
x+s(y) = s(x+y)
x+p(y) = p(x+y)
x−0 = x
x−s(y) = p(x−y)
x−p(y) = s(x−y)
invert(0) = 0
invert(s(x)) = p(invert(x))
invert(p(x)) = s(invert(x))
abs(x) = x ←− nonnegp(x)=true
abs(x) = invert(x) ←− nonnegp(x)= false
Note, however, that now the only known theorem that allows inferring confluence of
−→R16.6∪R16.7,VSIG conveniently is Theorem 77 of Wirth (1995). Moreover, we do not know how to
prove the important lemma
nonnegp(x)= true, nonnegp(x)= false
with our formulas because this needs terms like sn(0) (with n being a variable) which are beyond
our term language.
16.2 Application of Hypotheses
As illustrated in § 11.1, the Substitution Add rule of the previous section is usually not suffi-
cient to provide us with finite proofs utilizing the term-generatedness (“no junk”) (given by some
notion of inductive validity) unless cyclic arguments can be used. These cyclic arguments become
possible with the Hypothesis Apply and Hypothesis Rewrite rules we present in this section.
158
Let m,n ∈ N; Γ,Π,Π′,Λ0, . . . ,Λm,Θ ∈ Form; λ0, . . . ,λm−1 ∈ G EN L I T (sig,V); ℵ,k,k′ ∈
Weight(V).
Let L be a finite subset of ‘Form’, and H, G be finite subsets of ‘SynCons’:
Hypothesis Apply: (L ,H ∪ {(Π,k)} ,G ∪ { ( Γ , ℵ) } )
(L ,H ∪ {(Π,k)} ,G ∪ { ( λi ΛiΓ , ℵ) | i≺m }
∪ { ( (k′<ℵ)ΛmΓ , ℵ) } )
if, for some n m, (Π′,k′,Y,Θ) results from application of some µ ∈ G EN S UB (V,T )
to (Π,k) w.r.t. V (λn−1λn . . .λ0Γ,ℵ) and all the following holds:
- ∀i≺n.
(
Λi is contained in λi−1λi−2 . . .λ0
)
,
- ∀im.
(
Λi is contained in λi−1λi−2 . . .λ0Θ
)
,
- Π′ is contained in λm−1λm−2 . . .λ0ΘΓ,
- ∀x ∈ Y.
(
(Def xµ) is contained in λn−1λn−2 . . .λ0Γ
)
,
- ∀x∈GENDOM(µ).
(
(Def xµ) is contained in λm−1λm−2 . . .λ0Γ
)
.
Lemma 16.8 The Hypothesis Apply rule is a safe sub-rule of the Transformation rule.
The Hypothesis Apply rule differs from the Lemma Apply rule in adding a further sub-goal saying
that the instantiated weight of the hypothesis is smaller than the weight of the original goal in the
context of the goal and the literals of the lazy application. For a first understanding assume Y=
/0, i.e. ( V <(Π)∪V (k) )∩GENDOM(µ) = /0 or the induction ordering is semantic. Then we
get Θ= /0, Π′=Πµ, and k′=kµ. The intuition behind the Hypothesis Apply rule in the
complementary case is exhibited by the following Example 16.9.
159
Example 16.9 (continuing examples 5.12 and 5.15)
To prove (Irrefl 2 ack) of Example 5.15 we start with the new goal
(1) less(y,ack(x,y))= true ; wγ16.9(x,y)
First we use the Memorizing Rule of § 12.4 to copy (1) into the set of induction hypotheses. Then
Substitution Add yields the two new goals:
(1.1) less(y,ack(0,y))= true ; wγ16.9(0,y)
(1.2) less(y,ack(s(x),y))= true ; wγ16.9(s(x),y)
Lemma Rewrite with (ack1) yields:
(1.1.1) less(y, s(y))= true ; wγ16.9(0,y)
which is removed by Lemma Apply with (True less) of Example 5.15.
Further Substitution Add to (1.2) yields:
(1.2.1) less(0,ack(s(x),0))= true ; wγ16.9(s(x),0)
(1.2.2) less(s(y),ack(s(x),s(y)))= true ; wγ16.9(s(x),s(y))
Lemma Apply of (Pos ack) removes (1.2.1).
Lemma Rewrite with (ack3) yields:
(1.2.2.1) less(s(y),ack(x,ack(s(x),y)))= true ; wγ16.9(s(x), s(y))
A Lemma Apply of (Strict Trans less) via m := 4; λ0 := Defack(s(x),y)
; λ1 := Def ack(x,ack(s(x),y)) ; λ2 := less(y,ack(s(x),y)) 6= true ; λ3 :=
less(ack(s(x),y),ack(x,ack(s(x),y))) 6= true ; yields
(1.2.2.1.1) Defack(s(x),y),
less(s(y),ack(x,ack(s(x),y)))= true ; wγ16.9(s(x),s(y))
(1.2.2.1.2) Defack(x,ack(s(x),y)), Def ack(s(x),y),
less(s(y),ack(x,ack(s(x),y)))= true ; wγ16.9(s(x),s(y))
(1.2.2.1.3) less(y,ack(s(x),y))= true, Def ack(s(x),y),
less(s(y),ack(x,ack(s(x),y)))= true ; wγ16.9(s(x),s(y))
(1.2.2.1.4) less(ack(s(x),y),ack(x,ack(s(x),y)))= true, Def ack(s(x),y),
less(s(y),ack(x,ack(s(x),y)))= true ; wγ16.9(s(x),s(y))
Lemma Apply of (Defack) removes (1.2.2.1.1) and (1.2.2.1.2).
Hypothesis Apply of (1) to (1.2.2.1.3) via m := 0; µ1 := { x 7→s(x) }; Y := Θ := /0 yields:
(1.2.2.1.3.1) wγ16.9(s(x),y)<wγ16.9(s(x),s(y)),
less(y,ack(s(x),y))=true, Defack(s(x),y),
less(s(y),ack(x,ack(s(x),y)))= true ; wγ16.9(s(x), s(y))
160
Now we come to the Hypothesis Apply that explains the case of Y 6= /0. Hence, we assume that
the induction ordering is not (restricted to be) semantic.
We apply (1) to (1.2.2.1.4), choosing m := 0; µ0 := { y7→ack(s(x),y) }; Y := {y}; Λm :=
Θ := z 6=ack(s(x),y); k := wγ16.9(x,y); and k′ := w
γ
16.9(x,z).
The resulting goal is:
(1.2.2.1.4.1) wγ16.9(x,z)<wγ16.9(s(x), s(y)), z 6=ack(s(x),y),
less(ack(s(x),y),ack(x,ack(s(x),y)))= true, Def ack(s(x),y),
less(s(y),ack(x,ack(s(x),y)))= true ; wγ16.9(s(x),s(y))
Finally, to complete the proof it suffices to solve the following parts of the ordering conditions of
(1.2.2.1.3.1) and (1.2.2.1.4.1), resp.:
w
γ
16.9(s(x),y)<w
γ
16.9(s(x),s(y))
w
γ
16.9(x,z)<w
γ
16.9(s(x),s(y)), z 6=ack(s(x),y)
We can simply solve this by using a lexicographic ordering on the arguments of wγ16.9.113
We will now use Example 16.9 for a discussion of the Lemma and Hypothesis Apply rules accord-
ing to our design goals of § 11.3.
The careful reader may have noticed that the crucial step in the proof of Example 16.9 is the
application of the lemma (Strict Trans less) of Example 5.15.
The substitution applied to the lemma is
µ := { x 7→y, y7→ack(s(x),y), z 7→ack(x,ack(s(x),y)) }.
While the values of µ for x and z are directly given by matching the literal
less(s(x),z)
of the lemma to the literal
less(s(y),ack(x,ack(s(x),y)))
of the goal (1.2.2.1) of Example 16.9, the value of µ for y is not obvious from the current state of
the proof attempt. Nevertheless, it is crucial for a successful completion of this proof attempt that
this value is exactly ack(s(x),y). This violates the design goal called “natural flow of information”
in § 11.3. More precisely, this violation corresponds114 to one of those applications of the γ-rule
that were indicated as problematic in § 11.3 because the instantiation of y has to be guessed before
it can be recognized which instantiation will make the proof attempt successful. The design goal
of “natural flow of information” requires “that a certain decision can be delayed until the state of
the proof provides sufficient information to make a successful decision”. How can we achieve
this? The usual procedure is to replace y with a special kind of existential variable called “dummy
variable” in Prawitz (1960) and Kanger (1963) or “free variable” in the framework of semantic
tableaus,115 cf. Fitting (1990). We will try this in the following example:
113Note, however, that we cannot directly use the lexicographic path ordering because that would require
z<wγ16.9(s(x),s(y)), z 6=ack(s(x),y)
which would be quite difficult to satisfy.
114when writing the universally quantified lemma into the antecedent and our goal into the succedent of a sequent
115where the variables are the dual of existential, i.e. universal.
161
Example 16.10 (continuing Example 16.9)
Assume that we have a state of a proof attempt that is given exactly by that of Example 16.9
before the Lemma Apply of (Strict Trans less). We now continue this proof attempt with a free
existential constructor variable y¯:
A Lemma Apply of (Strict Trans less) via m := 3; λ0 := Defack(x,ack(s(x),y)) ; λ1 :=
less(y, y¯) 6=true ; λ2 := less(y¯,ack(x,ack(s(x),y))) 6= true ; yields
(1.2.2.1.2) Defack(x,ack(s(x),y)),
less(s(y),ack(x,ack(s(x),y)))= true ; wγ16.9(s(x),s(y))
(1.2.2.1.3) less(y, y¯)= true,
less(s(y),ack(x,ack(s(x),y)))= true ; wγ16.9(s(x),s(y))
(1.2.2.1.4) less(y¯,ack(x,ack(s(x),y)))= true,
less(s(y),ack(x,ack(s(x),y)))= true ; wγ16.9(s(x),s(y))
Now it becomes interesting to apply our hypothesis (1) of Example 16.9 to (1.2.2.1.4) because
the first literals of the two are unifiable when we treat the usual variables of the goal as constants.
This unifier now tells us that we should instantiate y¯ with ack(s(x),y). We have overcome the
problem of guessing the right instantiation of the variable y of the lemma by replacing it with the
dummy variable y¯ until it became obvious which instantiation is likely to make the proof attempt
successful. When instantiating y¯ with ack(s(x),y) (which actually produces the additional goal
Def ack(s(x),y) ), this Hypothesis Apply yields essentially the same goal as in Example 16.9:
(1.2.2.1.4.1) wγ16.9(x,z)<wγ16.9(s(x),s(y)), z 6=ack(s(x),y),
less(ack(s(x),y),ack(x,ack(s(x),y)))= true,
less(s(y),ack(x,ack(s(x),y)))= true ; wγ16.9(s(x), s(y))
It should be pointed out that in Example 16.10 the instantiation of the free existential variable y¯
during the transformation of (1.2.2.1.4) to (1.2.2.1.4.1) also changes the goal (1.2.2.1.3) where the
occurrence of y¯ has to be instantiated with the same term, i.e. with ack(s(x),y). A free variable
is global in the sense that it denotes the same object in all prover formulas in which it occurs.
This violates the “mutual independence of the proof sub-problems represented by the formulas at
the open nodes in the proof graph”, which is one of our design goals of § 11.3. We do not know
which way is the best to overcome this violation. In the example, of course, we can make y¯ local
simply by extending our prover formulas to consist of super-literals (i.e. conjunctions of literals)
instead of literals — resulting in a system with local free existential variables similar to those in
the sequent calculus of B. In general, however, reasoning with these super-literals either needs
an extension of the literals in the super-literals to disjunctions of literals, an extension of these
literals to super-literals, &c.116 or a premature instantiation of the free variable117.
116which together with our design goal of a “homogeneous representation” leads to a considerable extension of our
language for prover formulas and a considerable complication of our inference rules
117which again may violate our design goal of “natural flow of information”
162
Note that the possibility of solving the instantiation problem by drawing connections between
the literals containing unbound118 variables (like the ‘y’ from above) and complementary literals
of other lemmas or hypotheses (resulting in a single inference rule applying several lemmas and
hypotheses) is rather limited: In general, we need the whole inference system and not only Lemma
and Hypothesis Apply rules for finding the appropriate instantiation for the unbound variable, cf.
the justification of our design goal of a “homogeneous representation” in § 11.3.
Thus, we do not know how to treat free existential variables according to our design goals
without extending our framework considerably. Moreover, we have not calculated enough exam-
ples with free existential variables and therefore our ideas on their treatment are not as mature
as the rest of our inference system. Furthermore, we have not clearly understood the advantages
of the treatment of existential variables in the style of Padawitz (1992). Finally, the inclusion
of existential variables would make our framework technically more complicated. For all those
reasons, we decided not to include free existential variables in this thesis.
The proof of Example 16.9 does not obey our design goal of “natural flow of information” in even
another aspect: The lemma (Strict Trans less) is applied although only one of its three literals is
found in the goal, which means that it is not obvious from the state of the proof that the decision
for its application is likely to render the proof attempt successful. Moreover, even though only
a few lemmas are listed in Example 5.15, there is quite a big number of similarly interesting
lemmas. Even a very good heuristic for picking the right one does not help if the lemma is not
known at all. Interestingly, NQTHM119 proves the lemma (Irrefl 2 ack) automatically, even when
the lemma (Strict Trans less) is not provided and the function ‘less’ is redefined such that the built-
in features for treating arithmetics cannot help. Since NQTHM has no existential variables either,
it may be a good idea to search for a proof of (Irrefl 2 ack) according to the heuristic knowledge
built into the induction rule of explicit inductive theorem proving:
Example 16.11 (continuing Example 16.9)
Assume that we have a state of a proof attempt that is given exactly by that of Example 16.9
before the Lemma Apply of (Strict Trans less). We now continue this proof attempt in a style
very similar to explicit induction. By matching the subterm of the induction hypothesis (1) of
Example 16.9 that has the expanded function ‘ack’ as head symbol to the subterms of the goal
(1.2.2.1) of Example 16.9 we get the substitutions µ0 := {y7→ack(s(x),y)} and µ1 := {x 7→s(x)}.
Therefore, according to the heuristic knowledge built into the induction rule of explicit inductive
theorem proving, the following two Hypothesis Applies of (1) of Example 16.9 are likely to be
successful.
118i.e. not bound by the substitution matching the lemma (or hypotheses) to the goal
119cf. Boyer & Moore (1988)
163
The first uses µ0 and yields the following new goals:
(1.2.2.1.1) Defack(s(x),y),
less(s(y),ack(x,ack(s(x),y)))= true ; wγ16.9(s(x),s(y))
(1.2.2.1.2) less(ack(s(x),y),ack(x,ack(s(x),y))) 6= true, Def ack(s(x),y),
less(s(y),ack(x,ack(s(x),y)))= true ; wγ16.9(s(x),s(y))
(1.2.2.1.3) wγ16.9(x,z)<wγ16.9(s(x), s(y)), z 6=ack(s(x),y),
less(s(y),ack(x,ack(s(x),y)))= true ; wγ16.9(s(x),s(y))
Lemma Apply of (Defack) removes (1.2.2.1.1).
The second Hypothesis Apply uses µ1 and transforms (1.2.2.1.2) into
(1.2.2.1.2.1) less(y,ack(s(x),y)) 6=true,
less(ack(s(x),y),ack(x,ack(s(x),y))) 6= true, Defack(s(x),y),
less(s(y),ack(x,ack(s(x),y)))= true ; wγ16.9(s(x), s(y))
(1.2.2.1.2.2) wγ16.9(s(x),y)<wγ16.9(s(x),s(y)),
less(ack(s(x),y),ack(x,ack(s(x),y))) 6= true, Defack(s(x),y),
less(s(y),ack(x,ack(s(x),y)))= true ; wγ16.9(s(x), s(y))
Now a Lemma Apply of (Strict Trans less) can transform (1.2.2.1.2.1) into:
(1.2.2.1.2.1.1) Defack(x,ack(s(x),y)),
less(y,ack(s(x),y)) 6= true,
less(ack(s(x),y),ack(x,ack(s(x),y))) 6= true, Def ack(s(x),y),
less(s(y),ack(x,ack(s(x),y)))= true ; wγ16.9(s(x),s(y))
which can be removed by Lemma Apply of (Defack).
Now the proof attempt can be completed just as in Example 16.9.
Note that now the application (Strict Trans less) is straightforward (contrary to Example 16.9)
because all its literals occur in the goal. Moreover, even if (Strict Trans less) is not known, it can
be generated from (1.2.2.1.2.1) by good generalization heuristics, cf. e.g. Boyer & Moore (1979),
Walther (1994).
Finally, it should be noticed that from a more abstract point of view the proofs of the examples
16.9 and 16.11 do not differ: Both prove (1.2.2.1) of Example 16.9 by a Cut (or Context Add, cf.
§ 15.1) on
less(ack(s(x),y),ack(x,ack(s(x),y)))= true
and then a Cut on
less(y,ack(s(x),y))= true,
such that two of the three resulting sub-goals are instances of the induction hypothesis (1) and
the remaining one is an instance of the lemma (Strict Trans less). The only difference — which
is very important, however, for discovering the proof in practice — is that in Example 16.9 both
Cuts are generated by a rather unmotivated Lemma Apply, while in Example 16.11 each of the
Cuts is generated by a Hypothesis Apply that is directly recommended by the standard heuristics
of explicit induction.
164
Finally, we present the Hypothesis Rewrite rule that is for the Hypothesis Apply what the Lemma
Rewrite is for the Lemma Apply as discussed in § 14.5. We could repeat the whole discussion
of § 14.5 in a slightly adapted form here, but we think that the adaptation is obvious and the
discussion can be omitted.
Let m,n ∈ N; Γ,Π,Π′,Λ0, . . . ,Λm+1,Θ ∈ Form; λ0, . . . ,λm ∈ G EN L I T (sig,V); ℵ,k,k′ ∈
Weight(V). λ′′ ∈ L I T (sig,V); p ∈ POS (λ′′)\{ /0}.
Let L be a finite subset of ‘Form’, and H, G be finite subsets of ‘SynCons’:
Hypothesis Rewrite:
(L ,H ∪ {(Π,k)} ,G ∪ { ( Γλ′′∆ , ℵ) } )
(L ,H ∪ {(Π,k)} ,G ∪ { ( λi ΛiΓλ′′∆ , ℵ) | i≺m }
∪ { ( ΛmΓλ′′[ p← r ]∆ , ℵ) }
∪ { ( (k′<ℵ)Λm+1Γλ′′∆ , ℵ) } )
if, for some n m, (Π′,k′,Y,Θ) results from application of some µ ∈ G EN S UB (V,T )
to (Π,k) w.r.t. V (λn−1λn . . .λ0Γλ′′∆,ℵ) and all the following holds:
- λm equals (l=r) for l := λ′′/p,
- ∀i≺n.
(
Λi is contained in λi−1λi−2 . . .λ0
)
,
- ∀im+1.
(
Λi is contained in λi−1λi−2 . . .λ0Θ
)
,
- Π′Θ is contained in λmΛmΓ∆,
- ∀x∈Y.
(
(Def xµ) is contained in λn−1λn−2 . . .λ0Γ∆
)
,
- ∀x∈GENDOM(µ).
(
(Def xµ) is contained in ΛmΓ∆
)
.
Lemma 16.12 The Hypothesis Rewrite rule is a safe sub-rule of the Transformation rule.
Note that in the Hypothesis Rewrite rule we intend that Λm equals λm−1λm−2 . . .λ0Θ.
165
16.3 Solving Negative Literals
If the atom corresponding to a negative literal of a goal is false for a certain instantiation, then
the goal is true for this instantiation. Thus, we only have to consider those instantiations of a
goal which satisfy or solve the atoms corresponding to the negative literals. When we have a
complete description of all those solutions by means of pairs (Λ,σ) consisting of a formula Λ
and a substitution σ, such that for each substitution τ that solves the atoms corresponding to the
negative literals there is some (Λ,σ) of this description such that Λτ is false and ∃ϕ. τ=σϕ,
then we can transform the goal Γ into the sub-goals (ΛΓ)σ. An inference rule of this type will
be said to solve negative literals.
In this section we present rules solving negative literals by incremental narrowing. These
rules, namely the 6=- and Def-Solve rules, utilize the initiality or freeness of the algebras that
establish some specific notion of inductive validity, cf. § 11.1. In a certain sense, the 6=-Solve rule
generalizes the 6=-Tautology Remove rule of § 14.2.
Rules for solving negative literals play an essential role in similar inference systems, cf. e.g.
Bevers & Lewi (1990), Becker (1994), or Avenhaus & Madlener (1995). In our inference system
they are only needed on the one hand for exploiting the incompleteness of the case analysis of the
defining rules for a non-constructor function symbol (cf. Example 16.15) and on the other hand
for showing the inequality of two pure constructor terms (cf. examples 16.17 and 16.18). The
latter case is more generally applicable because it relies on the freeness of constructors only (no
confusion in the constructor sub-universe) which is given in the C-, D′-, D-, and E-case, whereas
the freeness requirements for the first case are only given in the D- or E-case. The major role of
the 6=-Solve rule in the above inference systems is played in our inference system by the more
generally applicable Substitution Add instead, possibly followed by some Context Adds.
Note that our Solve rules below do not require termination of the reduction relation given by
the defining set of rules R. This is contrary to the inference systems cited above where termination
is required — at least for effectiveness. The price we have to pay for this is that we have to
require the negative literal to be linear. Even though our inference system can linearize non-linear
literals (via Variable Add and Constant Rewrite), the linearity requirement makes it impossible
to simulate some proofs that are possible without, cf. Example 16.19. Since we have left the
induction ordering on an abstract level for the whole discussion of our concrete inference system,
we do not want to include the subject of practically establishing termination, especially not for
the optimization of an inference rule that is of little importance for our inference system.
For the definition of NARROW(. . ., . . ., . . .) cf. Definition 13.15.
166
Let Γ,∆ ∈ Form; s ∈ S; t,t ′ ∈ T SIG,s; ℵ ∈Weight(V).
Let L be a finite subset of ‘Form’, and H, G be finite subsets of ‘SynCons’.
6=-Solve:
(L ,H ,G ∪ { ( Γ(t 6=t ′)∆, ℵ) } )
(L ,H ,G ∪ { ( ΛΓ(t 6=t ′)∆, ℵ)σ | (Λ,σ) ∈ NARROW(t,t ′,V (Γ(t 6=t ′)∆,ℵ)) } )
if (t 6=t ′) is linear and
(
V (t 6=t ′)∩ (V <(Γ∆)∪V (ℵ)) = /0
∨ the induction ordering is semantic
)
.
Def-Solve:
(L ,H ,G ∪ { ( Γ(Def t)∆, ℵ) } )
(L ,H ,G ∪ { (ΛΓ(Def t)∆, ℵ)σ | (Λ,σ) ∈ NARROW(x,t,V (Γ(x 6=t)∆,ℵ)) } )
if x∈VC ,s\V (Γ(Def t)∆,ℵ),
t is linear, and
(
V (t)∩ (V <(Γ∆)∪V (ℵ)) = /0
∨ the induction ordering is semantic
)
.
Lemma 16.13 Assume either that the D- or E-case holds or otherwise that, for the literal (t 6=t ′)
of the 6=-Solve rule, t,t ′∈T (cons,VC ) and K is a sub-class of the class of constructor-minimal
models of R. Now:
The 6=-Solve rule is a safe sub-rule of the Transformation rule.
Lemma 16.14 Assume that the D- or E-case holds. Now:
The Def-Solve rule is a safe sub-rule of the Transformation rule.
Note that the linearity requirement for the literal of 6=-Solve rule is necessary: Otherwise the
following literals would be treated as valid which, however, is not true; thus resulting in an
unsound inference rule: For R: a=f(a) the literal x 6= f(x). For R: a=f(a); eq(x,x)=true
the literal eq(x, f(x)) 6= true. For R: a=b; b=a; q(a,b)=true the literal q(x,x) 6= true.
Moreover, note that in case that one of t, t ′, say t, is a variable X ∈ VSIG, it is unwise to apply
the 6=-Solve rule, cf. Example 16.19. Instead one should do the following: Use Constant Rewrite
to remove X from Γ,∆,ℵ. Note that X does not occur in t ′ due to the required linearity of (X 6=t ′).
Finally, remove the literal (X 6=t ′) with a SIG-Variable Remove.
Similarly, in case that one of t, t ′, say t, is a variable x ∈ VC and t ′∈T (cons,VC ) it is also
unwise to apply the 6=-Solve rule. Instead one should do the following: Use Constant Rewrite
to remove x from Γ,∆,ℵ. Then transform the literal (x 6=t ′) into the literal (Def t ′) with a C -
Variable Remove. Finally, remove (Def t ′) with a Subsumptive Literal Remove using the Def-
axiom (Def t ′). For the same reason, in case of t∈T (cons,VC ) one should always apply the
Subsumptive Literal Remove with the Def-axiom (Def t) instead of the Def-Solve rule.
167
Furthermore, note that if the literals are not linear (as required for the Def- and 6=-Solve
rules), then this can always be achieved by introducing new aliases x′0, . . .x′n−1 ∈ Vς,s for each
variable x ∈ Vς,s occurring n+1-times in the literal, then adding the literals (x 6=x′0) . . .(x 6=x′n−1)
by ς-Variable Add, and finally n Constant Rewrite steps for replacing the ith occurrence of x in
the original literal with x′i.
Example 16.15 (continuing Example 5.12)
Let X ,Y ∈ VSIG,nat. Let x,y ∈ VC ,nat. Assume that the induction ordering is semantic. Consider
the formulas
X−Y 6=0, X =Y
and
x−y 6=0, x=y
which are type-D and -E but not type-C or -D′ valid.
To prove the more general one, let us start with
(1) X−Y 6=0, X =Y ; wγ16.15(X ,Y )
Now we can apply the 6=-Solve rule to (X−Y 6=0), yielding:
(1.1) x−0 6=0, x=0 ; wγ16.15(x,0)
(1.2) s(x)−s(y) 6=0, s(x)=s(y) ; wγ16.15(s(x),s(y))
The first is transformed by a Lemma Rewrite into
(1.1.1) x 6=0, x=0 ; wγ16.15(x,0)
which is removed by =-Decompose.
The second is transformed by a Lemma Rewrite into
(1.2.1) x−y 6=0, s(x)=s(y) ; wγ16.15(s(x), s(y))
Now a Hypothesis Apply with our original goal transforms this into
(1.2.1.1) x 6=y, x−y 6=0, s(x)=s(y) ; wγ16.15(s(x),s(y))
(1.2.1.2) wγ16.15(x,y)<wγ16.15(s(x), s(y)), x−y 6=0, s(x)=s(y) ; wγ16.15(s(x),s(y))
An =-Decompose removes the goal (1.2.1.1) and the ordering literal of (1.2.1.2) can be easily
solved.
Note that the 6=-Solve is more powerful than a Substitution Add could have been. Even with
the weaker version of the original formula that has constructor variables only, a Substitution Add
would have produced a third goal, namely
(1.3) 0−s(y) 6=0, 0=s(y) ; wγ16.15(0,s(y))
which clearly exhibits why the original formula is only type-D and -E valid: The types C and
D′ must include the C :cons-term-generated constructor-minimal model with 0−s(y)=0 which
falsifies this third goal.
168
Note that it is not the case that the proofs of lemmas involving functions with incomplete defining
case distinctions usually include Solve rules. This would imply that these lemmas were only
known to be type-D and -E valid. Since we consider it to be important that the reader really
becomes aware that type-C is a most appropriate notion of inductive validity we give another
example:
Example 16.16 (continuing Example 5.12)
Let us prove the lemma (Def−) of Example 5.15:
(1) Def (x−y), leq(y,x) 6= true ; wγ16.16(x,y)
Substitution Add yields:
(1.1) Def (x−0), leq(0,x) 6= true ; wγ16.16(x,0)
(1.2) Def (x− s(y)), leq(s(y),x) 6= true ; wγ16.16(x, s(y))
Lemma Rewrite with rule (−1) of Example 5.12 yields:
(1.1.1) Def x, leq(0,x) 6= true ; wγ16.16(x,0)
which is removed by Def-Decompose.
Substitution Add to (1.2) yields:
(1.2.1) Def (0−s(y)), leq(s(y),0) 6= true ; wγ16.16(0,s(y))
(1.2.2) Def (s(x)−s(y)), leq(s(y), s(x)) 6= true ; wγ16.16(s(x),s(y))
Lemma Rewrite with the rule (leq2) of Example 5.12 yields
(1.2.1.1) Def (0−s(y)), false 6= true ; wγ16.16(0,s(y))
which is removed as an 6=-Tautology.
Lemma Rewrite with the rule (leq3) of Example 5.12 transforms (1.2.2) into
(1.2.2.1) Def (s(x)−s(y)), leq(y,x) 6= true ; wγ16.16(s(x),s(y))
Lemma Rewrite with the rule (−2) of Example 5.12 yields:
(1.2.2.1.1) Def (x−y), leq(y,x) 6= true ; wγ16.16(s(x), s(y))
Finally, Hypothesis Apply of (1) yields
(1.2.2.1.1.1) wγ16.16(x,y)<wγ16.16(s(x),s(y)),
Def (x−y), leq(y,x) 6= true ; wγ16.16(s(x),s(y))
whose ordering literal is trivially satisfiable.
169
Now let us see whether the 6=-Solve rule is powerful enough to prove those of Peano’s axioms
that contain negative equations:
Example 16.17 (continuing Example 5.12)
Let us prove the lemma (0 6=s) of Example 5.15 assuming that the induction ordering is semantic:
(1) 0 6=s(x) ; wγ16.17(x)
Since both 0 and s(x) are pure constructor terms, we can apply the 6=-Solve rule (or the 6=-
Tautology Remove rule) without restricting to the D- or E-case. This removes the goal directly
and finishes the proof.
Example 16.18 (continuing Example 5.12)
Let us prove the lemma (Inject s) of Example 5.15 assuming that the induction ordering is seman-
tic:
(1) s(x) 6=s(y), x=y ; wγ16.18(x,y)
Since both s(x) and s(y) are pure constructor terms, we can apply the 6=-Solve rule without re-
stricting to the D- or E-case. This results in the new goal
(1.1) s(x) 6=s(x), x=x ; wγ16.18(x,x)
which is removed by an =-Decompose.
Now, while this was rather fine, the following example shows a shortcoming of our 6=-Solve rule:
Example 16.19 (continuing Example 5.12)
Let us try to prove the lemma (Irrefl s) of Example 5.15 assuming that the induction ordering is
semantic:
(1) x 6=s(x) ; wγ16.19(x)
Now since x 6=s(x) is not linear, we cannot apply our 6=-Solve rule directly. (And since x and
s(x) are not clashing, we also cannot apply the 6=-Tautology Remove rule.) We first have to do a
C -Variable Add to yield
(1.1) y 6=x, x 6=s(x) ; wγ16.19(x)
and then a Constant Rewrite to yield
(1.1.1) y 6=x, y 6= s(x) ; wγ16.19(x)
Now, since y is a constructor variable and s(x) is a pure constructor term we are in a situation of
which we said above that it is unwise to apply an 6=-Solve. But let us be so silly as to do it:
(1.1.1.1) s(x) 6=x, s(x) 6=s(x) ; wγ16.19(x)
Then a Subsumptive Literal Remove with the =-axiom s(x)=s(x) yields
170
(15) s(x) 6=x ; wγ16.19(x)
Now the goal (15) equals the goal (1) which means that we have made no progress.
This means that our 6=-Solve rule is not powerful enough to prove the lemma (Irrefl s). Neverthe-
less, we prove it in Example 16.20 and again in Example 16.21.
Note that we could prove the lemma in a one step proof if the linearity restriction of the 6=-Solve
rule were omitted. This can really be done when all instantiations of the terms of the 6=-literal are
terminating, which is the case here with respect to R5.12. Cf. e.g. Avenhaus & Madlener (1995)
for an 6=-Solve rule for the special case of termination. We will include such a rule when we
come across a proof for which such a rule is necessary.
Example 16.20 (continuing Example 5.12)
Let us again try to prove the lemma (Irrefl s) of Example 5.15:
(1) x 6=s(x) ; wγ16.20(x)
A Substitution Add yields:
(1.1) 0 6=s(0) ; wγ16.20(0)
(1.2) s(x) 6=s(s(x)) ; wγ16.20(s(x))
An 6=-Tautology Remove deletes the goal (1.1).
A Lemma Apply of lemma (Inject s) of Example 5.15 transforms (1.2) into
(1.2.1) x 6= s(x), s(x) 6=s(s(x)) ; wγ16.20(s(x))
A Hypothesis Apply of (1) transforms this into the goal
(1.2.1.1) wγ16.20(x)<wγ16.20(s(x)), x 6=s(x), s(x) 6=s(s(x)) ; wγ16.20(s(x))
whose ordering literal is trivially satisfiable.
Shorter than the proof above is the following proof for the same lemma:
Example 16.21 (continuing Example 5.12)
Let us again prove the lemma (Irrefl s) of Example 5.15, now assuming the induction ordering to
be semantic:
(1) x 6=s(x) ; wγ16.21(x)
A Constant Rewrite yields:
(1.1) x 6=s(x) ; wγ16.21(s(x))
Finally, Hypothesis Apply of (1) yields:
(1.1.1) wγ16.21(x)<wγ16.21(s(x)), x 6=s(x) ; wγ16.21(s(x))
whose ordering literal is trivially satisfiable.
171
Finally, in the following examples, assuming X ,Y ∈VSIG,nat, x,y∈VC ,nat, and the induction
ordering to be semantic, we show how to use the Def-Solve rule for showing the strictness of
functions.
Example 16.22 (continuing Example 5.12)
Let us prove the following goal, whose formula is type-D but not type-C valid.
(1) Def s(X), Def X ; wγ16.22(X)
A Def-Solve yields:
(1.1) Def s(x), Def x ; wγ16.22(x)
which is removed by Def-Decompose.
Example 16.23 (continuing Example 5.12)
Let us prove the following goal, whose formula is type-D but not type-C valid.
(1) Def (X +Y ), Def X ; wγ16.23(X ,Y )
A Def-Solve yields:
(1.1) Def (x+0), Def x ; wγ16.23(x,0)
(1.2) Def (x+s(y)), Def x ; wγ16.23(x,s(y))
which are both removed by Def-Decompose.
Example 16.24 (continuing Example 5.12)
Let us prove the following goal, whose formula is type-D but not type-C valid.
(1) Def (X +Y ), DefY ; wγ16.24(X ,Y )
A Def-Solve yields:
(1.1) Def (x+0), Def0 ; wγ16.24(x,0)
(1.2) Def (x+s(y)), Def s(y) ; wγ16.24(x,s(y))
which are both removed by Def-Decompose.
It may be interesting to note that (1) could also be shown when we defined ‘+’ using general
variables instead of constructor variables. In this case, instead of (1.2) we would get:
(1.2′) Def (X +s(Y )), Def s(Y ) ; wγ16.24(X ,s(Y ))
Then we can use Def-Decompose to get:
(1.2′.1) DefY , Def (X +s(Y )), Def s(Y ) ; wγ16.24(X ,s(Y ))
172
A Subsumptive Literal Remove with the lemma shown in Example 16.22 yields
(1.2′.1.1) DefY , Def (X +s(Y )) ; wγ16.24(X ,s(Y ))
A Lemma Rewrite with the new version of the rule (+2) transforms (1.2′.1.1) into
(1.2′.1.1.1) DefY , Def s(X +Y ) ; wγ16.24(X ,s(Y ))
A Lemma Apply of the lemma shown in Example 16.22 yields
(1.2′.1.1.1.1) Def (X +Y ), DefY , Def s(X +Y ) ; wγ16.24(X ,s(Y ))
A Subsumptive Literal Remove with the Def-axiom Def (X +Y ), Def s(X +Y ) yields
(1.2′.15) Def (X +Y ), DefY ; wγ16.24(X ,s(Y ))
A Hypotheses Apply yields
(1.2′.16) wγ16.24(X ,Y )<wγ16.24(X ,s(Y )), Def (X +Y ), DefY ; wγ16.24(X ,s(Y ))
whose ordering literal can be solved, but only in the D- or E-case because otherwise Y and s(Y )
may be semantically equal for some fancy Y .
16.4 Generalization
Contrary to deductive first-order theorem proving, inductive theorem proving often is only suc-
cessful when one tries to show stronger theorems than the ones one initially intended to show.
This is because an inductive theorem is not only a task (as goal) but also a tool (as induction
hypothesis) for the inductive argumentation.
For this purpose we could present some generalizing sub-rules of the Transformation rule like
the Context Remove rule described in § 14.3. In a certain sense this Context Remove rule is an
antagonist of the Context Add rule. Similarly, we could present an antagonist of the Substitution
Add rule to replace certain terms with new variables. Since it is the nature of such generalizing
rules not to be safe, it is hardly reasonable to find out those sub-cases in which they are safe. Due
to their unsafe nature, generalizing inference steps should be done rarely and only for preparation
of new induction hypotheses. Since user supplied goals tend to be sufficiently general, most of the
time these generalizing rules are only needed before starting a lemma proof or a mutual induction.
Since an induction hypothesis is of no use without an appropriate weight, these generalizing rules
would also require a possibility to adjust the weight of the goal appropriately.
Before we are going to explain why we do not want and do not have to include generalizing
rules into our inference system here, we should try to make clear what we are talking about with
the help of the following example:
Example 16.25 (continuing Example 5.12)
Let x and y be constructor variables of the sort nat. Suppose we want to prove the lemma (True
p) of Example 5.15:
(1) p(x)= true ; wγ1(x)
173
First we use the Memorizing Rule of § 12.4 to copy (1) into the set of induction hypotheses. Then
we replace (1) via Substitution Add with the following new goals:
(1.1) p(0)= true ; wγ1(0)
(1.2) p(s(x))= true ; wγ1(s(x))
We remove (1.1) by Lemma Apply of (p1).
A Lemma Apply of (p2) (choosing m := 2; λ0 := p(x)6=true; λ1 := q(x, s(x))6=true)
transforms (1.2) into the new goals:
(1.2.1) p(x)= true, p(s(x))= true ; wγ1(s(x))
(1.2.2) q(x, s(x))=true, p(s(x))= true ; wγ1(s(x))
A Hypothesis Apply of (1) (choosing m := 0) transforms (1.2.1) into
(1.2.1.1) wγ1(x)<wγ1(s(x)), p(x)= true, p(s(x))= true ; wγ1(s(x))
which we delay until the end of the proof where we will talk about the induction ordering.
Now if we had generalizing sub-rules of the Transformation rule in our inference system, we
could use a Context Remove (on p(s(x))=true) and a Substitution Remove (with {y7→s(x)})
including a weight manipulation to transform (1.2.2) into
(2) q(x,y)= true ; wγ2(x,y)
Now, however, instead of transforming the goal (1.2.2) into the goal (2), we prefer to use the
Expansion rule of § 12.4 to add (2) as a new goal and delay the treatment of (1.2.2).
After copying (2) into the set of induction hypotheses with the Memorizing Rule of § 12.4, a
Substitution Add transforms (2) into the new goals:
(2.1) q(x,0)= true ; wγ2(x,0)
(2.2) q(x,s(y))= true ; wγ2(x,s(y))
A Lemma Apply of (q1) removes (2.1).
A Lemma Apply of (q2) (choosing m := 2; λ0 := q(x,y) 6=true; λ1 := p(x)6=true) transforms
(2.2) into the new goals:
(2.2.1) q(x,y)=true, q(x, s(y))= true ; wγ2(x, s(y))
(2.2.2) p(x)= true, q(x, s(y))= true ; wγ2(x,s(y))
A Hypothesis Apply of (2) (choosing m := 0) transforms (2.2.1) into
(2.2.1.1) wγ2(x,y)<wγ2(x,s(y)), q(x,y)= true, q(x, s(y))= true ; wγ2(x,s(y))
A Hypothesis apply of (1) (choosing m := 0) transforms (2.2.2) into
(2.2.2.1) wγ1(x)<wγ2(x,s(y)), p(x)= true, q(x,s(y))= true ; wγ2(x,s(y))
Now we have reached the first state of our proof attempt in which we know that the induction
proof of (2) depends on the induction proof of (1). This means that now we know that a Lemma
Apply of (2) to (1.2.2) will not lead to a successful completion of our proof attempt. Note that
a Lemma Apply is usually the better choice since it does not require us to solve an additional
ordering condition. Here, in our case, however, we now know that we have to use a Hypothesis
Apply of (2) to transform (1.2.2) into the new goal
(1.2.2.1) wγ2(x, s(x))<wγ1(s(x)), q(x,s(x))= true, p(s(x))= true ; wγ1(s(x))
174
Gathering the ordering conditions from the remaining goals, i.e. (1.2.1.1), (1.2.2.1), (2.2.1.1),
(2.2.2.1), we get
w
γ
1(x)<w
γ
1(s(x))
w
γ
2(x,s(x))<w
γ
1(s(x))
w
γ
2(x,y)<w
γ
2(x, s(y))
w
γ
1(x)<w
γ
2(x, s(y))
which are all satisfied by the lexicographic path ordering where wγ1 and w
γ
2 are equivalent in the
precedence.
This completes the proof. Note that if we had not adjusted the weight of (2) appropriately but
would have gone on with wγ1(x) instead of w
γ
2(x,y), then our proof attempt would not have been
successful since the last two of the above four ordering conditions would be unsatisfiable.
175
In comparison with the development and application of specialized generalizing sub-rules of the
Transformation rule, the generalization by use of the Expansion rule instead, as illustrated in the
above example, has the following advantages:
1. The choice whether to use a Lemma or a Hypothesis Apply to connect the intermediate sub-
goal with the generalized new goal can be delayed until we know whether the cheaper and
more widely applicable Lemma Apply will do or whether we have to use the Hypothesis
Apply rule which requires us to solve an additional ordering condition.
This means that generalization by use of the Expansion rule (contrary to generalizing sub-
rules of the Transformation rule) complies with our design goal of a “natural flow of infor-
mation” of § 11.3.
2. A whole and always incomplete bunch of very complicated and difficult to apply general-
izing sub-rules of the Transformation rule becomes superfluous.
3. We can restrict all Transformation steps to be safe.
The only unsafe steps in our proofs will be the Expansion steps then. When we organize our
proof attempts as a forest of trees where an Expansion adds a new root and a Transformation
adds new children to a leaf node, then we know the root to be invalid if one of its offspring
is invalid (provided all Transformations are safe).
On the other hand, note that for using the Expansion rule for generalization in practice we really
need something like a graph structure to organize our goals, including pointers for Lemma and
Hypothesis Applies as well as for the intention to do such an Apply.
176
Besides Context and Substitution Remove one could think of generalization steps for decompo-
sition similar to those generally unsafe steps called “inverse functionality” in § 6.3 of Walther
(1994). As explained above, we do not want to have any unsafe rule in our inference system
besides the Expansion rule. Fortunately, decomposition can be done in a safe way:
Example 16.26 (Decomposition in =-literals)
Suppose that we have a common top symbol ‘f’ on both sides of an equation
(1) f(t0)=f(t1), Γ ; ℵ
We can use an =-Decompose to yield
(1.1) t0=t1, f(t0)=f(t1), Γ ; ℵ
Finally, if really necessary, a Context Remove step could transform (1.1) into
(1.1.1) t0=t1, Γ ; ℵ
which is unsafe in general, so that we prefer to do this step with the Expansion rule instead.
If we, however, have a lemma
x=y, f(x) 6= f(y)
saying that f is injective, then we can do the step from (1.1) to (1.1.1) with a Subsumptive Literal
Remove, which is safe.
Example 16.27 (Decomposition in Def-literals)
Suppose that we have a constructor symbol ‘c’ on top of a Def-literal
(1) Def c(t), Γ ; ℵ
with120 t 6∈T (cons,VC ). Application of the Def-Decompose rule yields
(1.1) Def t, Def c(t), Γ ; ℵ
Finally, if really necessary, a Context Remove step could transform the (1.1) into
(1.1.1) Def t, Γ ; ℵ
which is unsafe in general, so that we prefer to do this step with the Expansion rule instead.
If we, however, have a lemma (X ∈VSIG)
(2) Def X , Def c(X)
saying that c is strict, then we can do the step from (1.1) to (1.1.1) with a Subsumptive Literal
Remove, which is safe. Note, however, that (2) will never121 be type-C valid. Nevertheless, when
all unifiers between c(X) and the left-hand sides of R instantiate X with a pure constructor term
ci, then a Def-Solve can transform (2) into
(2.i) Def ci, Def c(ci)
120otherwise we had better apply the Def-Decompose rule to remove the goal (1) immediately
121unless the universe for the sort of X is necessarily trivial, as is the case when R contains a rule like X=0.
177
which then can be removed by application of the Def-Decompose rule, cf. Example 16.22.
17 A Concrete Failure Predicate
In § 12.10 we have discussed the notions and requirements for an abstract failure predicate ‘FAIL’.
The simplest non-trivial sound failure predicate is given by defining F∈FAIL0 if /0∈F, i.e. a
prover state is a failure state if it contains the empty formula (or clause, sequent) (i.e. a formula
with zero literals) as a lemma, hypothesis, or goal. Together with our Literal Remove rules from
§ 14.3 and the Variable Remove rules from § 15.2 this turns out to be surprisingly useful because
the other rules in the inference system can help to find the failure.
Example 17.1 (continuing examples 5.12 and 5.15)
Suppose we have the goal (where x,y∈VC ,nat and ℵ∈Weight(V))
(1) y 6=0, x=y ; ℵ
An 6=-Solve on the first literal transforms this into
(1.1) 0 6=0, x=0 ; ℵ{y7→0}
A Subsumptive Literal Remove with the =-axiom 0=0 yields
(1.1.1) x=0 ; ℵ{y7→0}
A Substitution Add yields the two goals
(1.1.1.1) 0=0 ; ℵ{y7→0, x 7→0}
(1.1.1.2) s(x)=0 ; ℵ{y7→0, x 7→s(x)}
An =-Decompose removes the goal (1.1.1.1). A Subsumptive Literal Remove122 with the lemma
0 6=s(x) of Example 5.15 transforms (1.1.1.2) into the empty goal
(1.1.1.2.1) ; ℵ{y7→0, x 7→s(x)}
Now (1.1.1.2.1) is a failure state w.r.t. FAIL0. Moreover, since FAIL0 is sound and all applied
inference rules are safe123 we know that our original state (1) is invalid (cf. Corollary 12.35),
i.e. it contains an invalid lemma, hypotheses, or goal. Since the lemmas can be restricted to the
proved lemma 0 6=s(x) of Example 5.15, the Acquisition rule is safe,124 and hypotheses are
not involved, we know that the goal of (1) is invalid. Moreover, following the instantiations of
the above proof, we can explain why this goal is invalid, namely because it is not satisfied for
{y7→0, x 7→s(x)}.
122Note that it is more straightforward to use the =-Literal Remove rule here, but below we want to discuss what
to do when lemmas are involved.
123Cf. Lemma 16.13, Lemma 16.2, and Lemma 14.8.
124Cf. Corollary 12.32.
178
Let us see what happens when we replace the constructor variables with non-constructor vari-
ables:
Example 17.2 (continuing examples 5.12 and 5.15)
Suppose we have the goal (where X ,Y ∈VSIG,nat and ℵ∈Weight(V))
(1) Y 6=0, X =Y ; ℵ
Since an 6=-Solve on the first literal is only possible in the D- or E-case (cf. Lemma 16.13), we
now start with a Constant Rewrite
(1.1) Y 6=0, X =0 ; ℵ
followed by a SIG-Variable Remove yielding
(1.1.1) X =0 ; ℵ
Covering sets for a non-constructor variable are never125 useful for proving a goal because they
have to contain a renaming substitution. Therefore they have not been discussed before. Neverthe-
less, they can help to discover a failure: A Substitution Add with the covering set of substitutions
{X 7→X}, {X 7→s(0)} transforms (1.1.1) into
(1.1.1.1) X =0 ; ℵ
(1.1.1.2) s(0)=0 ; ℵ{X 7→s(0)}
Now an =-Literal Remove yields an empty goal again:
(1.1.1.2.1) ; ℵ{X 7→s(0)}
125provided that the sort of the non-constructor variable is non-trivial
179
Now (1.1.1.2.1) is a failure state w.r.t. FAIL0. Moreover, since FAIL0 is sound and all applied
inference rules are safe126 we know that our original state (1) is invalid. Since neither lemmas
nor hypotheses are involved, we know that the goal of (1) is invalid.
In Avenhaus & Madlener (1995) one can find more sophisticated failure predicates which, how-
ever, are not more powerful127 but only more convenient.
18 Summarizing the Concrete Inference System
In the following theorem we summarize our main results concerning our concrete inference rules.
The numbers on the right-hand sides of the assumptions indicate the global requirements that are
satisfied due to them. The numbers on the right-hand sides of the listed inference rules indicate
the lemmas or corollaries that supply the corresponding result. These numbers are also useful
for finding the definition of the relevant inference rule because this definition always directly
precedes the indicated lemmas or corollaries.
Theorem 18.1 Assume the following:
• The B′-, C-, D′-, D-, or E-case of Definition 10.1 holds. 13.2
• R is a Def-MCRS over sig/cons/V. −→R, /0 is confluent.
Moreover, in the D-case, even −→R,VSIG is confluent. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13.1
• The global requirements of § 13.1
concerning the induction ordering are satisfied. 13.3, 13.4, 13.5
Now, w.r.t. the definitions 10.7 and 10.5 of counterexamples and (inductive) validity, the following
rules are safe sub-rules of the Transformation rule:
=- and Def-Decompose 14.1, 14.2
Subsumptive Literal Remove . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14.7, 14.8
Constant Rewrite 14.11
Lemma Apply . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .14.12
Lemma Rewrite 14.16
Context Add . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15.1
SIG- and C -Variable Remove 15.3, 15.4
SIG- and C -Variable Add . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15.5, 15.6
126Cf. Lemma 14.11, Lemma 15.3, Lemma 16.2, and Lemma 14.9.
127unless the linearization required for our Solve rules makes them inferior to the analogous construction of Aven-
haus & Madlener (1995) which is partly more powerful when the defining rules are known to be terminating. If we
add special Solve rules for terminating R, however, this inferiority disappears because the linearity requirement can
be dropped in case of a terminating R.
180
Substitution Add 16.2
Hypothesis Apply . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16.8
Hypothesis Rewrite 16.12
In addition, the following rules are safe sub-rules of the Transformation rule in the C-, D′-, D-,
or E-case:
6=-Tautology Remove 14.3
=-Literal Remove in case that the removed
=-literal consists of pure constructor terms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14.7, 14.9
6=-Solve in case that the solved
6=-literal consists of pure constructor terms 16.13
Finally, the following are safe sub-rules of the Transformation rule in the D- or E-case:
=- and Def-Literal Remove 14.7, 14.9, 14.10
6=- and Def-Solve 16.13, 16.14
19 Outlook
Before coming to a conclusion we would like to point out the problems we have not sufficiently
solved or covered yet but will study in the future:
Induction Ordering: An important aspect that is not included in this version of our inference
system (but will be included in Kühler & Wirth (1998)) is a concrete set of possible types128
of induction orderings and inference rules for each of these types. So far our inference
system only generates a set of ordering conditions in the form of a set of formulas (open
goals).
Guidance: When designing our inference system we were not interested in a minimal calculus
that admits an easy automatic control or guidance. Nevertheless, due to the many possi-
bilities in which our inference rules can be applied, tactics and even whole strategies for
finding proofs have to be developed for a useful prover based on our inference system.
Since a very sophisticated concept of proof guidance is required, a powerful programming
system for proof tactics (cf. Sprenger (1996)) seems to be the adequate way to proceed.
128E.g., the following types of orderings are possible: Recursive path orderings, semantic path orderings, decompo-
sition orderings, semantic orderings based on the expressible ordering on the natural numbers, or semantic orderings
based on (the size of) uniquely denoting constructor ground terms.
181
Existential Variables: In our concrete inference system for proving inductive validity we do not
have to instantiate our hypotheses before they become useful for the proof. In this respect
our approach is superior to the existential variables used in Walther (1992) to improve the
hypotheses application of Boyer & Moore (1979). The unnatural flow of information in
case of the γ-rule,129 however, (for which the premature instantiation of the hypotheses in
Boyer & Moore (1979) is an example) may still occur in some proofs with our inference
system when we apply a lemma or hypothesis and the matching substitution does not in-
stantiate all of its variables (cf. e.g. the instantiation of the variable y in Example 16.9). We
hope to remove this shortcoming in a future version of our inference system by adding free
existential variables in a restricted form such that the independence and self-descriptiveness
of our prover formulas (cf. § 11.3) can be preserved.
Universal Framework for Induction: Moreover, we hope that one day we will be able to repre-
sent the proofs of all the other known first-order-based inductive inference systems in terms
of our prover formulas and our inference rules, to be able to represent the whole tactic and
strategic knowledge on inductive theorem proving in a homogeneous unified framework.
We are still far away from this goal, though. E.g. the possible treatment of existential prop-
erties or variables as described in Padawitz (1992) has not been included into our concrete
inference system yet.
129Cf. § 11.3.
182
20 Conclusion
We have presented a novel constructor-based approach to positive/negative-conditional equational
specifications, which was heavily inspired by previous work of Kapur & Musser (1987 & 1986)
(for the case of unconditional equations only) and Zhang (1988). Under some reasonable restric-
tions on the syntactic form of positive/negative-conditional rules it turns out that the combina-
tion of these ideas with the approach of Kaplan (1988) becomes very fruitful and also relevant
for practical purposes since many natural specifications involve both conditional equations with
positive and negative conditions and partially specified functions. For such specifications we have
been able to define semantics admitting a unique model, being initial in the class of constructor-
minimal models, if (ground) confluence of our reduction relation is provided. The lack of an
initial model is one of the main disadvantages of the approach of Kaplan (1988).
The addition of constructor variables conceptually completes the constructor-based approach
and (together with the positive and negative conditions of our equations) provides us with a uni-
fying framework for the function specification style of classic inductive theorem proving on the
one hand and for classic term rewriting on the other.
A thorough and precise analysis of termination and decidability issues has led to some useful
and slightly weakened “decreasingness”-notions for conditional rule systems.
By refinement and combination of known results and by utilizing the additional information
given by the separation of the signature into constructor and non-constructor symbols, we have
also been able to provide some interesting and practically useful confluence criteria.
We have shown that considering inductive validity of first-order equational clauses instead
of pure unconditional equations gives rise to various conceivable notions of inductive validity.
Within the framework of constructor-based positive/negative-conditional specifications (which
provides an adequate unique model semantics) we have demonstrated that all these notions enjoy
a desirable monotonic behavior w.r.t. consistent extension, which is not the case for classic initial
or perfect model validity.
The whole specification approach provides a firm theoretical basis for inductive validity and
inductive theorem proving in theories specified by positive/negative-conditional equations. More-
over, for practical purposes, our specification approach can be presented in a concise and easy to
read fashion, cf. Kühler & Wirth (1996).
After describing why we consider explicit induction to be a special case of implicit induction (cf.
also Example 16.11), we captured the idea of implicit inductive theorem proving on an abstract
level. On this level we explained the advantages of explicit weights and of the “non-switched”
framework for inference systems for inductive theorem proving. Moreover, this abstract level
already provides us with the inference rules of our inference system: The unsafe Expansion rule
for starting a proof attempt for a new conjecture, the safe Memorizing rule which just copies a
goal into the set of hypotheses, the safe Acquisition rule which makes lemmas and defining rules
available for the proof, and the Transformation rule.
183
In the rest of the thesis we have described a concrete instance of our abstract frame, refined
the Transformation rule by exhibiting two dozens of safe sub-rules of it, and described a simple
failure predicate.
This concrete instance of the abstract frame is conceptually interesting: It does not require
termination of the defining positive/negative-conditional equational rules, such that verification
in necessarily non-terminating domains like program execution becomes possible. Beyond that,
our constructor-based framework admits an adequate treatment of partially specified functions in
our simple and clear framework of notions of inductive validity. Note that partial specification of
functions is of practical importance because, even in the cases where an effective completion is
possible, the over-specification resulting from a completion of the function definitions imposes
many problems in practice.
Since, however abstract our treatment may appear, we have never lost sight of the practical
aspect and always have given it preference to theoretical elegance, we have reason to expect that
our inference system is well-suited as a kernel of a practically useful inductive theorem prover.
We hope to give evidence of this with a system we are implementing according to the ideas
elaborated in § 11, which we would like to recommend for a concluding second reading.
A Refutational Completeness
The definitions of § 12.10 are essential for this section.
For achieving refutational completeness we need a wellfounded ordering >
refut on finite sets130
of syntactic constructs.
To guarantee refutation of invalid initial states the following properties are appropriate.
Definition A.1 (FAIL-Completeness)
The failure predicate FAIL is complete w.r.t. ⊢ and >
refut if for all finite sets L⊆ Form; H,G⊆
SynCons; if form[G] is invalid, but (L,H,G) is not a failure state, then there are finite sets L′, H ′,
G′ with (L,H,G) +⊢ (L′,H ′,G′) and G>
refutG′.
By wellfoundedness of >
refut we immediately get:
130Note that for practical reasons it may be convenient to define >
refut on lists of syntactic constructs or some
other structural augmentation to a finite set of syntactic constructs to satisfy the fairness defined below more locally.
Nevertheless, since we do not know how to describe this structural augmentation abstractly, we just suppose that
>
refut is defined on finite sets of syntactic constructs.
184
Corollary A.2 (Non-Deterministic Refutational Completeness)
Let L ⊆ Form; H,G ⊆ SynCons be finite sets. Assume either that ⊢ is sound or that131 L is
valid, H⊆G, and ⊢ is inductively sound. Furthermore assume FAIL to be complete w.r.t. ⊢
and >
refut . Now, if form[G] is invalid, then there is some failure state (L′,H ′,G′) w.r.t. FAIL with
(L,H,G) ∗⊢ (L′,H ′,G′) .
Definition A.3 (Fairness)
Let β be an ordinal number with βω . Let Li ⊆ Form; Hi,Gi ⊆ SynCons for all i ≺ 1+β.
Consider the derivation (Li,Hi,Gi) ⊢ (Li+1,Hi+1,Gi+1) (i≺β). It is called fair w.r.t. FAIL if
∃i≺1+β. Gi = /0
∨
 β≺ω∧ (Lβ,Hβ,Gβ) 6∈dom( ⊢ ) 132
∧ FAIL is complete w.r.t. ⊢ and >
refut

∨ ∀i≺1+β.
( (
form[Gi] is invalid
∧ (Li,Hi,Gi) is no failure state
)
⇒ ∃ j≺1+β. Gi>refutG j
)

Corollary A.4 ([Deterministic] Refutational Completeness)
Let β be an ordinal number with βω . Let Li ⊆ Form; Hi,Gi ⊆ SynCons be finite sets for all
i ≺ 1+β. Let (Li,Hi,Gi) ⊢ (Li+1,Hi+1,Gi+1) (i≺β) be a fair derivation w.r.t. FAIL. Assume
either that ⊢ is sound or that L0 is valid, H0⊆G0, and ⊢ is inductively sound. Now, if form[G]
is invalid, there must exist some i≺ 1+β such that (Li,Hi,Gi) is a failure state w.r.t. FAIL.
131In this second case we also know that the goals never become valid: Otherwise Corollary 12.6(5) implies induc-
tiveness of the current state which implies inductiveness of the initial state, and then Corollary 12.25 implies validity
of the original set of goals which contradicts the following assumption.
132i.e. no inference rule can be applied to (Lβ,Hβ,Gβ)
185
B A Sequent Calculus for Deductive Validity
Similar to Gentzen (1935), we partition V into bound and free variables because this makes the
distinction of bound and free occurrences of variables as well as the procedure of applying a
substitution most simple: We assume
Vς,s = Vbound,ς, s⊎Vfree,ς, s
for each (ς,s) ∈ {SIG,C }×S. Beyond this, we then partition the free variables again into free
δ+- and free γ+-variables according to the classification of reductive inference rules of Smullyan
(1968) and the of variables these rules introduce in Wirth (2004):
Vfree,ς, s = Vγ+,ς, s⊎Vδ+,ς, s.
We assume each of the sets Vbound,ς, s, Vγ+,ς, s, and Vδ+,ς, s to be infinite.
We define (Q∈{bound, free,γ+,δ+}; ς∈{SIG,C }; s∈S):
VQ := (VQ,ς, s)(ς,s)∈{SIG,C }×S
VQ,ς := (VQ,ς, s)s∈S
VQ, s := (VQ,ς, s)ς∈{SIG,C }
Let ‘A T ’ be the set of atoms containing the set A T (sig,Vfree) (cf. § 5.7) and possibly other pred-
icate atoms with fixed arity over terms from T (sig,Vfree).
Let L I T := { A, A | A ∈ A T } be the set of literals.
Still proceeding similar to Gentzen (1935), let the set of formulas F be the smallest set sat-
isfying: If A ∈ A T then A ∈ F. If A,B ∈ F, then (A∨B), (A∧B), (A⇒B), A are all formulas
in F. Furthermore, if A ∈ F, then ∀xB and ∃xB are formulas in F for (ς,s) ∈ {SIG,C }×S,
x ∈ Vbound,ς, s\V (A), y ∈ Vfree,ς, s, and B = A{y7→x}. By “A{x 7→t}” we denote the result of
substituting each occurrence of the variable x in A with the term t. Note that we never use A{x 7→t}
when A has a subsequence of the form “∃x” or “∀x”.
A sequent is a list of formulas, i.e., an element of F∗. We define an equivalence relation on
sequents of the same length: A sequent A0, . . . ,Am−1 is called a variant of the sequent B0, . . . ,Bn−1
if m=n and for all i≺ m either Ai =Bi or Ai, Bi are both atoms of the same predicate symbol
such that Ai and Bi are congruent (i.e. their top level terms are) w.r.t.
R := { (s,t) | ∃ j≺n. ((s=t) = A j ∧ V (s,t)⊆Vδ+) }.
Furthermore, for Ai = (s=t) we may even always require Bi = (s′=t) with s being congruent to
s′ w.r.t. R. Note that it is important for our approach that Ai 6=Bi implies that Ai and Bi are atoms
and no negative =- or Def-literals which play a special role in our system.
186
The axioms of the sequent calculus we want to present are the variants of the sequents of the
following form (where Γ,∆,Π ∈ F∗; A is an atom with predicate symbol different from ‘=’
and ‘Def’ and with V (A)⊆Vδ+; t ∈ T (sig,Vδ+); u ∈ T (cons,Vδ+,C ); n ∈ N; p0, . . . , pn−1 ∈
POS (u) mutually parallel; v0, . . . ,vn−1 ∈ T (sig,Vδ+)):
ΓA∆AΠ
ΓA∆AΠ
Γ(t=t)Π
And if (Def vi) is contained in ΓΠ for all i≺n:
Γ(Def u[ pi ← vi | i≺n ])Π
The rules of our sequent calculus are the following ( Γ,∆,Π ∈ F∗; A,B,C ∈ F ):
α-rules:
Γ A Π
ΓAΠ
Γ(A∨B)Π
ΓA BΠ
Γ(A∧B)Π
ΓA BΠ
Γ(A⇒B)Π
ΓA BΠ
β-rules:
Γ(A∨B)Π
ΓAΠ ΓBΠ
Γ(A∧B)Π
ΓAΠ ΓBΠ
Γ(A⇒B)Π
ΓAΠ ΓBΠ
if V γ+(A)∩V γ+(B) = /0.
γ+-rules:
Γ ∃xB Π
Γ B{x 7→yγ+}Π
Γ ∀xB Π
Γ B{x 7→yγ+}Π
where for some (ς,s) ∈ {SIG,C }×S: x∈Vbound,ς, s and yγ
+
∈Vγ+,ς, s\V (B).
δ+-rules:
Γ ∃xB Π
Γ B{x 7→yδ+}Π
Γ ∀xB Π
Γ B{x 7→yδ+}Π
where for some (ς,s) ∈ {SIG,C }×S:
x∈Vbound,ς, s and yδ+∈Vδ+,ς, s\V (ΓBΠ) and V γ+(B)= /0.
187
Instantiation-rule:
ΓC Π
Γ C{xγ+ 7→t} C Π
where for some (ς,s) ∈ {SIG,C }×S: xγ+∈Vγ+,ς, s and t ∈ T (sig,Vfree)s and
xγ
+
∈VSIG
∨ ∃

u∈T (cons,Vfree,C )
n∈N
p0, . . . , pn−1∈POS (u)
v0, . . . ,vn−1∈T
 .
 t =u[ pi ← vi | i≺n ]
∧ ∀in.
(
ΓCΠ contains (Def vi)
) 
.
The Restricted Instantiation-rule is like the Instantiation-rule but with the following restrictions:
t ∈ T (sig,Vδ+)s; u∈T (cons,Vδ+,C ); v0, . . . ,vn−1∈T (sig,Vδ+); and either
• C is a literal and x∈V γ+(C);
• C is of one of the forms (A∨B), (A∧B), (A⇒B), and x∈V γ+(A)∩V γ+(B); or
• C is of one of the forms ∃xB , ∀xB, and x∈V γ+(B).
Cut-rule:
Γ
AΓ AΓ
This completes our sequent calculus. Note that we do not need the Cut rule and the non-restricted
Instantiation-rule for deductive completeness, cf. Theorem B.6. Thus, while we could omit the
Cut-rule, we do not have inference rules for equality, which is similar to the systems of Wang
(1960), Kanger (1963), and Lifschitz (1971).
A proof tree for a sequent Γ is a tree such that Γ is the label of the root and the labels of the
children of each node exactly result from applying an inference step of our sequent calculus to the
label of this (parent) node. A branch of a proof tree is called closed if it contains a node labeled
with an axiom. A branch is called fair if it is closed or each α-, β-, γ+-, δ+-, and Restricted
Instantiation-rule application that is possible for some sequent is done for some descendent of
this sequent in the branch below. Note that this fairness is easily established for α, β, γ+, and
δ+. Since the Restricted Instantiation-rule has to be applied for each t ∈ T (sig,Vδ+)s satisfying
the condition of the rule, some bookkeeping using an enumeration of the terms of T (sig,Vδ+)s
is required. Furthermore, note that, for the β- and Restricted133 Instantiation-rule, in the branch
below a sequent to which they are applicable, the condition keeps being satisfied and the principal
literal keeps being present until the rule for the literal (and the term t) is applied. Moreover, the
γ+- and δ+-rule keep being applicable too, possibly for a different free variable. A proof tree is
fair (closed) if all its branches that start from the root and do not end before a leaf is reached are
fair (closed). If there is a closed proof tree for Γ, then it describes a proof for Γ in our sequent
calculus and we say that Γ is provable.
133Note that the unrestricted Instantiation-rule may lose its principal literal C by an application of a β- or δ+-rule.
188
Definition B.1 (Validity of a Sequent in a sig/cons-Structure)
A sig/cons-structure A is an extension of a sig/cons-algebra such that for all predicate symbols P
of ‘sig’ with arity s0 . . .sm−1 we have PA ⊆ A SIG,s0× . . .×A SIG,sm−1.
Let X⊆ Vfree; A be a sig/cons-structure; and κ ∈ S UB (X,A ).
An atom (u=v)∈ A T (sig,Vfree) is true w.r.t. Aκ if V (u,v)⊆X and Aκ(u)=Aκ(v); and an atom
(Def u) ∈ A T (sig,Vfree) (with u∈T SIG,s; s∈S) is true w.r.t. Aκ if V (u)⊆X and Aκ(u)∈A C ,s;
Pt0 . . . tm−1 is true w.r.t. Aκ if V (t0, . . . ,tm−1)⊆X and (Aκ(t0), . . . ,Aκ(tm−1)) ∈ PA .
An atom (u=v)∈A T (sig,Vfree) is false w.r.t. Aκ if V (u,v)⊆X and Aκ(u) 6=Aκ(v); and an atom
(Def u) ∈ A T (sig,Vfree) (with u∈T SIG,s; s∈S) is false w.r.t. Aκ if V (u)⊆X and Aκ(u) 6∈A C ,s;
Pt0 . . . tm−1 is false w.r.t. Aκ if V (t0, . . . ,tm−1)⊆X and (Aκ(t0), . . . ,Aκ(tm−1)) /∈ PA .
Let A,B ∈ F. The following table defines being true or false w.r.t. Aκ by a complete case distinc-
tion: A B A (A∨B) (A∧B) (A⇒B)
false false true false false true
false true true true false true
true false false true false false
true true false true true true
Let A∈ F, (ς,s)∈ {SIG,C }×S, x∈Vbound,ς, s\V (A), y∈Vfree,ς, s, and B = A{y7→x}. Define
Y := V free(B).
∃xB is true (false) w.r.t. Aκ if
A is true (false) w.r.t. Aκ′ for some (all) κ′ ∈ S UB (Y⊎{y},A ) with κ′|Y⊆κ.
∀xB is true (false) w.r.t. Aκ if
A is true (false) w.r.t. Aκ′ for all (some) κ′ ∈ S UB (Y⊎{y},A ) with κ′|Y⊆κ.
A sequent Γ ∈ F∗ is true w.r.t. Aκ if
V free(Γ)⊆X and there is some literal λ in Γ that is true w.r.t. Aκ.
A sequent Γ ∈ F∗ is false w.r.t. Aκ if all literals λ in Γ are false w.r.t. Aκ.
A sequent Γ ∈ F∗ is valid in A if
∀κ∈S UB (V δ+(Γ),A ). ∃ε∈S UB (V γ+(Γ),A ). (Γ is true w.r.t. Aκ∪ε).
A sequent is deductively valid if it is valid in all sig/cons-structures A .
Corollary B.2 (Soundness and Safeness)
The inference rules of our sequent calculus are sound in the sense that all provable sequents are
deductively valid. Moreover, they are safe in the sense that a sequent that is not deductively valid
at a node in a proof tree implies that the sequent at the root of this tree is not deductively valid.
189
Lemma B.3 (Substitution-Lemma for Formulas)
Let X⊆Vfree. Let A be a sig/cons-structure. Let κ ∈ S UB (X,A ).
Let σ ∈ G EN S UB (Vfree,T (Vfree)). Let A ∈ F with V free(Aσ)⊆ X.
Now the following two are logically equivalent:
• Aσ is true w.r.t. Aκ.
• A is true w.r.t. AσAκ .
Definition B.4 (Dual Hintikka Sets)
A dual Hintikka set DHS is a subset of the set of formulas F such that the following conditions
hold:
α-Closed: • If A ∈ DHS, then A ∈ DHS .
• If (A∨B) ∈ DHS, then A ∈ DHS and B ∈ DHS .
• If (A∧B) ∈ DHS, then A ∈ DHS and B ∈ DHS .
• If (A⇒B) ∈ DHS, then A ∈ DHS and B ∈ DHS .
β-Closed: For all A and B with V γ+(A)∩V γ+(B)= /0 :
• If (A∨B) ∈ DHS, then A ∈ DHS or B ∈ DHS .
• If (A∧B) ∈ DHS, then A ∈ DHS or B ∈ DHS .
• If (A⇒B) ∈ DHS, then A ∈ DHS or B ∈ DHS .
γ+-Closed: For all B, for all (ς,s) ∈ S, and for all x ∈ Vbound,ς, s, there is some
zγ
+
∈ Vγ+,ς, s\V (B) such that: • If ∃xB ∈ DHS, then B{x 7→zγ
+
} ∈ DHS .
• If ∀xB ∈ DHS, then B{x 7→zγ+} ∈ DHS .
δ+-Closed: For all B with V γ+(B)= /0, for all (ς,s) ∈ S, and for all x ∈ Vbound,ς, s, there is some
t ∈ T (Vfree)ς,s such that: • If ∃xB ∈ DHS, then B{x 7→t} ∈ DHS .
• If ∀xB ∈ DHS, then B{x 7→t} ∈ DHS .
Instantiation-Closed: For all s ∈ S, for all x ∈ Vγ+, s, for all t ∈ T (sig,Vδ+)s, for all C ∈ DHS,
we have C{x 7→t} ∈ DHS
if

x∈VSIG
∨ ∃

u∈T (cons,Vδ+,C )
n∈N
p0, . . . , pn−1∈POS (u)
v0, . . . ,vn−1∈T (sig,Vδ+)
 .
 t =u[ pi ← vi | i≺n ]
∧ ∀in.
(
(Def vi)∈DHS
) 
 and:
• C is a literal and x∈V γ+(C);
• C is of one of the forms (A∨B), (A∧B), (A⇒B), and x∈V γ+(A)∩V γ+(B); or
• C is of one of the forms ∃xB , ∀xB, and x∈V γ+(B).
190
Leibniz-Substitutable: For all l,r∈T (sig,Vδ+) with (l=r)∈DHS or (r=l)∈DHS:
• For each atom A with predicate symbol different from ‘=’ and with V γ+(A)= /0 and
A/q= l : If A ∈ DHS, then A[q← r ] ∈ DHS.
• For each s,t ∈ T (sig,Vδ+) with s/q= l :
If (s = t) ∈ DHS, then (s[q← r ] = t) ∈ DHS.
Reflexive-Consistent: For each t ∈ T (sig,Vδ+): (t=t) 6∈ DHS.
Def-Consistent: For all n∈N; u∈T (cons,Vδ+,C ); p0, . . . , pn−1∈POS (u); v0, . . . ,vn−1∈
T (sig,Vδ+); with ∀i≺n.
(
(Def vi)∈DHS
)
: (Def u[ pi ← vi | i≺n ]) 6∈DHS.
Predicate-Consistent: There is no A ∈ A T with predicate symbol different from ‘=’ and ‘Def’
and with V γ+(A)= /0 such that A ∈ DHS and A ∈ DHS.
Lemma B.5
For each dual Hintikka set DHS there is some sig/cons-structure A and some ι ∈ S UB (Vδ+,A )
such that ∀A∈DHS. ∀ε∈S UB (Vγ+,A ). (A is false w.r.t. A ι∪ε).
Theorem B.6 (Soundness and Completeness)
A sequent is provable in the above sequent calculus iff it is deductively valid.
Moreover, this still holds when we omit the Cut-rule and replace the Instantiation-rule with the
Restricted Instantiation-rule.
191
C The Proofs
Proof of Lemma 5.3
Assume −→0 and −→1 to be locally commuting.
For the first claim we assume that −→0 ∪−→1 is terminating. We show commutation by in-
duction over the wellfounded ordering −→0 ∪−→1+. Suppose t ′0
∗
←−0s
∗
−→1t
′
1. We have to
show t ′0
∗
−→1 ◦
∗
←−0t
′
1. In case there is some i ≺ 2 with t ′i =s the proof is finished due to t ′i =
s
∗
−→1−it
′
1−i
∗
←−it
′
1−i. Otherwise t ′0
∗
←−0t0←−0s−→1t1
∗
−→1t
′
1 for some t0, t1 (cf. diagram below).
By local commutation there is some s′ with t0
∗
−→1s
′ ∗←−0t1. Due to s−→0t0, by induction hypo-
thesis we get some s′′ with t ′0
∗
−→1s
′′ ∗←−0s
′. Due to s−→1t1, by induction hypothesis we get
s′′
∗
−→1 ◦
∗
←−0t
′
1.
s
1
> t1
∗
1
> t ′1
t0
∨
0
∗
1
> s′
∗
∨
0
t ′0
∗
∨
0
∗
1
> s′′
∗
∨
0
∗
1
> ◦
∗
∨
0
For the second claim we now assume that −→0 or −→1 is transitive. W.l.o.g. (due to symmetry
in 0 and 1) say −→0 is transitive. It is sufficient to show
∀n∈N. ∀s,t0,t1. (t0
∗
←−0s
n
−→1t1 ⇒ t0
∗
−→1 ◦
∗
←−0t1).
n=0: t0
∗
−→1t0
∗
←−0s=t1.
n ⇒ (n+1): Assume t0
∗
←−0s
n
−→1t
′−→1t1 (cf. diagram below). By induction hypothesis there is
some w with t0
∗
−→1w
∗
←−0t
′. In case of w= t ′ the proof is finished by t0
∗
−→1w= t
′−→1t1
∗
←−0t1.
Otherwise, since −→0 is transitive, we have w←−0t ′−→1t1. By the local commutation of −→0
and −→1 this implies w
∗
−→1 ◦
∗
←−0t0.
s
n
1
> t ′
1
> t1
t0
∗
∨
0
∗
1
> w
∗
∨
0
∗
1
> ◦
∗
∨
0
192
Proof of Lemma 5.4
That (3) (or else (2)) implies (1) is trivial. For (1) implying (2) and (3) it is sufficient to show
under the assumption of (1) that
∀n∈N. ∀s,t0,t1. (t0
n
←−0s−→1t1 ⇒ t0
=
−→1 ◦
∗
←−0t1).
n=0: t0 =s−→1t1
∗
←−0t1.
n ⇒ (n+1): Suppose t0←−0t ′
n
←−0s−→1t1 (cf. diagram below). By induction hypothesis there is
some w with t ′ =−→1w
∗
←−0t1. In case of t ′=w the proof is finished due to t0
=
−→1t0←−0t
′=
w
∗
←−0t1. Otherwise we have t0←−0t ′−→1w and get by the assumed strong commutation
t0
=
−→1 ◦
∗
←−0w.
s
1
> t1
t ′
n
∨
0
=
1
> w
∗
∨
0
t0
∨
0
=
1
> ◦
∗
∨
0
For proving the final implication of the lemma, we may assume that −→1 strongly commutes
over
+
−→0 . A fortiori
+
−→0 and −→1 are locally commuting. By Lemma 5.3 they are commuting.
Therefore −→0 and −→1 are commuting, too.
Proof of Lemma 5.5
It is trivial to show ∀n∈N. n←→⊆ ↓ by induction on n.
193
Proof of Lemma 5.6
“Only if”: hsh−1s ⊆ id implies that hs is injective. id|B SIG,s ⊆ h−1s hs implies that B SIG,s ⊆
hs[A SIG,s]. h−1::B→A being a sig/cons-homomorphism implies h−1s [B C ,s] ⊆ A C ,s and then
id|B SIG,s ⊆ h−1s hs implies B C ,s = id|B SIG,s [B C ,s]⊆ hs[h−1s [B C ,s]]⊆ hs[A C ,s].
“If”: Define h−1 := (h−1s )s∈S. Since hs is injective, we have hsh−1s ⊆ id|A SIG,s . Since hs is total
on A SIG,s, we have id|A SIG,s ⊆ hsh−1s . Thus hh−1 = IdA .
Since hs is a function, we have h−1s hs ⊆ id|B SIG,s . Since B SIG,s ⊆ hs[A SIG,s], we have
id|B SIG,s ⊆ h−1s hs. Thus h−1h= IdB .
Finally, we have to show that h−1::B→A is a sig/cons-homomorphism. For f ∈ F,
since h::A→B is a sig/cons-homomorphism, we have: h−1sn ( f B (b0, . . . ,bn−1)) =
h−1sn ( f B (hs0(h−1s0 (b0)), . . . ,hsn−1(h−1sn−1(bn−1)))) = h−1sn (hsn( f A (h−1s0 (b0), . . . ,h−1sn−1(bn−1)))) =
f A (h−1s0 (b0), . . . ,h−1sn−1(bn−1)).
Moreover, due to hs[A C ,s]=B C ,s we have h−1s [B C ,s]=h−1s [hs[A C ,s]]= id|A SIG,s [A C ,s]=A C ,s.
Q.e.d. (Lemma 5.6)
Proof of Lemmas 5.7 and 5.8 For Lemma 5.7 one shows ∀s∈S. ∀t∈T (X)SIG,s. hs(Bκ(t))=
Cκh(t) by structural induction on t. Lemma 5.8 is just a corollary of Lemma 5.7 when one
realizes that tµ=T (X)µ(t). Then we get Aκ(tµ)=Aκ(T (X)µ(t))=A µAκ(t).
Q.e.d. (Lemmas 5.7 and 5.8)
Proof of Lemma 6.2
It is sufficient to treat the case of λ being an atom.
We show the first equivalence first. For an equality atom the following are logically equivalent
due to Lemma 5.8: (u=v)µ is true w.r.t. Aκ; Aκ(uµ)=Aκ(vµ); A µAκ(u)=A µAκ(v); (u=v) is
true w.r.t. A µAκ . Similarly, for a definedness atom the following are logically equivalent for s
being the sort of u: (Def u)µ is true w.r.t. Aκ; Aκ(uµ)∈A C ,s; A µAκ(u)∈A C ,s; (Def u) is true
w.r.t. A µAκ .
Finally we show that, under the additional assumptions, λµ is true w.r.t. Aκ iff λ′µ is true w.r.t. Aκ.
Since λ−→
(l=r)λ′, there is some p ∈ POS (λ) such that λ/p= l and λ′=λ[ p← r ]. Choose an
arbitrary x ∈ VSIG,s\V (λ) for s being the sort of l. For u∈T SIG,s define νu by (y∈V): yνu :={
uµ if y=x
yµ otherwise
}
. Due to Aκ(lµ)=Aκ(rµ) we get νlAκ =νrAκ. By our first equivalence
shown above the following are logically equivalent: λ[ p← x ]νl is true w.r.t. Aκ; λ[ p← x ]
is true w.r.t. AνlAκ ; λ[ p← x ] is true w.r.t. AνrAκ; λ[ p← x ]νr is true w.r.t. Aκ. This actually
finishes the proof due to λµ=λ[ p← l ]µ=λµ[ p← lµ ]=λνl[ p← xνl ]=λ[ p← x ]νl and λ′µ=
λ[ p← r ]µ=λµ[ p← rµ ]=λνr[ p← xνr ]=λ[ p← x ]νr. Q.e.d. (Lemma 6.2)
194
Proof of Lemma 6.3 Let h::A→B and h−1::B→A be sig/cons-homomorphisms with hh−1 =
IdA and h−1h= IdB . Assume that Γ is valid in A . It suffices to show that Γ is valid in B . For
κ′ ∈ S UB (V,B ) we have κ′=κ′ IdB =κ′h−1h Thus, since κ′h−1∈S UB (V,A ) it suffices to
show that, for an arbitrary κ ∈ S UB (V,A ), Γ contains some literal λ that is true w.r.t. Bκh. By
our assumption that Γ is valid in A , Γ contains some literal λ that is true w.r.t. Aκ. Now we finish
the proof by a case analysis on the form of λ, using the Homomorphism-Lemma(5.7): In case of
λ = (u=v) we have Aκ(u)=Aκ(v) and thus Bκh(u) = hs(Aκ(u)) = hs(Aκ(v)) = Bκh(v). In case
of λ = (Def u) we have Aκ(u)∈A C ,s and thus Bκh(u) = hs(Aκ(u)) ∈ hs[A C ,s]⊆ B C ,s. In case
of λ = (u 6=v) we have h−1s (Bκh(u)) = h−1s (hs(Aκ(u))) = Aκ(u) 6= Aκ(v) = h−1s (hs(Aκ(v))) =
h−1s (Bκh(v)) and thus Bκh(u) 6=Bκh(v). In case of λ = (Def u) we have h−1s (Bκh(u)) =
h−1s (hs(Aκ(u))) = Aκ(u) 6∈ A C ,s ⊇ h−1s [B C ,s] and thus Bκh(u) 6∈B C ,s. Q.e.d. (Lemma 6.3)
Proof of Lemma 6.6
1. Due to ker(A )=ker(B ), A and B do not differ in their evaluation of two ground terms of
the same sort regarding ‘=’ or ‘6=’. Furthermore, if A (t)∈A C ,s for some t ∈ G T SIG,s,
then there is some t ′ ∈ G T C ,s with B (t ′)=B (t), by which we get B (t)∈B C ,s. Thus
‘Def t’ is true w.r.t. A only if it is true w.r.t. B . Since ‘Def ’ occurs as a positive literal in
the conditions of the rules only, A is a sig/cons-model of each ground rule of which B is a
sig/cons-model.
Now, if B is a sig/cons-model of R, by the Substitution-Lemma(5.8), it is a sig/cons-model
of all ground instances of the rules of R, which implies that A is a sig/cons-model of all
ground instances of the rules of R, which again implies that A is a sig/cons-model of all
rules of R. This last step can be seen the following way: Let κ be any A -valuation of V.
Then by the Axiom of Choice there is a σ ∈ S UB (V,G T ) such that σA =κ . Then by the
Substitution-Lemma ∀t∈T . Aκ(t)=A (tσ).
2. Since l::A→B being a sig/cons-homomorphism implies A l =B (for the sig/cons-homo-
morphisms A ::G T →A , B ::G T →B ) by the Homomorphism-Lemma(5.7), this is nothing
but an application of the Homomorphism-Theorem(5.9).
3. By (2) and .H ⊆ .C .
Q.e.d. (Lemma 6.6)
195
Proof of Lemma 6.7
1. Trivial.
2. If B is minimal itself, we are finished. If not, by Lemma 6.6(2) we can w.l.o.g. assume B to
be a factor algebra of G T and consider congruences on G T instead of sig/cons-algebras.
We only have to apply Zorn’s Lemma to get a minimal congruence whose factor algebra is
a sig/cons-model of R, because this factor algebra will be a minimal sig/cons-model of R.
Therefore, we are now going to show that the premise of Zorn’s Lemma is satisfied.
Let CHAIN={ ∼i | i ∈ I } be a nonempty ⊆-chain of congruences on G T with ∀i∈ I.
(G T /∼i is a sig/cons-model of R). Define ≈ :=
T
i∈I ∼i . Of course, ≈ is a congruence
on G T that bounds CHAIN below. The only thing left to be shown is that G T /≈ is a
sig/cons-model of R.
Contrariwise there was134 a (l=r←−C) ∈ R and a σ ∈ S UB (V,G T ) with
∀L in C. ∀u,v. (L=(u=v)⇒ uσ≈ vσ);
∀L in C. ∀u. (L=(Defu)⇒ ∃uˆ ∈ G T (cons). uσ≈ uˆ) ;
∀L in C. ∀u,v. (L=(u 6=v)⇒ uσ 6≈ vσ); lσ 6≈ rσ.
Now, by asking for the “reasons” of the ‘6≈’, there is a J with J ⊆ I ;
∀L in C. ∀u,v. (L=(u 6=v)⇒ ∃ jL∈J. uσ 6∼ jL vσ);
∃ j(l,r)∈J. lσ 6∼ j(l,r) rσ; and |J|  |{ L in C | ∃u,v. L=(u 6=v) }| +1 .
Define ≡ :=
T
j∈J ∼ j . As ≈ ⊆ ≡ , ≡ yields no model of R for the same “reason” as ≈.
But (as J finite) { ∼ j | j ∈ J } has a ⊆-minimal135 element ∼ j0 with j0 ∈ J. Now ≡=
∼ j0 . Hence ∼ j0 yields no sig/cons-model of R, which is a contradiction.
3. By (1) and (2).
Q.e.d. (Lemma 6.7)
Proof of Lemma 7.3 By the restriction of Definition 5.11 on the constructor rules,−→R,X,ω is just
the standard closure over a finitary relation. Q.e.d. (Lemma 7.3)
134We tacitly use the Substitution-Lemma(5.8) again, just the way we used it at the end of (1) in the proof of
Lemma 6.6.
135and minimum
196
Proof of Lemma 7.4
We claim the following:
1. ∀Y⊆V. ∀s∈T (cons,Y). ∀t. (s ∗−→R,X,ωt ⇒ t∈T (cons,Y))
2. ∀i∈N. ∀n∈N. ( n−→R,X,ω+i ∩ (T (cons,VSIG⊎VC )×T )) ⊆
n
−→R,X,ω
3. ∀i∈N. −→R,X,ω ⊆ −→R,X,ω+i ⊆ −→R,X,ω+i+1
4. −→R,X satisfies the requirement of Lemma 7.4; i.e. −→R,X ∈ S.
5. −→R,X,ω ⊆
T
S
6. ∀ ∈S. ∀n∈N. ( n ∩(G T (cons)×T )) ⊆ n−→R,X,ω
7. ∀i∈N. −→R,X,ω+i ⊆
T
S
8. −→R,X is the minimum
T
S ∈ S.
9. For /0 6= S′ ⊆ S : TS′ ∈ S.
To the proofs of these claims:
1. By the restriction of Definition 5.11 on the constructor rules.
2. By induction on i using Lemma 7.3, (1), and the restriction of Definition 5.11 on the con-
structor rules.
3. i=0: By definition of −→R,X,ω . i ⇒ (i+1): By (2).
4. The first requirement follows directly from (2). The second follows from (3), taking
−→R,X,ω+i+1 on the left-hand side of the second requirement for the maximum i of all
−→R,X,ω+i occurring positively (i.e. not in a ∤↓-statement) in the fulfilledness condition (ex-
panded via Definition 7.1) of the right-hand side of the second requirement.
5. By Lemma 7.3, −→R,X,ω is the intersection of a superset of S.
6. By induction on n using ( ∩ (G T (cons)×T )) ⊆ −→R,X,ω and (1).
7. i=0: By (5). i ⇒ (i+1): By (6) and (3).
8. By (4) and (7).
9. By (6) and (5).
Q.e.d. (Lemma 7.4)
Proof of Lemma 7.10
Follows from items (2) and (1) of the Proof of Lemma 7.4.
Proof of Lemma 7.11
Follows from Lemma 7.10.
197
Proof of Lemma 7.12
Follows from item (3) of the Proof of Lemma 7.4 where monotonicity of fulfilledness additionally
needs Lemma 7.11 in case of a negative condition.
Proof of Lemma 7.13
The “if”-part of the proof is trivial. The “only if”-part is straightforward as follows: If u↓v,
then by confluence (below v) u ∗−→NF(v) and then by confluence (below u) NF(u)=NF(v). If
u
∗
−→uˆ∈G T (cons) then by confluence uˆ ∗−→NF(u) and then by Lemma 7.10 NF(u)∈G T (cons).
If uˆ, vˆ∈G T (cons) and u ∗−→uˆ ∤↓vˆ ∗←−v then by confluence NF(u) ∗←−uˆ ∤↓vˆ ∗−→NF(v); hence
NF(u) 6=NF(v) and by Lemma 7.10 NF(u),NF(v)∈G T (cons).
Proof of Lemma 7.14
By the Axiom of Choice there is some τ ∈ S UB (Y,T (X)) with τ|X⊆id. Using this τ in combi-
nation with Corollary 7.9 for getting rid of variables from Y\X (introduced by extra-variables),
the first sentence can be shown by induction on β and the rest is trivial.
Proof of Theorem 7.16
Let A := T (X)/ ∗←→R,X. Let I := G T /
∗
←→R, /0 .
Claim 1: If C is a sig/cons-model of R; µ ∈ S UB (X,C ); then
∀βω. ∀s∈S. −→R,X,β ∩ (T SIG,s×T SIG,s) ⊆ ker(Cµ)s .
The proof of Claim 1 is omitted because it reads just like the proof of Claim 2 until it comes to
β≻ ω.
Proof of Part (1) of the theorem:
By the Axiom of Choice, each element of S UB (V,A ) can be written σA ι for some σ ∈
S UB (V,T (X)). Thus, by Lemma 6.2, for A being a sig/cons-model of R it is sufficient to
note that for ((l,r),C) ∈ R; σ ∈ S UB (V,T (X)); we have:
If ∀u,v ∈ T .
 ( (( u=v ) in Cσ) ⇒ u
∗
←→R,Xv )
∧ ( ((Def u) in Cσ) ⇒ ∃uˆ∈T (X)C ,s. u ∗←→R,X uˆ )
∧ ( (( u 6=v ) in Cσ) ⇒ u 6∗←→R,Xv )
, then Cσ is fulfilled
w.r.t. −→R,X .
This is due to confluence of −→R,X [∩(DX×DX)], X⊆VSIG (i.e. T (X)C ,s =G T C ,s), Lemma 7.10,
and the fact that R is a Def-MCRS.
Now, for the proof that A is a constructor-minimum model, suppose C to be a sig/cons-
model of R. We have to find a cons-homomorphism from A |C⊎({C }×S) to C |C⊎({C }×S).
Let B be the ground term algebra over cons. Due to X⊆VSIG there is a cons-homo-
morphism h::A |C⊎({C }×S)→(B /(
∗
←→R,X∩(G T (cons)×G T (cons)))) given by (s∈ S; A∈A C ,s):
A 7→ G T (cons) ∩ A. Thus we only have to find a cons-homomorphism B /( ∗←→R,X ∩
(G T (cons)×G T (cons))) to C |C⊎({C }×S). Using the Homomorphism-Theorem (the usual one
for cons-homomorphism, not ours) all we have to show is ∀s∈S. ∗←→R,X ∩ (G T C ,s×G T C ,s) ⊆
ker(C )s, which by confluence of −→R,X [∩(DX×DX)] is the same as ∀s ∈ S. ↓R,X ∩
(G T C ,s×G T C ,s) ⊆ ker(C )s. Because of Lemma 7.10, ∀s∈S. −→R,X,ω ∩ (G T C ,s×G T C ,s) ⊆
ker(C )s is sufficient for this. But this is implied by Claim 1. Q.e.d. (Part (1) of the theorem)
198
Claim 2: If C ∈ K; µ ∈ S UB (X,C ); −→R, /0 [∩(D /0×D /0)] is confluent; then
∀β ω+ω. ∀s∈S. −→R,X,β ∩ (T SIG,s×T SIG,s) ⊆ ker(Cµ)s .
Proof of Claim 2: For the limit ordinals 0, ω, ω+ω the induction step is trivial. For a non-limit
ordinal β+1 the induction step is as follows: Suppose s−→R,X,β+1t. Then there are ((l,r),C) ∈ R;
σ ∈ S UB (V,T (X)); p ∈ POS (s); with s/p = lσ; t = s[ p← rσ ]; and Cσ fulfilled w.r.t.
−→R,X,β . As C is a sig/cons-model of R, for inferring Cµ(s) = Cµ(t) (by Lemma 6.2) we only
have to show that L is true w.r.t. Cµ for each literal L in the condition Cσ. Three cases:
If L = (u=v), by u↓R,X,βv the induction hypothesis implies Cµ(u) = Cµ(v).
If L = (Defu) with u ∈ T SIG,s′ , by the existence of some uˆ ∈ G T C ,s′ with u
∗
−→R,X,β uˆ the induction
hypothesis implies Cµ(u) = Cµ(uˆ) ∈ C C ,s′.
If L = (u 6=v), by the existence of some s ∈ S, uˆ, vˆ ∈ G T C ,s with u
∗
−→R,X,β uˆ ∤↓R,X,β vˆ
∗
←−R,X,βv the
induction hypothesis implies Cµ(u) = Cµ(uˆ) = C (uˆ) and C (vˆ) = Cµ(vˆ) = Cµ(v). Thus, for
Cµ(u) 6=Cµ(v) it is sufficient to show C (uˆ) 6=C (vˆ). By ωβ and Lemma 7.12 we know uˆ ∤↓R,X,ω vˆ.
By Lemma 7.11 uˆ ∤↓
R,X
vˆ. Then by Lemma 7.14 uˆ ∤↓
R, /0
vˆ; and therefore (by confluence of −→R, /0
[∩(D /0×D /0)]) uˆ 6
∗
←→R, /0 vˆ. Because of part (1) of the theorem (matching its X to /0), C must be
not only a constructor-minimal model but also a constructor-minimum model of R, just like I .
Thus there is some cons-homomorphism h::C |C⊎({C }×S)→I |C⊎({C }×S). Now, using the Homo-
morphism-Lemma for cons-homomorphism (i.e. the analogue of Lemma 5.7), due to uˆ, vˆ∈G T C ,s
we get hs(C |C (uˆ))= I |C (uˆ) 6= I |C (vˆ)=hs(C |C (vˆ)), which implies C (uˆ) 6=C (vˆ).
Q.e.d. (Claim 2)
Claim 3: If −→R, /0 [∩(D /0×D /0)] is confluent, then A is free for K over X w.r.t. ι.
Proof of Claim 3: Suppose C ∈ K and µ to be a C -valuation of X. The uniqueness of the re-
quired sig/cons-homomorphism h::A→C with µ= ιh is trivial. For its existence (by the Homo-
morphism-Theorem(5.9)) we only have to show
∀s ∈ S.
∗
←→R,X ∩ (T SIG,s×T SIG,s) ⊆ ker(Cµ)s ,
which is implied by Claim 2. Q.e.d. (Claim 3)
Claim 4: If −→R,X [∩(DX×DX)] is confluent, then −→R, /0 [∩(D /0×D /0)] is confluent, too.
Proof of Claim 4: Trivial by Lemma 7.14. Q.e.d. (Claim 4)
Proof of Part (2) of the theorem: Since A ∈ K by part (1) of the theorem, this is implied by the
claims 4 and 3.
Proof of Part (3) of the theorem: Suppose C to be a sig/cons-model of R with C .HA . Then
C .C A . By part (1) of the theorem we get C ∈K, and then by part (2) of the theorem A .HC .
Q.e.d. (Theorem 7.16)
199
Proof of Theorem 7.18
First note that the remark below the theorem is respected during the whole proof.
Claim 1: ∀i∈N. ∀n∈N. ∀s∈T (cons,X). ∀t.(
s
n
−→R′,X′,it ⇒ (s
n
−→R,X,it ∈ T (cons,X))
)
Claim 2: ∀β ω+ω. −→R,X,β ⊆ −→R′,X′,β
Claim 2 and Claim 1 (using Lemma 7.10 and T (cons,X)⊆ T (cons′,X′) ) imply (1); and Claim 2
implies (2) and (3).
Proof of Claim 1: i = 0: −→R′,X′,0 = /0. i⇒ (i+1): n = 0: Trivial.
n⇒ (n+1): Suppose s n−→R′,X′,i+1s
′−→R′,X′,i+1t. By induction hypothesis in n we know
s
n
−→R,X,i+1s
′ ∈ T (cons,X). By ($) there must be some l ∈ T (cons,VSIG⊎VC ); ((l,r),C) ∈ R;
σ ∈ S UB (V,T ); p ∈ POS (s′) with s′/p= lσ; t =s′[ p← rσ ]; Cσ fulfilled w.r.t. −→R′,X′,i ;
∀x∈V (l). xσ∈T (cons,X). By the structure of constructor equations we have no inequality lit-
eral in Cσ. For (u=v) in Cσ we have u,v ∈ T (cons,X) and u↓R′,X′,iv and therefore by induction
hypothesis in i: u↓R,X,iv. For (Defu) in Cσ we have u ∈ T (cons,X) and u
∗
−→R′,X′,i uˆ for some
uˆ∈G T (cons′) and hence by induction hypothesis in i: u ∗−→R,X,i uˆ∈ (T (cons,X)∩G T (cons′))=
G T (cons). Thus, finally we conclude that Cσ is fulfilled w.r.t. −→R,X,i , i.e. s′−→R,X,i+1t ∈
T (cons,X). Q.e.d. (Claim 1)
Proof of Claim 2: The induction step for the limit ordinals 0, ω, and ω+ω is trivial. For a non-
limit ordinal β+1 the induction step is as follows: Suppose s−→R,X,β+1t. There must be some
((l,r),C) ∈R; σ∈ S UB (V,T ); p∈ POS (s) with s/p= lσ; t =s[ p← rσ ]; Cσ fulfilled w.r.t.
−→R,X,β . The only thing to be shown is: Cσ fulfilled w.r.t. −→R′,X′,β . For (u=v) in Cσ we have
u↓R,X,βv and therefore by induction hypothesis u↓R′,X′,βv. For (Defu) in Cσ we have u
∗
−→R,X,β uˆ
for some uˆ ∈ G T (cons) and therefore by induction hypothesis u ∗−→R′,X′,β uˆ. For (u 6=v) in Cσ
we have u ∗−→R,X,β uˆ ∤↓R,X,β vˆ
∗
←−R,X,βv for some uˆ, vˆ ∈ G T (cons) and ωβ. We get uˆ ∤↓R,X,ω vˆ by
Lemma 7.12, and then (by Claim 1) uˆ ∤↓
R′,X′,ω
vˆ and (by Lemma 7.11) uˆ ∤↓
R′,X′
vˆ, and thus uˆ ∤↓
R′,X′,β vˆ.
Finally, by induction hypothesis we get u ∗−→R′,X′,β uˆ ∤↓R′,X′,β vˆ
∗
←−R′,X′,βv. Q.e.d. (Theorem 7.18)
Proof of Lemma 8.1 and Lemma 8.2
It is standard to encode a universal deterministic Turing machine with a finite set of left-linear
rules without critical pairs. This can be done in the following way, where stop, left, right, nil, 0,
⊥ are constant symbols, s is a singulary function symbol, c and nth are binary, cmd, state are
ternary, T is sexary; and T(l,a, r,c,s,p) encodes the Turing machine with
meaning intended range
l being the tape to the left of the head nil or c(sn(0), list-of-integers)
a being the symbol under the head sn(0)
r being the tape to the right of the head nil or c(sn(0), list-of-integers)
c being the next command to be executed stop or left or right or sn(0)
s being the next state to be in sn(0)
p being the program c(table-of-commands, table-of-states)
200
T(l, a, r, stop, s, p) = ⊥
T(nil, a, r, left, s, p) = T(nil, 0, c(a,r), cmd(0,s,p), state(0,s,p), p)
T(c(b,l), a, r, left, s, p) = T(l, b, c(a,r), cmd(b,s,p), state(b,s,p), p)
T(l, a, nil, right, s, p) = T(c(a,l), 0, nil, cmd(0,s,p), state(0,s,p), p)
T(l, a, c(b,r), right, s, p) = T(c(a,l), b, r, cmd(b,s,p), state(b,s,p), p)
T(l, a, r, 0, s, p) = T(l, 0, r, cmd(0,s,p), state(0,s,p), p)
T(l, a, r, s(x), s, p) = T(l, s(x), r, cmd(s(x),s,p), state(s(x),s,p), p)
cmd(a,s,c(table-of-commands, table-of-states)) = nth(a,nth(s, table-of-commands))
state(a,s,c(table-of-commands, table-of-states)) = nth(a,nth(s, table-of-states))
nth(0,c(a, l)) = a nth(s(x),c(a, l)) = nth(x, l)
We use ⊥ instead of a reasonable output because we are interested in the halting problem only.
We assume all function symbols so far to be constructor symbols.
From this system we are now going to construct our positive-conditional rule system by exchang-
ing the recursive T-rules of the form “ T(l,a, r,c,s,p) = T(l′,a′, r′,c′,s′,p′) ” for rules of the
form “ T(l,a, r,c,s,p) = ⊥←−T(l′,a′, r′,c′,s′,p′)=⊥ ”. Now the above Turing machine halts
in the described configuration iff the ground term “ T(l,a, r,c,s,p) ” is reducible. Therefore
(the halting problem being not co-semi-decidable) the reducibility of ground terms cannot be
co-semi-decidable.
For Lemma 8.2 we now add the following new rule:
foreverp(l,a,r,c,s, p) = true←− T(l,a,r,c,s, p) 6=⊥, DefT(l,a,r,c,s, p), Def⊥
Now “ foreverp(l,a, r,c,s,p) ” is reducible iff the above Turing machine does not halt. Therefore
the reducibility of ground terms cannot be semi-decidable.
Q.e.d. (Lemma 8.1 and Lemma 8.2)
Proof of Theorem 8.3
Proof of (1): The computable function g that firstly tests whether its single argument s is in the
enumerable set T (sig,X), secondly tries to compute f (s), and thirdly (if s∈T (sig,X) and f (s)
is defined) is defined iff the test f (s)=s succeeds, is defined exactly on the irreducible terms
from T (sig,X).
Proof of (2):
Claim 1: The following sets are universally136 enumerable for all β ω+ω and s ∈ T (sig,X):
Yβ(s) := { t | s−→R,X,βt }
Zβ(s) := { t | s
∗
−→R,X,βt }
If Claim 1 holds, we can enumerate Zω+ω(s) and simultaneously the irreducible terms from
T (sig,X) until one term t occurs in both enumerations and we can return f (s) := t.
136By this we want to express that there is not only for each βω+ω and s ∈ T (sig,X) some computable function
which enumerates Yβ(s) but even one single computable universal function which enumerates Yβ(s) when its first
argument (or index) is (β,s).
201
Proof of Claim 1: By induction on β. It suffices to show that Yβ(s) is universally enumerable for
all β  ω+ω and s ∈ T (sig,X). The induction step for the limit ordinals 0, ω, ω+ω is trivial
(Y0(s) = /0; Yω(s) = Si≺ωYi(s); Yω+ω(s) =
S
i≺ωYω+i(s)). The induction step for the non-limit
ordinals β+1 can be done the following way: For all rules ((l,r),C) ∈ R and all p ∈ POS (s) and
all σ in the enumerable set S UB (V (((l,r),C)),T (X)) with s/p= lσ we test in an enumerative
fashion whether Cσ is fulfilled w.r.t. −→R,X,β and enumerate s[ p← rσ ] if the test succeeds. The
test of “Cσ fulfilled w.r.t. −→R,X,β” can be semi-decided the following way: For (u=v) in Cσ we
test the enumerable set Zβ(u)∩Zβ(v) for non-emptiness. For (Defu) in Cσ we test the enumerable
set Zβ(u)∩G T (cons) for non-emptiness. For (u 6=v) in Cσ we test for the existence of uˆ ∈ A(u)
and vˆ ∈ A(v) with uˆ 6= vˆ (syntactically) for the enumerable sets A(w) := Zβ(w)∩ (G T (cons)\
dom(−→R,X)). This last test succeeds only if ∃uˆ, vˆ∈G T (cons). u
∗
−→R,X,β uˆ ∤↓R,X,β vˆ
∗
←−R,X,βv holds.
It also succeeds if this property holds because of ∀s∈G T (cons). ∃t. s ∗−→R,Xt 6∈dom(−→R,X),
Lemma 7.10, and ωβ. Q.e.d. (Theorem 8.3)
Proof of Lemma 8.5 There exists some τ ∈ S UB (V,T (X)). It suffices to show for all t,t ′ ∈ T :
Claim 1: For t−→R,Vt ′ we have tτ−→R,Xt ′τ.
Claim 2: For q ∈ POS (t) and t/q։R,Vt ′ we have tτ։R,Xt ′τ.
Proof of Claim 1: By Corollary 7.9 we get tτ−→R,Vt ′τ, then by Lemma 7.14 tτ−→R,Xt ′τ.
Proof of Claim 2: There are ((l,r),C)∈R; σ∈S UB (V,T ); p∈POS (t/q); u∈T ERM S (C) with
t/qp= lσ; t ′=uσ; Cσ fulfilled w.r.t. −→R,V . By Corollary 7.9, Cστ is fulfilled w.r.t. −→R,V .
By Lemma 7.14, Cστ is fulfilled w.r.t. −→R,X . Thus; since tτ∈T (sig,X); στ∈S UB (V,T (X));
qp∈POS (tτ); tτ/qp= lστ; t ′τ=uστ; we get tτ։R,Xt ′τ. Q.e.d. (Lemma 8.5)
Proof of Lemma 8.6
1.: Since the direction “⊇” is trivial we only have to show “⊆” and begin with the first equation.
For t ′ ∈DST[T] there are some t ∈ T and p ∈ POS (t) with t/p=t ′. Now, in case of t ′⇉ t ′′ by
sort-invariance and T-monotonicity of⇉ we get t = t[ p← t ′ ]⇉ t[ p← t ′′ ]∈T, which implies
t ′′∈DST[T]. Thus we have shown id|DST [T] ◦⇉ ⊆ id|DST [T] ◦⇉ ◦ id|DST [T]. In case of t
′∈T
we can choose p= /0 and get t ′′∈T, which proves id|T ◦⇉ ⊆ id|T ◦⇉ ◦ id|T.
2.: For T ∋ tSTt ′ ⇉ t ′′ there is a p ∈ POS (t); p 6= /0 with t ′= t/p. By sort-invariance and
T-monotonicity of⇉ we get t = t[ p← t ′ ]⇉ t[ p← t ′′ ]STt ′′ and t[ p← t ′′ ]∈T.
3.: The subset relationship is simple:
id|DST [T] ◦ (⇉ ∪ST)
+ ⊆ EST ◦ id|T ◦ DST ◦ (⇉ ∪ST)
+ ⊆ EST ◦ id|T ◦ (⇉ ∪ST)
+.
The first equality follows from (1) and id|DST [T] ◦ ST = id|DST [T] ◦ ST ◦ id|DST [T] . For the
second equality consider the following subset relationships as a word rewriting system over the
alphabet {id|T,⇉,ST} (containing three letters):
id|T ◦ ST ◦⇉ ⊆ id|T ◦⇉ ◦ id|T ◦ ST ;
ST ◦ ST ⊆ ST ;
id|T ◦⇉ ◦ ST ⊆ id|T ◦⇉ ◦ id|T ◦ ST ;
id|T ◦⇉ ◦⇉ ⊆ id|T ◦⇉ ◦ id|T ◦⇉ .
202
First note that the system is sound: The first rule was proved in (2). The second is transitiv-
ity of ST . The third and fourth are implied by (1). Since the number of substrings from
{⇉,ST}
2 is decreased by 1 by each of the rules, the word rewriting system is terminating.
Thus, since all normal forms from id|T{⇉,ST}+ are in {id|TST}∪ {id|T⇉}+[{id|TST}],
we get id|T ◦ (⇉∪ST )
+ ⊆
(
id|T ◦ ST
)
∪
(
( id|T ◦⇉ )+ ◦ ( id|T ◦ ST )
=
)
. Using (1)
again as well as ST= ⊆ DST, this implies the one direction; the other direction as well as the
special case are trivial.
4.: By the first equation of (3) we conclude id|DST [T] ◦ (⇉ ∪ST)
+ ⊆ DST[T]×DST[T] as well as
transitivity of id|DST [T] ◦ (⇉ ∪ST)
+. Suppose that id|DST [T] ◦ (⇉ ∪ST)
+ is not terminating.
By the first equation of (3) there is some r : N→DST[T] with ∀i∈N. ( ri⇉ri+1 ∨ riSTri+1 ).
There is some t0 ∈ T and some p0 ∈ POS (t0) with t0/p0 =r0. Moreover, there is also some
p : N+ → N∗ such that
∀i∈N.
( (
ri⇉ ri+1
∧ pi+1 = /0
)
∨
(
riSTri+1
∧ ri/pi+1 =ri+1
) )
.
Define (tn)n∈N inductively by tn+1 := tn[ p0 . . . pn+1 ← rn+1 ].
Claim 2: For each n ∈ N we get

tn,tn+1∈T
∧ tn/p0 . . . pn =rn
∧ tn+1/p0 . . . pn+1 =rn+1
∧
(
tn⇉tn+1 ∨
(
tn = tn+1
∧ rnSTrn+1
) )
.
Proof of Claim 2: We have tn∈T and tn/p0 . . . pn =rn in case of n=0 by our choice
above and otherwise inductively by Claim 2. In case of rn⇉rn+1 ∧ pn+1 = /0, since ⇉ is
sort-invariant and T-monotonic, we thus get: tn = tn[ p0 . . . pn ← rn ]⇉ tn[ p0 . . . pn ← rn+1 ]=
tn[ p0 . . . pn pn+1 ← rn+1 ]= tn+1∈T. Otherwise we have rnSTrn+1 and rn/pn+1 =rn+1 and
get: T∋ tn = tn[ p0 . . . pn ← rn ]= tn[ p0 . . . pn ← rn[ pn+1 ← rn+1 ] ]=
tn[ p0 . . . pn ← rn ][ p0 . . . pn pn+1 ← rn+1 ]= tn[ p0 . . . pn pn+1 ← rn+1 ]= tn+1. In both cases we
have tn+1/p0 . . . pn+1 = tn[ p0 . . . pn+1 ← rn+1 ]/p0 . . . pn+1 =rn+1. Q.e.d. (Claim 2)
Since ST is terminating, Claim 2 contradicts⇉ being terminating (below all t ∈ T).
If ⇉ and T are X-stable, additionally, then id|DST [T] ◦ (⇉ ∪ST)
+ is X-stable too, because
DST[T], id|DST [T], and ST are.
Let  denote id|DST [T] ◦ (⇉ ∪ST)
+. Here is an example for  not sort-invariant and not T-
monotonic: Let A,B be two different sorts. Let α(a) = A , α(f) = A → B , α(g) = A → A
. Define ⇉:= /0 and T := T . Then we have  = ST and therefrom: f(a)  a (hence not
sort-invariant); and g(a)a but f(g(a))⋫ f(a) (hence not T-monotonic).
5.: Take the signature from the example in the proof of (4). Define⇉ := {(a, f(a))} and T := T .
Now⇉ is a T-monotonic (indeed!), terminating relation on T that is not sort-invariant; whereas
id|DST [T] ◦ (⇉ ∪ST)
+ is not irreflexive: a ⇉ f(a) ST a . If one changes α(f) to be α(f) =
A → A , then ⇉ is a sort-invariant, terminating relation on T that is not T-monotonic but /0-
monotonic; whereas neither id|DST [T] ◦ (⇉ ∪ST)
+
nor (⇉ ∪ST)
+ (in contrast to id|DST [ /0] ◦
(⇉ ∪ST)
+) are irreflexive. Q.e.d. (Lemma 8.6)
203
Proof of Lemma 8.8
Suppose  is not terminating. Then there is a t : N→ T with ∀i∈N. ti(⇉ ∪ →֒ ∪ST)ti+1.
Define k : N→ N by: k0 = 0, ki+1 = 1 + min{ j | j ≥ ki ∧ t j →֒ t j+1 }. The above minimum
always exists because (⇉ ∪ST) is terminating. We have
tki(⇉ ∪ST)
∗◦ →֒ tki+1 . By ST◦⇉ ⊆ ⇉ ◦ST we get tki⇉∗ ◦ST∗◦ →֒ tki+1 , which means
tki(⇉ ∪ (DST◦ →֒))
+tki+1 , which contradicts the assertion that
(⇉ ∪ (DST◦ →֒)) is terminating.
An alternative proof (using the Axiom of Choice) can be done the following way:
(⇉ ∪ (DST ◦ →֒)) quasi-commutes over (⇉ ∪ ST) in the sense of Bachmair & Dershowitz
(1986). Thus, (⇉ ∪ →֒ ∪ST) must be terminating by Theorem 1 of Bachmair & Dershowitz
(1986). Q.e.d. (Lemma 8.8)
Proof of Lemma 8.12 −→R,Y ⊆ > is trivial by induction on the construction of −→R,Y using
Lemma 7.12. −→R,Y ∪։R,Y ∪ST ⊆  is trivial by definition of։R,Y . R is X-compatible with
(>,) by Lemma 7.14. By Lemma 8.5 we know that (−→R,V ∪ (DST ◦։R,V)) is terminating. By
Corollary 8.7 and Lemma 8.8 we know that ( +−→R,V , (−→R,V ∪։R,V ∪ST)
+ ) is a termination-
pair over sig/V, with which R is V-compatible by Lemma 7.4. Q.e.d. (Lemma 8.12)
Proof of Lemma 8.16 Statement (1) follows from statement (2). By Lemma 8.12 we can now
show statements (2) and (3) by noetherian induction on s w.r.t. .
Proof of (2): There is only a finite number of positions p ∈ POS (s) and of rules l=r←−C of R
matching s/p, and the set of matching substitutions σ ∈ S UB (V (l=r←−C),T (X)) with s/p =
lσ is enumerable. Since s s[ p← rσ ] for Cσ being fulfilled, by induction hypothesis we only
have to be able to semi-decide whether Cσ is fulfilled. In case of left-right-compatibility we semi-
decide the fulfilledness of the literals from left to right; in case of compatibility only, we wait with
our parallel enumeration until we have been able to establish the condition terms to be -smaller
than lσ. Thus, for semi-deciding the fulfilledness of a literal L in Cσ we can assume its terms to
be -smaller than s. By induction hypothesis it is obvious now how to semi-decide fulfilledness
of ‘=’- and ‘Def ’-literals in Cσ, and how to semi-decide ‘6=’-literals using statement (3).
Proof of (3): By Lemma 7.10, the constructor rules being extra-variable free (i.e. the matching
of a left-hand side to a subterm of s determines the relevant part of the substitution), and R
and POS (s) being finite, there can be only a finite number of terms t with s−→t, and by the
induction hypothesis this also holds for those t with s +−→t. In case of left-right-compatibility we
decide the fulfilledness of the literals from left to right; in case of compatibility only, we know
that Cσ cannot be fulfilled if the test fails whether all its terms are -smaller than lσ. Thus, for
deciding the fulfilledness of a literal L in Cσ we can assume its terms to be -smaller than s. By
induction hypothesis it is obvious now how to decide fulfilledness of ‘=’- and ‘Def ’-literals in
Cσ. Q.e.d. (Lemma 8.16)
204
Proof of Lemma 8.17 Take the unconditional rule system of the proof of Lemma 8.1. From
this system we are now going to construct our positive-conditional rule system by adding as
new first argument a step-counter to our Turing machine by exchanging the recursive T-rules of
the form “ T(l,a, r,c,s,p) = T(l′,a′, r′,c′,s′,p′) ” for rules of the form “ T(s(x), l,a, r,c,s,p) =
T(x, l′,a′, r′,c′,s′,p′) ” and the non-recursive T-rule by T(x, l,a,r,stop,s, p) = ⊥. Finally we
add the rule terminatesp(l,a,r,c,s, p) = true←−T(x, l,a,r,c,s, p)=⊥ , where ‘terminatesp’
and ‘true’ are of a new sort. For the decidable ordering  of the termination-pair take the lex-
icographic path ordering where ‘terminatesp’ is bigger than all other function symbols and the
variables of the old sorts; ‘T’ is bigger than all function symbols except ‘terminatesp’; and ‘cmd’
and ‘state’ are bigger than ‘nth’.
Now, since “ terminatesp(l,a, r,c,s,p) ” is reducible iff the Turing machine of the proof of
Lemma 8.1 halts, reducibility of ground terms cannot be co-semi-decidable.
Q.e.d. (Lemma 8.17)
Proof of Lemma 8.18 The proof is very similar to that of Lemma 8.16. Finally, (3) follows from
(2), Theorem 9.6, and T (sig,X) being enumerable. Q.e.d. (Lemma 8.18)
Proof of Lemma 8.19 Take the unconditional part of the rule system of the proof of Lemma 8.17.
For getting our positive conditional CRS R, add the rules terminatesp(x) = false and
terminatesp(x) = true ←− T(x, l,a, r,c,s,p) =⊥ , where ‘terminatesp’, ‘false’, and ‘true’
are of a new sort; and l,a, r,c,s,p are ground terms. For the decidable ordering  of the
termination-pair take the lexicographic path ordering where ‘terminatesp’ is bigger than all
other function symbols and the variables of the old sorts; ‘T’ is bigger than all function sym-
bols except ‘terminatesp’; and ‘cmd’ and ‘state’ are bigger than ‘nth’. Now, using Theo-
rem 9.6, the following sentences are logically equivalent: −→R,V is confluent. The critical peak
((true,T(x, l,a, r,c,s,p)=⊥, . . .), (false, /0, . . .), terminatesp(x), /0) is joinable w.r.t. R,V. There
is no term t ∈ T (sig,VSIG⊎VC ) with T(t, l,a, r,c,s,p)
∗
−→R,V⊥. The Turing machine of the proof
of Lemma 8.1 does not halt. Q.e.d. (Lemma 8.19)
205
Proof of Theorem 9.1
Claim: By the condition of (1) or (2), for βω+ω and s ∗−→R,X,βt we have Aκ(s)=Aκ(t).
Proof of Claim: By induction on β. By induction on the number of derivation steps, it suffices
to do the proof for −→R,X,β instead of
∗
−→R,X,β . If β is one of the limit ordinals 0, ω, ω+ω, the
induction step is trivial. If β is a non-limit ordinal γ+1, the induction step is as follows: For
s−→R,X,γ+1t there is a substitution σ ∈ S UB (V,T (X)), a rule ((l,r),C) ∈ R, and a p ∈ POS (s)
with s/p= lσ, t =s[ p← rσ ], and Cσ fulfilled w.r.t. −→R,X,γ . Since A is a sig/cons-model of
R, (by Lemma 6.2) we only have to show that each literal of Cσ is true w.r.t. Aκ. For (u=v) in
Cσ we have u↓R,X,γv and hence by induction hypothesis we have Aκ(u)=Aκ(v). For u¯ ∈ S,
u ∈ T (sig,X)u¯, (Def u) in Cσ there is some uˆ ∈ G T C ,u¯ with u
∗
−→R,X,γ uˆ and hence by induction
hypothesis we have Aκ(u)=Aκ(uˆ)∈A C ,u¯. For (u 6=v) in Cσ we know ωγ and there are uˆ, vˆ ∈
G T (cons) with u ∗−→R,X,γ uˆ ∤↓R,X,γ vˆ
∗
←−R,X,γv and w.l.o.g. (since −→R,X[∩(DX×DX)] is terminating
and by Lemma 7.10) uˆ, vˆ 6∈dom(−→R,X); thus, since uˆ and vˆ are of the same sort and unequal, by
the condition of (1) or (2), we get Aκ(uˆ) 6=Aκ(vˆ). By the induction hypothesis, we have Aκ(u)=
Aκ(uˆ) and Aκ(vˆ)=Aκ(v). All in all, we get the required Aκ(u) 6=Aκ(v). Q.e.d. (Claim)
Now we show confluence for part (1) of the theorem. Suppose u ∗←−R,Xs ∗−→R,Xv. Since −→R,X is
terminating, there are uˆ, vˆ ∈ T (sig,X)\dom(−→R,X) with u
∗
−→R,X uˆ and v
∗
−→R,X vˆ. By Claim we
have Aκ(uˆ)=Aκ(u)=Aκ(s)=Aκ(v)=Aκ(vˆ) and therefore uˆ= vˆ.
Finally for the proof of part (2) of the theorem, in the above we can additionally assume s∈DX
and thus the existence of some sˆ ∈ G T (cons) \ dom(−→R,X) (since −→R,X ∩ (DX×DX) is ter-
minating and by Lemma 7.10) with s ∗←→R,X sˆ. Since −→R,X ∩ (DX×DX) is terminating we get
uˆ, vˆ like above. Then by Claim we have Aκ(uˆ)=Aκ(u)=Aκ(s)=Aκ(sˆ) and Aκ(vˆ)=Aκ(v)=
Aκ(s)=Aκ(sˆ), i.e. uˆ= sˆ= vˆ. Q.e.d. (Theorem 9.1)
Proof of Lemma 9.4 For ((t0,C0,Λ0), (t1,C1,Λ1), tˆ, σ, p)∈CP(R) there are two rules
l0=r0←−C0 and l1=r1←−C1 in R (assuming V (l0=r0←−C0)∩V (l1=r1←−C1) = /0 w.l.o.g.)
with l0σ= l1σ/p; (t0, t1, tˆ ) = (l1[ p← r0 ], r1, l1). Let ϕ∈S UB (V,T (X)) and assume
(C0C1)σϕ fulfilled w.r.t. −→R,X . Then
t0σϕ= l1σϕ[ p← r0σϕ ]←−R,X l1σϕ−→R,Xr1σϕ = t1σϕ.
By the assumed confluence we have t0σϕ↓R,Xt1σϕ . Q.e.d. (Lemma 9.4)
206
Proof of Lemma 9.5
Let ϕ ∈ S UB (V,T (X)) be arbitrary. We reduce the conditions of the definition of -weak join-
ability ad absurdum for a weakly complementary critical peak
((t0,C0,Λ0), (t1,C1,Λ1), tˆ, σ, p)∈CP(R).
There are two rules l0=r0←−C0 and l1=r1←−C1 in R (assuming V (l0=r0←−C0) ∩
V (l1=r1←−C1) = /0 w.l.o.g.) with l0σ= l1σ/p; (t0, t1, tˆ ) = (l1[ p← r0 ], r1, l1). When
we assume that the first item in the conjunctive condition of the definition of -weak joinabil-
ity holds, then both C0σϕ and C1σϕ are fulfilled w.r.t. −→R,X . Since R is X-compatible with
(>,), this implies ∀i≺2. ∀u∈T ERM S (Ci). liσϕuσϕ. Since l0σϕ= l1σϕ/pE l1σϕ= tˆσϕ,
the second item in the conjunctive condition of the definition of -weak joinability implies that
∀u∈T ERM S ((C0C1)σ). ( −→R,X is confluent below uϕ ).
One case of the assumed weak complementarity is that (C0C1)σ contains two literals (u=v)
(or (v=u)) and (u 6=v). By the assumption that (C0C1)σϕ is fulfilled w.r.t. −→R,X , there are
w0 ∈ T (sig,X) with uϕ ∗−→R,Xw0
∗
←−R,Xvϕ and uˆ, vˆ ∈ G T (cons) with uϕ
∗
−→R,X uˆ ∤↓R,X vˆ
∗
←−R,Xvϕ.
By the above confluence of −→R,X below uϕ there is some w1 with uˆ
∗
−→R,Xw1
∗
←−R,Xw0.
By w1
∗
←−R,Xvϕ and the above confluence of −→R,X below vϕ there is some w2 with
w1
∗
−→R,Xw2
∗
←−R,X vˆ. But then uˆ
∗
−→R,Xw2
∗
←−R,X vˆ contradicts uˆ ∤↓R,X vˆ.
The other case of the assumed weak complementarity is that (C0C1)σ contains two literals
(p=true) (or (true=p)) and (p=false) (or (false=p)) with true, false∈G T \dom(−→R,X) and
true 6= false. By the assumption that (C0C1)σϕ is fulfilled w.r.t. −→R,X , there are w0,w1 ∈
T (sig,X) with pϕ ∗−→R,Xw0
∗
←−R,Xtrue and pϕ
∗
−→R,Xw1
∗
←−R,Xfalse. By the above confluence of
−→R,X below pϕ there is some w2 with w0
∗
−→R,Xw2
∗
←−R,Xw1. This implies true↓R,Xfalse which
contradicts true, false 6∈dom(−→R,X) and true 6= false from above. Q.e.d. (Lemma 9.5)
Proof of Theorem 9.6
Cf. Theorem 73 in Wirth (1995).
Proof of Lemma 9.9 If ((t0,C0,Λ0), (t1,C1,Λ1), tˆ, σ, p) is overlay joinable, then p= /0.
Let ϕ ∈ S UB (V,T (X)) be arbitrary. In case of (tˆ/p′)σϕ=(tˆ/ /0)σϕ we get p′= /0. Thus
∆ ⊆ FPOS (tˆ)\{ /0} together with ∀p′∈∆. (tˆ/p′)σϕ=(tˆ/ /0)σϕ implies ∆= /0. If (C0C1)σϕ is
fulfilled w.r.t. −→R,X , the assumed (overlay) joinability implies t0σϕ ∗−→R,Xv ∗←−R,Xt1σϕ and we
also have t1σϕ←−R,Xsσϕ for s := tˆ/ /0. Thus t0[ p′← s′ | p′∈∆ ]σϕ= t0σϕ
∗
−→R,Xv
∗
←−R,X,<st1σϕ.
Q.e.d. (Lemma 9.9)
207
Proof of Lemma 9.10
For the proof of Claim 3 below, we enrich the signatures sig, cons to sig′, cons′ by a new sort
snew and new constructor symbols eqs¯ for each old sort s¯ ∈ S with arity s¯s¯ → snew and ⊥ with
arity snew. We take (in addition to R) the following set of new rules (with Xs¯ ∈ VSIG,s¯ for s¯ ∈ S):
R′ := { eqs¯(Xs¯,Xs¯) =⊥ | s¯ ∈ S }. Since the sort restrictions do not allow −→R∪R′,X,β to make any
use of terms of the sort snew when rewriting terms of an “old” sort, we get
∀β ω+ω. −→R∪R′,X,β |T (sig,X) = −→R,X,β/sig/cons
(the latter being defined over the non-enriched signatures). Thus, T := ∗−→[{sˆ}], −→|T, and
−→|D[T] do not change when we exchange the one−→with the other. We use ‘ST’ to denote the
subterm ordering over the enriched signature. For keeping the assumptions of our lemma valid for
this subterm ordering (instead of the subterm ordering on the non-enriched signature) we have to
extend  with eqs¯(t0,t1)t ′ if ∃i≺2. tiDSTt ′ for some s¯∈ S and t0,t1 ∈ T (sig,VSIG⊎VC )s¯. This
extension neither changes D[T] nor −→|D[T]. Thus, since −→|D[T] is not changed by any of the
extensions, it now suffices to show its confluence after the extensions. Since the sort restrictions
do not allow a term of the sort snew to be a proper subterm of any other term, it is obvious
that after the extension of  we still may assume either that −→R∪R′,X|T is terminating and
 = ST or that −→R∪R′,X |D[T] ⊆ , ST ⊆ , and  is a wellfounded ordering on T . As no
new critical peaks occur, the critical peaks keep being -quasi overlay joinable because the only
negative occurrences of the relations −→ and  in the definition of -quasi overlay joinability
are in “(C0C1)σϕ fulfilled w.r.t. −→R,X” and “−→R,X is confluent below w”, where the terms in
(C0C1)σϕ are all old and also w must be old even after the extension because w(←−∪)+sσϕ,
and sσϕ is old, and due to the sort restrictions not allowing a term of the sort snew to be a proper
subterm of any other term.
We define −→β :=−→R∪R′,X,β for any ordinal β with β≺ω+ω; and −→ :=−→ω+ω :=−→R∪R′,X .
Since −→ is sort-invariant, T-monotonic (cf. Corollary 7.8), and terminating below all t ∈ T, by
Lemma 8.6(4), ′ := id|DST [T] ◦ (−→∪ST)
+ is a wellfounded ordering on DST[T]. In case
of =ST, we define > := ′ . Otherwise, in case that −→R,X|D[T] ⊆ , ST ⊆ , and 
is a wellfounded ordering, we define > := ∩ (D[T]×D[T]) . In any case, > is a wellfounded
ordering on D[T] containing id|D[T] ◦ (−→∪ST ∪)
+. This means in particular that D[T] is
closed under −→, ST , and .
We say that P(v,u,s,t,Π) holds if for v,u,t ∈ T (sig′,X′) and s ∈ D[T] with v ∗←−u; and
s
∗
−→t; Π ⊆ POS (u) with ∀p,q∈Π. ( p 6=q ⇒ p‖q ) and ∀o∈Π. u/o=s; we have v ↓
u[o← t | o∈Π ]. Now (by Π := { /0}) it suffices to show that P(v,u,s,t,Π) holds for all appropri-
ate v,u,s,t,Π. We will show this by noetherian induction over the lexicographic combination of
the following wellfounded orderings:
1. >
2. ≻
3. ≻
using the following measure on (v,u,s,t,Π):
1. s
2. the smallest ordinal β ω+ω for which v ∗←−βu
3. the smallest n ∈ N for which v n←−βu for the β of (2)
208
For the limit ordinals 0, ω, ω+ω in the second position of the measure, the induction step is
trivial ( ∗←−0 ⊆ id ; ∗←−ω ⊆
S
i∈N
∗
←−i ;
∗
←−ω+ω ⊆
S
i∈N
∗
←−ω+i ). Thus, as we now suppose a
smallest (v,u,s,t,Π) with P(v,u,s,t,Π) not holding for, the second position of the measure must
be a non-limit ordinal β+1.
As P(v,u,s,t,Π) holds trivially for u = v or s = t we have some u′,s′ with
v
n
←−β+1u
′←−β+1u (n∈N) (with ∀m∈N. (v
m
←−β+1u ⇒ m≻n)) and s−→s′
∗
−→t. Now for a
contradiction it is sufficient to show
Claim: There is some z with v ∗−→z ∗←−u[o← s′ | o ∈Π ].
because then we have z ↓ u[o← t | o ∈Π ] by P(z,u[o← s′ | o ∈Π ],s′,t,Π), which is smaller
than (v,u,s,t,Π) in the first position of the measure by s−→s′.
u ‖
ω+ω,Π
> u[o← s′ | o∈Π ]
u′
∨
β+1
v
n
∨
β+1
∗
> z
∗
∨
Claim 0: We may assume ∀p′′∈POS (s)\{ /0}. s/p′′ 6∈dom(−→).
Proof of Claim 0: Otherwise there are some p′′ ∈ POS (s)\{ /0} and some s′′ with s/p′′−→s′′.
v <
n+1
β+1 u ‖
ω+ω,Π
> u[o← s′ | o∈Π ]
v′
∗
∨
<
∗
u[o← s[ p′′← s′′ ] | o∈Π ]
==
∨
ω+ω,Πp′′
∗
> u[o← s′′′ | o∈Π ]
∗
∨
◦
∗
∨
=========================================================== ◦
∗
∨
Then, by P(s′,s,s/p′′,s′′,{p′′}), which is smaller in the first position of the measure by
sSTs/p′′, we get s′
∗
−→s′′′
∗
←−s[ p′′← s′′ ] for some s′′′. Similarly, by P(v,u,s/p′′,s′′,Πp′′)
we get v ∗−→v′ ∗←−u[ p← s′′ | p∈Πp′′ ]=u[o← s[ p′′← s′′ ] | o∈Π ] for some v′. Finally, by
P(v′, u[o← s[ p′′← s′′ ] | o∈Π ], s[ p′′← s′′ ], s′′′, Π ), which is smaller in the first position of
the measure by s−→s[ p′′← s′′ ], we get v′ ↓ u[o← s′′′ | o∈Π ] ∗←−u[o← s′ | o∈Π ].
Q.e.d. (Claim 0)
By Claim 0 there are some ((l0,r0),C0) ∈ R∪R′; µ0 ∈ S UB (V,T (X)); with s = l0µ0; s′ = r0µ0;
and C0µ0 is fulfilled w.r.t. −→. Furthermore, we have some q ∈ POS (u); ((l1,r1),C1) ∈ R∪R′;
µ1 ∈ S UB (V,T (X)); with u/q= l1µ1; u′=u[q← r1µ1 ]; C1µ1 fulfilled w.r.t. −→β; and if C1
contains some inequality (u 6=v) then ωβ. By Claim 0 we may assume that q is not strictly
below any p ∈Π, i.e. that there are no p, p′ with pp′=q, p′ 6= /0, and p∈Π.
209
Define Ξ := Π\ (qN∗) ;
Π′ := { p′ | qp′∈Π ∧ (p′∈POS (l1)⇒ l1/p′∈V) } ;
Π′′ := { p′ | qp′∈Π\(qΠ′) } .
Define a function Γ on V by (x∈V): Γ(x) := { p′′ | ∃p′. (l1/p′ = x ∧ p′p′′ ∈Π′) }. Since for
p′′ ∈ Γ(x) we always have some p′ with l1/p′=x; xµ1/p′′= l1µ1/p′p′′=u/qp′p′′=s; we have
∀x∈V. ∀p′′∈Γ(x). xµ1/p′′=s. (#0)
Since the proper subterm ordering is irreflexive we cannot have sSTs, and therefore get
∀x∈V. ∀p′, p′′∈Γ(x). ( p′= p′′ ∨ p′ ‖ p′′ ). (#1)
Due to (#0) and (#1) we can define µ′1 by (x∈V):
xµ′1 := xµ1[ p
′′← s′ | p′′ ∈ Γ(x) ].
Define for w¯ ∈ T :
Θw¯ := { p′p′′ | ∃x. (w¯/p′=x ∧ p′′∈Γ(x)) }.
By (#0) we get
∀w¯∈T . ∀p′∈Θw¯. w¯µ1/p′=s (#Θ1)
and by (#1)
∀w¯∈T . ∀p′, p′′∈Θw¯. ( p′= p′′ ∨ p′ ‖ p′′ ) (#Θ2)
and
∀w¯∈T . w¯µ′1 = w¯µ1[ p
′← s′ | p′∈Θw¯ ]. (#Θ3)
Note that for Λ := Θl1\Π′ we have
Θl1 = Π′⊎Λ. (#2)
By (#Θ1) and (#2) we get
∀p′ ∈Π′∪Λ∪Π′′. l1µ1/p′=s (#3)
and by (#Θ2) and (#2)
∀p′, p′′∈Π′∪Λ. ( p′= p′′ ∨ p′ ‖ p′′ ). (#4)
Since
∀p′∈Π′∪Λ. (p′∈POS (l1) ⇒ l1/p′ ∈ V);
∀p′′∈Π′′. ( p′′∈POS (l1) ∧ l1/p′′ /∈ V ) (#5)
we get by (#3)
∀p′∈Π′∪Λ. ∀p′′∈Π′′. p′′ ‖ p′ (#6)
and then together with (#2) and (#4)
∀p′, p′′ ∈Π′⊎Λ⊎Π′′. ( p′= p′′ ∨ p′ ‖ p′′ ). (#7)
Now due to (#2) and (#Θ3) we have
l1µ′1 = l1µ1[ p′← s | p′∈Π′∪Λ ] (#8)
and then by (#6) and (#3)
∀p′′∈Π′′. l1µ′1/p′′=s. (#9)
210
Summing up and defining we have:
uˇ0 := u[q← l1µ1[ p′← s′ | p′∈Π′ ] ] [o← s′ | o ∈ Ξ ] ;
uˇ1 := u[q← l1µ1[ p′← s′ | p′∈Π′∪Λ ] ] [o← s′ | o ∈ Ξ ]
(by (#8)) = u[q← l1µ′1 ] [o← s′ | o ∈ Ξ ] ;
uˇ2 := u[q← l1µ1[ p′← s′ | p′∈Π′∪Π′′ ] ] [o← s′ | o ∈ Ξ ] ;
uˇ3 := u[q← l1µ1[ p′← s′ | p′∈Π′∪Λ∪Π′′ ] ][o← s′ | o ∈ Ξ ]
(by (#6), (#8)) = u[q← l1µ′1[ p′← s′ | p′∈Π′′ ] ] [o← s′ | o ∈ Ξ ] ;
u′ = u[q← r1µ1 ] ;
uˆ0 := u[q← r1µ′1 ] [o← s
′ | o ∈ Ξ ]
(by Claim 2) = u[q← u¯0 ] [o← s′ | o ∈ Ξ ] ;
uˆi+1 := u[q← u¯i+1 ] [o← s′ | o ∈ Ξ ] .
u β+1,q > u
′ n
β+1 > v
uˇ0
==
∨
ω+ω,Ξ∪(qΠ′)
‖
ω+ω, (qΛ)
> uˇ1 ω+ω,q
> uˆ0
==
∨
ω+ω, Ξ∪(qΘr1)
∗
> w0
∗
∨
uˆ1
∨
ω+ω,<s
∗
> w1
∗
∨
.
.
.
.
.
.
uˇ2
==
∨
ω+ω, (qΠ′′)
‖
ω+ω, (qΛ)
> uˇ3
==
∨
ω+ω, (qΠ′′)
∗
> uˆn
∗
> wn
Due to (#3) we have uˇ2←−q ω+ω,(qΠ′′)uˇ0−→q ω+ω,(qΛ)uˇ1.
Thus by (#6): uˇ2−→q ω+ω,(qΛ)uˇ3←−q ω+ω,(qΠ′′)uˇ1.
We get uˇ1−→ω+ω,q uˆ0 by Lemma 7.4 and
Claim 3: C1µ′1 is fulfilled.
Moreover, we get uˆ0
∗
−→w0
∗
←−v for some w0 by (#Θ1), (#Θ2), (#Θ3), and
P(v,u′,s,s′,Ξ∪ (qΘr1)), which is smaller in the second or third position of the measure.
Claim 1: We may assume that there is some p∈Π′′ with l1µ′1[ p← s′ ] 6=r1µ′1.
Claim 2: There are some n¯∈N; p¯ : {0, . . . , n¯−1}→ N+∗; u¯ : {0, . . . , n¯}→ T (sig,X); such that
l1µ′1[ p′′← s′ | p′′∈Π′′ ]
∗
−→u¯n;
∀i≺n.
(
u¯i+1 = u¯i[ p¯i ← u¯i+1/ p¯i ]
∧ u¯i+1/ p¯i←−u¯i/ p¯i < s
)
; and u¯0 =r1µ′1.
Inductively for i ≺ n we now get some wi+1 with uˆi+1
∗
−→wi+1
∗
←−wi due to Claim 2 and
P(wi, uˆi, u¯i/ p¯i, u¯i+1/ p¯i,{qp¯i}) which is smaller in the first position of the measure by Claim 2.
Finally by Claim 2 we get uˇ3
∗
−→u[q← u¯n ][o← s′ | o ∈ Ξ ]= uˆn. This completes the proof of
Claim due to u[o← s′ | o ∈Π ]= uˇ2
∗
−→wn
∗
←−v.
211
Proof of Claim 1: In case of p, p′∈Π′′ with l1µ′1[ p← s′ ]=r1µ′1 and l1µ′1[ p′← s′ ]=r1µ′1
we cannot have p‖ p′ because then by (#9) we would get the contradiction s= l1µ′1/p=
l1µ′1[ p′← s′ ]/p=r1µ′1/p= l1µ′1[ p← s′ ]/p=s′<s. Therefore, if Claim 1 does not hold, i.e. if
∀p′′∈Π′′. l1µ′1[ p′′← s′ ]=r1µ′1, by (#7) must have we have |Π′′| 1. In case Π′′= /0, we
have uˇ3 = uˇ1
∗
−→w0. Otherwise, in case of Π′′={p} and l1µ′1[ p← s′ ]=r1µ′1, we have
l1µ′1[ p′← s′ | p′∈Π′′ ]= l1µ′1[ p← s′ ]=r1µ′1, and then uˇ3 = uˆ0
∗
−→w0. In both cases we have
shown Claim due to u[o← s′ | o ∈Π ]= uˇ2
∗
−→uˇ3
∗
−→w0
∗
←−v. Q.e.d. (Claim 1)
Proof of Claim 2: Let ξ ∈ S UB (V,V) be a bijection with ξ[V (l0=r0←−C0)] ∩
V (l1=r1←−C1) = /0. Let ρ be given by (x ∈ V): xρ :=
{
xµ′1 if x ∈ V (l1=r1←−C1)
xξ−1µ0 otherwise
}
.
By (#9) and (#5) for the p of Claim 1 we have l0ξρ= l0ξξ−1µ0 =s= l1µ′1/p=(l1/p)ρ and
l1/p 6∈V. Thus, let Y := V ((l0=r0←−C0)ξ, l1=r1←−C1); σ := mgu({(l0ξ, l1/p)},Y);
and ϕ ∈ S UB (V,T (X)) with (σϕ)|Y = ρ|Y. Let t0 := l1[ p← r0ξ ] and t1 := r1. By
Claim 1 we may assume t0σ 6= t1σ (since otherwise l1µ′1[ p← s′ ]= l1µ′1[ p← r0µ0 ]=
t0σϕ= t1σϕ=r1µ′1). Thus ((t0,C0ξ, . . .), (t1,C1, . . .), l1, σ, p) is a critical peak. By
Lemma 7.12, (C0ξC1)σϕ is fulfilled w.r.t. −→ω+ω . Since (l1/p)σϕ=s it makes
sense to define ∆ := { p′∈FPOS (l1)\{p} | (l1/p′)σϕ=s }. Then by (#5) and (#9)
we get Π′′ ⊆ {p}∪∆. Thus by p∈Π′′ we get Π′′∪∆ = {p}∪∆ and therefore
l1µ′1[ p′′← s′ | p′′∈Π′′ ] = l1σϕ[ p′′← s′ | p′′∈Π′′ ] [ p′′← s | p′′∈∆\Π′′ ]
∗
−→ l1σϕ[ p′′← s′ | p′′∈Π′′ ] [ p′′← s′ | p′′∈∆\Π′′ ]
= l1σϕ[ p′′← s′ | p′′∈{p}∪∆ ]
= l1[ p← r0ξ ] [ p′′← r0ξ | p′′∈∆ ] σϕ
= t0 [ p′′← t0/p | p′′∈∆ ] σϕ.
Moreover, for w with w(←−∪)+ (l1/p)σϕ due to (l1/p)σϕ=s we have w<s
and therefore −→ is confluent below w due to P(?,w,w,?,{ /0}) which is smaller in the
first position of the measure. Finally, by Claim 0 we get ∀p′′∈POS ((l1/p)σϕ)\{ /0}.
(l1/p)σϕ/p′′ 6∈dom(−→R,X). Thus, by -quasi overlay joinability, there are some n¯∈N;
p¯ : {0, . . . , n¯−1}→ N+∗; u¯ : {0, . . . , n¯}→ T ; with t0[ p′′← t0/p | p′′∈∆ ]σϕ ∗−→u¯n¯;
∀i≺ n¯.
(
u¯i+1 = u¯i[ p¯i ← u¯i+1/ p¯i ]
∧ u¯i+1/ p¯i←−u¯i/ p¯i (←−∪)+ (l1/p)σϕ=s
)
and u¯0 =t1σϕ=r1µ′1. Finally, for all
v¯ due to s∈D[T] we know that s(−→∪)+v¯ implies s>v¯. Q.e.d. (Claim 2)
Proof of Claim 3: For (u¯=v¯) in C1 we have u¯µ1↓β v¯µ1. In case of β=0, due to (#Θ1), (#Θ2),
and (#Θ3), we have u¯µ1[ p′← s′ | p′∈Θu¯ ]←−q Θu¯ u¯µ1 = v¯µ1−→q Θv¯ v¯µ1[ p′← s′ | p′∈Θv¯ ] and then
u¯µ′1 = u¯µ1[ p
′← s′ | p′∈Θu¯ ]−→q Θv¯\Θu¯
u¯µ1[ p′← s′ | p′∈Θu¯∪Θv¯ ]= v¯µ1[ p′← s′ | p′∈Θv¯∪Θu¯ ]←−q Θu¯\Θv¯ v¯µ1[ p′← s′ | p′∈Θv¯ ]= v¯µ1.
Otherwise, in case of 0≺β, we have for the sort s¯ ∈ S of u¯: ⊥ +←−β(eqs¯(u¯, v¯))µ1. We get
⊥ ↓ (eqs¯(u¯, v¯))µ′1 by P(⊥, (eqs¯(u¯, v¯))µ1, s, s′ ,Θeqs¯(u¯, v¯)) which is smaller in the second position.
Since there are no rules for ⊥ and only one for eqs¯, this means u¯µ′1 ↓ v¯µ′1. For (Def u¯) in C1 we
know the existence of some ~¯u ∈ G T (cons) with ~¯u ∗←−β u¯µ1. We get some ˆ¯u with ~¯u
∗
−→ ˆ¯u
∗
←−u¯µ′1
by P(~¯u, u¯µ1,s,s′,Θu¯) which is smaller in the second position. By Lemma 7.10 we get ˆ¯u ∈
G T (cons). Finally, for (u¯ 6=v¯) in C1 we have some~¯u,~¯v∈ G T (cons) with u¯µ1
∗
−→β~¯u ∤↓~¯v
∗
←−β v¯µ1 (by
Lemma 7.11 and ωβ). By applying the same procedure as before twice we get ˆ¯u, ˆ¯v∈ G T (cons)
with u¯µ′1
∗
−→ ˆ¯u
∗
←−~¯u ∤↓~¯v
∗
−→ ˆ¯v
∗
←−v¯µ′1, i.e. u¯µ′1
∗
−→ ˆ¯u ∤↓ ˆ¯v
∗
←−v¯µ′1. Q.e.d. (Claim 3)
212
Q.e.d. (Lemma 9.10)
Proof of Theorem 9.11
Directly by Lemma 9.10.
Proof of Lemma 9.14 If R has conservative constructors we get V (C)⊆VC (since
l∈T (cons,VSIG⊎VC )). If V (C)⊆ VC ,
then T ERM S (Cµ)⊆T (cons,VSIG⊎VC ) (since l∈T (cons,VSIG⊎VC )).
Thus we can always assume T ERM S (Cµ)⊆T (cons,VSIG⊎VC ). Then we have ∀x∈V (C).
xµ∈T (cons,VSIG⊎VC ) and thus ∀x∈V (C). xµ
∗
−→R,X,ωxν by Lemma 7.10. Moreover Cµ is
fulfilled w.r.t. −→R,X,ω by Lemma 7.10. By confluence of−→R,X,ω and Lemma 7.10 Cν is fulfilled
w.r.t. −→R,X,ω . By Lemma 7.3 we finally get lν−→R,X,ωrν. Q.e.d. (Lemma 9.14)
Proof of Theorem 9.15
For proving part I we are going to apply Theorem 71(I) of Wirth (1995) which guarantees ω-
level confluence of R,X, which again implies confluence of −→R,X according to Corollary 23 of
Wirth (1995). For proving part II we are going to apply Theorem 68(I) of Wirth (1995) which
guarantees ω-shallow confluence of R,X, which again implies confluence of −→R,X according to
Corollary 23 of Wirth (1995). Both theorems require us to show some sophisticated ω-shallow
joinability properties for the critical peaks of the form (0,1) or (1,0). Additionally, Theorem 71(I)
(or 68(I)) requires us to show some some sophisticated ω-level (or -shallow) joinability properties
for the critical peaks of the form (1,1). Since we want to use the required (weak) complementarity
of the critical peaks for showing their conditions to be infeasible, we do not really need the whole
definitions of these joinability properties, but only have to show that the conditions under which
the critical pairs must be joined are never satisfied.
Let us consider the critical peaks ((t0,C0,Λ0), (t1,C1,Λ1), tˆ, σ, p) of the form (0,1) or (1,0)
first. The conditions of the ω-shallow joinability properties allow us to assume that (C0C1)σϕ is
fulfilled w.r.t. −→R,X for those ϕ ∈ S UB (V,T (X)) for which some special form of joinability of
t0σϕ and t1σϕ is to be given. Due to the assumed complementarity, there are two possible cases:
213
There are u,v ∈ T and i≺2 such that
(u=v) or (v=u) occurs in Ciσ and (u 6=v) occurs in C1−iσ:
Under this assumption there are some uˆ, vˆ ∈ G T (cons) such that uˆ ∗←−R,Xuϕ
∗
−→R,X ◦
∗
←−R,Xvϕ
∗
−→R,X vˆ and uˆ ∤↓R,X vˆ. By Lemma 7.10 and by Claim 1 below we get
uˆ
∗
←−R,X,ωuϕ
∗
−→R,X,ω ◦
∗
←−R,X,ωvϕ
∗
−→R,X,ω vˆ and then by the assumed confluence of −→R,X,ω the
contradictory uˆ↓R,X,ω vˆ.
Claim 1: We have uϕ,vϕ ∈ T (cons,VC ).
Proof of Claim 1: Since the critical peak is of the form (0,1) or (1,0), one of the rules gener-
ating the critical peak must be a constructor rule. Since the theorem requires ∀((l,r),C)∈RC .
V (C)⊆VC , all condition terms of this constructor rule are pure constructor terms. Thus, since u
and v occur in both instantiated condition lists, they occur also in the instantiated condition list of
the constructor rule, such that we have uϕ,vϕ ∈ T (cons,VC ). Q.e.d. (Claim 1)
There are p ∈ T ; true, false ∈ G T \dom(−→R,X); and i≺2 such that (p=true)
or (true=p) occurs in Ciσ, (p=false) or (false=p) occurs in C1−iσ, and true 6= false :
Under this assumption we have true ∗←−R,X pϕ
∗
−→R,Xfalse. By Lemma 7.10 and by Claim 2 below
we get true ∗←−R,X,ω pϕ
∗
−→R,X,ωfalse and then by the assumed confluence of −→R,X,ω the contra-
dictory true↓R,X,ωfalse.
Claim 2: We have pϕ ∈ T (cons,VC ).
Proof of Claim 2: Since the critical peak is of the form (0,1) or (1,0), one of the rules gener-
ating the critical peak must be a constructor rule. Since the theorem requires ∀((l,r),C)∈RC .
V (C)⊆VC , all condition terms of this constructor rule are pure constructor terms. Thus, since
p occurs in both instantiated condition lists, it occurs also in the instantiated condition list of the
constructor rule, such that we have pϕ ∈ T (cons,VC ). Q.e.d. (Claim 2)
Proof of part I:
Due to the left-linearity of R, the confluence of −→R,X,ω , the assumption of part I that
∀((l,r),C)∈R. V (C)⊆VC , and the treatment of critical peaks of the form (0,1) or (1,0) above,
for the applicability of Theorem 71(I) we only have left to show the ω-level joinabilities of the
critical peaks ((t0,C0,Λ0), (t1,C1,Λ1), tˆ, σ, p) of the form (1,1). The conditions of the ω-level
joinability properties allow us to assume that (C0C1)σϕ is fulfilled w.r.t. −→R,X,ω+n and that R,X
is ω-level confluent up to n for those n ∈N and ϕ ∈ S UB (V,T (X)) for which some special form
of joinability of t0σϕ and t1σϕ is to be given. Due to the assumed weak complementarity, there
are two possible cases:
There are u,v ∈ T such that (u=v) (or (v=u)) and (u 6=v) occur in (C0C1)σ:
Under this assumption there are some uˆ, vˆ ∈ G T (cons) such that uˆ ∗←−R,X,ω+nuϕ
∗
−→R,X,ω+n ◦
∗
←−R,X,ω+nvϕ
∗
−→R,X,ω+n vˆ and uˆ ∤↓R,X,ω+n vˆ. Since ω-level confluence up to n implies confluence
of −→R,X,ω+n we get the contradictory uˆ↓R,X,ω+n vˆ.
There are p ∈ T ; true, false ∈ G T \dom(−→R,X); such that
(p=true) (or (true=p)) and (p=false) (or (false=p)) occur in (C0C1)σ, and true 6= false :
Under this assumption we have true ∗←−R,X,ω+n pϕ
∗
−→R,X,ω+nfalse. Since ω-level confluence up to
n implies confluence of −→R,X,ω+n we get the contradictory true↓R,X,ω+nfalse. Q.e.d. (part I)
214
Proof of part II:
Since X⊆VSIG, for u ∈ T (cons,VC ) and ϕ ∈ S UB (V,T (X)), we always have uϕ∈G T (cons).
Therefore the reduction relation is not changed at all when we add the literal (Def u) to each
condition of a rule that has a condition term u ∈ T (cons,VC ). Thus, w.l.o.g., we can simplify the
assumption of part II into the following form:
∀((l,r),C)∈R. ∀(u0=u1) in C. ∃i≺2.
(
(Def ui) occurs in C
∨ ui ∈ G T \dom(−→R,X)
)
.
This implies the quasi-normality of Definition 58 of Wirth (1995), which is required for the appli-
cation of Theorem 68(I), — just like conservative constructors, (a weak form of) left-linearity
of R, and confluence of −→R,X,ω . Since we have already treated the critical peaks of the form
(0,1) or (1,0) above, for the applicability of Theorem 68(I) we only have left to show the ω-
shallow joinabilities of the critical peaks ((t0,C0,Λ0), (t1,C1,Λ1), tˆ, σ, p) of the form (1,1).
The conditions of the ω-shallow joinability properties allow us to assume for those n0,n1 ∈N and
ϕ ∈ S UB (V,T (X)) for which some special form of joinability of t0σϕ and t1σϕ is to be given
the following: ∀i≺2.Ciσϕ is fulfilled w.r.t. −→R,X,ω+ni and R,X is ω-shallow confluent up to
ω+n0+n1. Due to the assumed complementarity, there are two possible cases:
There are u0,u1 ∈ T and i≺2 such that
(u0=u1) or (u1=u0) occurs in Ciσ, and (u0 6=u1) occurs in C1−iσ:
Since (u0=u1) occurs in Ciσ, by the above statement there is some j ≺ 2 such that(
(Def u j) occurs in Ciσ
∨ u j∈G T \dom(−→R,X)
)
. Thus, by the above fulfilledness, there are some u′0,u′1,t ′ ∈
G T (cons) such that u′0
∗
←−R,X,ω+n1−i u0ϕ
∗
−→R,X,ω+ni ◦
∗
←−R,X,ω+ni u1ϕ
∗
−→R,X,ω+n1−i u
′
1, u
′
0 ∤↓R,X,ω+n1−i
u′1,
and
(
u jϕ ∗−→R,X,ω+ni t
′
∨ u jϕ 6∈dom(−→R,X)
)
. By Lemma 69(4) of Wirth (1995) and the ω-shallow conflu-
ence of R,X up to ω+n0+n1 this implies u′0↓R,X,ω+ni u
′
1, which by Lemma 7.10 implies the
contradictory u′0↓R,X,ωu′1.
There are p ∈ T ; true, false ∈ G T \dom(−→R,X); and i≺2 such that (p=true)
or (true=p) occurs in Ciσ, (p=false) or (false=p) occurs in C1−iσ, and true 6= false :
In this case true ∗←−R,X,ω+ni pϕ
∗
−→R,X,ω+n1−i false. By the ω-shallow confluence of R,X up to
ω+n0+n1 this implies the contradictory true
∗
−→R,X,ω+n1−i ◦
∗
←−R,X,ω+ni false. Q.e.d. (part II)
Q.e.d. (Theorem 9.15)
215
Proof of Theorem 10.4 Let A ∈ K be arbitrary. Since we are in the B′-, C-, D′-, D-, or E-case,
we know that A is C :cons-term-generated. Thus we have A ιA [T (VSIGA )C ,s]=A [G T C ,s]=A C ,s.
Thus, since A ιA ::T (VSIGA )→A is surjective, by the Axiom of Choice we have S UB (V,A )=
{ τA ιA | τ∈S UB (V,T (VSIG
A )) }. Therefore, the following propositions are logically equi-
valent for and a formula Γ not containing ‘<’-literals: Γ is valid in A . (By Definition 6.1:)
∀κ∈S UB (V,A ). (Γ is true w.r.t. Aκ). ∀τ∈S UB (V,T (VSIGA )). (Γ is true w.r.t. A τA ιA ). (By
Lemma 6.2:) ∀τ∈S UB (V,T (VSIGA )). (Γτ is true w.r.t. A ιA ). Q.e.d. (Theorem 10.4)
Proof of Lemma 10.9
Let KT denote the K of the T -case.
(a): By Theorem 10.4 we only have to show that Γ is true w.r.t. Aκ for A ∈ KB′ (A ∈ KC) and
κ ∈ S UB (V,A ). Since A is C :cons-term-generated, by the Axiom of Choice, there is some
τ ∈ CGSUB(V,cons) with κ=τAκ. Thus, by Lemma 6.2, it suffices to show that Γτ is true
w.r.t. Aκ. Since A ∈KB′⊆KA (A ∈KC⊆KB) we may assume this.
(b): KB⊆KA and KC⊆KB′ .
(c): Assume Γ to be type-C valid. Since KD′⊆KC we know that Γ is type-D′ valid, and this
does not change when we remove some Def-literals from Γ because these are always invalid in
SIG:cons-term-generated algebras.
(d): By Theorem 7.16 we have KD⊆KC.
(e): By Corollary 10.6 and Lemma 7.14.
(f): By Theorem 7.16 we have KE⊆KC.
(g): Since ∗−→R, /0 is sufficiently complete, G T /
∗
←→R, /0 is SIG:cons-term-generated. By Corol-
lary 7.17, G T / ∗←→R, /0 is a constructor-minimal model of R. Thus, KE⊆KD′ in this case.
Q.e.d. (Lemma 10.9)
216
Proof of Lemma 10.14
Let KT denote the K of the T -case.
(a): By Corollary 10.6, Lemma 7.14, and { τ|VC | τ∈S UB (V,T (VSIG)) } = { τ|VC |
τ∈S UB (V,T ( /0)) }.
(b): Define A := T (VSIG)/ ∗←→R,VSIG . Define I := G T /
∗
←→R, /0. Let ι be given by (x∈VSIG):
x 7→
∗
←→R,VSIG [{x}]. Let B be an arbitrary C :cons-term-generated constructor-minimal model
of R and µ an arbitrary B -valuation. By Theorem 10.4 it suffices to show that Γ is true
w.r.t. Bµ under the assumption that Γ is valid in A . By confluence of −→R, /0[∩(D /0×D /0)]
and Theorem 7.16, there is a sig/cons-homomorphism h::A→B with µ|VSIG = ιh. Further-
more, since B is C :cons-term-generated and by the Axiom of Choice, there is some substitution
τ : VC → G T (cons) with µ|VC = τB . Define χ ∈ S UB (V,A ) by χ := ι⊎ τA . We have µ = χh
by the Homomorphism-Lemma(5.7).
By our assumption that Γ is valid in A , there has to be some literal A in Γ such that A is true
w.r.t. Aχ. It now suffices to show that A is true w.r.t. Bµ. Four cases:
If A=(Def u) with u∈T SIG,s, then by the Homomorphism-Lemma(5.7) (since Aχ(u)∈A C ,s)
Bµ(u) = Bχh(u) = hs(Aχ(u)) ∈ B C ,s.
If A=(u=v), then (since Aχ(u)=Aχ(v)) Bµ(u)=hs(Aχ(u))=hs(Aχ(v))=Bµ(v).
If A=(Def u), this contradicts the assumption of the lemma that (Def u) is type-D valid.
If A=(u 6=v), then (since the formulas (Def u) and (Def v) are type-D valid by assump-
tion of the lemma) there are some s ∈ S; uˆ, vˆ ∈ G T C ,s with Aχ(u)=A (uˆ) and
Aχ(v)=A (vˆ). Now, for reduction ad absurdum, assume that A is false w.r.t. Bµ. Then
by the Homomorphism-Lemma(5.7) we get B (uˆ)=hs(A (uˆ))=hs(Aχ(u))=Bχh(u)=Bµ(u)=
Bµ(v)=Bχh(v)=hs(Aχ(v))=hs(A (vˆ))=B (vˆ). By confluence of −→R, /0[∩(D /0×D /0)] and
Theorem 7.16(1), I and therefore also B is a constructor-minimum model. Hence (since
uˆ, vˆ∈G T (cons)) I (uˆ)= I (vˆ); i.e. uˆ ∗←→R, /0 vˆ. By Lemma 7.14 we get uˆ ∗←→R,VSIG vˆ, and then
Aχ(u)=A (uˆ)=A (vˆ)=Aχ(v). Thus A is false w.r.t. Aχ, which contradicts the assumption that A
is true w.r.t. Aχ.
217
(c): For an arbitrary A ∈ KB (KA) we show that Γ is valid in A . Define the sig/cons-algebra B
similar to A by B |F⊎({SIG}×S) := A |F⊎({SIG}×S) but with B C ,s := A [G T C ,s] (s∈S). Now the
following two properties hold:
(1) ∀χ∈S UB (V,B ). ∀(u=v)∈A T (sig,V).(
(u=v) is true w.r.t. Bχ ⇔ (u=v) is true w.r.t. Aχ
)
(2) ∀χ∈S UB (V,B ). ∀(Def u)∈A T (sig,V).(
(Def u) is true w.r.t. Bχ ⇒ (Def u) is true w.r.t. Aχ
)
If B were not a sig/cons-model of R, then there would be some B -valuation χ and a rule such
that all its literals are false w.r.t. Bχ when we consider the rule as a formula. Now, since all these
literals have to be of one of the forms (u=v), (u 6=v), (Def u), by (1) and (2), the rule would not
be true w.r.t. Aχ, which contradicts A being a sig/cons-model of R. Thus, since B is C :cons-
term-generated by construction, B is a C :cons-term-generated sig/cons-model of R. More-
over, by the inclusion-homomorphism, B is a constructor-minimal model if A is. Thus B ∈KC
(B ∈KB′). Now it suffices to show that Γτ is true w.r.t. Aκ for arbitrary τ ∈ CGSUB(V,cons)
and κ ∈ S UB (V,A ). By Lemma 6.2, it suffices to show that Γ is true w.r.t. A τAκ . Since
τAκ∈S UB (V,B ), by the assumed type-C (type-B′) validity of Γ and Theorem 10.4, we know
that Γ is true w.r.t. B τAκ . Thus, Γ contains some literal λ that is true w.r.t. B τAκ . If this literal were
of the form (Def u), this would contradict the assumption that for such literals (Def u) is type-C
(type-B′) valid. Thus, λ has to be of one of the forms (u=v), (u 6=v), or (Def u), and then, by (1)
or (2), λ is true w.r.t. A τAκ .
(d): By (c) it suffices to show that type-B validity of Γ implies type-A validity of Γ. Thus we
assume type-B validity of Γ. It suffices to show that Γτ is true w.r.t. Bµ for arbitrary B ∈ KA,
µ ∈ S UB (V,B ), and τ ∈ CGSUB(V,cons). Since no rule in R has a negative condition, there
is some A being free in KA over V w.r.t. some ι, e.g. T (V)/
∗
←→R,V and x 7→
∗
←→R,V[{x}]
(x∈V). This means that there is some sig/cons-homomorphism h::A→B with µ= ιh and that
A is a constructor-minimal model of R, i.e. A ∈KB. Since Γ is type-B valid by assumption,
there must be some atom (u=v) or some atom (Def u) occurring in Γτ (as a positive literal) that
is true w.r.t. A ι. Then we have A ι(u)=A ι(v) or A ι(u)∈A C ,s for some s ∈ S. By the Homo-
morphism-Lemma(5.7) we have Bµ(u)=B ιh(u)=hs(A ι(u)) and then Bµ(u)=hs(A ι(v))=Bµ(v)
or Bµ(u)∈B C ,s. Q.e.d. (Lemma 10.14)
218
Proof of Theorem 10.15
Proof of (A), (B′), (B), (C), and (D′):
Assume that the “old” formula Γ is not valid w.r.t. sig′/cons′/R′. It suffices to show that Γ is not
valid w.r.t. sig/cons/R.
Let A ′ be a sig′/cons′-algebra. Define the sig/cons-algebra A by: A := A ′|F⊎{SIG,C }×S. Now
an any “old” formula not containing ‘<’-literals is valid in A iff it is valid in A ′. Fur-
thermore, its constructor ground instances Γτ do not differ for τ ∈ CGSUB(V,cons) and
τ ∈ CGSUB(V′,cons′) due to ∀s∈S. G T (cons)s =G T (cons′)s. Moreover, if A ′ is C :cons′-
term-generated, then A is C :cons-term-generated. Similarly, if A ′ is SIG:cons′-term-generated,
then A is SIG:cons-term-generated.
Thus (using Theorem 10.4), for proving (A) and (B′) [as well as (B), (C), and (D′)], it suffices to
show the following:
Claim 1: If A ′ is a [constructor-minimal] model of R′,
then A is a [constructor-minimal] model of R.
Proof of Claim 1: Assume that A ′ is a model of R′. As each rule from R can be translated into
an “old” formula not containing ‘<’-literals (on which A and A ′ do not differ (cf. above)), A is a
sig/cons-model of R.
Let us now assume that R′ is Def-moderated, that A ′ is a constructor-minimal model of R′, and
that (∗) and (∗∗) hold.
It now suffices to show A .C C for an arbitrary sig/cons-model C of R.
Let G T ′ denote the ground term algebra over sig′/cons′ and G T (cons) denote the ground term
algebra over cons. By confluence of −→R′, /0 [∩(D′/0×D′/0)] and Theorem 7.16(1), G T ′/
∗
←→R′, /0
is a constructor-minimum model of R′ w.r.t. sig′/cons′. Thus, A ′ must be a constructor-
minimum model of R′ w.r.t. sig′/cons′, too. Hence, there exists some cons′-homomorphism
h′::A ′|C ′⊎({C }×S′)→(G T
′/
∗
←→R′, /0)|C ′⊎({C }×S′). By defining hs(a) := h
′
s(a)∩ G T (cons) (for
a∈A C ,s; s∈S), we get a cons-homomorphism
h::A |C⊎({C }×S)→G T (cons)/(
∗
←→R′, /0 ∩ (G T (cons)×G T (cons))).
By confluence of −→R′, /0 [∩(D′/0×D′/0)] and Theorem 7.18(1) and Lemma 7.11 we get
(
∗
←→R′, /0 ∩ (G T (cons)×G T (cons))) ⊆ (↓R′, /0 ∩ (G T (cons)×G T (cons))) ⊆
(↓R, /0 ∩ (G T (cons)×G T (cons))) ⊆ ↓R, /0,ω ⊆
∗
←→R, /0,ω.
Finally, for each sig/cons-model C of R we get
∀βω. ∀s∈S. −→R, /0,β ∩ (G T SIG,s×G T SIG,s) ⊆ ker(C )s
by induction on β; thus
∀s∈S. (
∗
←→R′, /0 ∩ (G T (cons)s×G T (cons)s)) ⊆ ker(C )s ;
and then by the Homomorphism-Theorem
G T (cons)/(
∗
←→R′, /0 ∩ (G T (cons)×G T (cons))) .C C ,
which together with
A .C G T (cons)/(
∗
←→R′, /0 ∩ (G T (cons)×G T (cons)))
(given by h from above) implies A .C C as we had to show. Q.e.d. (Claim 1)
219
Proof of (D):
We do the proof for the equivalent version of type-D inductive validity given by Corol-
lary 10.6. It suffices to show that Γτ′ is valid in the sense of Corollary 10.6 for arbi-
trary τ′ ∈ S UB (V′,T ′(V′SIG)). We may suppose that no negative literal (u 6=v) of Γτ′ im-
plies type-D inductive validity via Corollary 10.6. There is a constructor ground substitution
τ ∈ CGSUB(V′,cons′) and a substitution σ : V′SIG → T ′(V′SIG) such that τ′=τσ. Note that
τ|V ∈ S UB (V,T (VSIG)).
Claim 2: For each negative literal λ occurring in Γ, λτ is valid in the sense of Corollary 10.6.
Proof of Claim 2: For each negative literal (u 6=v) in Γ we have assumed that the formulas (Def u)
and (Def v) are type-D valid w.r.t. sig/cons/R. Thus there are uˆ, vˆ∈ G T (cons) with uτ ∗←→R,VSIG uˆ
and vτ ∗←→R,VSIG vˆ. By Theorem 7.18(2) we get uτ
∗
←→R′,V′SIG
uˆ and vτ ∗←→R′,V′SIG vˆ , and then by
Corollary 7.9 and the supposed uτ′ ∗←→R′,V′SIG vτ
′ get uˆ= uˆσ ∗←→R′,V′SIG uτσ=uτ
′ ∗←→R′,V′SIG
vτ′=
vτσ
∗
←→R′,V′SIG
vˆσ= vˆ. By Lemma 7.14 we get uˆ ∗←→R′, /0 vˆ and then (by confluence of −→R′, /0
[∩(D′/0×D′/0)]) uˆ↓R′, /0 vˆ , and then by Theorem 7.18(1) we get uˆ↓R, /0 vˆ and then by Lemma 7.14
uτ
∗
←→R,VSIG uˆ
∗
←→R,VSIG vˆ
∗
←→R,VSIG vτ. Furthermore, for each negative literal (Def u) in Γ we have
assumed that the formula (Def u) is type-D valid w.r.t. sig/cons/R. Thus there is a uˆ∈ G T (cons)
with uτ ∗←→R,VSIG uˆ. Q.e.d. (Claim 2)
Since Γ is type-D valid w.r.t. sig/cons/R by assumption, by Claim 2 there is a positive literal
(u=v) or (Def u) in Γ with uτ ∗←→R,VSIG vτ or, for some uˆ ∈ G T (cons), uτ
∗
←→R,VSIG uˆ, resp..
By Theorem 7.18(2) we get uτ ∗←→R′,V′SIG vτ or uτ
∗
←→R′,V′SIG
uˆ , and then by Corollary 7.9
uτσ
∗
←→R′,V′SIG
vτσ or uτσ
∗
←→R′,V′SIG
uˆ∈G T (cons′).
Proof of (E): By Lemma 10.14(a), (D), and Lemma 10.9(e).
Q.e.d. (Theorem 10.15)
220
Proof of Lemma 10.16
Let KT denote the K of the T -case. Let I := G T /
∗
←→R, /0 .
(a): By Theorem 10.4 we only have to show that, for an arbitrary algebra A ∈ KD′ , that Γ is valid
in A iff it is valid in I . By Lemma 6.3 it suffices to show that A and I are sig/cons-isomorphic.
By Corollary 7.17, I is is initial in the class of all SIG:sig-term-generated constructor-minimal
models of R, which is a superclass of KD′ . Thus, there is some sig/cons-homomorphism h::I→A .
We are now going to show that h::I→A is a sig/cons-isomorphism. Since A is SIG:cons-term-
generated we have for each s ∈ S: A SIG,s ⊆ A [G T (cons)s]⊆ A C ,s ⊆ A SIG,s, i.e. A SIG,s =A C ,s.
Since ∗−→R, /0 is sufficiently complete, I is SIG:cons-term-generated, too, and therefore we also
have I SIG,s = I C ,s. Thus, h::I |C⊎({C }×S)→A |C⊎({C }×S) is a cons-homomorphism. Since A is
a constructor-minimal model, there is some cons-homomorphism c::A |C⊎({C }×S)→I |C⊎({C }×S).
Then ch::A |C⊎({C }×S)→A |C⊎({C }×S) is a cons-homomorphism. Since the SIG:cons-term-gene-
rated algebra A is C :cons-term-generated a fortiori, we have ch= IdA |C⊎({C }×S) . Just the same we
get hc= IdI |C⊎({C }×S) . Thus, for all s ∈ S, hs : I C ,s → A C ,s is a bijection. By the above equalities
of constructor sub-universes with (general) universes, this is nothing but: hs : I SIG,s → A SIG,s is
a bijection. Moreover, it implies hs[I C ,s]=A C ,s. By Lemma 5.6, h::I→A is a sig/cons-iso-
morphism.
(b): By Lemma 10.9(a) type-B validity of Γ implies type-C validity of Γ. By Lemma 10.9(c) type-
C validity of Γ implies type-D′ validity of Γ. By Lemma 10.9(g) type-D′ validity of Γ implies
type-E validity of Γ. By Lemma 10.14(a) type-E validity of Γ implies type-D validity of Γ.
By Lemma 10.14(b) and Claim 1 below, type-D validity of Γ implies type-C validity of Γ. By
Lemma 10.14(c) and Claim 1 below, type-C validity of Γ implies type-B validity of Γ.
Claim 1: For u ∈ T with V SIG(u)= /0 the formula (Def u) is type-E , -D and -C inductively valid.
Proof of Claim 1: Since ∗−→R, /0 is sufficiently complete, (Def u) is type-E valid by Corollary 10.6.
Then it is type-D valid by Lemma 10.14(a). Then it is type-C valid by Lemma 10.14(b).
Q.e.d. (Claim 1) Q.e.d. (Lemma 10.16)
Proof of Lemma 12.19 The only rule whose soundness is non-trivial is the Deletion rule for
form[G] being valid. By Corollary 12.6(2) we get Gց /0. Thus by Corollary 12.10(2) and the
condition of the rule we get {S}ցH. By Corollary 12.18 we may assume that (L,H,G∪{S}) is
weakly correct. Thus (since G∪{S}ցH due to Corollary 12.9(1)) we can conclude that form[H]
must be valid. By Corollary 12.6(7) this means that form(S) is valid, i.e. that form[G∪{S}] is
valid. Q.e.d. (Lemma 12.19)
221
Proof of Lemma 12.21 Assume L to be valid. We show invariance of weak correctness first:
Expansion: Assume G∪{S}ցH. By Corollary 12.9(2) we get GցH. Now form[H] must
be valid due to weak correctness of (L,H,G). Hypothesizing: Assume GցH∪{S}. By
Lemma 12.27 we get GցH. By weak correctness of (L,H,G), form[H] must be valid, which
by Corollary 12.6(7) means that form[G∪H] is valid. By the condition of the rule and Corol-
lary 12.6(6), we know that form(S) is valid. Therefore form[H∪{S}] is valid, too. Acquisition:
Trivial. Deletion: Assume GցH. By Lemma 12.27 we get G∪{S}ցH. By weak correctness
of (L,H,G∪{S}), form[H] must be valid.
Finally we show invariance of correctness: Expansion: By Corollary 12.9(2). Hypothesizing:
By Corollary 12.11 we get GyG. If we assume HyG, we get H∪GyG by Corollary 12.9(1).
By the condition of the rule and Corollary 12.11 this means {S}yG. By our assumption we now
get H∪{S}yG via Corollary 12.9(1). Acquisition: Trivial. Deletion: Assume HyG∪{S}. By
Corollary 12.10(1) from the condition of the rule we get {S}yG. By Corollary 12.11 we have
GyG and then by Corollary 12.9(1) G∪{S}yG. By the assumption and Corollary 12.11 this
means HyG. Q.e.d. (Lemma 12.21)
Proof of Lemma 12.27 Expansion: By Corollary 12.9(2). Hypothesizing: By Corollary 12.11 we
get HyH and then from the condition of the rule H∪{S}yH∪G by Corollary 12.9(1). If we
now assume GցH∪{S}, we get GցH∪G by Corollary 12.8, and then by corollaries 12.9(3)
and 12.9(2) GցH. Acquisition: Trivial. Deletion: Assume GցH. By the condition of the rule
and Corollary 12.10(2) we get {S}ցH. Thus by our assumption and Corollary 12.9(1) we get
G∪{S}ցH. Q.e.d. (Lemma 12.27)
Proof of Lemma 13.11 It is sufficient to show for each literal λ in Π that (λµ)τ is true w.r.t. A ιA iff
(λν)pi is true w.r.t. A ιA . Additionally, we can restrict λ to be an atom. For a non-generalized literal
λ ∈ L I T (sig,V) the following are logically equivalent due to Lemma 6.2 and (µτA ιA )|V (Π) =
(νpiA ιA )|V (Π) : λµτ is true w.r.t. A ιA ; λ is true w.r.t. A µτA ιA ; λ is true w.r.t. AνpiA ιA ; λνpi
is true w.r.t. A ιA . For a ‘<’-atom the argumentation is different because semantic equality is
not enough here. However, in case of µτ|V <(Π) =νpi|V <(Π), for a literal (k<ℵ) or (k<ℵ)
in Π we have k(µτ)=k(νpi) and ℵ(µτ)=ℵ(νpi) by Global Requirement 13.3. By Global
Requirement 13.5 we then get (kµ)τ≈A (kν)pi and (ℵµ)τ≈A (ℵν)pi. This also holds in the case
of a semantic induction ordering. Therefore the following are logically equivalent: ((k<ℵ)µ)τ
is true w.r.t. A ιA ; (kµ)τ<A (ℵµ)τ; (kν)pi<A (ℵν)pi; ((k<ℵ)ν)pi is true w.r.t. A ιA .
Q.e.d. (Lemma 13.11)
Proof of Lemma 13.14
For each x ∈ Y′ ∩ GENDOM(µ) (due to ((Def xµ),τ,A ) being a counterexample) we have
A ιA (xµτ)∈A C ,s for s being the sort of x. Since A ∈K we know that A is C :cons-term-generated
by Global Requirement 13.2. Thus there is some ux ∈ G T (cons)s with A ιA (xµτ)=A (ux). For
222
x ∈ GENDOM(µ) \Y′ let ux be some arbitrary constructor ground term of the sort of x. Us-
ing the Axiom of Choice, we now define (x∈V): xpi :=
{
ux if x∈GENDOM(µ)
xµτ otherwise
}
. Now
we immediately get the items 1, 2, and 3 of the lemma. Next we show item 4. In case of
GENDOM(µ)∩V <(Π)= /0 by item 2 we get pi|V <(Π) =(µτ)|V <(Π). Thus item 4 follows from
V (Π)⊆Y′, item 3, and Lemma 13.11.
Now assume that (Π′,k′,Y,Θ) results from application of µ to (Π,k) w.r.t. Z. Let ξ be given as
in Definition 13.13.
We define the substitution τ′ by a little change of τ on the set of variables ξ[Y]: τ′|V\ξ[Y]=τ|V\ξ[Y];
τ′|ξ[Y] =(ξ−1pi)|ξ[Y]. By item 1 we get (τ′,A )∈ Info. Moreover, since, by Definition 13.13,ξ[Y]∩Z= /0, we get τ′|Z =τ|Z. For x ∈ Y by item 3 (due to Y⊆Y′) we get xξτ′A ιA =xpiA ιA =
xµτA ιA =xµτ
′A ιA because of ξ[Y]∩V (µ[Y]) = /0 by Definition 13.13. Therefore, (Θ,τ′,A ) is a
counterexample, i.e. item 5 holds.
Finally we are going to show item 6. Define (x∈V): xρ :=
{
xξτ if x ∈ Y
xpi otherwise
}
. Due to item 1
we get (ρ,A )∈ Info.
Claim 0: For x ∈ V (Π,k) we have xρA ιA =x(µ|V\Y∪ξ|Y)τA ιA . When the induction ordering is
not semantic, for x ∈ V <(Π)∪V (k) we have xρ=x(µ|V\Y∪ξ|Y)τ.
Proof of Claim 0: In case of x∈Y we have xρ=xξτ=x(µ|V\Y∪ξ|Y)τ. Otherwise, in case
of x ∈ V (Π,k) \Y, by item 3 (due to V (Π,k)⊆Y′) we have xρA ιA =xpiA ιA =xµτA ιA =
x(µ|V\Y∪ξ|Y)τA ιA . Now assume the induction ordering not to be semantic. In case of x ∈
(V <(Π)∪V (k))\Y, since we are in the second case of the definition of Y in Definition 13.13,
we have x 6∈GENDOM(µ) and thus get by item 2: xρ=xpi=xµτ=x(µ|V\Y∪ξ|Y)τ.
Q.e.d. (Claim 0)
Claim 1: (Π,ρ,A ) is a counterexample.
Proof of Claim 1: Let λ be an arbitrary literal from Π. We have to show that λρ is false w.r.t. A ιA .
We first treat the case that λ is a non-generalized literal. Then (according to the definition of Π′)
λµ occurs in Π′. Since (Π′,τ,A ) is a counterexample, (λµ,τ,A ) is a counterexample, too. Thus,
by Lemma 13.11, we only have to show xρA ιA =xµτA ιA for all x∈ V (λ). In case of x∈Y, by the
assumption that (Θ,τ,A ) is a counterexample, xρA ιA =xξτA ιA =xµτA ιA . Otherwise, by item 3
(due to V (Π,k)⊆Y′) we get xρA ιA =xpiA ιA =xµτA ιA .
Now, on the contrary, we assume that λ is a ‘<’-literal. Then (according to the definition
of Π′) λ(µ|V\Y∪ξ|Y) occurs in Π′. Since (Π′,τ,A ) is a counterexample, (λ(µ|V\Y∪ξ|Y),τ,A )
is a counterexample, too. By Claim 0 we can apply Lemma 13.11 to infer that (λ,ρ,A ) is a
counterexample. Q.e.d. (Claim 1)
Claim 2: kρ.A k′τ.
Proof of Claim 2: By definition we have k′=k(µ|V\Y∪ξ|Y). Thus by Global Requirement 13.5
and Claim 0 we have k′τ=(k(µ|V\Y∪ξ|Y))τ≈A k((µ|V\Y∪ξ|Y)τ)≈A kρ. Q.e.d. (Claim 2)
Q.e.d. (Lemma 13.14)
223
Proof of Lemma 13.16 If no step in the reduction tτ ∗−→R,Xt ′′ takes place at a non-variable po-
sition of t, then due to the linearity of t there is some τ′ ∈ G EN S UB (V,T (X∪X′)) such that
t ′′= tτ′; ∀x∈V (t). xτ ∗−→R,Xxτ
′; and ∀x∈V\V (t). xτ=xτ′. By X⊆X′ and Lemma 7.10:
τ′∈S UB (V,T (X′)). Since this was excluded by the assumption of the lemma, we know that
there must be some first reduction step at a non-variable position p ∈ FPOS (t). More precisely,
there must be some τ′ ∈ S UB (V,T (X′)) as above and some µ ∈ S UB (V,T (X)) and some rule
(l=r←−λ0 . . .λn−1) ∈ R such that (t/p)τ′= lµ and (λ0 . . .λn−1)µ is fulfilled w.r.t. −→R,X . De-
fine Z := V (l=r←−λ0 . . .λn−1). Let ξ be as in the definition of SUPERPOSE(t,Y). Define
(x∈V) xρ :=
{
xξ−1µ if x∈ξ[Z]
xτ′ otherwise
}
. Due to lξρ= lξξ−1µ= lµ=(t/p)τ′=(t/p)ρ (last step
due to ξ[Z]∩Y= /0 and V (t)⊆Y) we can define σ := mgu({(lξ,t/p)},Y∪ξ[Z]) and then get some
substitution pi with (σpi)|Y∪ξ[Z] =ρ|Y∪ξ[Z]. Since µ∈S UB (V,T (X)), τ′∈S UB (V,T (X′)),
and X⊆X′; and since ξ ∈ S UB (V,V) is a bijection; we get ρ∈S UB (V,T (X′)). Thus we
can assume pi∈S UB (V,T (X′)) w.l.o.g., i.e. item 1 is satisfied. Moreover, using the fact that
ξ[Z]∩Y= /0, we get (σpi)|Y =ρ|Y =τ′|Y. Thus, from τ′|V\V (t) =τ|V\V (t) we know that item 2
is satisfied, and from (τ′Iι)|V (t) =(τIι)|V (t) and V (t)⊆Y we know that item 3 is satisfied.
When we now define Λ := (λ0 . . .λn−1)ξ, then we know that (Λ,σ)∈SUPERPOSE(t,Y). Item 4
holds, because, in case of t∈T (cons,VC ), we have tτ∈T (cons,VC ) and then by Lemma 7.10
(t/p)τ′∈T (cons,VC ), so that the matching rule l=r←−λ0 . . .λn−1 must be a constructor rule
and thus the literals λi are all positive, cf. Definition 5.11. For item 5 it now suffices to show that
λiξσpi is true w.r.t. Iι for each i ≺ n. Due to λiξσpi=λiξρ=λiξξ−1µ=λiµ it suffices to show
λiµ to be true w.r.t. Iι. Note that we already know that λiµ is fulfilled w.r.t. −→R,X . Thus, in
case of λi = (u=v) for some u,v ∈ T , we get uµ↓R,Xvµ, i.e. Iι(uµ)= Iι(vµ). Otherwise, in
case of λi = (Def u), we get uµ ∗−→R,X uˆ for some uˆ ∈ G T (cons), i.e. Iι(uµ)= Iι(uˆ)∈ I C ,s for
s being the sort of uˆ. Finally, in case of λi = (u 6=v), we get uµ ∗−→R,X uˆ ∤↓R,X vˆ
∗
←−R,Xvµ for some
uˆ, vˆ ∈ G T (cons). Since by item 4 we may assume −→R,X to be confluent in this case, we get
uˆ 6
∗
←→R,X vˆ and therefore Iι(uµ)= Iι(uˆ) 6= Iι(vˆ)= Iι(vµ). Q.e.d. (Lemma 13.16)
Proof of Lemma 13.17 Due to tτ ∗←→R,Xt ′τ and confluence of−→R,X we get tτ
∗
−→R,Xt
′′ ∗←−R,Xt
′τ
for some t ′′. First we consider the case that there is some τ′ ∈ S UB (V,T (X′)) such that
tτ′= t ′′= t ′τ′; ∀x∈V (t,t ′). xτ ∗−→R,Xxτ
′; ∀x∈V\V (t,t ′). xτ=xτ′. In this case we can define
Λ := /0 and σ := mgu({(t,t ′)},Y) and get some pi with (σpi)|Y =τ′|Y. W.l.o.g. we may assume
pi∈S UB (V,T (X′)). Then we have (Λ,σ)∈NARROW(t,t ′,Y) and all items of the lemma
hold due to V (t,t ′)⊆Y. Otherwise, if such a τ′ does not exist, due to t and t ′ being linear and
V (t)∩V (t ′)= /0, the conditions of Lemma 13.16 are satisfied, matching its t either to our t or to
our t ′. Thus, in any case, we have (Λ,σ)∈NARROW(t,t ′,Y) and all items of the lemma hold
due to V (t,t ′)⊆Y. Q.e.d. (Lemma 13.17)
224
Proof of Lemma 13.18 In the D-case −→R,X is confluent due to Definition 10.1. Other-
wise we have X= /0 and thus −→R,X is confluent due to Global Requirement 13.1. Now as-
sume A ιA (tτ)=A ιA (t
′τ). If the D- or E-case holds we get A = I and therefore IιI (tτ)=
IιI (t
′τ). Otherwise the lemma says that t,t ′∈T (cons,VC ), X= /0, and K is a sub-class of
the class of constructor-minimal models of R; and we define I as in the E-case. Then we have
tτ,t ′τ∈G T (cons) and, since R is a Def-MCRS and −→R, /0 is confluent (cf. Global Require-
ment 13.1), by Theorem 7.16(1), I is a constructor-minimum model of R. By Definition 10.7
we have A ∈K. Thus, A is a constructor-minimal model of R. Since I is a constructor-
minimum model, A must be a constructor-minimum model of R, too. Thus there must be a
cons-homomorphism c::A |C⊎({C }×S)→I |C⊎({C }×S). Now Lemma 5.7 says that A |C⊎({C }×S) c =
I |C⊎({C }×S) (where A |C⊎({C }×S) is meant to denote the evaluation cons-homomorphism of the
cons-algebra A |C⊎({C }×S)). Thus we get I (tτ)= I (t ′τ) from cs(A (tτ))=cs(A (t ′τ)) due to
tτ,t ′τ∈G T (cons). This means that we get IιI (tτ)= IιI (t ′τ) in any case. In other words
tτ
∗
←→R,Xt
′τ. Finally, if t,t ′ are a linear terms with V (t)∩V (t ′)= /0, V (t,t ′)⊆Y, and Y is a
finite subset of V, then by Lemma 13.17 we get NARROW(t,t ′,Y) 6= /0. Q.e.d. (Lemma 13.18)
Proof of Lemma 14.1 Since (u0 6=v0) . . .(um−2 6=vm−2)(um−1 6=vm−1)(t[ p j ← u j | j≺m ]=
t[ p j ← v j | j≺m ]) is valid (even deductively), we can assume this formula to be in L w.l.o.g..
Then the =-Decompose rule is a sub-rule of the Lemma Apply rule which is a safe sub-rule of
the Transformation rule according to Lemma 14.12. Q.e.d. (Lemma 14.1)
Proof of Lemma 14.2 For j ≺ m, let x j be a constructor variable of the sort of v j that not al-
ready occurs in t. Moreover assume the x j to be mutually distinct. Let µ ∈ G EN S UB (V,T )
be given in such a way that GENDOM(µ) ⊆ {x0, . . . ,xm−1} and ∀ j≺m. x jµ=v j. Now since
(Def t[ p j ← x j | j≺m ]) is valid (even deductively) due to t[ p j ← x j | j≺m ] ∈ T (cons,VC ),
we can assume (Def t[ p j ← x j | j≺m ]) ∈ L w.l.o.g.. Then the Def-Decompose rule is a sub-
rule of the Lemma Apply rule which is a safe sub-rule of the Transformation rule according to
Lemma 14.12. Q.e.d. (Lemma 14.2)
Proof of Lemma 14.3 The 6=-Tautology Remove rule is trivially safe. For showing it to
be a sub-rule of the Transformation rule it is sufficient to show that (u0 6=u1) is valid under
the assumption that the conditions of the 6=-Tautology Remove rule are satisfied. Then there
are some terms v0,v1 ∈ T (cons,VC ) and some ζ ∈ S UB (V,V) such that (v0 6=v1) is lin-
ear and (v0 6=v1)ζ = (u0 6=u1). Furthermore: v0,v1 are clashing and ∀i≺2. ∀p∈FPOS (vi).
∀((l,r),C)∈R. ( vi/p and l are clashing ). Therefore we have NARROW(v0,v1,V (v0,v1))=
/0. Now for each (τ,A ) ∈ Info we get (ζτ,A )∈ Info and thus A ιA (v0ζτ) 6=A ιA (v1ζτ) by
Lemma 13.18 and the assumed constructor-minimality. This means that (u0 6=u1) is valid.
Q.e.d. (Lemma 14.3)
Proof of Lemma 14.6 In the first three cases of Definition 14.5, Π is trivially valid in all sig/cons-
algebras. Let Λ be given as in the fourth case of Definition 14.5 and assume that (Π,τ,A ) is a
counterexample. By the condition that Λµ is contained in Π, we conclude that (Λµ,τ,A ) is a
225
counterexample, too. By the condition that ∀x∈GENDOM(µ). (Def xµ) is contained in Π, we
conclude ∀x∈GENDOM(µ). ((Def xµ),τ,A ) is a counterexample. Thus, by the condition that(
GENDOM(µ)∩V <(Λ)= /0
∨ the induction ordering is semantic
)
, item 1 and 4 of Lemma 13.14 imply the existence
of some pi such that (Λ,pi,A ) is a counterexample, which contradicts the validity of Λ.
Q.e.d. (Lemma 14.6)
Proof of Lemma 14.8 If the Subsumptive Literal Remove rule were not safe, then there would
be some (τ,A ) ∈ Info such that (Γ∆,τ,A ) is a counterexample, but (Γλ∆,τ,A ) is not. This
implies that (λ,τ,A ) is a counterexample.
Claim 1: (Π,τ,A ) is a counterexample.
Proof of Claim 1: If Π=Γ∆, the claim is trivial. Otherwise, by the condition of the Subsumptive
Literal Remove rule, there are some l, r such that λ equals (l=r) and Π ∗←→
(l=r)Γ∆. By Corol-
lary 13.9, the claim holds again by induction on the number of rewrite steps. Q.e.d. (Claim 1)
By Claim 1 we now know that (λΠ,τ,A ) is a counterexample. By Lemma 14.6 and because the
condition of the Subsumptive Literal Remove rule says that λΠ is subsumed by L∪ form[H ∪G],
this implies that already some formula of L∪ form[H ∪G] is invalid. Q.e.d. (Lemma 14.8)
Proof of Lemma 14.9 When the conditions of the =-Literal Remove rule are satisfied, then we
get A ιA (tτ) 6=A ιA (t ′τ) for each (τ,A ) ∈ Info by Lemma 13.18. Q.e.d. (Lemma 14.9)Proof of Lemma 14.10 Assume that the conditions of the Def-Literal Remove rule are satisfied.
Let (τ,A ) ∈ Info. It suffices to refute A ιA (tτ)∈A C ,s. If this were the case, then (since A is
C :cons-term-generated by Definition 10.7 and Global Requirement 13.2) there would be some
u ∈ G T (cons) with A ιA (tτ)=A (u). When we define (y∈V) yτ′ :=
{
u if y=x
yτ otherwise
}
we get
(τ′,A )∈ Info and A ιA (xτ′)=A ιA (u)=A ιA (tτ)=A ιA (tτ′). Then, by the assumed D- or E-case,
Lemma 13.18 implies that NARROW(x,t,V (x,t)) 6= /0 which contradicts the conditions of the
Def-Literal Remove rule. Q.e.d. (Lemma 14.10)
Proof of Lemma 14.11 Claim 1: (Γλ′′∆,τ,A ) is a counterexample iff (Γ′λ′′∆′,τ,A ) is a
counterexample. Moreover, in this case we have ℵ≈A ℵ′.
Proof of Claim 1: Since λ′′ equals (l 6=r), ((l 6=r),τ,A ) is a counterexample, too. Thus, the claim
follows from Corollary 13.9 by an induction on the number of rewrite steps. Q.e.d. (Claim 1)
That the Constant Rewrite rule is safe follows directly from Claim 1. To show it to be a
sub-rule of the Transformation rule suppose ((Γλ′′∆,ℵ),τ,A ) to be a counterexample. By
Claim 1, ((Γ′λ′′∆′,ℵ′),τ,A ) is a counterexample, too. By Claim 1, ((Γ′λ′′∆′,ℵ′),τ,A ) .
((Γλ′′∆,ℵ),τ,A ). Q.e.d. (Lemma 14.11)
226
Proof of Lemma 14.12
Since Γ is contained in all newly introduced formulas, the Lemma Apply rule is safe. To show
it to be sub-rule of the Transformation rule assume ((Γ,ℵ),(τ,A )) to be a counterexample. We
make a complete case analysis as follows.
There is some i≺ m with λiτ being true w.r.t. A ιA :
Taking the smallest such i, we know that (λi λi−1 . . .λ0)τ is false w.r.t. A ιA . Then by the condition
that all literals of Λi are contained in λi−1 . . .λ0, we conclude that ((λi ΛiΓ,ℵ),(τ,A )) is a
counterexample.
∀i≺m. (λiτ is false w.r.t. A ιA ):
In this case, (λm−1 . . .λ0Γ,τ,A ) is a counterexample. From the condition that all literals
(Def xµ) with x∈GENDOM(µ) are contained in λm−1 . . .λ0Γ, we get ∀x∈GENDOM(µ).
((Def xµ),τ,A ) is a counterexample. Let pi be given according to Lemma 13.14. Now,
since λm−1 . . .λ0Γ contains Πµ, we know that Πµτ is not true w.r.t. A ιA . Since(
GENDOM(µ)∩V <(Π)= /0
∨ the induction ordering is semantic
)
, Lemma 13.14(4) implies that also Πpi is not true
w.r.t. A ιA . By Lemma 13.14(1) (Π,pi,A ) is a counterexample. This means that the proof is com-
plete because we have an invalid lemma. Q.e.d. (Lemma 14.12)
Proof of Lemma 14.16
The result of the Lemma Rewrite rule can be obtained by a Lemma Apply (matching m to m+1
and Γ to Γλ′′∆) followed by a Constant Rewrite followed by a Context Remove (cf. § 14.3)
that removes the literal λm. Since all these rules are sub-rules of the Transformation rule (cf.
Lemma 14.12, Lemma 14.11, and Corollary 14.4), by applying Corollary 12.13 twice we can
conclude that the Lemma Rewrite rule is a sub-rule of the Transformation rule, too.
More interesting is to find out, why it is safe. If it were not, this would have to be due to the only
newly introduced formula that does not contain Γλ′′∆ as a sub-formula. More precisely, there
would have to be some counterexample (ΛmΓλ′′[ p← r ]∆,τ,A ) such that (Γλ′′∆)τ is true w.r.t.
A ιA . This means that λ′′τ is true w.r.t. A ιA but λ′′[ p← r ]τ is not.
Claim 1: λmτ is false w.r.t. A ιA .
Proof of Claim 1: Otherwise we have A ιA (lτ)=A ιA (rτ) and then due to λ′′∈L I T (sig,V) we
get by Lemma 6.2 that λ′′τ is true w.r.t. A ιA iff λ′′[ p← r ]τ is true w.r.t. A ιA . This contradicts
the situation described above. Q.e.d. (Claim 1)
By Claim 1 we now know that (λmΛmΓ∆)τ is false w.r.t. A ιA . Since we also have the
condition that (Def xµ) is contained in ΛmΓ∆ for all x ∈ GENDOM(µ), we conclude that
((Def xµ),τ,A ) is a counterexample. Let pi be given according to Lemma 13.14. Since the
literals of Πµ are contained in λmΛmΓ∆, it follows that Πµτ is false w.r.t. A ιA . Since(
GENDOM(µ)∩V <(Π)= /0
∨ the induction ordering is semantic
)
, Lemma 13.14(4) implies that Πpi is false w.r.t. A ιA ,
too. By Lemma 13.14(1) this means that Π is not valid. Q.e.d. (Lemma 14.16)
227
Proof of Theorem 14.19
If L̂ |= Γ, then |= L̂,Γ. Thus, considering all variables of Γ to be from Vδ+, by Theorem B.6
there is a proof tree (without Cut rule and with the restricted version of the Instantiation-
rule only) for L̂,Γ in our sequent calculus of B such that all leaf nodes are labeled with
axioms. The axioms of this sequent calculus can be removed by Constant Rewrite on atoms
and subsequent =- and Def-Decompose with the restrictions given in the theorem. The only
possible rule applications on L̂,Γ are those that put L̂ to pieces. α-rules break L̂ into
∀x0,0 . . .∀x0,m0−1C0, . . . ,∀xn−1,0 . . .∀xn−1,mn−1Cn−1 where C0, . . . ,Cn−1 lists the elements of L.
Subsequent applications of γ+-rules remove the universal quantifiers and finally β- and Restricted
Instantiation-rule applications split the tree and set new literals free. The only relevant part of the
results of this process are the literals λ with V (λ)⊆Vδ+, since no other formulas influence appli-
cability of inference rules or the property of being an axiom. Regarding these literals the result
of a completed sequence of steps of the above kind can be achieved by a sequence of Lemma
Applies with the restrictions given in the theorem. Thus, the subsystem is deductively complete.
If each formula from L contains a positive equation literal and our subsystem contains the Lemma
Rewrite instead of the Lemma Apply then we may have to do some proof transformation steps
starting from a proof tree consisting solely of Lemma Applies of the restricted kind specified in
the theorem as inner nodes and B axioms as leaf nodes:
1. Reorder the tree such that each left child of a Lemma Apply adds an inequality literal.
2. Associate with each leaf a sequence of Constant Rewrite steps on atoms that transform the
formula at its label into a formula that can be removed by a =- or a Def-Decomposition
with the restrictions given in the theorem.
3. We will now do a transformation according to two proof transformation rules. For being
able to show their termination, we assume that they are always applied at the deepest appli-
cable position in the branch from the root to its leftmost leaf, or, if there is no application
possible at this branch, recursively to all subtrees (in any order) that result when one cuts
off this branch. Note that this is not leftmost innermost, but more like “innermost leftmost”.
The first transformation rule is to transform the tree in such a way that no Lemma
Apply introduces an inequality literal to its left child that is not needed for the Constant
Rewrite proof associated with its leftmost leaf. Note that also such literals are not needed
which have been introduced above or already occur in the original root formula. This
transformation can be described by associating with each Lemma Apply a new function
symbol which has the children as arguments. Suppose f to be a Lemma Apply that
introduces an inequality literal (l 6=r) to its left child that is not needed for the Constant
Rewrite proof of its leftmost leaf. If this left child is a leaf, then we rewrite according to
f (((l 6=r)∆),(y1), . . . ,(ym)) =⇒ (∆)
where the yi denote the other children of f which are all discarded here. Otherwise, if the
left child of f (introducing (l 6=r), λ1, . . . , λm) is another Lemma Apply g (introducing λ′0,
. . . , λ′n). Then we rewrite according to
228
f ( g( (λ′0(l 6=r)x0) , . . . , (λ′n(l 6=r)xn) ),
(λ1y1),
.
.
.
(λmym) )
=⇒ g( t0 , . . . , tn )
where
ti :=

(λ′ixi) if (l 6=r) is not needed in the Constant Rewrite
proofs of the leaves of (λ′i(l 6=r)xi)
f ( ((l 6=r)λ′ixi),
(λ1λ′iy1),
.
.
.
(λnλ′iym))
otherwise

.
The second transformation rule is to transform the tree in such a way that Lemma Applies
in each leftmost branch ending in a leaf are in the order of their first usage for rewriting
steps with their invented inequality literals in the Constant Rewrite proof associated with its
leaf axiom. Suppose f to be a Lemma Apply being parent of its left child being the Lemma
Apply g which should come before f . Then we rewrite according to the same rule as given
above.
Note that the termination of the whole transformation can be shown using a lexicographic
path ordering where the function symbol f is strictly bigger than g in the quasi-ordering
on function symbols. The whole quasi-ordering can be constructed a priori by saying a
function symbol to be bigger than another if in the original tree it occurs above the other:
Due to our strategy for applying our transformation rules, if we have finished our bottom-
up cleaning of the branch from the root to its leftmost leaf, then, in all subtrees that result
when one cuts off this branch, each node’s function symbol is still bigger than the function
symbols of its children.
Furthermore, note that we really can do the Lemma Apply g before f because f does not
add a negated Def-literal (on the presence of which the applicability of g could depend) to
its left child (but a negated equality literal only).
4. To each left child of a Lemma Apply add the list of the negated literals added to its other
children. This list will play the role of the Λm in the Lemma Rewrite rule.
5. Rearrange the tree such that Constant Rewrite steps and Context Remove (cf. § 14.3) steps
are inserted into each leftmost branch ending in a leaf in such a way that the inequality
literals introduced for each left child of a Lemma Apply are at once used for a Constant
Rewrite step and then removed by a Context Remove step. Note that here we also may have
to include some Constant Rewrite steps with inequality literals of the original root formula
Γ and also to include some Lemma Rewrite steps with m = 0 for nevertheless rewriting
with inequalities removed by the Context Remove steps (either for using the inequality
again or for undoing the steps for keeping the Constant Rewrite proofs of the non-leftmost
leaves possible). The latter is possible due to step 4.
6. Finally, we replace all Lemma Applies together with their following Constant Rewrite and
Context Remove steps with a Lemma Rewrite where Πµ equals λmΛm.
Q.e.d. (Theorem 14.19)
229
Proof of Lemma 15.3 The SIG-Variable Remove rule is a sub-rule of the Transformation rule
since Γ(x 6=t)∆ contains Γ∆. To show the SIG-Variable Remove rule to be safe, suppose
(Γ∆,τ,A ) to be a counterexample. Define pi∈ S UB (V,T (VSIGA )) via pi|V\{x}⊆ τ and xpi := tτ.
Since x 6∈V (t,Γ,∆) we know that (Γ∆)pi = (Γ∆)τ and tpi= tτ=xpi. Thus (Γ(x 6=t)∆,pi,A ) is
a counterexample, too. Q.e.d. (Lemma 15.3)
Proof of Lemma 15.4 To show that the C -Variable Remove rule is a sub-rule of the Transforma-
tion rule, assume that ((Γ(x 6=t)∆,ℵ),τ,A ) is a counterexample. Then for the sort s of x (due
to x∈VC ) we have A C ,s∋A ιA (xτ)=A ιA (tτ). Thus ((Γ(Def t)∆,ℵ),τ,A ) is a counterexample,
too.
To show that the C -Variable Remove rule is safe, assume that (Γ(Def t)∆,τ,A ) is a counter-
example. Then A ιA (tτ)∈A C ,s for s being the sort of x. By Global Requirement 13.2, A
is C :cons-term-generated. Thus there is some u ∈ G T (cons)s with A ιA (tτ)=A (u). De-
fine pi ∈ S UB (V,T (VSIGA )) via pi|V\{x} ⊆ τ and xpi := u. Since x 6∈V (t,Γ,∆) we know
that (Γ∆)pi = (Γ∆)τ and tpi= tτ. Moreover, A ιA (xpi)=A ιA (u)=A ιA (tτ)=A ιA (tpi). Thus,
(Γ(x 6=t)∆,pi,A ) is a counterexample, too. Q.e.d. (Lemma 15.4)
Proof of Lemma 15.5 The SIG-Variable Add rule is safe because (x 6=t)Γ contains Γ. To
show that the SIG-Variable Add rule is a sub-rule of the Transformation rule, assume that
((Γ,ℵ),(τ,A )) is a counterexample. Define pi ∈ S UB (V,T (VSIGA )) via pi|V\{x} ⊆ τ and
xpi := tτ. Since x 6∈V (t,Γ,ℵ) we know that Γpi=Γτ, xpi= tτ= tpi, and (by Global Require-
ment 13.3) ℵpi=ℵτ. Thus we get the counterexample (((x 6=t)Γ,ℵ),(pi,A )). ((Γ,ℵ),(τ,A )).
Q.e.d. (Lemma 15.5)
Proof of Lemma 15.6 The C -Variable Add rule is safe because (x 6=tτ[ pi ← vi | i≺n ])Γ
contains Γ. To show that the C -Variable Add rule is a sub-rule of the Transformation
rule, assume that ((Γ,ℵ),(τ,A )) is a counterexample. For all i ≺ n the condition of
the rule says that Γ contains (Def vi). Thus, A ιA (viτ)∈A C ,si for si being the sort of
vi. By Global Requirement 13.2, A is C :cons-term-generated. Thus there is some ui ∈
G T (cons)si with A ιA (viτ)=A (ui). We define pi ∈ S UB (V,T (VSIG
A )) via pi|V\{x} ⊆ τ
and xpi := tτ[ pi ← ui | i≺n ]. Since x 6∈V (t[ pi ← vi | i≺n ],Γ,ℵ) we know that Γpi=
Γτ, A ιA (xpi)=A ιA (tτ[ pi ← ui | i≺n ])=A ιA (tτ[ pi ← viτ | i≺n ])=A ιA (t[ pi ← vi | i≺n ]τ)=
A ιA (t[ pi ← vi | i≺n ]pi), and (by Global Requirement 13.3) ℵpi=ℵτ. Thus we get the counter-
example (((x 6=tτ[ pi ← vi | i≺n ])Γ,ℵ),(pi,A )) . ((Γ,ℵ),(τ,A )). Q.e.d. (Lemma 15.6)
Proof of Lemma 16.2 The Substitution Add rule is safe, since if (Γσi,τ,A ) is a counterexample
then (Γ,σiτ,A ) is a counterexample, too. To show it to be a sub-rule of the Transformation
rule assume that ((Γ,ℵ),(τ,A )) is a counterexample. Then there are some i  n and some
ϕ with (ϕ,A )∈ Info; ℵτ&A ℵ(σiϕ); (τA ιA )|V (Γ) =(σiϕA ιA )|V (Γ); and either τ|V <(Γ) =
(σiϕ)|V <(Γ) or the induction ordering is semantic. By Lemma 13.11 we infer that (Γσi,ϕ,A )
is a counterexample. By Global Requirement 13.5 we get ℵτ&A ℵ(σiϕ)≈A (ℵσi)ϕ. Thus, we
get a counterexample ((Γσi,ℵσi),(ϕ,A )). ((Γ,ℵ),(τ,A )). Q.e.d. (Lemma 16.2)
Proof of Lemma 16.8
Since Γ is contained in all newly introduced formulas, the Hypothesis Apply rule is safe. To
show it to be sub-rule of the Transformation rule assume ((Γ,ℵ),(τ,A )) to be a counterexample.
We make a complete case analysis as follows.
230
There is some i≺ n with λiτ being true w.r.t. A ιA :
Taking the smallest such i, we know that (λi λi−1 . . .λ0)τ is false w.r.t. A ιA . Then by the condition
that all literals of Λi are contained in λi−1 . . .λ0, we conclude that ((λi ΛiΓ,ℵ),(τ,A )) is a
counterexample.
∀i≺n. (λiτ is false w.r.t. A ιA ):
In this case, (λn−1 . . .λ0Γ,τ,A ) is a counterexample. From the condition that all literals (Def xµ)
with x ∈ Y are contained in λn−1 . . .λ0Γ, we get ∀x ∈ Y. ((Def xµ),τ,A ) is a counterexample.
Define Z := V (λn−1 . . .λ0Γ,ℵ). The condition of the rule says that (Π′,k′,Y,Θ) results from
application of µ to (Π,k) w.r.t. Z. By Lemma 13.14(5) (matching its Y′ to our Y) there is some
τ′ such that (τ′,A )∈ Info, τ′|Z =τ|Z, and (Θ,τ′,A ) is a counterexample. Thus, we have the
counterexample ((λn−1 . . .λ0ΘΓ,ℵ),(τ′,A )). ((Γ,ℵ),(τ,A )).
There is some i with n i≺ m and λiτ′ being true w.r.t. A ιA :
Taking the smallest such i, we know that (λi λi−1 . . .λ0ΘΓ,τ′,A ) is a counterexample. Then
by the condition that all literals of Λi are contained in λi−1 . . .λ0Θ, we conclude that
((λi ΛiΓ,ℵ),(τ′,A )). ((Γ,ℵ),(τ,A )) is a counterexample.
∀i≺m. (λiτ′ is false w.r.t. A ιA ):
In this case, (λm−1 . . .λ0ΘΓ,τ′,A ) is a counterexample. If we now do not have k′τ′<A ℵτ′,
then we conclude with the counterexample ((k′<ℵ)ΛmΓ,ℵ),(τ′,A )) . ((Γ,ℵ),(τ,A )) be-
cause all literals of Λm are contained in λm−1 . . .λ0Θ. Otherwise, since the condition
of the rule says that λm−1 . . .λ0ΘΓ contains Π′, we know that we have a counterexample
((Π′,k′),(τ′,A )) < ((Γ,ℵ),(τ′,A )) . ((Γ,ℵ),(τ,A )). Thus, it is now sufficient to find a
counterexample ((Π,k),(ρ,A )) . ((Π′,k′),(τ′,A )) because then we have a counterexample
for a hypothesis which is strictly smaller than our original counterexample for the goal. That
counterexample is given by an application of Lemma 13.14(6) (matching its τ to our τ′ and its Y′
to V) because from the condition that all literals (Def xµ) with x ∈ GENDOM(µ) are contained
in λm−1 . . .λ0Γ, we get ∀x∈GENDOM(µ). ((Def xµ),τ′,A ) is a counterexample.
231
Q.e.d. (Lemma 16.8)
Proof of Lemma 16.12
The proof is like that of Lemma 14.16 but uses Lemma 16.8 instead of Lemma 14.12, Hypothesis
Apply instead of Lemma Apply, and Hypothesis Rewrite instead of Lemma Rewrite. Moreover,
the last paragraph of the proof of Lemma 14.16 must be replaced with:
By Claim 1 we now know that (λmΛmΓ∆)τ is false w.r.t. A ιA . Since we also have the condition
that (Def xµ) is contained in ΛmΓ∆ for all x ∈ GENDOM(µ), we conclude that ((Def xµ),τ,A )
is a counterexample. (Π′,τ,A ) and (Θ,τ,A ) are counterexamples because Π′Θ is contained in
λmΛmΓ∆ by the condition of the Hypothesis Rewrite rule. Thus, by Lemma 13.14(6) there is some
counterexample (Π,ρ,A ). This means that Π is an invalid hypothesis. Q.e.d. (Lemma 16.12)
Proof of Lemma 16.13
Define Y:=V (Γ(t 6=t ′)∆,ℵ). For showing the 6=-Solve rule to be a sub-rule of the Transformation
rule assume that ((Γ(t 6=t ′)∆,ℵ),(τ,A )) is a counterexample. Then A ιA (tτ)=A ιA (t ′τ).
If the D- or E-case holds, let X and I be defined as usual in these cases, cf. Definition 10.1, and
X′ := X. Otherwise the lemma says that t,t ′∈T (cons,VC ), and we define X and I as in the
E-case and X′ := VSIGA .
Now Lemma 13.18 says that −→R,X is confluent and tτ
∗
←→R,Xt
′τ. Thus by Lemma 13.17 we
have some pi and some (Λ,σ)∈NARROW(t,t ′,Y) such that the items of Lemma 13.17 hold.
Item 5 of Lemma 13.17 says that Λσpi is false w.r.t. Iι. In case of the D- or E-case we then
immediately know that Λσpi is false w.r.t. A ιA . Otherwise, since R is a Def-MCRS and −→R, /0 is
confluent (cf. Global Requirement 13.1) and K is a sub-class of the class of constructor-minimal
models, by Corollary 7.17 I is initial in K. Thus, we get some h::I→A and then by Lemma 5.7
I h=A . By item 4 of Lemma 13.17, Λ contains only negative literals, which also must be from
L I T (sig,V) because of (Λ,σ)∈NARROW(t,t ′,Y). In case of a literal (u 6=v) in Λ (where s′ is
the sort of u) we get A (uσpi)=hs′(I (uσpi))=hs′(I (vσpi))=A (vσpi). In case of a literal (Def u)
in Λ we get A (uσpi)=hs′(I (uσpi))∈hs′[I C ,s′]⊆A C ,s′. Thus, in any case Λσpi is false w.r.t. A ιA .
By item 2 of Lemma 13.17 and the condition of the 6=-Solve rule we get (σpi)|V <(Γ(t 6=t ′)∆)∪V (ℵ) =
τ|V <(Γ(t 6=t ′)∆)∪V (ℵ) or the induction ordering is semantic. From item 3 of Lemma 13.17 we
get (σpiA ιA )|V (t,t ′) =(τA ιA )|V (t,t ′); in the D- or E-case directly, otherwise after application
of the above h. Together with item 2 of Lemma 13.17 we have (σpiA ιA )|V (Γ(t 6=t ′)∆)∪V (ℵ) =
(τA ιA )|V (Γ(t 6=t ′)∆)∪V (ℵ). Thus, since (Γ(t 6=t ′)∆,τ,A ) is a counterexample, by Lemma 13.11
((Γ(t 6=t ′)∆)σ,pi,A ) is a counterexample, too. Moreover, by Global Requirement 13.3, Global
Requirement 13.5, and Definition 13.7 we get (ℵσ)pi≈A ℵτ.
All in all we get the new counterexample ((ΛΓ(t 6=t ′)∆,ℵ)σ,(pi,A )) . ((Γ(t 6=t ′)∆,ℵ),(τ,A )),
which completes the proof that the 6=-Solve rule is a sub-rule of the Transformation rule.
232
Finally, the 6=-Solve rule is safe because if a new goal has a counterexample ((ΛΓ(t 6=t ′)∆)σ,τ,A )
then (Γ(t 6=t ′)∆,στ,A ) is a counterexample, too. Q.e.d. (Lemma 16.13)
Proof of Lemma 16.14 The result of an application of a Def-Solve rule can be achieved in the
following way: First a C -Variable Add to introduce the literal (x 6=t), then a 6=-Solve of this literal,
and finally a C -Variable Remove or (in case of σ being the unifier of x and t) a Subsumptive
Literal Remove with the =-axiom (x=t)σ. Since (under the assumptions of the lemma) all these
inference steps are safe applications of the Transformation rule (cf. 15.6, 16.13, 15.4, 14.7) by
Corollary 12.13 this also holds for the Def-Solve rule. Q.e.d. (Lemma 16.14)
Proof of Lemma B.3 By induction on A, using Lemma 5.8, similar to the proof of Lemma 6.2.
The only non-trivial step is that for the quantifiers: We consider the induction steps for ∀xB and
∃xB by denoting one them with QxB. Assume (ς,s) ∈ {SIG,C }×S, x ∈ Vbound,ς, s\V (A),
y ∈ Vfree,ς, s, and B = A{y7→x}. We may w.l.o.g. assume y 6∈V (σ[V (B)]). Define σ′ ∈
G EN S UB (Vfree,T (Vfree)) by yσ′=y and σ′|Vfree\{y}=σ|Vfree\{y}. Note that (QxB)σ=Qx(Bσ)
and Bσ=Bσ′=A{y7→x}σ′=Aσ′{y7→x}. Let a ∈ A ς,s be (meta-) Q-quantified. Define κ′ ∈
S UB (V free(Bσ)⊎{y},A ) by yκ′=a, κ′|V free(Bσ) ⊆ κ; and κ
′′ ∈ S UB (V free(B)⊎{y},A ) by
yκ′′=a, κ′′|V free(B) ⊆ (σAκ). Note that κ
′′=(σ′Aκ′)|V free(B)⊎{y}. Now the following are logi-
cally equivalent by our induction hypothesis: Qx(Bσ) is true w.r.t. Aκ; Aσ′ is true w.r.t. Aκ′ ; A
is true w.r.t. Aσ′Aκ′ ; A is true w.r.t. Aκ′′; QxB is true w.r.t. AσAκ . Q.e.d. (Lemma B.3)
Proof of Lemma B.5
Assume DHS to be a dual Hintikka set. We then define RDHS := { (l,r) |
(l=r)∈DHS ∧ V (l,r)⊆Vδ+ }. Let
∗
←→RDHS be the congruence closure of RDHS on T (sig,Vδ+)
and on atoms with top level terms from T (sig,Vδ+). Furthermore we define the sig/cons-structure
B in the following way: B SIG,s := T (sig,Vδ+)s;
B C ,s :=

u[ pi ← vi | i≺n ]∈T (sig,Vδ+)s
∣∣∣∣∣∣∣∣∣∣

n∈N
∧ p0, . . . , pn−1 ∈ POS (u)
∧ v0, . . . ,vn−1 ∈ T (sig,Vδ+)
∧ u∈T (cons,Vδ+,C )
∧ ∀i≺n. (Def vi)∈DHS


;
PB := { (t0, . . . ,tm−1) | (Pt0 . . . tm−1)∈DHS ∧ ∀i≺m. ti∈T (sig,Vδ+) };
f B (t0, . . . ,tm−1) := f t0 . . . tm−1.
Note that the definition of B C ,s must be so complicated to make the constructor sub-universes
of B closed under constructor function applications. Moreover, we define A := B / ∗←→RDHS .
Finally we define ι ∈ S UB (Vδ+,A ) by (x∈Vδ+) x 7→
∗
←→RDHS [{x}].
233
Claim 1: For all A ∈ A T with A∈DHS we have
∀ε∈S UB (Vγ+,A ). (A is true w.r.t. A ι∪ε).
Proof of Claim 1: For each ε ∈ S UB (V γ+(A),A ) there is some ε ∈ S UB (V γ+(A),B ) with ε=
εA ι since V γ+(A) is finite. Now assume A ∈ A T with A∈DHS. By the Instantiation-Closure
property we know that A(id|Vδ+∪ε)∈DHS. Directly from the definition of A ι we conclude that
A(id|Vδ+∪ε) is true w.r.t. A ι. By Lemma B.3, A is true w.r.t. A (id|Vδ+∪ε)A ι , which finishes the proof
due to (id|Vδ+∪ε)A ι = ι∪ε. Q.e.d. (Claim 1)
Claim 2: For all A ∈ A T with A∈DHS we have
∀ε∈S UB (Vγ+,A ). (A is false w.r.t. A ι∪ε).
Proof of Claim 2: For each ε ∈ S UB (V γ+(A),A ) there is some ε ∈ S UB (V γ+(A),B ) with ε=
εA ι since V γ+(A) is finite. Now assume A ∈ A T with A∈DHS. By the Instantiation-
Closure property we know that A(id|Vδ+∪ε)∈DHS. Now suppose that A would be true
w.r.t. A ι∪ε. Due to ι∪ε=(id|Vδ+∪ε)A ι, by Lemma B.3 we know that A(id|Vδ+∪ε) is true
w.r.t. A ι. First assume that the predicate symbol of A is different from ‘=’ and ‘Def’. Now,
when A(id|Vδ+∪ε) is true w.r.t. A ι, then there is some B ∈ A T with A(id|Vδ+∪ε)
∗
←→RDHS B,
B∈DHS, and V γ+(B)= /0. By A(id|Vδ+∪ε)∈DHS and the Leibniz-Substitutability we
get B∈DHS. This, however, contradicts the Predicate-Consistency. Second, assume that
A is is of the form (Def t). Now, when A(id|Vδ+∪ε) is true w.r.t. A ι, then there are
some n∈N; u∈T (cons,Vδ+,C ); p0, . . . , pn−1∈POS (u); v0, . . . ,vn−1∈T (sig,Vδ+); with ∀i≺n.
(Def vi)∈DHS and t(id|Vδ+∪ε)
∗
←→RDHS u[ pi ← vi | i≺n ]. By (Def t)(id|Vδ+∪ε)∈DHS and the
Leibniz-Substitutability we get (Def u[ pi ← vi | i≺n ])∈DHS. This, however, contradicts the
Def-Consistency. Finally assume that A = (s=t). Now, when A(id|Vδ+∪ε) is true w.r.t. A ι, then
s(id|Vδ+∪ε)
∗
←→RDHS t(id|Vδ+∪ε). By the Leibniz-Substitutability from (s=t)(id|Vδ+∪ε)∈DHS we
get (t(id|Vδ+∪ε)=t(id|Vδ+∪ε))∈DHS, which contradicts the Reflexive-Consistency.
Q.e.d. (Claim 2)
Now that we have shown that for each literal A ∈ DHS we have ∀ε∈S UB (Vγ+,A ).
(A is false w.r.t. A ι∪ε), we want to show this for an arbitrary formula A. If a formula is not a
literal, then it is of one of the forms of α, β, γ+, or δ+. The induction step for the case α is trivial.
Consider a β-formula, say (A∧B) ∈ DHS (other cases analogously), assume ε ∈ S UB (Vγ+,A ),
and define Y := V γ+(A)∩V γ+(B). In case of Y= /0, by the β-Closure property we know that
A∈DHS or B∈DHS, thus, by induction hypothesis, A or B is false w.r.t. A ι∪ε, thus (A∧B)
is false w.r.t. A ι∪ε. Otherwise, in case of Y 6= /0, the Instantiation-Closure property says that
(A∧B)(id|Vfree\Y∪ε)∈DHS for any ε ∈ S UB (Y,B ) with εA ι ⊆ ε (which exists since Y is
finite). Since V γ+(A(id|Vfree\Y∪ε))∩V γ+(B(id|Vfree\Y∪ε)) = /0, according to the first case shown
above we know that (A∧B)(id|Vfree\Y∪ε) is false w.r.t. A ι∪ε. By Lemma B.3 we know that (A∧B)
is false w.r.t. A (id|Vfree\Y∪ε)A ι∪ε , which finishes the proof of the β-case due to (id|Vfree\Y∪ε)A ι∪ε =
ι∪ε.
For γ+ we proceed as follows: Assume (ς,s)∈{SIG,C }×S, x∈Vbound,ς, s\V (A), y∈Vfree,ς, s, B=
A{y7→x}, ∃xB∈DHS (∀xB ∈DHS). Let Y:= V free(B). Assume ι′ ∈ S UB (Y⊎{y},A ) with ι′|Y ⊆
ι∪ε. It now suffices to show that A (A) is false w.r.t. A ι′ . By the γ+-Closure property we have
B{x 7→zγ+}∈DHS (B{x 7→zγ+}∈DHS) for some zγ+ ∈ Vγ+,ς, s\V (B). Let σ ∈ S UB (Vfree,Vfree) be
234
given by yσ=zγ+ and σ|Vfree\{y}⊆id. Due to x 6∈V (A) we have B{x 7→z
γ+}=A{y7→x}{x 7→zγ+}=
A{y7→zγ+}=Aσ. By induction hypothesis, Aσ (Aσ) is false w.r.t. A ι∪ε′ for the ε′ ∈ S UB (Vγ+,A )
given by zγ+ε′=yι′ and ε′|Vγ+\{zγ+}⊆ε. By Lemma B.3 we know that A (A) is false w.r.t. AσA ι∪ε′ ,
which finishes the γ+-case due to ι′⊆σA ι∪ε′. The latter is really the case: Since zγ
+
6∈V (B)
we have zγ+ 6∈Y, since B=A{y7→x} we have y 6∈Y; and thus we get ι′|Y =(ι∪ε)|Y =
(ι∪ε′)|Y⊆σ(ι∪ε′)=σA ι∪ε′. Moreover, yι′=zγ
+
ε′=zγ
+
A ι∪ε′ =yσA ι∪ε′.
Finally, we prove the δ+-case: Assume (ς,s)∈{SIG,C }×S, x∈Vbound,ς, s\V (A), y∈Vfree,ς, s,
B=A{y7→x}, ∃xB ∈DHS. (∀xB∈DHS).
First, we treat the case of V γ+(B)= /0. Then, by the δ+-Closure property, there is some
t ∈ T (Vfree)ς,s such that B{x 7→t}∈DHS (B{x 7→t}∈DHS). Thus, for Y := V free(B), we can de-
fine ι′ ∈ S UB (Y⊎{y},A ) by yι′= tA ι∪ε∈A ς,s and ι′|Y⊆ι∪ε. Let σ ∈ S UB (Vfree,T (Vfree)) be
given by yσ = t and σ|Vfree\{y}⊆id. Due to x 6∈V (A) we have B{x 7→t}=A{y7→x}{x 7→t}=
A{y7→t}=Aσ. By induction hypothesis, Aσ (Aσ) is false w.r.t. A ι∪ε. By Lemma B.3, A (A) is
false w.r.t. AσA ι∪ε , which finishes the proof due to ι′⊆σA ι∪ε.
Second, in case of Y 6= /0 for Y := V γ+(B), the Instantiation-Closure property says that
∃xB(id|Vfree\Y∪ε)∈DHS (∀xB(id|Vfree\Y∪ε)∈DHS) for any ε∈ S UB (Y,B ) with εA ι⊆ ε (which
exists since Y is finite). Since V γ+(B(id|Vfree\Y∪ε)) = /0, according to the first case shown above
we know that ∃xB(id|Vfree\Y∪ε) (∀xB(id|Vfree\Y∪ε)) is false w.r.t. A ι∪ε. By Lemma B.3 we know
that ∃xB (∀xB) is false w.r.t. A (id|Vfree\Y∪ε)A ι∪ε , which finishes the proof of the δ
+
-case due to
(id|Vfree\Y∪ε)A ι∪ε = ι∪ε. Q.e.d. (Lemma B.5)
Proof of Theorem B.6
The soundness direction of the logical equivalence follows from Corollary B.2. The completeness
without the Cut-rule and the non-restricted Instantiation-rule can be shown as follows:
For each sequent Γ there exists some fair proof tree. If it is closed, then Γ is provable. Otherwise
there is some non-closed fair branch that starts from the root and does not end before a leaf is
reached. Let DHS be the set of all formulas of all variants of all sequents of this branch. Now
DHS is a dual Hintikka set (cf. Definition B.4):
The α-, β-, γ+- and δ+-Closure properties are trivial since the branch is fair. For the Instantiation-
Closure one has to notice that, for t ∈ T (sig,Vδ+), (Def t) ∈ DHS implies that (Def t) appears
in some sequent of the branch and thus in all sequents below. Since the principal formula C of
the Restricted Instantiation-rule can never be removed, fairness implies the Instantiation-Closure
property, too. Since we consider all variants of formulas and since atoms as well as formulas of
the form (l=r) are never removed from a sequent, DHS also satisfies the Leibniz-Substitutability.
Finally, since the branch is not closed and literals are never removed from sequents, DHS is
Reflexive-, Def-, and Predicate-Consistent.
By Lemma B.5, Γ is not deductively valid. Thus, all deductively valid sequents are provable in
our sequent calculus. Q.e.d. (Theorem B.6)
235
References
Jürgen Avenhaus, Klaus Becker (1992). Conditional Rewriting modulo a Built-in Algebra. SEKI-
Report SR–92–11 (SFB), FB Informatik, Univ. Kaiserslautern.
Jürgen Avenhaus, Klaus Becker (1994). Operational Specifications with Built-Ins.
11th STACS 1994, LNCS 775, pp. 263–274, Springer.
Jürgen Avenhaus, Carlos A. Loría-Sáenz (1994). On Conditional Rewrite Systems with Extra-
Variables and Deterministic Logic Programs. 5th LPAR 1994, LNAI 822, pp. 215–229, Sprin-
ger.
Jürgen Avenhaus, Klaus Madlener (1990). Term Rewriting and Equational Reasoning. In: R. B.
Banerji (ed.). Formal Techniques in Artificial Intelligence. pp. 1-43, Elsevier.
Jürgen Avenhaus, Klaus Madlener (1995). Theorem Proving in Hierarchical Clausal Specifica-
tions. SEKI-Report SR–95–14 (SFB), FB Informatik, Univ. Kaiserslautern.
Matthias Baaz, Christian G. Fermüller (1995). Non-elementary Speedups between Different Ver-
sions of Tableaus. 4th TABLEAUX 1995, LNAI 918, pp. 217–230, Springer.
Matthias Baaz, Alexander Leitsch (1995). Methods of Functional Extension. Collegium Logicum,
Annals of the Kurt Gödel Society, Vol. 1, pp. 87-122, Springer.
Leo Bachmair (1988). Proof By Consistency in Equational Theories. 3rd IEEE Symposium on
Logic In Computer Sci., pp. 228–233, IEEE Press.
Leo Bachmair, Nachum Dershowitz (1986). Commutation, Transformation, and Termination.
8th CADE 1986, LNCS 230, pp. 5–20, Springer.
Leo Bachmair, Harald Ganzinger (1991). Perfect Model Semantics for Logic Programs with
Equality. In Furukawa (1991), pp. 645–659.
Leo Bachmair, Harald Ganzinger (1994). Rewrite-based Equational Theorem Proving with Se-
lection and Simplification. J. Logic Computat. 4, pp. 217–247, Oxford Univ. Press.
Klaus Becker (1993a). Semantics for Positive/Negative-Conditional Rewrite Systems.
3rd CTRS 1992, LNCS 656, pp. 213–225, Springer.
Klaus Becker (1993b). Proving Ground Confluence and Inductive Validity in Constructor Based
Equational Specifications. TAPSOFT 1993, LNCS 668, pp. 46–60, Springer.
Klaus Becker (1994). Rewrite Operationalization of Clausal Specifications with Predefined Struc-
tures. Dissertation (Ph.D. thesis), FB Informatik, Univ. Kaiserslautern.
Klaus Becker (1996). How to Prove Ground Confluence. SEKI-Report SR–96–02, FB Informatik,
Univ. Kaiserslautern.
236
Rudolf Berghammer (1993). On the Characterization of the Integers: The Hidden Function Prob-
lem Revisited. Acta Cybernetica 11 (1-2), pp. 85–96, Szeged.
Jan A. Bergstra, Jan Willem Klop (1986). Conditional Rewrite Rules: Confluence and Termina-
tion. J. Computer and System Sci. 32, pp. 323–362, Academic Press (Elsevier).
Eddy Bevers, Johan Lewi (1990). Proof by Consistency in Conditional Equational Theories. Re-
port CW 102, Revised July 1990. Department of Computer Sci., K. U. Leuven. Short version
in: 2nd CTRS 1990, LNCS 516, pp. 194–205, Springer.
Wolfgang Bibel, E. Eder (1993). Methods and Calculi for Deduction. In: Gabbay &al. (1993 ff.),
Vol. 1, pp. 67-182.
Susanne Biundo, Birgit Hummel, Dieter Hutter, Christoph Walther (1986). The Karlsruhe Induc-
tion Theorem Proving System. 8th CADE 1986, LNCS 230, pp. 672–674, Springer.
Adel Bouhoula, Michaël Rusinowitch (1995). Implicit Induction in Conditional Theories. J.
Automated Reasoning 14, pp. 189–235, Kluwer (Springer).
Adel Bouhoula, Emmanuël Kounalis, Michaël Rusinowitch (1992). Automated Mathematical In-
duction. Technical Report 1636, INRIA.
Robert S. Boyer, J S. Moore (1979). A Computational Logic. Academic Press (Elsevier).
Robert S. Boyer, J S. Moore (1988). A Computational Logic Handbook. Academic Press
(Elsevier).
Robert S. Boyer, J S. Moore (1989). The Addition of Bounded Quantification and Partial Func-
tions to A Computational Logic and Its Theorem Prover. In: Manfred Broy (ed.), Constructive
Methods in Computing Sci., NATO ASI Series, Vol. F 55, pp. 95-145, Springer.
François Bronsard, Uday S. Reddy (1991). Conditional Rewriting in Focus. 2nd CTRS 1990,
LNCS 516, pp. 2–13, Springer.
Anatoli Degtyarev, Andrei Voronkov (1995). Reduction of Second-Order Unification to Simulta-
neous Rigid E-Unification. UPMAIL Technical Report 109, Computing Sci. Dept., Uppsala
Univ..
Anatoli Degtyarev, Andrei Voronkov (1997). What you always wanted to know about Rigid E-
Unifikation. UPMAIL Technical Report 143, Computing Sci. Dept., Uppsala Univ..
Nachum Dershowitz (1987). Termination of Rewriting. J. Symbolic Computation 3, pp. 69–116,
Academic Press (Elsevier).
Nachum Dershowitz, Mitsuhiro Okada, G. Sivakumar (1988a). Confluence of Conditional
Rewrite Systems. 1st CTRS 1987, LNCS 308, pp. 31–44, Springer.
Nachum Dershowitz, Mitsuhiro Okada, G. Sivakumar (1988b). Canonical Conditional Rewrite
Systems. 9th CADE 1988, LNAI 310, pp. 538–549, Springer.
237
Hartmut Ehrig, Bernd Mahr (1985). Fundamentals of Algebraic Specification 1. Springer.
Herbert B. Enderton (1973). A Mathematical Introduction to Logic. Academic Press (Elsevier),
2nd printing.
Melvin C. Fitting (1990). First-Order Logic and Automated Theorem Proving. Springer. 2nd (ex-
tended) edition 1996.
Koichi Furukawa (ed.) (1991). Proc. 8th Int. Conf. on Logic Programming. MIT Press.
Ulrich Fraus (1993). A Calculus for Conditional Inductive Theorem Proving. 3rd CTRS 1992,
LNCS 656, pp. 357–362, Springer.
Ulrich Fraus (1994). Mechanizing Inductive Theorem Proving in Conditional Theories. Disserta-
tion (Ph.D. thesis), Univ. Passau.
Dov M. Gabbay, C. J. Hogger, J. A. Robinson (eds.) (1993 ff.). Handbook of Logic in Artificial
Intelligence and Logic Programming. Clarendon Press.
Harald Ganzinger (1988). A Completion Procedure for Conditional Equations. 1st CTRS 1987,
LNCS 308, pp. 62–83, Springer.
Harald Ganzinger, Jürgen Stuber (1992). Inductive Theorem Proving by Consistency for First-
Order Clauses. In: Informatik-Festschrift zum 60. Geburtstag von Günter Hotz. Teubner Ver-
lag, Stuttgart. Also in: 3rd CTRS 1992, LNCS 656, pp. 226–241, Springer, 1993.
Gerhard Gentzen (1935). Untersuchungen über das logische Schließen. Mathematische
Zeitschrift 39, pp. 176-210, 405–431.
Gerhard Gentzen (1938). Die gegenwärtige Lage in der mathematischen Grundlagenforschung
– Neue Fassung des Widerspruchsfreiheitsbeweises für die reine Zahlentheorie. Forschungen
zur Logik und zur Grundlegung der exakten Wissenschaften, Folge 4, Leipzig.
Gerhard Gentzen (1943). Beweisbarkeit und Unbeweisbarkeit von Anfangsfällen der transfiniten
Induktion in der reinen Zahlentheorie. Mathematische Annalen 119, pp. 140–161.
Alfons Geser (1994). An Improved General Path Order. MIP-9407, Univ. Passau. Also in: J. Ap-
plicable Algebra in Engineering, Communication and Computing (AAECC) 7 (6), pp. 469–
511, Springer, 1996.
Kurt Gödel (1931). Über formal unentscheidbare Sätze der Principia Mathematica und ver-
wandter Systeme I. Monatshefte für Mathematik und Physik 38, pp. 173–198.
Martin Gogolla (1983). Algebraic Specifications with Partially Ordered Sorts and Declarations.
Report 169/1983, FB Informatik, Univ. Dortmund.
238
Bernhard Gramlich (1989). Inductive Theorem Proving Using Refined Unfailing Completion
Techniques. SEKI-Report SR–89–14 (SFB), FB Informatik, Univ. Kaiserslautern. Short ver-
sion in: 9th European Conf. on Artificial Intelligence (ECAI 1990), pp. 314–319, Pitman Publ..
Bernhard Gramlich (1994). On Modularity of Termination and Confluence Properties of Condi-
tional Rewrite Systems. 4th Algebraic and Logic Programming 1994, LNCS 850, pp. 186–203,
Springer.
Bernhard Gramlich (1995). On Termination and Confluence of Conditional Rewrite Systems.
4th CTRS 1994, LNCS 968, pp. 166–185, Springer.
Bernhard Gramlich, Wolfgang Lindner (1991). A Guide to UNICOM, an Inductive Theorem
Prover Based on Rewriting and Completion Techniques. SEKI-Report SR–91–17 (SFB), FB
Informatik, Univ. Kaiserslautern.
Bernhard Gramlich, Claus-Peter Wirth (1996). Confluence of Terminating Conditional Term
Rewriting Systems Revisited. 7th RTA 1996, LNCS 1103, pp. 245–259, Springer.
Claus Hintermeier (1995). How to Transform Canonical Decreasing CTRSs into Equivalent
Canonical TRSs. 4th CTRS 1994, LNCS 968, pp. 186–205, Springer.
Gérard Huet (1980). Confluent Reductions: Abstract Properties and Applications to Term Rewrit-
ing Systems. J. ACM 27 (4), pp. 797–821, ACM Press.
Dieter Hutter, Claus Sengler (1996). INKA: The Next Generation. 13th CADE 1996, LNAI 1104,
pp. 288–292, Springer.
Jean-Pierre Jouannaud, Bernard Waldmann (1986). Reductive Conditional Term Rewriting Sys-
tems. In: Proceedings of the 3rd Working Conference on Formal Description of Programming
Concepts, pp. 223-244, Elsevier.
Stig Kanger (1963). A simplified proof method for elementary logic. In: Siekmann & Wrightson
(1983), Vol. 1, pp. 364-371.
Stéphane Kaplan (1984). Conditional Rewrite Rules. Theoretical Computer Sci. 33, pp. 175–193,
Elsevier.
Stéphane Kaplan (1987). Simplifying Conditional Term Rewriting Systems: Unification, Termi-
nation and Confluence. J. Symbolic Computation 4, pp. 295–334, Academic Press (Elsevier).
Stéphane Kaplan (1988). Positive/Negative-Conditional Rewriting. 1st CTRS 1987, LNCS 308,
pp. 129–143, Springer.
Deepak Kapur, David R. Musser (1986). Inductive Reasoning with Incomplete Specifications. 1st
IEEE Symposium on Logic In Computer Sci., pp. 367–377, IEEE Press.
Deepak Kapur, David R. Musser (1987). Proof by Consistency. Artificial Intelligence 31, pp. 125–
157.
239
Deepak Kapur, Hantao Zhang (1989). An Overview of Rewrite Rule Laboratory (RRL).
3rd RTA 1989, LNCS 355, pp. 559–563, Springer.
Deepak Kapur, David R. Musser, Paliath Narendran (1988). Only Prime Superpositions Need be
Considered in the Knuth-Bendix Completion Procedure. J. Symbolic Computation 6, pp. 19–
36, Academic Press (Elsevier).
Deepak Kapur, Paliath Narendran, Friedrich Otto (1990). On Ground-Confluence of Term Rewrit-
ing Systems. Information and Computation 86, pp. 14–31, Academic Press (Elsevier).
Jan Willem Klop (1980). Combinatory Reduction Systems. Mathematical Centre Tracts 127,
Mathematisch Centrum, Amsterdam.
Jan Willem Klop (1992). Term Rewriting Systems. In: S. Abramsky, Dov M. Gabbay, T. S. E.
Maibaum (eds.). Handbook of Logic in Computer Sci., Vol. 2. Clarendon Press.
Emmanuël Kounalis, Michaël Rusinowitch (1988). On Word Problems in Horn Theories.
9th CADE 1988, LNAI 310, pp. 527–535, Springer.
Emmanuël Kounalis, Michaël Rusinowitch (1990). Mechanizing Inductive Reasoning. 8th AAAI
1990, pp. 240–245, MIT Press.
Hans-Jörg Kreowski (1987). Partial Algebras Flow from Algebraic Specifications. 14th Automata,
Languages and Programming 1987, LNCS 267, pp. 521–530, Springer.
Ulrich Kühler (1991). Ein funktionaler und struktureller Vergleich verschiedener Induktionsbe-
weiser. Diplomarbeit, FB Informatik, Univ. Kaiserslautern.
Ulrich Kühler, Claus-Peter Wirth (1996). Conditional Equational Specifications of Data Types
with Partial Operations for Inductive Theorem Proving. SEKI-Report SR–96–11, FB Infor-
matik, Univ. Kaiserslautern. Short version in: 8th RTA 1997, LNCS 1232, pp. 38–52, Springer.
Ulrich Kühler, Claus-Peter Wirth (1998). A User-Oriented Rewrite-Based Framework for Induc-
tive Theorem Proving. SEKI-Report SR–98–03, FB Informatik, Univ. Kaiserslautern.
Vladimir A. Lifschitz (1971). Specialization of the Form of Deduction in the Predicate Calculus
with Equality and Function Symbols. In: Orevkov (1971), pp. 1-24.
Vladimir A. Lifschitz (1989). What Is the Inverse Method?. J. Automated Reasoning 5, pp. 1–23,
Kluwer (Springer).
Rüdiger Lunde, Claus-Peter Wirth (1994). ASF+ – eine ASF-ähnliche Spezifikationssprache.
SEKI-Working-Paper SWP–94–05 (SFB), FB Informatik, Univ. Kaiserslautern.
240
David B. MacQueen, Donald T. Sannella (1985). Completeness of Proof Systems for Equational
Specifications. IEEE Transactions on Software Engineering 11 (5), pp. 454–461, IEEE Press.
Sergey Yu. Maslov (1971). The Inverse Method for Establishing Deducibility for Logic Calculi.
In: Orevkov (1971), pp. 25-96.
Aart Middeldorp (1993). Modular Properties of Conditional Term Rewriting Systems. Informa-
tion and Computation 104, pp. 110–158, Academic Press (Elsevier).
Aart Middeldorp, Erik Hamoen (1994). Completeness Results for Basic Narrowing. J. Applicable
Algebra in Engineering, Communication and Computing (AAECC) 5, pp. 213–253, Springer.
Cyrus F. Nourani (1994). Types, Induction, and Incompleteness. Bull. EATCS 53, pp. 226–247.
Vincent van Oostrom (1994a). Confluence for Abstract and Higher-Order Rewriting. Ph.D. thesis,
Vrije Univ. te Amsterdam.
Vincent van Oostrom (1994b). Developing Developments. ISRL–94–4, Information Sci. and Re-
search Laboratory, Nippon Telegraph and Telephone Corporation.
Vladimir P. Orevkov (1971). The Calculi of Symbolic Logic.I. American Mathematical Society,
Providence, Rhode Island.
Peter Padawitz (1992). Deduction and Declarative Programming. Cambridge Univ. Press.
David A. Plaisted (1985). Semantic Confluence Tests and Completion Methods. Information and
Control 65, pp. 182–215.
Dag Prawitz (1960). An Improved Proof Procedure. In: Siekmann & Wrightson (1983), Vol. 1,
pp. 159-199.
Dag Prawitz (1965). Natural Deduction. Almquist & Wiksells, Uppsala.
Martin Protzen (1994). Lazy Generation of Induction Hypotheses. 12th CADE 1994, LNAI 814,
pp. 42–56, Springer.
Martin Protzen (1995). Lazy Generation of Induction Hypotheses and Patching Faulty Conjec-
tures. Infix, Akademische Verlagsgesellschaft Aka GmbH, Sankt Augustin, Berlin.
Uday S. Reddy (1990). Term Rewriting Induction. 10th CADE 1990, LNAI 449, pp. 162–177,
Springer.
Horst Reichel (1987). Initial Computability, Algebraic Specifications, and Partial Algebras.
Clarendon Press.
241
Jörg Siekmann, Graham Wrightson (eds.) (1983). Automation of Reasoning. Springer.
Gerd Smolka, Werner Nutt, Joseph A. Goguen, José Meseguer (1989). Order-Sorted Equational
Computation. In: H. Ait-Kaci, M. Nivat (eds.). Resolution of Equations in Algebraic Struc-
tures. Vol. 2, pp. 297-367, Academic Press (Elsevier).
Raymond M. Smullyan (1968). First-Order Logic. Springer.
Christof Sprenger (1996). Über die Beweissteuerung des induktiven Theorembeweisers QUOD-
LIBET mit Taktiken. Diplomarbeit, FB Informatik, Univ. Kaiserslautern.
Taro Suzuki, Aart Middeldorp, Tetsuo Ida (1995). Level-Confluence of Conditional Rewrite Sys-
tems with Extra Variables in Right-Hand Sides. 6th RTA 1995, LNCS 914, pp. 179–193, Sprin-
ger.
Alfred Tarski (1935). Der Wahrheitsbegriff in den formalisierten Sprachen. Studia phil. 1, pp.
261-404, Leopoli.
Alfred Tarski (1986). What are logical notions?. History and Philosophy of Logic 7, pp. 143–154,
Taylor & Francis, London.
Yoshihito Toyama (1988). Commutativity of Term Rewriting Systems. In: K. Fuchi, L. Kott (eds.).
Programming of Future Generation Computers II. Elsevier. Also in: Toyama (1990).
Yoshihito Toyama (1990). Term Rewriting Systems and the Church-Rosser Property. Ph.D. thesis,
Tohoku Univ. / Nippon Telegraph and Telephone Corporation.
Uwe Waldmann (1992). Semantics of Order-Sorted Specifications. Theoretical Computer Sci. 94,
pp. 1–35, Elsevier.
Humphrey Robert “Pum” Walters, Hans Zantema (1995). Rewrite Systems for Integer Arithmetic.
6th RTA 1995, LNCS 914, pp. 324–338, Springer.
Christoph Walther (1988). Argument-Bounded Algorithms as a Basis for Automated Termination
Proofs. 9th CADE 1988, LNAI 310, pp. 601–622, Springer.
Christoph Walther (1992). Computing Induction Axioms. 3rd LPAR 1992, LNAI 624, pp. 381–392,
Springer.
Christoph Walther (1994). Mathematical Induction. In: Gabbay &al. (1993 ff.), Vol. 2, pp. 127-
228.
Hao Wang (1960). Toward Mechanical Mathematics. In: Siekmann & Wrightson (1983), Vol. 1,
pp. 244-264.
Claus-Peter Wirth (1991). Inductive Theorem Proving in Theories Specified by Positive/Nega-
tive-Conditional Equations. Diplomarbeit, FB Informatik, Univ. Kaiserslautern. Abstract in:
1st Workshop on Construction of Computational Logics, Val d’Ajol (France), 1992, Rapport
Interne CRIN 93–R–023, p. 38, Villers-les-Nancy, 1993.
242
Claus-Peter Wirth (1995). Syntactic Confluence Criteria for Positive/Negative-Conditional Term
Rewriting Systems. SEKI-Report SR–95–09 (SFB), FB Informatik, Univ. Kaiserslautern.
Claus-Peter Wirth (2004). Descente Infinie + Deduction. Logic J. of the IGPL 12, pp. 1–96, Ox-
ford Univ. Press.
Claus-Peter Wirth, Klaus Becker (1995). Abstract Notions and Inference Systems for Proofs by
Mathematical Induction. 4th CTRS 1994, LNCS 968, pp. 353–373, Springer.
Claus-Peter Wirth, Bernhard Gramlich (1992). A Constructor-Based Approach for Positive/Nega-
tive-Conditional Equational Specifications. SEKI-Report SR–92–10 (SFB), FB Informatik,
Univ. Kaiserslautern. Revised and shortened version is Wirth & Gramlich (1993).
Claus-Peter Wirth, Bernhard Gramlich (1993). A Constructor-Based Approach for Positive/Nega-
tive-Conditional Equational Specifications. 3rd CTRS 1992, LNCS 656, pp. 198–212, Sprin-
ger. Revised and extended version is Wirth & Gramlich (1994a).
Claus-Peter Wirth, Bernhard Gramlich (1994a). A Constructor-Based Approach for Positive/Ne-
gative-Conditional Equational Specifications. J. Symbolic Computation 17, pp. 51–90, Aca-
demic Press (Elsevier).
Claus-Peter Wirth, Bernhard Gramlich (1994b). On Notions of Inductive Validity for First-Order
Equational Clauses. 12th CADE 1994, LNAI 814, pp. 162–176, Springer.
Claus-Peter Wirth, Ulrich Kühler (1995). Inductive Theorem Proving in Theories Specified
by Positive/Negative-Conditional Equations. SEKI-Report SR–95–15 (SFB), FB Informatik,
Univ. Kaiserslautern.
Claus-Peter Wirth, Rüdiger Lunde (1994). Writing Positive/Negative-Conditional Equations Con-
veniently. SEKI-Working-Paper SWP–94–04 (SFB), FB Informatik, Univ. Kaiserslautern.
Claus-Peter Wirth, Bernhard Gramlich, Ulrich Kühler, Horst Prote (1993). Constructor-Based
Inductive Validity in Positive/Negative-Conditional Equational Specifications. SEKI-Report
SR–93–05 (SFB), FB Informatik, Univ. Kaiserslautern. Revised and extended version of first
part is Wirth & Gramlich (1994a), revised version of second part is Wirth & Gramlich (1994b).
Hantao Zhang (1988). Reduction, Superposition and Induction: Automated Reasoning in an
Equational Logic. Rensselaer Polytech. Inst., Dept. of Comp. Sci., Troy, NY, Ph.D. thesis.
Hantao Zhang (1993). Implementing Contextual Rewriting. 3rd CTRS 1992, LNCS 656, pp. 363–
377, Springer.
Hantao Zhang, Deepak Kapur (1988). First-Order Theorem Proving using Conditional Rewrite
Rules. 9th CADE 1988, LNAI 310, pp. 1–20, Springer.
Hantao Zhang, Deepak Kapur, Mukkai S. Krishnamoorthy (1988). A Mechanizable Induction
Principle for Equational Specifications. 9th CADE 1988, LNAI 310, pp. 162–181, Springer.
243
Index
The following list contains all notion and symbol names defined in this thesis, succeeded by the
pages and (if possible) the numbers of their definitions.
[ ] 23
[ ← | ] 24
| 23
‖ 25
↓ 26
 26
:: → 29
.C 30
.H 30
.A 37
−→
(l=r)
(special) 32, 5.10
(general) 127, 13.8
−→R,X,β,p 42, 7.2
−→q R,X,β,Π 43, 7.6
ց 110, 12.5
y 110, 12.5
ց/y 110, 12.5
ℵ, i, k 31
α 23
Aκ 29
A-case 73, 10.1
Acquisition Rule 112
Algebras 29
Analytic Approach 114
A T (,) 31
Atoms 31
Axioms for Subsumption 136, 14.5
B-case 73, 10.1
B′-case 73, 10.1
Backwards Approach 116
Bound Variables 185
C 23
C-case 73, 10.1
CGSUB(V,cons) 74, 10.2
Clashing of terms 25
Commutation 28, 5.2
Compatibility
with a Termination-Pair 51, 8.11
Don’t-Care-Compatibility 51, 8.14
Left-Right-Compatibility 51, 8.13
Complementary Critical Peak 59
Completeness
cf. “Deductive Completeness”
cf. “Refutational Completeness”
cf. “Sufficient Completeness”
CON DL I T () 31
Confluence 28, 5.2
Congruences 30
C 24
cons 23
Conservative Constructors 69, 9.13
Constant Rewriting 139
Constructor Ground Substitutions 74, 10.2
Constructor Rules 33, 5.11
Constructor Sub-Signature 23
Constructor Sub-Universe 29
Constructor Symbols 23
Constructor Variables 24
Constructor-Preservation 33
Contains 35, 5.14
Context Addition 149
Context Removal 136
Contextual Rewriting 133 ff.
Correctness of Proof State 114, 12.16
Weak Correctness 114, 12.17
Counterexample
(abstract) 108
(concrete) 77, 10.7
Covering Sets of Substitutions 155, 16.1
Critical Peak 58, 9.2
CRS 33, 5.11
244
N 23
D-case 73, 10.1
D′-case 73, 10.1
Decomposition 134 f.
cf. also “Generalizing Decomposition”
Decreasingness of a rule system 52
Deductive Completeness 147, 14.19
Def-MCRS 45, 7.15
Def-Moderate 45, 7.15
Deletion Rule 112
dom() 23
Don’t-Care-Compatibility 51, 8.14
Dual Hintikka Sets 189, B.4
E-case 73, 10.1
Epimorphisms 30
Equals 35, 5.14
Equivalences 27
Existential Variables 185
Expansion Rule 112
Explicit Induction
(concept) 94
(example) 162 f.
Extra Information
(abstract) 108
(concrete) 77, 10.7
Extra-Variable Freeness 33, 5.11
F 23
Failure Recognition
(abstract) 121
(concrete) 177
Failure State 122, 12.34
Form cf. “Formulas”
form() 108
Formula Rewriting 127, 13.8
Formulas
(abstract) 104
(concrete) 35, 5.13
FPOS () 24
Frame Inference System 112
cf. also “Switched Inference System”
Free Variables 185
Freeness 30
Fulfilledness 41, 7.1
G EN A T (,) 31
GENDOM() 129, 13.12
General Variables 24
Generalization 172
Generalized Substitutions
(definition) 25
(usage) 129 f.
Generalizing Decomposition 176
G EN L I T (,) 31
G EN S UB (,)
cf. “Generalized Substitutions”
Global Requirement 13.1 123
Global Requirement 13.2 123
Global Requirement 13.3 124
Global Requirement 13.4 124
Global Requirement 13.5 125
Groundedness 110, 12.5
G T 24
245
Hebrew letters 31
Hintikka Sets cf. “Dual Hintikka Sets”
Homomorphisms 29
Hypothesis Application 157
Hypothesis Rewriting 164
Hypothesizing Rule 112
Image of a relation or a function 23
Implicit Induction 94
Induction Ordering
(abstract) 108
(conceptual) 93
(concrete) 125, 13.6
cf. also “Semantic Induction Ordering”
Inductive Soundness 116, 12.23
Inductive Validity
cf. “Type-. . . Inductive Validity”
Inductiveness 116, 12.23
Info cf. “Extra Information”
Information, Extra cf. “Extra Information”
Initiality 30
Isomorphism 29
Joinability of a critical peak 59
Overlay Joinability 59
Quasi Overlay Joinability 63, 9.8
Strong Joinability 59
Weak Joinability 59
Joinability of two terms 26
ker() 30
Left-Linearity 33, 5.11
Left-Right-Compatibility 51, 8.13
Lemma Application 140 ff.
Lemma Rewriting 144
Linearity of a literal 31
Linearity of a rule 33, 5.11
Linearity of a term 25
L I T (,) 31
Literal Removal 136 ff.
Literal Rewriting
(special) 32, 5.10
(general) 127, 13.8
Literals 31
Memorizing Rule 112
Memorizing Switched Transformation Rule
118
Mgu() 25
Model 39, 6.4
Monotonicity 26
N+ 23
NARROW(, ,) 131, 13.15
Non-Switched Inference System
cf. “Frame Inference System”
Orderings 27
Overlay 59
Overlay Joinability 59
Parallel Reduction 43, 7.6
Parallelism of positions 25
Partially Specified Function 17
POS () 25
POS () 31
Proof State 104
Quasi Overlay Joinability 63, 9.8
Quasi-Ordering 27
RC 33, 5.11
ran() 23
Reducingness of a rule 52
Reduction Relation 42, 7.2
Reductiveness of a rule system 52
Refutational Completeness 183
Requirement, Global
cf. “Global Requirement”
Restriction of a relation or a function 23
Results From Application Of 129, 13.13
Rule System 33, 5.11
246
S 23
Safeness 121, 12.31
Semantic Induction Ordering 126, 13.7
SIG 24
sig 23
Signature 23
Simple Switched Transformation Rule 118
Simplifyingness of a rule 52
Solving Negative Literals 165 f.
Sort-Invariance 26
Soundness
of a failure predicate 121, 12.33
of an inference step 114, 12.14
Stability 26
Strong Joinability of a critical peak 59
Strong Joinability of two terms 26
S UB (,) 25
Substitution Addition 155
Subsumption 136, 14.5
Sufficient Completeness 26
SUPERPOSE(,) 131, 13.15
Switched Deletion Rule 118
Switched Hypothesizing Rule 118
Switched Inference System 118
SynCons cf. “Syntactic Constructs”
Syntactic Constructs
(abstract) 105
(concrete) 77, 10.7
T 24
Tautology Removal 134 f.
Term-Generatedness 30
Termination 26
Termination-Pair 50, 8.9
Terms 24
T ERM S () 32
Transformation Rule 113
Type-A Inductive Validity 74, 10.3
Type-B Inductive Validity 74, 10.3
Type-B′ Inductive Validity 77, 10.5
Type-C Inductive Validity 77, 10.5
Type-D Inductive Validity 77, 10.5
Type-D′ Inductive Validity 77, 10.5
Type-E Inductive Validity 77, 10.5
Unifier 25
Universal Variables 185
Universe 29
V () 24
V <() 128, 13.10
V 24
Vδ 185
Vγ 185
Vbound 185
VC 24
Vfree 185
VSIG 24
VSIGA 76
Validity
(abstract) 104
Inductive Validity
cf. “Type-. . . Inductive Validity”
of a formula 37, 6.1
of a proof state 121, 12.31
of a sequent 188, B.1
Valuations 29
Variable Addition 151
Variable Positions 25
Variable Removal 151
Variable-System 24
VPOS () 25
Weight Rewriting 127, 13.8
Weight(V) cf. “Weights”
Weights 31
(abstract usage) 104
(more concrete) 124
Weak Correctness of a proof state
114, 12.17
Weak Joinability 59
Weakly Complementary Critical Peak 59
Wellfoundedness 27
