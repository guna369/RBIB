Rodrigo CeÂ´sar de Castro Miranda
Um algoritmo para pesquisa aproximada de
padroËœes baseado no meÂ´todo de Landau e
Vishkin e uso de arranjos de sufixos para
reduzir o uso de espacÂ¸o
BrasÂ´Ä±lia
2006
Rodrigo CeÂ´sar de Castro Miranda
Um algoritmo para pesquisa aproximada de
padroËœes baseado no meÂ´todo de Landau e
Vishkin e uso de arranjos de sufixos para
reduzir o uso de espacÂ¸o
Descrevemos uma variante do algoritmo de
Landau e Vishkin que substitui o uso de
aÂ´rvores de sufixos nesse algoritmo por arran-
jos de sufixos, com o objeto de diminuir o
espacÂ¸o utilizado.
Orientador:
Mauricio Ayala-RincoÂ´n
Universidade de BrasÂ´Ä±lia
Mestrado em InformaÂ´tica
BrasÂ´Ä±lia
2006
Dedico esta dissertacÂ¸aËœo a meus pais,
pelo carinho e exemplo de honestidade e trabalho,
ao meu irmaËœo, pela amizade e apoio,
e a minha esposa, pelo amor, pelo apoio
e por compartilhar comigo os dias de sol e os dias de chuva.
Agradecimentos
Dedico meus sinceros agradecimentos para:
â€“ o professor doutor MaurÂ´Ä±cio Ayala-RincoÂ´n, pela orientacÂ¸aËœo, pela pacieË†ncia, pelo
exemplo, pelo incentivo, pelo trabalho, e pela amizade;
â€“ aos colegas Daniel Sobral, Leon SoÂ´lon, Marcus Yuri, Ricardo Lima, Rinaldi Neto,
Thomas Santâ€™Ana, e Wilton JoseÂ´, pelo apoio e inuÂ´meras discussoËœes e sobre computacÂ¸aËœo,
o universo e o nuÂ´mero 42;
â€“ aos colegas Rinaldi Maya Neto e Wilton JoseÂ´ Pereira dos Santos, pela contribuicÂ¸aËœo
na revisaËœo do trabalho;
â€“ a equipe da secretaria de poÂ´s-graduacÂ¸aËœo do CIC;
â€“ a minha famÄ±Â´lia, pelo apoio e compreensaËœo;
â€“ a todos os colegas do Mestrado em InformaÂ´tica da UnB.
Resumo
A pesquisa aproximada de padroËœes em um texto eÂ´ um problema importante para
a cieË†ncia da computacÂ¸aËœo. A pesquisa de algoritmos eficientes para solucionar esse pro-
blema influencia o desenvolvimento de aplicacÂ¸oËœes em aÂ´reas como biologia computacional
e pesquisa textual em grandes massas de dados (como a web, por exemplo). Mas para
o tratamento de volumes de informacÂ¸aËœo da magnitude envolvida nessas aplicacÂ¸oËœes, o uso
eficiente de tempo e espacÂ¸o eÂ´ uma condicÂ¸aËœo essencial. A solucÂ¸aËœo mais conhecida para
esse problema eÂ´ um algoritmo de programacÂ¸aËœo dinaË†mica com complexidade Î¸(mn) para
duas palavras P e T de comprimento m e n. Landau e Vishkin desenvolveram um al-
goritmo que usa aÂ´rvores de sufixos para acelerar a computacÂ¸aËœo de caminhos da tabela
de programacÂ¸aËœo dinaË†mica que correspondem a`s ocorreË†ncias de um padraËœo em um texto
com no maÂ´ximo k diferencÂ¸as, cuja complexidade de tempo e espacÂ¸o estaÂ´ em Î¸(kn). Nesse
algoritmo as aÂ´rvores de sufixos saËœo utilizadas para permitir o caÂ´lculo em tempo constante
do comprimento do maior prefixo comum entre quaisquer dois sufixos de P e T . Propuse-
mos e implementamos uma variacÂ¸aËœo do algoritmo de Landau e Vishkin que usa arranjos
de sufixos para esse caÂ´lculo, melhorando o uso de espacÂ¸o e mantendo um desempenho
similar, e apresentamos a relacÂ¸aËœo de custo e benefÂ´Ä±cio de cada alternativa examinada.
Com isso, desenvolvemos um mecanismo que torna possÂ´Ä±vel substituir o uso de aÂ´rvores de
sufixos por arranjos de sufixos em determinadas aplicacÂ¸oËœes, com ganho no uso de espacÂ¸o,
o que permite processar um volume maior de informacÂ¸oËœes. A modificacÂ¸aËœo realizada naËœo eÂ´
trivial, pois os algoritmos e estruturas de dados utilizadas saËœo complexos, e os paraË†metros
de desempenho e uso de espacÂ¸o rigorosos.
Abstract
Approximate pattern matching in an important problem in computer science. The
research of efficient solutions for this problem influences the development of applications
in disciplines such as computational biology and searching the web, and in order to be
able to handle such massive ammounts of information the efficient use of computational
resources is a necessary condition. The most known solution for the approximate pattern
matching problem is a dynamic programming algorithm which has Î¸(mn) complexity
given two strings P and T of length m and n. Landau and Vishkin developed a Î¸(kn)
algorithm which uses suffix trees for a faster computation of paths along the dynamic
programming table that correspond to matches of a pattern in a text with at most k
differences. In this algorithm the suffix trees are used for a constant-time calculus of the
longest common extension of any two suffixes of P and T . We proposed and implemented
a variation of Landau and Vishkinâ€™s algorithm which uses suffix arrays for this calculus,
improving the space requirements of the algorithm while keeping a similar running time
performance, and present the costs and benefits of each algorithm. In order to achieve
this we developed a technique that makes it possible to replace the use os suffix trees
for suffix arrays in certain applications with an improved memory usage that allows the
processing of a larger ammount of information. The modifications done were not trivial
ones, as the algorithms and data structures involved are very complex, and the parameters
for accepted running time performance and space usage are very rigorous.
SumaÂ´rio
1 IntroducÂ¸aËœo p. 8
2 DefinicÂ¸aËœo do Problema p. 11
2.1 Preliminares . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . p. 11
2.1.1 Palavras . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . p. 11
2.1.2 AÂ´rvores e o LCA . . . . . . . . . . . . . . . . . . . . . . . . . . p. 12
2.2 DistaË†ncia de EdicÂ¸aËœo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . p. 14
2.3 Pesquisa aproximada de padroËœes com k erros . . . . . . . . . . . . . . . p. 18
3 Algoritmo de Landau e Vishkin p. 20
3.1 Fase de PreÂ´-processamento . . . . . . . . . . . . . . . . . . . . . . . . . p. 20
3.1.1 AÂ´rvores de sufixos . . . . . . . . . . . . . . . . . . . . . . . . . . p. 21
3.1.2 CaÂ´lculo do LCA em O(1) para uma aÂ´rvore binaÂ´ria completa . . p. 24
3.1.3 PreÂ´-processamento para caÂ´lculo do LCA de uma aÂ´rvore qualquer p. 29
3.1.4 CaÂ´lculo do LCA em O(1) em uma aÂ´rvore de sufixos . . . . . . . p. 32
3.2 Fase de iteracÂ¸aËœo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . p. 34
3.2.1 ConstrucÂ¸aËœo e extensaËœo de d-caminhos . . . . . . . . . . . . . . . p. 35
3.2.2 A iteracÂ¸aËœo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . p. 36
3.3 O algoritmo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . p. 38
3.4 AnaÂ´lise do algoritmo . . . . . . . . . . . . . . . . . . . . . . . . . . . . p. 39
3.4.1 A fase de preÂ´-processamento . . . . . . . . . . . . . . . . . . . . p. 39
3.4.2 A fase de iteracÂ¸aËœo . . . . . . . . . . . . . . . . . . . . . . . . . . p. 39
4 Algoritmo de Landau e Vishkin Modificado para Usar Arranjos de
Sufixos p. 40
4.1 Arranjo de Sufixos . . . . . . . . . . . . . . . . . . . . . . . . . . . . . p. 40
4.2 CaÂ´lculo do Comprimento do Maior Prefixo Comum Usando Arranjos de
Sufixos . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . p. 42
4.3 O algoritmo proposto . . . . . . . . . . . . . . . . . . . . . . . . . . . . p. 45
4.4 AnaÂ´lise do algoritmo proposto . . . . . . . . . . . . . . . . . . . . . . . p. 47
5 AnaÂ´lise Experimental p. 49
5.1 ImplementacÂ¸oËœes utilizadas . . . . . . . . . . . . . . . . . . . . . . . . . p. 49
5.1.1 AÂ´rvore de sufixos . . . . . . . . . . . . . . . . . . . . . . . . . . p. 50
5.1.2 Arranjos de sufixos . . . . . . . . . . . . . . . . . . . . . . . . . p. 51
5.1.3 Usando algoritmos que melhoram o caso meÂ´dio . . . . . . . . . p. 51
5.1.4 Diminuindo mais o uso de espacÂ¸o . . . . . . . . . . . . . . . . . p. 52
5.2 AnaÂ´lise e ComparacÂ¸aËœo de resultados . . . . . . . . . . . . . . . . . . . . p. 52
5.2.1 Ambiente computacional . . . . . . . . . . . . . . . . . . . . . . p. 52
5.2.2 Dados aleatoÂ´rios . . . . . . . . . . . . . . . . . . . . . . . . . . p. 53
5.2.3 Dados reais . . . . . . . . . . . . . . . . . . . . . . . . . . . . . p. 68
5.2.4 AvaliacÂ¸aËœo dos resultados . . . . . . . . . . . . . . . . . . . . . . p. 75
6 ConclusaËœo e caminhos futuros p. 77
RefereË†ncias p. 80
81 IntroducÂ¸aËœo
A pesquisa aproximada de padroËœes em um texto eÂ´ um problema importante para a
cieË†ncia da computacÂ¸aËœo com aplicacÂ¸oËœes para a biologia computacional, bancos de dados de
textos, e a pesquisa de textos na web. A pesquisa de algoritmos eficientes para solucionar
esse problema influencia o desenvolvimento de aplicacÂ¸oËœes em aÂ´reas como biologia compu-
tacional e pesquisa textual de grandes massas de dados como a web e bancos de dados
de textos (como a pesquisa da jurisprudeË†ncia de um tribunal, por exemplo). Mas para
o tratamento de volumes de informacÂ¸aËœo da magnitude envolvida nessas aplicacÂ¸oËœes o uso
eficiente de tempo e espacÂ¸o eÂ´ uma condicÂ¸aËœo essencial.
O problema baÂ´sico para a pesquisa aproximada de padroËœes eÂ´ o problema de distaË†ncia
de edicÂ¸aËœo entre duas palavras P e T , que foi proposto por Vladimir I. Levenshtein em
1965, e trata de encontrar o nuÂ´mero mÄ±Â´nimo de operacÂ¸oËœes que transformariam P em T ou
vice-versa. A solucÂ¸aËœo mais conhecida para esse problema eÂ´ um algoritmo de programacÂ¸aËœo
dinaË†mica com complexidade Î¸(mn) quando o comprimento de P e T saËœo m e n, respec-
tivamente. Levenshtein mostrou que a distaË†ncia de edicÂ¸aËœo de P e T seraÂ´ obtida a partir
das distaË†ncias de edicÂ¸aËœo entre os prefixos de comprimento mâˆ’ 1 e nâˆ’ 1 de P e T , e entre
esses prefixos e P e T , o que nos nos daÂ´ uma relacÂ¸aËœo de recorreË†ncia que podemos resolver
de forma eficiente com um algoritmo de programacÂ¸aËœo dinaË†mica.
O algoritmo de pesquisa de padroËœes aproximados eÂ´ uma variacÂ¸aËœo do algoritmo de
distaË†ncia de edicÂ¸aËœo. Nesse caso buscamos subpalavras de T cuja distaË†ncia de edicÂ¸aËœo com
respeito a P eÂ´ a menor possÂ´Ä±vel. Do ponto de vista algorÂ´Ä±tmico a diferencÂ¸a eÂ´ a condicÂ¸aËœo
inicial do algoritmo.
Em 1970 Needleman e Wunsch(1) adaptaram o algoritmo de Levenshtein para o pro-
cessamento de sequÂ¨eË†ncias bioloÂ´gicas. O problema de distaË†ncia de edicÂ¸aËœo eÂ´ um problema
de minimizacÂ¸aËœo no qual se busca o conjunto mÄ±Â´nimo de operacÂ¸oËœes para transformar uma
palavra na outra, que naËœo leva em conta informacÂ¸oËœes da Biologia sobre a evolucÂ¸aËœo de
sequÂ¨eË†ncias bioloÂ´gicas. Needleman e Wunsch propuseram uma medida de similaridade ou
9semelhancÂ¸a entre duas sequÂ¨eË†ncias, que eÂ´ calculada de forma similar a` distaË†ncia de edicÂ¸aËœo,
mas transformando o caÂ´lculo numa maximizacÂ¸aËœo na qual se busca ter a maÂ´xima simila-
ridade. O algoritmo de Needleman e Wunsch eÂ´ conhecido com algoritmo de alinhamento
global.
Smith e Waterman(2) posteriormente propuseram uma modificacÂ¸aËœo ao algoritmo de
Needleman e Wunsch que eÂ´ adequada para encontrar regioËœes de grande similaridade entre
duas sequÂ¨eË†ncias. O algoritmo de Smith e Waterman eÂ´ conhecido como algoritmo de
alinhamento local. Ambos algoritmos usam a estrutura baÂ´sica do algoritmo de distaË†ncia
de edicÂ¸aËœo.
Na forma tradicional, o algoritmo de caÂ´lculo de distaË†ncia de edicÂ¸aËœo usa uma tabela
de programacÂ¸aËœo dinaË†mica de tamanho n + 1 Ã— m + 1, e dessa forma sua complexidade
de espacÂ¸o estaÂ´ em Î¸(mn). Pode-se usar uma teÂ´cnica desenvolvida por Hirschberg(3) para
alterar a complexidade de espacÂ¸o do algoritmo para Î¸(n), dobrando o tempo de execucÂ¸aËœo.
Landau e Vishkin(4) desenvolveram e apresentaram em 1986 um algoritmo que usa
aÂ´rvores de sufixos para acelerar a computacÂ¸aËœo de caminhos da tabela de programacÂ¸aËœo
dinaË†mica de Î¸(mn) para Î¸(nk) onde k eÂ´ a quantidade maÂ´xima de diferencÂ¸as. O uso
de espacÂ¸o do algoritmo de Landau e Vishkin eÂ´ Î¸(kn), mas assim como na programacÂ¸aËœo
dinaË†mica podemos modificar o algoritmo para executar usando espacÂ¸o Î¸(n) para calcular
as posicÂ¸oËœes onde P estaÂ´ em T com no maÂ´ximo k diferencÂ¸as e um algoritmo Î¸(km) para
calcular cada sequÂ¨eË†ncia de operacÂ¸oËœes de transformacÂ¸aËœo ou alinhamento.
Mesmo para a variante em que o uso de espacÂ¸o eÂ´ Î¸(n), o algoritmo de Landau e
Vishkin usa um fator multiplicador de n que eÂ´ grande, em parte por causa do uso de
aÂ´rvores de sufixos para calcular os Ä±Â´ndices que permitem acelerar a computacÂ¸aËœo da tabela
de programacÂ¸aËœo dinaË†mica. AÂ´rvores de sufixos saËœo estruturas de dados que formam um
Ä±Â´ndice de todos os sufixos de um texto ou palavra, e que podem ser construÂ´Ä±das em espacÂ¸o
e tempo linear. Apesar da complexidade linear no uso de espacÂ¸o, mostramos que eÂ´ possÂ´Ä±vel
diminuÂ´Ä±-lo utilizando uma estrutura de dados mais simples que tambeÂ´m eÂ´ um Ä±Â´ndice de
todos os sufixos de uma palavra, chamada de arranjo de sufixos.
Propusemos e implementamos uma variacÂ¸aËœo do algoritmo de Landau e Vishkin que
usa arranjos de sufixos para esse caÂ´lculo, melhorando o uso de espacÂ¸o e mantendo um
desempenho similar ao do algoritmo original (em meÂ´dia 25% mais lento que a versaËœo
original para cadeias de DNA quando a memoÂ´ria do computador eÂ´ suficiente para toda a
execucÂ¸aËœo do algoritmo) mas que diminui o uso de espacÂ¸o. Para o caso de DNA e RNA,
podemos obter ganhos de 26 a 29% com respeito ao uso de espacÂ¸o, o que possibilita pro-
10
cessar palavras que naËœo seriam processadas com o algoritmo original baseado em aÂ´rvores
de sufixos.
O algoritmo proposto foi inicialmente descrito em (5) como um resumo estendido,
e posteriormente publicado como artigo completo. Neste trabalho expandimos essa des-
cricÂ¸aËœo e apresentamos os ajustes necessaÂ´rios para realizar a computacÂ¸aËœo do LCE (Longest
Common Extension, definida na secÂ¸aËœo 2.1) por meio de arranjos de sufixos utilizando
aÂ´rvores cartesianas, e a descricÂ¸aËœo da implementacÂ¸aËœo e experimentos. 1
Desenvolvemos um mecanismo para consultas em tempo constante do comprimento
do maior prefixo comum de dois sufixos quaisquer de uma palavra, o que torna possÂ´Ä±vel
substituir o uso de aÂ´rvores de sufixos por arranjos de sufixos em aplicacÂ¸oËœes que precisem
desse caÂ´lculo, como eÂ´ o caso do algoritmo de Landau e Vishkin.
A modificacÂ¸aËœo realizada naËœo eÂ´ trivial. Foi preciso desenvolver a forma de calcular o
comprimento do maior prefixo comum de dois sufixos de uma palavra em tempo constante
apoÂ´s processamento linear de um arranjo de sufixos, diminuindo o uso de espacÂ¸o. Isso
foi possÂ´Ä±vel com a construcÂ¸aËœo de uma aÂ´rvore cartesiana que eÂ´ processada para consultas
de LCA (Lowest Common Ancestor, definida na secÂ¸aËœo 2.1) em tempo constante. Apesar
do aparente aumento da quantidade de informacÂ¸aËœo (inserimos uma quantidade maior de
estruturas de dados e etapas de processamento) na praÂ´tica foi possÂ´Ä±vel manter a ordem
de complexidade de execucÂ¸aËœo e diminuir efetivamente o espacÂ¸o utilizado.
O restante deste trabalho estaÂ´ dividido da seguinte forma.
â€¢ No capÂ´Ä±tulo 2 definimos o problema e apresentamos conceitos teoÂ´ricos que seraËœo
utilizados ao longo do trabalho.
â€¢ No capÂ´Ä±tulo 3 apresentamos o algoritmo de Landau e Vishkin e as teÂ´cnicas para sua
implementacÂ¸aËœo.
â€¢ No capÂ´Ä±tulo 4 apresentamos nossas modificacÂ¸oËœes no algoritmo de Landau e Vishkin.
â€¢ No capÂ´Ä±tulo 5 apresentamos a implementacÂ¸aËœo realizada e a anaÂ´lise dos dados expe-
rimentais obtidos
â€¢ No capÂ´Ä±tulo 6 concluÂ´Ä±mos o trabalho e apresentamos algumas direcÂ¸oËœes futuras.
1A implementacÂ¸aËœo estaraÂ´ disponÂ´Ä±vel a partir da paÂ´gina http://www.mat.unb.br/~ayala/TCgroup/
11
2 DefinicÂ¸aËœo do Problema
2.1 Preliminares
Neste trabalho usaremos os termos palavra, cadeia de caracteres, sequÂ¨eË†ncia, texto e
padraËœo como equivalentes a` palavra inglesa string que em computacÂ¸aËœo eÂ´ a palavra mais
comum para descrever uma sequÂ¨eË†ncia ordenada de caracteres. Os nomes texto e padraËœo
serviraËœo para identificar o papel especÂ´Ä±fico de cada palavra no contexto que estiver sendo
descrito. Representaremos palavras com letras maiuÂ´sculas como P e T , e caracteres como
p, t em letras minuÂ´sculas, sendo que o caractere ti seraÂ´ o i-eÂ´simo caractere da palavra T .
As formas caligraÂ´ficas B, T ou C seraËœo usadas para nomear aÂ´rvores.
2.1.1 Palavras
Dadas as palavras T = t1...tn e P = p1...pm de comprimento |T | = n e |P | = m,
m â‰¤ n, sobre um alfabeto Î£ apresentamos as definicÂ¸oËœes:
â€¢ Îµ eÂ´ a palavra vazia, e |Îµ| = 0.
â€¢ P eÂ´ uma subpalavra de T se m â‰¤ n e p1...pm = ti...ti+mâˆ’1 para algum i â‰¥ 1 e
i+mâˆ’ 1 â‰¤ n. Se m < n dizemos que P eÂ´ uma subpalavra proÂ´pria de T .
â€¢ P eÂ´ um prefixo de T se m â‰¤ n e pi = ti para 1 â‰¤ i â‰¤ m. Se m < n entaËœo dizemos
que P eÂ´ um prefixo proÂ´prio de T .
â€¢ P eÂ´ um sufixo de T se p1...pm = ti...ti+mâˆ’1 para i +m âˆ’ 1 = n e i â‰¥ 1. Se i > 1
entaËœo dizemos que P eÂ´ um sufixo proÂ´prio de T . TambeÂ´m dizemos que Ti = ti...tn
onde i â‰¥ 1 eÂ´ o i-eÂ´simo sufixo de T (ou seja, o sufixo de T que comecÂ¸a na posicÂ¸aËœo i).
â€¢ O maior prefixo comum ou LCP (Longest Common Prefix ) de T e P eÂ´ a maior
palavra L = l1...lk tal que 0 â‰¤ k â‰¤ m e l1 . . . lk = p1 . . . pk = t1 . . . tk. Se k = 0 entaËœo
L = Îµ.
12
â€¢ AleÂ´m disso usamos a notacÂ¸aËœo LCPP,T para indicar o LCP de P e T . Indicamos
ainda LCPP,T (i, j) como sendo o maior prefixo comum de Pi e Tj. Quando P e T
forem oÂ´bvios pelo contexto, usaremos apenas LCP (i, j).
â€¢ A maior extensaËœo comum ou LCE (Longest Common Extension) de T e P eÂ´ o
comprimento do maior prefixo comum de P e T : |LCPP,T |. Usaremos a notacÂ¸aËœo
LCEP,T para indicar o LCE de P e T , e LCEP,T (i, j) como sendo o comprimento
de LCPP,T (i, j). Quando P e T forem oÂ´bvios pelo contexto, usaremos apenas
LCE(i, j).
Para efeitos dos algoritmos apresentados neste trabalho, chamaremos as palavras T e
P de texto e padraËœo, respectivamente.
2.1.2 AÂ´rvores e o LCA
Uma aÂ´rvore T eÂ´ um conjunto de noÂ´s (ou veÂ´rtices) e arestas que possui as seguintes
propriedades:
â€¢ uma aresta liga exatamente dois noÂ´s.
â€¢ Um caminho em T eÂ´ uma lista de noÂ´s distintos tal que dois noÂ´s em sequÂ¨eË†ncia saËœo
unidos por uma aresta, e nenhuma aresta se repete. O comprimento de um caminho
eÂ´ o nuÂ´mero de noÂ´s presentes nesse caminho.
â€¢ Existe exatamente um caminho entre dois noÂ´s quaisquer de T.
Uma outra forma de descrever uma aÂ´rvore eÂ´ como um grafo conectado sem ciclos.
Podemos designar um noÂ´ de T como sua raiz, o que transforma a aÂ´rvore em uma
estrutura hieraÂ´rquica. A definicÂ¸aËœo de aÂ´rvores apresentada por Knuth em (6) explicita
essa estrutura hieraÂ´rquica.
Para efeitos deste trabalho, todas as aÂ´rvores possuem uma raiz. Assim dizemos que
para um noÂ´ v qualquer, os noÂ´s no caminho entre v e a raiz saËœo os noÂ´s ancestrais de v
(note que v eÂ´ ancestral de si mesmo). Um ancestral proÂ´prio de v eÂ´ um ancestral de v que
naËœo eÂ´ o proÂ´prio v.
Para todo noÂ´ v, exceto a raiz, temos exatamente um ancestral proÂ´prio w que estaÂ´
ligado a v por uma aresta. Dizemos que w eÂ´ o noÂ´ pai de v, e que v eÂ´ um noÂ´ filho de w.
Dizemos que dois noÂ´s saËœo irmaËœos se saËœo filhos do mesmo noÂ´.
13
Figura 1: exemplo de LCA
A raiz da aÂ´rvore naËœo possui ancestrais proÂ´prios e portanto naËœo possui noÂ´ pai. AleÂ´m
disso, a raiz eÂ´ ancestral proÂ´prio de todos os demais noÂ´s da aÂ´rvore.
Chamamos de folha um noÂ´ que naËœo possui noÂ´s filhos, e de noÂ´s internos todos os
demais noÂ´s.
Dizemos ainda que cada noÂ´ v da aÂ´rvore T define uma sub-aÂ´rvore, que eÂ´ a aÂ´rvore
formada pelos noÂ´s dos quais v eÂ´ ancestral, e as arestas que ligam esses noÂ´s. A raiz da
sub-aÂ´rvore de v eÂ´ o noÂ´ v.
Uma aÂ´rvore binaÂ´ria eÂ´ uma aÂ´rvore em que cada noÂ´ possui no maÂ´ximo 2 filhos.
Uma aÂ´rvore binaÂ´ria completa eÂ´ uma aÂ´rvore binaÂ´ria em que todos seus noÂ´s que naËœo
saËœo folhas possuem exatamente 2 filhos, e aleÂ´m disso o comprimento dos caminhos da raiz
ateÂ´ cada folha eÂ´ o mesmo. Uma aÂ´rvore binaÂ´ria completa com p folhas teraÂ´ exatamente
2pâˆ’ 1 noÂ´s, e p seraÂ´ da forma p = 2x para algum x âˆˆ N.
DefinicÂ¸aËœo 2.1.1 (LCA). Dada a aÂ´rvore T, o LCA (Lowest Common Ancestor) de dois
noÂ´s v e w de T eÂ´ o noÂ´ x que eÂ´ ancestral de v e w tal que nenhum outro noÂ´ na sub-aÂ´rvore
de x tambeÂ´m seja ancestral de v e w.
Dados os noÂ´s v e w da aÂ´rvore T, indicaremos o LCA de v e w por LCAT(v, w). Onde
for oÂ´bvio qual a aÂ´rvore sendo referenciada, usaremos a notacÂ¸aËœo LCA(v, w).
Exemplo 2.1.1 (LCA). Na figura 1 temos uma aÂ´rvore binaÂ´ria completa, e alguns noÂ´s
rotulados. Da definicÂ¸aËœo de LCA, temos que:
â€¢ LCA(a, b) = b.
â€¢ LCA(a, c) = LCA(b, c) = d.
â€¢ LCA(d, e) = LCA(c, e) = LCA(b, e) = LCA(a, e) = r.
14
â€¢ LCA(a, d) = LCA(b, d) = d.
2.2 DistaË†ncia de EdicÂ¸aËœo
O conceito de distaË†ncia de edicÂ¸aËœo leva ao problema de que tratamos neste trabalho.
DefinicÂ¸aËœo 2.2.1 (DistaË†ncia de EdicÂ¸aËœo). A distaË†ncia de edicÂ¸aËœo entre duas palavras P =
p1...pm e T = t1...tn eÂ´ a quantidade mÄ±Â´nima de operacÂ¸oËœes necessaÂ´rias para transformar P
em T ou vice-versa, onde as operacÂ¸oËœes possÂ´Ä±veis saËœo:
â€¢ SubstituicÂ¸aËœo quando o caractere pi de P eÂ´ substituÂ´Ä±do por um caractere tj de T .
â€¢ InsercÂ¸aËœo quando um caractere pi de P eÂ´ inserido na posicÂ¸aËœo j de T .
â€¢ RemocÂ¸aËœo quando o caractere pi eÂ´ removido de P .
Quando o pi = tj dizemos que eÂ´ um casamento ou pareamento (match).
A distaË†ncia de edicÂ¸aËœo entre as palavras P e T eÂ´ uma medida do grau de diferencÂ¸a
entre elas, mas aleÂ´m da distaË†ncia de edicÂ¸aËœo nos interessa saber a sequÂ¨eË†ncia de operacÂ¸oËœes
que transformariam uma dessas palavras na outra, que chamamos de transcrito de edicÂ¸aËœo.
Para ilustrar os conceitos de distaË†ncia e transcrito de edicÂ¸aËœo apresentamos o exemplo
2.2.1 que segue:
Exemplo 2.2.1 (Transcrito de edicÂ¸aËœo). Dadas as palavras P=TGCCATA e T=ATCCCTGAT,
o transcrito de edicÂ¸aËœo de P em T eÂ´ a sequÂ¨eË†ncia de operacÂ¸oËœes:
1. Inserimos o caractere â€œAâ€ na posicÂ¸aËœo 1: ATGCCATA.
2. SubstituÂ´Ä±mos o caractere na posicÂ¸aËœo 3 (â€œGâ€) por â€œCâ€: ATCCCATA.
2. Removemos o caractere na posicÂ¸aËœo 6 (â€œAâ€): ATCCCTA.
4. Inserimos o caractere â€œGâ€ na posicÂ¸aËœo 7: ATCCCTGA.
5. Inserimos o caractere â€œTâ€ apoÂ´s a posicÂ¸aËœo 8: ATCCCTGAT = T .
Observe que com 5 operacÂ¸oËœes podemos transformar P em T , e vice-versa. Em especial,
o caÂ´lculo da a distaË†ncia de edicÂ¸aËœo apresentado a seguir indica que esse eÂ´ o nuÂ´mero mÄ±Â´nimo
de operacÂ¸oËœes para P e T dados (baseado na tabela de programacÂ¸aËœo dinaË†mica apresentada
na figura 2).
15
A distaË†ncia de edicÂ¸aËœo entre T e P pode ser encontrada por meio de uma relacÂ¸aËœo
de recorreË†ncia sobre as distaË†ncias de edicÂ¸aËœo de prefixos de T e P , ou seja, a distaË†ncia
de edicÂ¸aËœo D(i, j) entre p1...pi e t1...tj seraÂ´ calculada das distaË†ncias D(i âˆ’ 1, j âˆ’ 1) entre
p1...piâˆ’1 e t1...tjâˆ’1, D(i âˆ’ 1, j) entre p1...piâˆ’1 e t1...tj e D(i, j âˆ’ 1) entre p1...pi e t1...tjâˆ’1
utilizando a relacÂ¸aËœo de recorreË†ncia:
D(i, j) =
ï£±ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£²ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£³
i+ j se j = 0 ou i = 0,
mÄ±Â´nimo
ï£±ï£´ï£´ï£²ï£´ï£´ï£³
D(iâˆ’ 1, j âˆ’ 1) + d
D(iâˆ’ 1, j) + 1
D(i, j âˆ’ 1) + 1
ï£¼ï£´ï£´ï£½ï£´ï£´ï£¾ caso contraÂ´rio
onde d = 0 se pi = tj ou 1 se pi 6= tj
Essa relacÂ¸aËœo de recorreË†ncia pode ser calculada por um algoritmo de programacÂ¸aËœo
dinaË†mica de complexidade Î¸(nm) que utiliza uma tabela de programacÂ¸aËœo dinaË†mica de
tamanho (n + 1) Ã— (m + 1), tambeÂ´m denotada por D. Os alinhamentos ou transcritos
de edicÂ¸aËœo podem ser recuperados utilizando ponteiros de retorno (traceback) que formam
um caminho na tabela de programacÂ¸aËœo dinaË†mica.
Para recuperar a sequÂ¨eË†ncia de operacÂ¸oËœes que formam o transcrito de edicÂ¸aËœo basta
seguir os ponteiros de retorno a partir da ceÂ´lula D(m,n).
Na ceÂ´lula D(i, j) da tabela de programacÂ¸aËœo dinaË†mica um ponteiro para a ceÂ´lula su-
perior significa que removemos o caractere pi de P , um ponteiro para a ceÂ´lula a` esquerda
significa que inserimos o caractere tj em P , e um ponteiro na diagonal significa um casa-
mento de pi e tk ou entaËœo uma substituicÂ¸aËœo se pi 6= tj. Seguimos os ponteiros de retorno
ateÂ´ chegarmos a uma ceÂ´lula D(0, k) ou D(k, 0). Nesse ponto removemos os k primeiros
caracteres do padraËœo ou do texto, respectivamente.
O algoritmo de programacÂ¸aËœo dinaË†mica consiste em construir uma tabela para os va-
lores D(i, j) conforme a relacÂ¸aËœo de recorreË†ncia acima tal que o valor da ceÂ´lula D(i, j)
seraÂ´ o valor D(i, j) na relacÂ¸aËœo de recorreË†ncia. Na figura 2 temos um exemplo das tabe-
las de distaË†ncia de edicÂ¸aËœo e de ponteiros de retorno para as palavras P=TGCCATA e
T=ATCCCTGAT utilizadas no exemplo 2.2.1. Cada ceÂ´lula D(i, j) da tabela possui o
valor da distaË†ncia de edicÂ¸aËœo de p1 . . . pi e t1 . . . tj (i = 0 ou j = 0 saËœo condicÂ¸oËœes iniciais
para o caÂ´lculo). O ponteiro de retorno indica qual ceÂ´lula na tabela foi escolhida para
calcular o valor da ceÂ´lula corrente.
16
Figura 2: Tabela de programacÂ¸aËœo dinaË†mica e ponteiros de retorno
Uma teÂ´cnica descrita por Hirschberg(3) em 1975 permite que o caÂ´lculo da relacÂ¸aËœo
de recorreË†ncia seja feito usando espacÂ¸o Î¸(n) ao inveÂ´s de Î¸(nm), dobrando o tempo de
execucÂ¸aËœo. Essa teÂ´cnica consiste em encontrar um ponto no alinhamento oÂ´timo entre P
e T . Esse ponto oÂ´timo divide a tabela de programacÂ¸aËœo dinaË†mica em dois subproblemas
que juntos teË†m a metade do tamanho do problema original. EntaËœo esses subproblemas
saËœo resolvidos recursivamente.
Exemplo 2.2.2 (Tabela de programacÂ¸aËœo dinaË†mica e ponteiros de retorno). Na figura
2 temos a tabela de programacÂ¸aËœo dinaË†mica calculada para o exemplo 2.2.1, e a mesma
tabela com os ponteiros de retorno desenhados, indicando quais as operacÂ¸oËœes que devem
ser executadas para transformar P em T .
O algoritmo de alinhamento global de Needleman e Wunsch usa uma relacÂ¸aËœo de re-
correË†ncia semelhante a` de distaË†ncia de edicÂ¸aËœo. Seja Î£â€² = Î£ âˆª {â€“} onde o caractere â€œâ€“â€
representa um espacÂ¸o. EntaËœo dada uma funcÂ¸aËœo de pontuacÂ¸aËœo Î´ : Î£â€²Ã—Î£â€² â†’ <, a similari-
dade S entre duas sequÂ¨eË†ncias P e T eÂ´ dada pela relacÂ¸aËœo de recorreË†ncia:
S(i, j) =
ï£±ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£²ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£³
0 se j = 0 e i = 0,
S(iâˆ’ 1, 0) + Î´(pi,âˆ’) se j = 0 e 1 â‰¤ i â‰¤ m,
S(0, j âˆ’ 1) + Î´(âˆ’, tj) se i = 0 e 1 â‰¤ j â‰¤ n,
maÂ´ximo
ï£±ï£´ï£´ï£²ï£´ï£´ï£³
S(iâˆ’ 1, j âˆ’ 1) + Î´(pi, tj)
S(iâˆ’ 1, j) + Î´(âˆ’, tj)
S(i, j âˆ’ 1) + Î´(pi,âˆ’)
ï£¼ï£´ï£´ï£½ï£´ï£´ï£¾ caso contraÂ´rio
Essa relacÂ¸aËœo de recorreË†ncia pode ser calculada por um algoritmo de programacÂ¸aËœo
dinaË†mica de complexidade Î¸(mn) similar ao algoritmo para a distaË†ncia de edicÂ¸aËœo, usando
uma tabela de programacÂ¸aËœo dinaË†mica que aqui tambeÂ´m seraÂ´ denotada por S.
17
A funcÂ¸aËœo de pontuacÂ¸aËœo Î´ indica o quaËœo provaÂ´vel ou aceitaÂ´vel supomos uma substi-
tuicÂ¸aËœo especÂ´Ä±fica ou um espacÂ¸o. Por exemplo, se Î´(e, i) = 2 e Î´(e, a) = âˆ’1 isso quer
dizer que uma substituicÂ¸aËœo de e por i eÂ´ mais aceitaÂ´vel no caÂ´lculo que estamos realizando
que uma substituicÂ¸aËœo de e por a. Para o alinhamento de sequÂ¨eË†ncias moleculares Î´ cos-
tuma indicar a probabilidade da ocorreË†ncia de uma mutacÂ¸aËœo que transforme uma base ou
aminoaÂ´cido em outro (7).
O algoritmo de Needleman e Wunsch procura a maÂ´xima similaridade entre duas
sequÂ¨eË†ncias, enquanto o algoritmo de distaË†ncia de edicÂ¸aËœo busca a mÄ±Â´nima diferencÂ¸a. AleÂ´m
disso o algoritmo de Needleman e Wunsch usa uma funcÂ¸aËœo de pontuacÂ¸aËœo que pode atri-
buir pontuacÂ¸oËœes distintas a pares distintos de caracteres. Podemos dizer que o algoritmo
de Needleman e Wunsch resolve um problema mais geneÂ´rico que inclui o problema de
distaË†ncia de edicÂ¸aËœo. Dada a funcÂ¸aËœo Î´ apropriada podemos usar o caÂ´lculo de similaridade
para calcular a distaË†ncia de edicÂ¸aËœo entre duas palavras P e T . Observe que se fizermos
Î´(a, b) = {0 se a = b, âˆ’1 caso contraÂ´rio}, obteremos S(m,n) tal que D(m,n) = âˆ’S(m,n).
Como o algoritmo de Needleman e Wunsch naËœo usa o conceito de edicÂ¸aËœo da palavra,
ao inveÂ´s do transcrito de edicÂ¸aËœo usamos o conceito de alinhamento para representar as
semelhancÂ¸as entre as sequÂ¨eË†ncias.
DefinicÂ¸aËœo 2.2.2 (Alinhamento). Um alinhamento de duas sequÂ¨eË†ncias P e T eÂ´ uma matriz
2 Ã— l (l â‰¥ m,n) tal que a primeira linha da matriz conteÂ´m os caracteres de P na ordem
em que aparecem em P mesclados com lâˆ’m espacÂ¸os (representados por â€œâ€“â€) e a segunda
linha conteÂ´m os caracteres de T na ordem em que aparecem em T mesclados com l âˆ’ n
espacÂ¸os tal que nenhuma coluna da matriz possui espacÂ¸os em ambas as linhas (8).
Na representacÂ¸aËœo visual de um alinhamento podemos desenhar uma linha extra entre
as linhas do alinhamento com um caractere â€œ|â€ sempre que os caracteres c1 e c2 de uma
coluna
(
c1
c2
)
do alinhamento forem iguais, e em branco caso contraÂ´rio. Isso permite
visualizar melhor as situacÂ¸oËœes em que foi feita uma operacÂ¸aËœo de substituicÂ¸aËœo. Usaremos o
conceito de alinhamento ao inveÂ´s de transcrito de edicÂ¸aËœo, pois eÂ´ um conceito mais geneÂ´rico
e mais coË†modo.
O alinhamento pode ser recuperado seguindo os ponteiros de retorno de forma similar
ao transcrito de edicÂ¸aËœo. Na ceÂ´lula S(i, j) da tabela de programacÂ¸aËœo dinaË†mica, um ponteiro
para a ceÂ´lula superior significa um espacÂ¸o na segunda linha da coluna, um ponteiro para
a ceÂ´lula a` esquerda significa um espacÂ¸o na primeira linha da coluna, e um ponteiro na
diagonal significa uma coluna sem espacÂ¸os com pi na primeira linha e tj na segunda.
18
Podemos tambeÂ´m construir um alinhamento de duas palavras P e T a partir do
transcrito de edicÂ¸aËœo de P em T percorrendo os caracteres de P e T na ordem em que
aparecem da seguinte forma:
â€¢ Suponha que jaÂ´ temos as k primeiras colunas do alinhamento, e a proÂ´xima coluna
seraÂ´ a coluna k+1 e vamos processar os caracteres pi e tj tal que a ceÂ´lula D(i, j) se
encontra no caminho formado pelos ponteiros de retorno. Se k = 0 entaËœo i = j = 1.
â€“ Se pi = tj entaËœo acrescentamos a coluna Ck+1 =
(
pi
tj
)
e fazemos i = i + 1,
j = j + 1 e k = k + 1.
â€“ Se fazemos a substituicÂ¸aËœo de pi por tj, entaËœo acrescentamos a coluna Ck+1 =(
pi
tj
)
e fazemos i = i+ 1, j = j + 1 e k = k + 1.
â€“ Se removemos o caractere pi entaËœo acrescentamos a coluna Ck+1 =
(
pi
âˆ’
)
e
fazemos i = i+ 1 e k = k + 1.
â€“ Se inserimos o caractere tj entaËœo acrescentamos a coluna Ck+1 =
(
âˆ’
tj
)
e
fazemos j = j + 1 e k = k + 1.
â€¢ Repetimos as operacÂ¸oËœes ateÂ´ que todos os caracteres de P e T estejam no alinhamento,
e todas as operacÂ¸oËœes do transcrito de edicÂ¸aËœo tenham sido representadas.
Exemplo 2.2.3 (Alinhamento). Dadas P e T como no exemplo 2.2.1 e o transcrito de
edicÂ¸aËœo gerado de P para T , o alinhamento correspondente seria:
P: - T G C C A T - A -
| | | | |
T: A T C C C - T G A T
2.3 Pesquisa aproximada de padroËœes com k erros
O problema da pesquisa aproximada de padroËœes com k erros entre um padraËœo P e
um texto T eÂ´ o problema de encontrar todos os pares de posicÂ¸oËœes (i, j) em T tal que a
19
distaË†ncia de edicÂ¸aËœo entre P e ti...tj eÂ´ no maÂ´ximo k. O caso especial em que k = 0 eÂ´ o
problema de encontrar todas as ocorreË†ncias de P em T .
Esse problema pode ser resolvido pelo algoritmo de programacÂ¸aËœo dinaË†mica usado
para o problema da distaË†ncia de edicÂ¸aËœo com uma alteracÂ¸aËœo simples: na condicÂ¸aËœo inicial
definimos que D(i, 0) = 0 para cada 0 â‰¤ i â‰¤ n. As ocorreË†ncias de P em T seraËœo
os caminhos que iniciem na linha 0 e terminem na linha m da tabela de programacÂ¸aËœo
dinaË†mica. Um alinhamento gerado a partir desses caminhos eÂ´ chamado de alinhamento
semi-global
20
3 Algoritmo de Landau e Vishkin
Landau e Vishkin(4) desenvolveram um algoritmo de complexidade Î¸(kn) para o pro-
blema da pesquisa aproximada de padroËœes com k erros, melhorando dessa forma a com-
plexidade da solucÂ¸aËœo de programacÂ¸aËœo dinaË†mica Î¸(nm), onde n e m saËœo os comprimentos
do texto e do padraËœo, respectivamente. O algoritmo eÂ´ dividido em duas fases: uma fase
de preÂ´-processamento e uma fase de iteracÂ¸aËœo. A apresentacÂ¸aËœo mostrada aqui segue a de
Gusfield(9).
Na fase de preÂ´-processamento o algoritmo de Landau e Vishkin constroÂ´i uma aÂ´rvore
de sufixos T para as palavras P e T (concatenadas) e processa T para que seja possÂ´Ä±vel
calcular o LCA (secÂ¸aËœo 2.1.2) de quaisquer de suas folhas em tempo O(1). Na sua fase de
iteracÂ¸aËœo o algoritmo de Landau e Vishkin usa a observacÂ¸aËœo de que ocorreË†ncias do padraËœo no
texto seraËœo representados por caminhos ao longo das diagonais da tabela de programacÂ¸aËœo
dinaË†mica (representando casamentos) intercalados com trechos na vertical, horizontal e
diagonais que representem erros. Assim o algoritmo percorre as diagonais da tabela de
programacÂ¸aËœo dinaË†mica fazendo saltos em tempo constante ao longo das diagonais, e o
comprimento de cada salto eÂ´ calculado a partir do LCA na aÂ´rvore de sufixos de suas
folhas correspondentes aos sufixos envolvidos de P e T .
Apesar das suas propriedades teoÂ´ricas, naËœo temos conhecimento de uma aplicacÂ¸aËœo
praÂ´tica do algoritmo de Landau e Vishkin na anaÂ´lise de sequÂ¨eË†ncias bioloÂ´gicas.
3.1 Fase de PreÂ´-processamento
Na fase de preÂ´-processamento construÂ´Ä±mos uma aÂ´rvore de sufixos T para P concate-
nada a T e a processamos para que possamos calcular o LCA (ver secÂ¸aËœo 2.1.2) de duas
folhas quaisquer em O(1).
Esse processamento faz um mapeamento dos noÂ´s de T para os noÂ´s de uma aÂ´rvore
binaÂ´ria completa B implÂ´Ä±cita, para a qual calculamos facilmente o LCA de dois noÂ´s em
21
tempo O(1), dessa forma obtendo um caÂ´lculo de LCA em tempo O(1) para uma aÂ´rvore
qualquer.
3.1.1 AÂ´rvores de sufixos
A aÂ´rvore de sufixos eÂ´ uma estrutura de dados desenvolvida por Weiner(10) que forma
um Ä±Â´ndice de todos os sufixos de uma palavra, permitindo consultas raÂ´pidas a`s suas
subpalavras e a informacÂ¸oËœes da sua estrutura. Weiner(10) e McCreight(11) mostraram
como eÂ´ possÂ´Ä±vel construir uma aÂ´rvore de sufixos usando espacÂ¸o e tempo linear, o que tornou
o uso da estrutura de dados mais praÂ´tico, e Ukkonen(12) desenvolveu um algoritmo que
constroi uma aÂ´rvore de sufixos de forma incremental (on-line). Posteriormente Kurtz(13)
mostrou que apesar de usar espacÂ¸o da ordem Î¸(n) o fator multiplicador de n pode ser
alto, e desenvolveu teÂ´cnicas para buscar uma diminuicÂ¸aËœo desse fator.
Uma aÂ´rvore de sufixos T para a palavra T = t1...tn sobre um alfabeto Î£ eÂ´ uma aÂ´rvore
que possui as seguintes propriedades:
â€¢ T possui exatamente n folhas, numeradas de 1 a n.
â€¢ Cada noÂ´ interno de T, exceto possivelmente pela raiz, possui pelo menos dois noÂ´s
filhos.
â€¢ Cada aresta T eÂ´ rotulada por uma subpalavra de T , tal que para um noÂ´ v os roÂ´tulos
das arestas que ligam v a seus filhos se diferenciam pelo menos por seus caracteres
iniciais.
â€¢ Para uma folha i de T, a concatenacÂ¸aËœo dos roÂ´tulos das arestas no caminho da raiz
de T ateÂ´ i, na ordem em que saËœo visitadas, eÂ´ o sufixo Ti de T .
â€¢ A concatenacÂ¸aËœo dos roÂ´tulos das arestas no caminho da raiz ateÂ´ o noÂ´ que eÂ´ o
LCAT(v, v
â€²) de duas folhas v e vâ€² de T nos daÂ´ o maior prefixo comum de Tv e
Tvâ€² .
Um caractere chamado sentinela que naËœo pertence a Î£ eÂ´ concatenado a T para garantir
que T possui exatamente n + 1 folhas. Denotamos os caracteres sentinelas como $ e
#, tal que $ 6= #. Na figura 3 apresentamos a aÂ´rvore de sufixos T para a palavra
T = GATGACCA$.
A aÂ´rvore de sufixos para uma palavra de comprimento n pode ser construÂ´Ä±da em
tempo Î¸(n) utilizando espacÂ¸o Î¸(n), como descrito por McCreight(11) e Ukkonen(12). O
22
Figura 3: AÂ´rvore de sufixos para a palavra GATGACCA$
algoritmo de McCreight adiciona os sufixos de T a` aÂ´rvore T um apoÂ´s o outro, adicionando
primeiro o sufixo T1, seguido do sufixo T2 e assim sucessivamente ateÂ´ que o todos os sufixos
de T tenham sido adicionados a T. O algoritmo de Ukkonen constroÂ´i a aÂ´rvore de sufixos
T adicionando os prefixos de T na ordem crescente de seu comprimento, construindo
primeiro a aÂ´rvore de sufixos T1 para a palavra t1, depois adicionando o caractere t2 para
obter a aÂ´rvore de sufixos T2 para a palavra t1t2, depois acrescentando t3 para obter a
aÂ´rvore de sufixos T3 para a palavra t1t2t3, e assim sucessivamente ateÂ´ que eÂ´ construÂ´Ä±da a
aÂ´rvore T para t1 . . . tn a partir da aÂ´rvore Tnâˆ’1 para t1 . . . tnâˆ’1. Por construir a aÂ´rvore de
sufixos processando um caractere de T por vez, na ordem em que aparecem na palavra,
dizemos que o algoritmo de Ukkonen eÂ´ um algoritmo on-line. Apesar dos algoritmos de
McCreight e de Ukkonen parecerem algoritmos muito distintos, Kurtz e Giegerich(14)
mostraram que saËœo na verdade muito parecidos.
Para permitir a construcÂ¸aËœo usando tempo e espacÂ¸o Î¸(n) rotulamos cada aresta de T
com o Ä±Â´ndice em T do caractere inicial de seu roÂ´tulo e com o comprimento do roÂ´tulo (ou
entaËœo o Ä±Â´ndice do seu caractere final em T ). Assim cada roÂ´tulo consome o espacÂ¸o constante
de 2 nuÂ´meros inteiros para sua representacÂ¸aËœo.
Para a construcÂ¸aËœo em tempo Î¸(n) ambos os algoritmos usam ponteiros de sufixos
(sufix links) para acelerar a atualizacÂ¸aËœo dos roÂ´tulos.
Seja xÂ¯ a palavra formada pela concatenacÂ¸aËœo dos roÂ´tulos das arestas no caminho da
raiz de T ateÂ´ o noÂ´ x, na ordem em que saËœo visitados, note que se x eÂ´ a raiz de T entaËœo
xÂ¯ = . EntaËœo seja o noÂ´ x tal que xÂ¯ = Î±Î² onde Î± seja um caractere e Î² uma palavra
(possivelmente a palavra vazia ). EntaËœo o ponteiro de sufixos desse noÂ´ apontaraÂ´ para o
noÂ´ interno y tal que yÂ¯ eÂ´ prefixo de Î² (se y existir).
23
A primeira utilidade da aÂ´rvore de sufixos eÂ´ a pesquisa exata de padroËœes. Dadas as
palavras T e P , e aÂ´rvore de sufixos T construÂ´Ä±da a partir de T , a consulta para saber se
P eÂ´ subpalavra de T eÂ´ Î¸(m). A consulta pode ser feita da seguinte forma:
1. Fazemos o noÂ´ x igual a raiz de T.
2. Se x eÂ´ uma folha, entaËœo P naËœo eÂ´ subpalavra de T .
3. Selecionamos a aresta saindo de x para o noÂ´ y filho de x tal que o seu roÂ´tulo se
inicia com o caractere p1, se naËœo existe essa aresta entaËœo P naËœo eÂ´ uma subpalavra
de T .
4. Caso contraÂ´rio seja R = r1...rk o roÂ´tulo da aresta selecionada.
5. Comparamos r2 com p2, r3 com p3 e assim sucessivamente ateÂ´ que todo os caracteres
do R ou de P tenham sido comparados, ou ateÂ´ que encontremos i (1 < i â‰¤ m e
1 < i â‰¤ k) tal que ri 6= pi
6. Se encontramos i descrito no passo anterior, entaËœo P naËœo eÂ´ subpalavra de T .
7. Se m â‰¤ k e naËœo encontramos i no passo 5 acima, entaËœo P eÂ´ uma subpalavra de T ,
e y eÂ´ o noÂ´ mais proÂ´ximo da raiz tal que P eÂ´ subpalavra de yÂ¯.
8. Caso contraÂ´rio, m > k, entaËœo fazemos x = y, P = Pk+1 e voltamos ao passo 2.
Encontrado P em yÂ¯, todas as folhas na sub-aÂ´rvore de x representam os sufixos de
T do qual P eÂ´ um prefixo. AleÂ´m disso, a quantidade de folhas na sub-aÂ´rvore de y eÂ´ a
quantidade de vezes que P estaÂ´ em T .
Na praÂ´tica, a implementacÂ¸aËœo e construcÂ¸aËœo eficiente de aÂ´rvores de sufixos eÂ´ complexa.
Kurtz(13) mostra que apesar de uma aÂ´rvore de sufixos usar espacÂ¸o que eÂ´ linear com
respeito ao comprimento da palavra, muitas implementacÂ¸oËœes saËœo pouco eficientes no uso de
espacÂ¸o e possuem um fator multiplicador de n que eÂ´ grande demais (maior que 24n bytes na
maioria das implementacÂ¸oËœes). No mesmo artigo Kurtz analisa em detalhe as informacÂ¸oËœes
necessaÂ´rias para construir uma aÂ´rvore de sufixos e descreve teÂ´cnicas de implementacÂ¸aËœo
que melhoram o uso de espacÂ¸o da aÂ´rvore de sufixos de forma que o espacÂ¸o utilizado seja
de 10n a 12n bytes para palavras de ateÂ´ 128 milhoËœes de caracteres.
AÂ´rvores de sufixos saËœo muito utilizadas para aplicacÂ¸oËœes em biologia computacional,
como nos sistemas MUMMER (15) que faz alinhamento de sequÂ¨eË†ncias bioloÂ´gicas, e RE-
Puter (16) que encontra repeticÂ¸oËœes em sequÂ¨eË†ncias bioloÂ´gicas, ambos capazes de trabalhar
24
com massas de dados do tamanho de genomas inteiros. Para poder processar palavras
desse porte, a implementacÂ¸aËœo de aÂ´rvore de sufixos do sistema MUMMER usa cerca de
15n bytes para cadeias de DNA.
3.1.2 CaÂ´lculo do LCA em O(1) para uma aÂ´rvore binaÂ´ria com-
pleta
O algoritmo de Landau e Vishkin usa um caÂ´lculo de LCA em uma aÂ´rvore binaÂ´ria
completa com complexidade O(1) para calcular o LCA em uma aÂ´rvore geneÂ´rica em O(1).
Nesta secÂ¸aËœo apresentamos o caÂ´lculo para a aÂ´rvore binaÂ´ria completa B.
Seja B a aÂ´rvore binaÂ´ria completa com p folhas (ver secÂ¸aËœo 2.1.2). Como B eÂ´ completa,
B possui n = 2p âˆ’ 1 noÂ´s, e todas as suas folhas estaËœo a` mesma distaË†ncia da raiz e cada
sub-aÂ´rvore dos noÂ´s filhos da raiz tem exatamente p âˆ’ 1 noÂ´s. Rotulamos cada noÂ´ de B
com um nuÂ´mero binaÂ´rio de (d+1) bits, onde d = log2 p. Esse roÂ´tulo eÂ´ obtido com uma
visita em-ordem (17) de cada noÂ´ v de B, numerando cada noÂ´ na medida em que esse seja
visitado. Para efeitos de notacÂ¸aËœo, vamos identificar um noÂ´ de B com seu roÂ´tulo.
Seja h(v) a funcÂ¸aËœo que retorna a altura do noÂ´ v, ou seja o nuÂ´mero de noÂ´s presentes
no caminho v ateÂ´ as folhas da sub-aÂ´rvore da qual eÂ´ raiz. Calculamos h(v) como sendo a
posicÂ¸aËœo (contada a partir do bit mais a` direita) do bit igual a 1 menos significativo (mais
a` direita) do roÂ´tulo de v. Diremos que o bit i de v eÂ´ o bit na posicÂ¸aËœo i contada a partir
do bit mais a` direita de v.
Note que B possui p folhas e 2p âˆ’ 1 noÂ´s. Como B eÂ´ completa entaËœo a sub-aÂ´rvore de
cada um dos filhos da raiz (se existirem) teraÂ´ p
2
folhas e pâˆ’ 1 noÂ´s. Seja v a raiz de B. Se
p = 1 B possui 2pâˆ’1 = 1 noÂ´ e h(v) = 1. Se p = 2 folhas entaËœo v tem exatamente 2 filhos,
B possui 2pâˆ’ 1 = 3 noÂ´s e h(v) = 2. Se p = 4 entaËœo B possui 2pâˆ’ 1 = 7 noÂ´s, e h(v) = 3.
EÂ´ faÂ´cil verificar que se v eÂ´ a raiz de B, entaËœo B teraÂ´ 2h(v)âˆ’1 noÂ´s, e 2h(v)âˆ’1 folhas. Como a
numeracÂ¸aËœo dos noÂ´s eÂ´ feita em-ordem, entaËœo temos que se i = h(v), numeramos os noÂ´s na
sub-aÂ´rvore do filho a` esquerda de v com os valores do intervalo 1 . . . 2iâˆ’1 âˆ’ 1, numeramos
v com 2iâˆ’1, e os noÂ´s na sub-aÂ´rvore do filho a` direita de v com os valores do intervalo
2iâˆ’1 + 1 . . . 2i+1 âˆ’ 1. Note que h(v) depende apenas de v, e que eÂ´ o valor exatamente na
metade do intervalo que define os valores dos roÂ´tulos na sua sub-aÂ´rvore, e que o tamanho
desse intervalo pode ser calculado de h(v).
Assim, seja v a raiz de uma sub-aÂ´rvore qualquer de B. EntaËœo a sua sub-aÂ´rvore possui
2h(v)âˆ’1 noÂ´s, e seus roÂ´tulos seraËœo os roÂ´tulos vi onde vâˆ’(2h(v)âˆ’1âˆ’1) â‰¤ vi â‰¤ v+(2h(v)âˆ’1âˆ’1),
25
independentemente do valor de v e do tamanho de B (pois B eÂ´ completa e os roÂ´tulos
numerados em-ordem).
Podemos verificar se dados dois noÂ´s v e w, v 6= w, se um eÂ´ ancestral do outro da
seguinte forma:
â€¢ Seja hv = h(v) e hw = h(w). Se hv = hw entaËœo nem v eÂ´ ancestral de w e nem w eÂ´
ancestral de v.
â€¢ Suponha que hv > hw, entaËœo para verificar se v eÂ´ ancestral de w verificamos se
v âˆ’ (2hvâˆ’1 âˆ’ 1) â‰¤ w â‰¤ v + (2hvâˆ’1 âˆ’ 1).
â€¢ Em caso afirmativo v eÂ´ ancestral de w, caso contraÂ´rio nem v eÂ´ ancestral de w e nem
w eÂ´ ancestral de v.
Exemplo 3.1.1 (VerificacÂ¸aËœo se um de dois noÂ´s eÂ´ ancestral do outro). Tomemos como
exemplo a aÂ´rvore binaÂ´ria completa ilustrada na figura 4(b).
Seja v = 10 e w = 3, hv = h(10) = 2 e hw = h(3) = 1. Como hv > hw, e verificamos
que naËœo eÂ´ verdade que 10 âˆ’ (22âˆ’1 âˆ’ 1) â‰¤ 3 â‰¤ 10 + (22âˆ’1 âˆ’ 1), entaËœo v naËœo eÂ´ ancestral
de v e nem w eÂ´ ancestral de v.
Agora seja v = 6 e w = 4, hv = h(6) = 2 e hw = h(4) = 3. Como hv < hw, e
verificamos que 4âˆ’ (23âˆ’1 âˆ’ 1) â‰¤ 6 â‰¤ 4 + (23âˆ’1 âˆ’ 1), entaËœo w eÂ´ ancestral de v.
Para encontrar o LCA x de dois noÂ´s v e w de B verificamos primeiro se v estaÂ´ na
sub-aÂ´rvore de w ou vice-versa. Se naËœo for esse o caso, entaËœo seja o noÂ´ x = LCA(v, w). Sem
perda de generalidade, podemos dizer que x seraÂ´ um noÂ´ tal que v estaÂ´ na sub-aÂ´rvore de seu
filho a` esquerda, e w na sub-aÂ´rvore de seu filho a` direita, ou seja xâˆ’ (2h(x)âˆ’1âˆ’ 1) â‰¤ v < x
e x > w â‰¤ x+ (2h(x)âˆ’1 âˆ’ 1), e h(x) > h(v) e h(x) > h(w).
Observe que uma maneira de encontrar x a partir de v e w eÂ´ subir a aÂ´rvore a partir
de v ou w, ateÂ´ chegarmos num noÂ´ que eÂ´ ancestral de v e de w ao mesmo tempo. Para
isso precisamos primeiro descobrir como encontrar o noÂ´ vâ€² que eÂ´ pai de v manipulando o
roÂ´tulo de v:
ProposicÂ¸aËœo 3.1.1. Seja h(v) a altura do noÂ´ v. O noÂ´ vâ€² ancestral de v seraÂ´ o noÂ´ cujo
roÂ´tulo eÂ´ igual ao roÂ´tulo de v com o bit h(v) + 1 alterado para 1, o bit h(v) alterado para
0.
DemonstracÂ¸aËœo. Suponha que h(v) = 1. EntaËœo o uÂ´ltimo bit de v eÂ´ 1. Como B eÂ´ completa,
h(vâ€²) = 2, e vale vâ€² âˆ’ (2h(vâ€²)âˆ’1 âˆ’ 1) â‰¤ v â‰¤ vâ€² + (2h(vâ€²)âˆ’1 âˆ’ 1), de onde obtemos que
26
v = vâ€² âˆ’ 1 ou v = vâ€² + 1. Como h(v) = 1 entaËœo os uÂ´ltimos 2 bits de v podem ser 01
ou 11. Da numeracÂ¸aËœo em-ordem sabemos que se v < vâ€² entaËœo os uÂ´ltimos 2 bits de v
seraËœo 01. Nesse caso v = vâ€² âˆ’ 1 => vâ€² = v + 1, de forma que os uÂ´ltimos 2 bits de vâ€²
seraËœo 10 e vale a proposicÂ¸aËœo. Se v > vâ€² entaËœo os uÂ´ltimos 2 bits de v seraËœo 11. Nesse caso
v = vâ€²+1 => vâ€² = vâˆ’1, de forma que os uÂ´ltimos 2 bits de vâ€² seraËœo 10 e vale a proposicÂ¸aËœo.
Se vâ€² eÂ´ ancestral de v, entaËœo h(vâ€²) = h(v) + 1, e vâ€² âˆ’ (2h(v) âˆ’ 1) â‰¤ v â‰¤ vâ€² + (2h(v) âˆ’ 1).
Da definicÂ¸aËœo de h sabemos que vâ€² tem seus uÂ´ltimos h(v) bits com valor 0, precedido por
um bit 1. Resta mostrar que os bits a` esquerda do bit h(vâ€²) saËœo iguais em v e vâ€². Suponha
que exista um bit b > h(vâ€²) em v aÂ´ esquerda de h(vâ€™) que seja diferente do mesmo bit b
em vâ€². Se esse bit for 1 em v e 0 em vâ€², entaËœo temos que v > vâ€². Ora, sabemos que a
sub-aÂ´rvore a direita de vâ€² tem 2h(v
â€²)âˆ’1âˆ’ 1 noÂ´s, e o maior roÂ´tulo de um noÂ´ nessa subaÂ´rvore
seraÂ´ vâ€² + 2h(v
â€²)âˆ’1 âˆ’ 1. Como todos os bits a` direita do bit h(vâ€²) saËœo zero, e o bit mais
significante de 2h(v
â€²)âˆ’1 eÂ´ o bit h(v) = h(vâ€²)âˆ’ 1, entaËœo v > vâ€² + (2h(vâ€²)âˆ’1 âˆ’ 1) e v naËœo pode
estar na sub-aÂ´rvore de vâ€² o que eÂ´ uma contradicÂ¸aËœo. De forma anaÂ´loga, se o bit b for 0
em v e 1 em vâ€², v < vâ€² e v estaria na sub-aÂ´rvore a` esquerda de vâ€². Mas temos entaËœo que
v < vâ€² âˆ’ (2h(v) âˆ’ 1) o que eÂ´ uma contradicÂ¸aËœo e temos que o bit b > h(vâ€²) possui o mesmo
valor em v e vâ€².
Como sabemos achar o pai de v a partir de v, eÂ´ faÂ´cil calcular x = LCA(v, w). Esco-
lhemos o noÂ´ dentre v e w que tem a menor altura, e subimos na aÂ´rvore ateÂ´ encontrarmos
o seu ancestral que possui altura igual a` do outro noÂ´. Feito isso, subimos na aÂ´rvore a
partir de ambos os noÂ´s, um nÂ´Ä±vel por vez, ateÂ´ que o ancestral encontrado subindo a aÂ´rvore
a partir de v e w seja o mesmo. Esse procedimento eÂ´ correto porque cada noÂ´ possui
exatamente um uÂ´nico noÂ´ pai (exceto a raiz, que naËœo possui nenhum) e a raiz eÂ´ ancestral
de todos os noÂ´s.
Para verificar que naËœo eÂ´ necessaÂ´rio subir a aÂ´rvore a partir de cada noÂ´ para chegar
no LCA de v e w, observe que esse ancestral x de v e w tem no seu roÂ´tulo todos os
bits a` esquerda do bit h(x) iguais aos bits correspondentes em v e w, e que exatamente
nessa posicÂ¸aËœo os bits em v e w seraËœo diferentes, indicando que v estaÂ´ na sub-aÂ´rvore a`
esquerda de x (pois x âˆ’ (2h(x)âˆ’1 âˆ’ 1) â‰¤ v < x) e w estaÂ´ na sub-aÂ´rvore a` direita de x
(pois x > w â‰¤ x+ (2h(x)âˆ’1âˆ’ 1)). EntaËœo basta descobrir essa posicÂ¸aËœo h(x) para podermos
descobrir x a partir de v ou w. Como os bits em v e w a` esquerda do bit h(x) saËœo iguais,
e o bit h(x) eÂ´ diferente, basta fazer uma operacÂ¸aËœo OU-EXCLUSIVO ou XOR dos roÂ´tulos
de v e x e procurar a posicÂ¸aËœo do primeiro bit com valor 1 a partir da esquerda (primeira
27
posicÂ¸aËœo onde haÂ´ divergeË†ncia entre os bits de v e w). Isso vai nos dar a posicÂ¸aËœo do bit h(x).
Pela definicÂ¸aËœo de h sabemos que todos os bits a` direita dessa posicÂ¸aËœo teraËœo valor 0. AleÂ´m
disso da proposicÂ¸aËœo 3.1.1 temos que os bits a` esquerda dessa posicÂ¸aËœo seraËœo iguais aos bits
nessas posicÂ¸oËœes em v e w, entaËœo basta pegar o roÂ´tulo de v ou de w, fazer o bit h(x) igual 1
e completar com h(x)âˆ’ 1 bits 0 a` direita do bit h(x), e com isso encontramos o x (roÂ´tulo
do noÂ´ que eÂ´ LCA de v e w).
Assim, rotulada a aÂ´rvore, podemos encontrar o LCA x de dois noÂ´s v e w de B em
O(1) da seguinte forma:
i. Sejam hv = h(v) e hw = h(w)
ii. Se hv < hw entaËœo se w âˆ’ (2hwâˆ’1) + 1 â‰¤ v â‰¤ w + (2hwâˆ’1)âˆ’ 1 entaËœo x = w
iii. SenaËœo se v âˆ’ (2hvâˆ’1 + 1) â‰¤ w â‰¤ v + (2hvâˆ’1 âˆ’ 1) entaËœo x = v
iv. Se nem (ii.) e nem (iii.) valem, entaËœo calculamos x:
â€“ xâ€² = v XOR w
â€“ k = posicÂ¸aËœo do bit 1 mais a` esquerda de xâ€²
â€“ xâ€²â€² = v com seus bits deslocados d+ 1âˆ’ k bits para a direita
â€“ xâ€²â€²â€² = xâ€²â€² com o seu bit menos significante alterado para 1
â€“ x = xâ€²â€²â€² com seus bits deslocados d+ 1âˆ’ k para a esquerda.
Dessa forma calculamos o roÂ´tulo x do noÂ´ que eÂ´ o LCA de v e w em O(1).
ObservacÂ¸aËœo 3.1.1 (OperacÂ¸oËœes bit-a-bit em tempo constante). Algumas das operacÂ¸oËœes
bit-a-bit que tratamos como constantes saËœo na realidade Î¸(log2n). Na praÂ´tica, fixamos
n para essas operacÂ¸oËœes como sendo o maior valor inteiro que a arquitetura da maÂ´quina
suporta. Uma vez fixado n independente do tamanho da entrada para o algoritmo, a
complexidade dessas operacÂ¸oËœes bit-a-bit pode ser analisada como O(1).
As operacÂ¸oËœes em questaËœo saËœo a pesquisa da posicÂ¸aËœo do bit 1 mais significativo ou
menos significativo de um nuÂ´mero inteiro, que usam consultas em tempo O(1) em uma
tabela.
Exemplo 3.1.2 (CaÂ´lculo do LCA em uma aÂ´rvore binaÂ´ria completa). Seja a B a aÂ´rvore
binaÂ´ria completa como na figura 4 (a). B possui p = 8 folhas, e n = 2p âˆ’ 1 = 15 noÂ´s,
d = log2 p = 3. Primeiramente visitamos todos os noÂ´s de B em-ordem e rotulamos os noÂ´s
28
Figura 4: CaÂ´lculo em O(1) de LCA em aÂ´rvore binaÂ´ria completa
com um nuÂ´mero de d+1 = 4 bits na ordem em que saËœo visitados, de forma que os roÂ´tulos
ficam como na figura 4 (b).
Dados dois noÂ´s v e w de B, temos dois casos distintos:
â€¢ v eÂ´ ancestral de w, ou seja LCAB(v, w) = v.
â€¢ LCAB(v, w) = x, onde x 6= v e x 6= w.
No caso de w ser ancestral de v, simplesmente chamamos v de w e w de v.
Caso 1. Vamos escolher os noÂ´s v = 4 = 0100 e w = 7 = 0111. EntaËœo hv = h(0100) =
3, e hw = h(0111) = 1. Como hw < hv entaËœo fazemos k = 2
hvâˆ’1 = 22 = 4 e verificamos
que v âˆ’ k + 1 â‰¤ w â‰¤ v + k âˆ’ 1, logo o LCAB(v, w) = v = 4.
Caso 2. Vamos escolher os noÂ´s v = 9 = 1001 e w = 14 = 1110. Nesse caso
hv = h(1001) = 1 e hw = h(1110) = 2. Como hv < hw, fazemos k = 2
hwâˆ’1 = 2 e
verificamos que w âˆ’ k + 1 > v e logo LCAB(v, w) = x 6= v 6= w. Para encontrar x entaËœo
seguimos com o algoritmo:
â€¢ xâ€² = v XOR w = 1001 XOR 1110 = 0111.
â€¢ k = 2
â€¢ xâ€²â€² = 0010 (1001 com seus bits deslocados 3 + 1âˆ’ 2 = 2 bits para a direita)
â€¢ xâ€²â€²â€² = 0011 (0010 com o seu bit menos significante alterado para 1)
â€¢ x = 1100 (0011 com seus bits deslocados 3 + 1âˆ’ 2 para a esquerda)
Logo, para o caso 2, temos corretamente que LCAB(v, w) = 12.
29
3.1.3 PreÂ´-processamento para caÂ´lculo do LCA de uma aÂ´rvore
qualquer
Para calcular o LCA de duas folhas de uma aÂ´rvore de sufixos T com complexidade
O(1) construimos um mapeamento de T para a aÂ´rvore binaÂ´ria completa B.
Visitamos cada noÂ´ de T numa visita em preÂ´-ordem (17), rotulando cada noÂ´ com a
ordem em que eÂ´ visitado, e vamos identificar um noÂ´ com o seu roÂ´tulo.
Definimos uma funcÂ¸aËœo I como um mapeamento de noÂ´s da aÂ´rvore geneÂ´rica T na aÂ´rvore
binaÂ´ria completa B, ou seja, dado o noÂ´ v de T, I(v) = w, onde w eÂ´ um noÂ´ de B, e
calculamos w da seguinte forma:
Se v eÂ´ uma folha em T, entaËœo w = v (o roÂ´tulo do noÂ´ w em B seraÂ´ o roÂ´tulo v). Se v
naËœo for uma folha, entaËœo w seraÂ´ o roÂ´tulo de um noÂ´ vâ€² na sub-aÂ´rvore de v tal que para todo
outro noÂ´ x na sub-aÂ´rvore de v, h(vâ€²) > h(x).
A definicÂ¸aËœo de I eÂ´ bem formada porque garante a unicidade de w na sub-aÂ´rvore de v.
Observe que a altura de um noÂ´ com roÂ´tulo w em B naËœo depende do tamanho de B, mas
eÂ´ determinada pela quantidade de zeros a` direita do bit 1 menos significativo de w. AleÂ´m
disso observe que se existirem dois noÂ´s vâ€² e vâ€²â€² na sub-aÂ´rvore de v tal que h(v) = h(vâ€²),
entaËœo teremos um noÂ´ w onde v â‰¤ w â‰¤ vâ€² tal que h(w) > h(v).
A funcÂ¸aËœo I particiona T em conjuntos de noÂ´s que saËœo mapeados para o mesmo noÂ´
I(v) de B. Dizemos que a cabecÂ¸a de cada uma dessas particÂ¸oËœes eÂ´ o noÂ´ v de T na particÂ¸aËœo
que estaÂ´ mais proÂ´ximo da raiz de T.
O caÂ´lculo de I pode ser feito em tempo O(n) visitando cada noÂ´ v de T em preÂ´-ordem
com o seguinte algoritmo recursivo:
Algoritmo 1 CaÂ´lculo do mapeamento I(v)
1. Se v eÂ´ uma folha, ent~ao I(v) = v.
2. Caso ContraÂ´rio, sejam w1 ...wk os k filhos de v:
2.1 Fazemos Ii = I(wi) para 1 â‰¤ i â‰¤ k (executando este algoritmo
recursivamente para cada filho wi de v).
2.2. Seja h0 = h(v) e hi = h(Ii) para 1 â‰¤ i â‰¤ k.
2.3. Seja m o Ä±Â´ndice tal que hm eÂ´ o maÂ´ximo de h0 . . . hk.
2.4. Se m = 0 ent~ao I(v) = v, sen~ao I(v) = Im
AleÂ´m de I, precisamos de mais informacÂ¸aËœo da estrutura de T. Assim calculamos as
funcÂ¸oËœes L e A, onde L(v) eÂ´ a cabecÂ¸a da particÂ¸aËœo I(v) e A(v) eÂ´ o nuÂ´mero binaÂ´rio tal que
o i-eÂ´simo bit de A(v) eÂ´ 1 se o noÂ´ v possui um ancestral u em T tal que h(I(u)) = i, e 0
30
caso contraÂ´rio. Ou seja, L indica o noÂ´ mais proÂ´ximo da raiz de T que eÂ´ mapeado para o
mesmo noÂ´ I(v) em B e A codifica parte da estrutura hieraÂ´rquica de T da raiz ateÂ´ o noÂ´ v.
L pode ser calculado juntamente com I. Para isso acrescentamos um passo 3 ao
algoritmo 1 no qual fazemos L(I(v)) = v.
Tendo calculado I, calculamos A com uma visita em preÂ´-ordem aos noÂ´s de T, sendo
que se v eÂ´ noÂ´ filho de vâ€², entaËœo A(v) seraÂ´ o valor de A(vâ€²) com o bit h(I(v)) com o valor 1.
Como cada uma das funcÂ¸oËœes eÂ´ calculada por um percurso em preÂ´-ordem de T que
percorre exatamente 2 vezes cada noÂ´ para rotular cada noÂ´ e calcular I e L, e 1 vez cada
noÂ´ para calcular A, entaËœo a complexidade total eÂ´ Î¸(n) para uma aÂ´rvore com n noÂ´s.
Exemplo 3.1.3 (Mapeamento da aÂ´rvore de sufixos T para a aÂ´rvore binaÂ´ria completa B).
Seja a aÂ´rvore de sufixos T mostrada na figura 5. Observe que a numeracÂ¸aËœo da visita em
preÂ´-ordem de cada noÂ´ estaÂ´ representada por um nuÂ´mero sublinhado proÂ´ximo ao noÂ´. Vamos
mostrar o caÂ´lculo de I, A e L para a sub-aÂ´rvore do noÂ´ com roÂ´tulo v = 5 (representado
por 5 na figura).
Mostramos primeiro o caÂ´lculo de I e L para a sub-aÂ´rvore de v:
â€¢ Primeiro calculamos I(vi) para cada filho de vi, visitando cada um em preÂ´-ordem:
â€“ Seja v1 = 6. Como v1 eÂ´ uma folha entaËœo I(6) = 6, e fazemos L(I(v1)) =
L(6) = 6.
â€“ Seja v2 = 7. Como v2 eÂ´ uma folha entaËœo I(7) = 7, e fazemos L(I(v2)) =
L(7) = 7.
â€“ Seja v3 = 8. Como v3 eÂ´ uma folha entaËœo I(8) = 8, e fazemos L(I(v3)) =
L(8) = 8.
â€“ Como naËœo haÂ´ mais filhos de v, voltamos para v para calcular I(v) e L(v).
â€¢ Fazemos h0 = h(v) = h(5) = 1, h1 = h(v1) = h(6) = 2, h2 = h(v2) = h(7) = 1 e
h3 = h(v3) = h(8) = 4.
â€¢ Escolhemos i tal que hi eÂ´ maÂ´ximo. No caso, i = 3 pois h3 = 4 eÂ´ a maior altura
dentre os valores selecionados.
â€¢ Como 3 = i 6= 0, fazemos I(v) = I(vi) = I(8) = 8.
â€¢ Fazemos L(I(v)) = L(8) = v = 5.
31
Figura 5: Mapeamento da aÂ´rvore de sufixos T para a aÂ´rvore binaÂ´ria completa B
O caÂ´lculo para os demais noÂ´s se faz de maneira similar. Neste exemplo, em especial,
observe que I(1) seraÂ´ 8.
Calculados I e L, vamos ilustrar agora o caÂ´lculo de A para a sub-aÂ´rvore de v. Da
figura, sabemos que o pai de v eÂ´ a proÂ´pria raiz da aÂ´rvore, o noÂ´ 1. Note que I(1) = 8 e
L(8) = 1.
Vamos calcular os valores de A para a raiz e a sub-aÂ´rvore de v = 5.
â€¢ Como o noÂ´ 1 eÂ´ a raiz da aÂ´rvore (naËœo possui pai), o valor de A(1) seraÂ´ o nuÂ´mero
binaÂ´rio 0000 com o bit h(I(1)) alterado para o valor 1. Assim A(1) = 1000 = 8.
â€¢ Como o noÂ´ 1 eÂ´ o pai de v, Calculamos A(v) = A(5) como sendo A(1) com o bit
h(I(v)) alterado para 1. Observe que temos I(v) = 8 e h(8) = 4, logo A(5) =
1000 = 8.
â€¢ Agora calcular A(vi) para cada filho vi de v:
â€“ Seja v1 = 6. I(6) = 6, e h(6) = 2, fazemos A(6) como sendo A(5) com o bit 2
com valor 1. Assim, A(6) = 1010 = 10.
â€“ Seja v2 = 7. I(7) = 7, e h(7) = 1, fazemos A(7) como sendo A(5) com o bit 1
com valor 1. Assim, A(7) = 1001 = 9.
â€“ Seja v3 = 8. I(8) = 8, e h(8) = 4, fazemos A(8) como sendo A(5) com o bit 4
com valor 1. Assim, A(8) = 1000 = 8.
Dessa forma ilustramos o caÂ´lculo de I, L e A. Na figura 5 mostramos as tabelas I, L
e A completas para a aÂ´rvore T.
32
3.1.4 CaÂ´lculo do LCA em O(1) em uma aÂ´rvore de sufixos
Uma vez calculados I, L e A, podemos calcular o LCA de dois noÂ´s v e w de T em
O(1) usando a seguintes propriedade:
Propriedade 3.1.1. Se z eÂ´ ancestral de x em T entaËœo I(z) eÂ´ ancestral de I(x) em B.
Assim, seja z o LCA de v e w em T, e seja o b = LCAB(I(v), I(w)) o LCA de I(v)
e I(w) em B. Como B eÂ´ uma aÂ´rvore binaÂ´ria completa, b pode ser encontrado em O(1)
como vimos na subsecÂ¸aËœo 3.1.2.
Podemos usar b para encontrar a altura de I(z) a partir da informacÂ¸aËœo da estrutura
de T armazenda em A. Observe que A(v) codifica a altura h(I(vâ€²)) de cada ancestral vâ€² de
v. A(w) armazena a mesma informacÂ¸aËœo para w. Ora, z = LCAT(v, w) por ser ancestral
de v e de w teraÂ´ a altura do seu mapeamento j = h(I(z)) mapeada em A(v) e em A(w),
ou seja, o bit j teraÂ´ o valor 1 em A(v) e em A(w). Para encontrar j observamos que os
primeiros bons candidatos saËœo as alturas mapeadas em ambos A(v) e A(w) (pois o bit j
estaraÂ´ com o valor 1 em ambos). AleÂ´m disso, pela propriedade 3.1.1 sabemos que a altura
de j seraÂ´ no mÄ±Â´nimo a altura de b. EntaËœo j seraÂ´ a posicÂ¸aËœo do primeiro bit a` esquerda do
bit i = h(b) que tem o valor 1 em A(v) e A(w).
Se h(b) = i, entaËœo podemos encontrar j = h(I(z)) em O(1) da seguinte forma:
â€¢ Seja x = A(v) AND A(w) (observe que dessa forma deixamos com valor 1 apenas
os bits que marcam as alturas comuns em B dos ancestrais de v e w).
â€¢ xâ€² = x com seus bits deslocados para a direita e de volta iâˆ’ 1 bits (zeramos os bits
a` direita do (i)-eÂ´simo bit).
â€¢ j = h(xâ€²)
Sabendo a altura do mapeamento de z, podemos encontrar os noÂ´s vÂ¯ e wÂ¯ que saËœo
ancestrais de v e w, respectivamente, que possuem o mesmo mapeamento que z. Para
isso encontramos I(x), onde x eÂ´ um noÂ´ em uma particÂ¸aËœo cuja cabecÂ¸a L(I(x)) eÂ´ um noÂ´ filho
de vÂ¯. Assim, ao encontrar I(x) encontramos vÂ¯ facilmente. De forma anaÂ´loga encontramos
wÂ¯. Perceba que vÂ¯ eÂ´ ancestral de v tal que I(vÂ¯) = I(z) assim como wÂ¯ eÂ´ ancestral de w tal
que I(wÂ¯) = I(z). EntaËœo pela numeracÂ¸aËœo em preÂ´-ordem, z = min(vÂ¯, wÂ¯).
Podemos encontrar vÂ¯ da seguinte forma:
33
â€¢ Seja vÂ¯ o noÂ´ ancestral de v que estaÂ´ na mesma particÂ¸aËœo de z (ou seja, I(vÂ¯) = I(z)):
â€“ se h(I(v)) = h(I(z)) entaËœo vÂ¯ = v.
â€“ caso contraÂ´rio vÂ¯ 6= v (h(v) < j):
âˆ— seja x o ancestral de v tal que vÂ¯ seja o noÂ´ pai de x. EntaËœo h(I(x)) = k eÂ´ a
maior posicÂ¸aËœo de um bit 1 em A(v) que eÂ´ menor que j.
âˆ— encontramos I(x) = bits de I(v) a` esquerda da posicÂ¸aËœo k seguida de um
bit 1 e completada com zeros.
âˆ— O noÂ´ vÂ¯ seraÂ´ o noÂ´ pai de L(I(x)).
â€¢ calculamos wÂ¯ de forma similar a vÂ¯.
â€¢ se vÂ¯ < wÂ¯ entaËœo o LCA de v e w eÂ´ vÂ¯ caso contraÂ´rio eÂ´ wÂ¯.
Exemplo 3.1.4 (CaÂ´lculo do LCA em uma aÂ´rvore de sufixos T). Seja a aÂ´rvore de sufixos
T mostrada na figura 5. Sejam os noÂ´s v = 6 e w = 8. Vamos encontrar o z = LCA(v, w).
â€¢ Em primeiro lugar fazemos Iv = I(v) = 6 e Iw = I(w) = 8, e calculamos b =
LCAB(Iv, Iw) como vimos na secÂ¸aËœo 3.1.2. Como h(Iv) < h(Iw) verificamos que
8âˆ’ (2h(8)âˆ’1 âˆ’ 1) â‰¤ 6 â‰¤ 8 + (2h(8)âˆ’1 âˆ’ 1), de forma que o LCAB(6, 8) = 8.
â€¢ Fazemos i = h(b) = h(8) = 4.
â€¢ Encontramos em seguida j = h(I(z)) a partir de b. Calculamos x = A(v) AND
A(w) = 1010 AND 1000 = 1000, e zeramos os bits a` direita do bit i e obtemos
xâ€² = 1000, e j = h(xâ€²) = 4.
â€¢ Vamos encontrar vÂ¯ e wÂ¯:
â€“ Observe que h(v) < j. EntaËœo seja x ancestral de v tal que o pai de x seja vÂ¯.
Calculamos k = h(I(x)) como sendo a posicÂ¸aËœo do bit 1 mais significante de
A(v) que estaÂ´ a` direita do bit j. Como A(v) = 1010 entaËœo k = 2.
â€“ Fazemos I(x) = I(v) com o bit na posicÂ¸aËœo k igual a 1 e os bits a` direita da
posicÂ¸aËœo k iguais a 0. Como I(v) = 0110 = 6, entaËœo I(x) = 0110 = 6.
â€“ O noÂ´ vÂ¯ seraÂ´ o noÂ´ pai do noÂ´ L(I(x)). Como L(6)=6, vÂ¯ = 5.
â€“ Como h(w) = j, entaËœo wÂ¯ = w = 8.
â€¢ Como vÂ¯ < wÂ¯, entaËœo z = vÂ¯ = 5.
Dessa forma ilustramos a busca do LCA de dois noÂ´s 6 e 8 de T, e encontramos o noÂ´
5.
34
3.2 Fase de iteracÂ¸aËœo
Na fase de iteracÂ¸aËœo do algoritmo construÂ´Ä±mos caminhos seguindo as diagonais da
tabela de programacÂ¸aËœo dinaË†mica.
Na tabela de programacÂ¸aËœo dinaË†mica D, supondo que o caractere tj do texto rotula
a coluna j da tabela, e o caractere pi do padraËœo rotula a linha i, uma ocorreË†ncia de P
em T forma um caminho sem ciclos que percorre a tabela iniciando na primeira linha e
terminando na uÂ´ltima linha.
Mais formalmente, dizemos que:
â€¢ Uma diagonal d da tabela de programacÂ¸aËœo dinaË†mica D saËœo todas as ceÂ´lulas D(i, j)
tal que j âˆ’ i = d.
â€¢ A diagonal principal eÂ´ a diagonal 0 de D composta pelas ceÂ´lulas D(i, i) onde 0 â‰¤
i â‰¤ m â‰¤ n.
â€¢ Duas ceÂ´lulas D(i, j) e D(iâ€², jâ€²) saËœo ditas adjacentes se iâ€² 6= i ou jâ€² 6= j e aleÂ´m disso
i â‰¤ iâ€² â‰¤ i+ 1 e j â‰¤ jâ€² â‰¤ j + 1.
â€¢ Um caminho na tabela de programacÂ¸aËœo dinaË†mica eÂ´ uma sequÂ¨eË†ncia de ceÂ´lulas C0 . . . Ck
onde para qualquer kâ€² âˆˆ {0 . . . k âˆ’ 1}, Ckâ€² e Ckâ€²+1 saËœo adjacentes.
â€¢ Se a ceÂ´lula Ck+1 = D(i, j) eÂ´ a ceÂ´lula que segue a ceÂ´lula Ck = D(i âˆ’ 1, j âˆ’ 1) em
um caminho, entaËœo dizemos que eÂ´ um descasamento se tj 6= pi, e um casamento se
tj = pi.
â€¢ Se a ceÂ´lula Ck+1 = D(i + 1, j) ou a ceÂ´lula Ck+1 = D(i, j + 1) segue a ceÂ´lula Ck =
D(i, j) em um caminho entaËœo dizemos que eÂ´ um espacÂ¸o.
â€¢ Um erro em um caminho eÂ´ um descasamento ou um espacÂ¸o.
â€¢ Um d-caminho em D eÂ´ um caminho que se inicia ou na coluna 1 antes da linha d+1
ou na linha 1 e possui as propriedades:
â€“ Caminhos que iniciem na linha 1 comecÂ¸am com 0 erros e caminhos que iniciem
na ceÂ´lula C0 = D(i, 1) para 1 â‰¤ i â‰¤ d iniciam com i erros.
â€“ Se a ceÂ´lula Ck = D(i, j) estaÂ´ no caminho, entaËœo a ceÂ´lula Ck+1 = D(i
â€², jâ€²) eÂ´ a
ceÂ´lula imediatamente apoÂ´s Ck no caminho (se existir) e D(i
â€², jâ€²) âˆˆ {D(i+1, j+
1), D(i, j + 1), D(i+ 1, j)}.
35
Figura 6: Caminho de maior alcance na diagonal i
â€“ Possui exatamente d erros.
â€“ Um d-caminho eÂ´ o de maior alcance na diagonal i se eÂ´ um d-caminho que
termina em uma ceÂ´lula Ck = D(r, c) na diagonal i e o Ä±Â´ndice c da coluna de
Ck eÂ´ maior ou igual ao Ä±Â´ndice da coluna da ceÂ´lula final de todos os outros
d-caminhos que terminem na diagonal i.
Na figura 6 mostramos dois caminho que terminam na diagonal i. Na figura o caminho
que se inicia na diagonal k â‰¤ iâˆ’ 1 eÂ´ o caminho de maior alcance na diagonal i.
A fase de iteracÂ¸aËœo do algoritmo de Landau e Vishkin constroÂ´i todos os 0-caminhos da
tabela de programacÂ¸aËœo dinaË†mica, e a partir desses todos os 1-caminhos, e a partir desses
todos os 2-caminhos, e assim sucessivamente ateÂ´ que todos os d-caminhos procurados
foram construÂ´Ä±dos. Isso eÂ´ feito percorrendo cada diagonal i de D e extendendo os (dâˆ’ 1)-
caminhos nas diagonais iâˆ’ 1, i, e i+ 1 para a diagonal i como seraÂ´ mostrado a seguir.
3.2.1 ConstrucÂ¸aËœo e extensaËœo de d-caminhos
Usaremos a notacÂ¸aËœo LCE(i, j) para indicar o LCEP,T (i, j) (ver secÂ¸aËœo 2.1).
Um d-caminho eÂ´ construÂ´Ä±do em D da seguinte forma.
Se d = 0 entaËœo um 0-caminho que inicia na diagonal i eÂ´ o caminho que comecÂ¸a na
36
ceÂ´lula D(1, i) e eÂ´ estendido na diagonal i ateÂ´ a ceÂ´lula D(j, i+ j), onde j eÂ´ o LCE(1,i+1).
Um d-caminho comecÂ¸ando na ceÂ´lula D(d, 1), para 0 < d â‰¤ m eÂ´ estendido ateÂ´ a ceÂ´lula
D(d+ j, j), onde j eÂ´ o LCE(d, 1).
Se d > 0 entaËœo um d-caminho eÂ´ construÂ´Ä±do a partir de um (dâˆ’1)-caminho cuja ceÂ´lula
final Ck = D(r, c) estaÂ´ na diagonal i estendendo-o inicialmente para a ceÂ´lula D(r
â€², câ€²) na
diagonal iâ€² de uma de treË†s formas:
â€¢ o caminho eÂ´ estendido uma ceÂ´lula para a direita para a ceÂ´lula Drâ€²,câ€² = D(r, c + 1)
na diagonal iâ€² = i+1, significando a insercÂ¸aËœo de um espacÂ¸o no padraËœo na posicÂ¸aËœo r;
â€¢ o caminho eÂ´ estendido uma ceÂ´lula para baixo para a ceÂ´lula Drâ€²,câ€² = D(r + 1, c) na
diagonal iâ€² = iâˆ’ 1, significando a insercÂ¸aËœo de um espacÂ¸o no texto na posicÂ¸aËœo c;
â€¢ o caminho eÂ´ estendido uma ceÂ´lula na diagonal iâ€² = i para a ceÂ´lula Drâ€²,câ€² = D(r +
1, c+ 1), significando um descasamento entre tc e pr.
ApoÂ´s estender o (d âˆ’ 1)-caminho para a ceÂ´lula (râ€², câ€²) na diagonal iâ€², o caminho eÂ´
estendido l ceÂ´lulas na diagonal iâ€² onde l = LCE(râ€², câ€²).
3.2.2 A iteracÂ¸aËœo
O algoritmo de Landau e Vishkin, apresentado no algoritmo 2, percorre cada diagonal
i da tabela de programacÂ¸aËœo dinaË†mica, construindo os d-caminhos que saËœo de maior alcance
em cada diagonal, comecÂ¸ando com todos os 0-caminhos, e depois desses calculando todos
os 1-caminhos e assim sucessivamente ateÂ´ que todos os k-caminhos sejam encontrados.
Os kâ€²-caminhos (onde 0 â‰¤ kâ€² â‰¤ k) que terminem na linha m da tabela de programacÂ¸aËœo
dinaË†mica saËœo ocorreË†ncias de P em T com no maÂ´ximo k diferencÂ¸as.
Em cada iteracÂ¸aËœo calculamos o d-caminho de maior alcance na diagonal i da seguinte
forma:
â€¢ Se d = 0 entaËœo o 0-caminho que inicia na diagonal i eÂ´ o 0-caminho de maior alcance
em i.
â€¢ Se d > 0, encontramos o d-caminho de maior alcance em i a partir dos (d âˆ’ 1)-
caminhos de maior alcance nas diagonais iâˆ’ 1, i e i+ 1 da seguinte forma:
37
Figura 7: ExtensaËœo de caminhos para a diagonal i
â€“ Estendemos o (dâˆ’ 1)-caminho de maior alcance na diagonal iâˆ’ 1 uma ceÂ´lula
para a direita para a ceÂ´lula D(ih, jh) na diagonal i e entaËœo o estendemos lh =
LCE(ih, jh) ceÂ´lulas ao longo da diagonal i como descrito na subsecÂ¸aËœo 3.2.1.
â€“ De forma similar estendemos o (dâˆ’ 1)-caminho de maior alcance na diagonal
i + 1 uma ceÂ´lula para a baixo para a ceÂ´lula D(iv, jv) na diagonal i e entaËœo o
estendemos lv = LCE(iv, jv) ceÂ´lulas ao longo de i.
â€“ Estendemos tambeÂ´m o (d âˆ’ 1)-caminho de maior alcance na diagonal i uma
ceÂ´lula ao longo da diagonal i para a ceÂ´lula D(id, jd), e entaËœo o estendemos
ld = LCE(id, jd) ceÂ´lulas ao longo de i.
â€“ O d-caminho de maior alcance na diagonal i eÂ´ escolhido dos treË†s construÂ´Ä±dos
acima como sendo aquele que tem o maior Ä±Â´ndice na coluna de sua ceÂ´lula final.
Na figura 7 ilustramos a extensaËœo dos d âˆ’ 1 caminhos nas diagonais i âˆ’ 1, i e i + 1
para a diagonal i com o acreÂ´scimo de 1 erro representado por uma linha pontilhada e a
extensaËœo ao longo da diagonal i.
Observe que uma vez que construÂ´Ä±mos uma arvore de sufixos T para a concatenacÂ¸aËœo de
P e T , todos os sufixos de P e de T seraËœo folhas em T. Assim, dados i e j correspondentes
a Pi e Tj, respectivamente, o LCAT das folhas correspondentes nos daÂ´ o LCP (i, j), e
portanto o LCE(i, j). Dessa forma, o caÂ´lculo do LCE para a extensaËœo dos d-caminhos
38
depende do caÂ´lculo do LCA na aÂ´rvore de sufixos.
3.3 O algoritmo
No algoritmo 2 apresentamos as duas fases do algoritmo de Landau e Vishkin. Na
primeira fase construÂ´Ä±mos uma aÂ´rvore de sufixos generalizada T para P e T , e a pro-
cessamos para que seja possÂ´Ä±vel calcular o LCA de duas folhas quaisquer em O(1). Em
seguida construÂ´Ä±mos todos os 0-caminhos e executamos a iteracÂ¸aËœo ateÂ´ encontrarmos todos
os k-caminhos.
Algoritmo 2 Algoritmo de Landau e Vishkin para pesquisa aproximada de padroËœes
1. Construimos a aÂ´rvore de sufixos generalizada T para P e T.
2. Processamos T em O(n) de forma a responder consultas LCA em O(1).
3. Para cada diagonal i da tabela de programacÂ¸~ao dina^mica, encontramos
o seu 0-caminho de maior alcance com uma consulta de LCA entre P
e Ti+1.
4. Para d = 1 ...k:
4.1 Para cada diagonal i da tabela de programacÂ¸~ao dina^mica:
4.1.1 Estendemos o (dâˆ’ 1)-caminho de maior alcance na diagonal iâˆ’ 1
uma ceÂ´lula para a direita para a ceÂ´lula D(r, s) na diagonal i
4.1.2 Estendemos esse caminho ao longo da diagonal i pela
quantidade de ceÂ´lulas igual a` profundidade do
LCA dos sufixos correspondentes de P e T
(P [r]...P [m] e T [s]..T [n]).
4.1.3 Estendemos o (dâˆ’ 1)-caminho de maior alcance na diagonal i+ 1
uma ceÂ´lula para a baixo para a ceÂ´lula D(râ€², sâ€²) na diagonal i
4.1.4 Estendemos esse caminho ao longo da diagonal i pela
quantidade de ceÂ´lulas igual a` profundidade do
LCA dos sufixos correspondentes de P e T
(P [râ€²]...P [m] e T [sâ€²]..T [n]).
4.1.5 Estendemos o (dâˆ’ 1)-caminho de maior alcance na diagonal i
uma ceÂ´lula ao longo da diagonal i para a ceÂ´lula D(râ€²â€², sâ€²â€²)
4.1.6 Estendemos esse caminho ao longo da diagonal i pela
quantidade de ceÂ´lulas igual a` profundidade do
LCA dos sufixos correspondentes de P e T
(P [râ€²â€²]...P [m] e T [sâ€²â€²]..T [n]).
4.1.7 Escolhemos o d-caminho de maior alcance dentre os tre^s.
5. Cada caminho que alcancÂ¸ar a linha m eÂ´ uma ocorre^ncia de P em T
com no maÂ´ximo k erros.
39
3.4 AnaÂ´lise do algoritmo
Vamos analisar cada fase em separado.
3.4.1 A fase de preÂ´-processamento
A fase de preÂ´-processamento possui duas etapas distintas.
i. construÂ´Ä±mos a aÂ´rvore de sufixos generalizada T para P e T em Î¸(n).
ii. preÂ´-processamos T em Î¸(n) para o caÂ´lculo do LCA em O(1)
Sabemos que a aÂ´rvore de sufixos pode ser construÂ´Ä±da com complexidade de espacÂ¸o e
tempo linear, entaËœo a etapa (i) eÂ´ executada em Î¸(n+m) = Î¸(n) (pois n â‰¥ m).
A segunda etapa eÂ´ executada com complexidade de tempo e espacÂ¸o linear sobre o
nuÂ´mero de noÂ´s da aÂ´rvore. Como o nuÂ´mero de noÂ´s da aÂ´rvore de sufixos eÂ´ Î¸(n), entaËœo a
segunda etapa tambeÂ´m eÂ´ executada em Î¸(n), de forma que a complexidade geral da fase
de preÂ´-processamento eÂ´ Î¸(n).
3.4.2 A fase de iteracÂ¸aËœo
A fase de iteracÂ¸aËœo eÂ´ composta de k + 1 passos onde percorremos n + k diagonais.
Como o caÂ´lculo do LCA de duas folhas da aÂ´rvore de sufixos eÂ´ O(1) apoÂ´s a fase de preÂ´-
processamento, entaËœo para cada diagonal fazemos 3 operacÂ¸oËœes de extensaËœo de caminho
em tempo O(1), de forma que a complexidade total do algoritmo eÂ´ Î¸(kn).
A complexidade de espacÂ¸o tambeÂ´m eÂ´ Î¸(kn) se for necessaÂ´rio apresentar os alinha-
mentos das ocorreË†ncias de P em T . Se somente os pares de posicÂ¸oËœes inicial e final de
cada ocorreË†ncia de P em T forem necessaÂ´rios, entaËœo o uso de espacÂ¸o pode ser reduzido
para Î¸(n) pois basta manter somente a lista das posicÂ¸oËœes finais dos (dâˆ’ 1)-caminhos para
calcular as posicÂ¸oËœes finais dos d-caminhos.
40
4 Algoritmo de Landau e Vishkin
Modificado para Usar Arranjos
de Sufixos
Identificamos no uso de aÂ´rvores de sufixos uma oportunidade de melhorar o uso de
espacÂ¸o do algoritmo de Landau e Vishkin. Nossa proposta eÂ´ substituir o uso de uma
aÂ´rvore de sufixos nesse algoritmo por um arranjo de sufixos e estruturas adicionais para
calcular em tempo constante os comprimentos dos maiores prefixos comuns de sufixos
do texto e do padraËœo. A vantagem dessa modificacÂ¸aËœo eÂ´ diminuir o uso de memoÂ´ria com
relacÂ¸aËœo ao algoritmo original.
A maior parte da modificacÂ¸aËœo foi realizada na fase de preÂ´-processamento, e as mu-
dancÂ¸as na fase de iteracÂ¸aËœo saËœo mÄ±Â´nimas.
4.1 Arranjo de Sufixos
O arranjo de sufixos eÂ´ uma estrutura de dados introduzida por Manber e Myers(18)
em 1989 com propoÂ´sito similar ao da aÂ´rvore de sufixos (ver secÂ¸aËœo 3.1.1), que eÂ´ formar um
Ä±Â´ndice de todos os sufixos de uma palavra para facilitar consultas a`s suas subpalavras.
DefinicÂ¸aËœo 4.1.1 (Arranjo de sufixos). Um arranjo de sufixos Pos para a palavra T eÂ´ um
arranjo que conteÂ´m a sequÂ¨eË†ncia dos sufixos de T segundo a ordem lexicograÂ´fica (18).
Para a construcÂ¸aËœo do arranjo de sufixos Pos, o alfabeto Î£ precisa ser ordenado com
uma ordem total. Costuma-se adicionar um caractere sentinela $ ao fim de T para garantir
que nenhum sufixo de T eÂ´ prefixo de outro sufixo de T , e que possui a propriedade de ser
ou maior ou menor que qualquer sÂ´Ä±mbolo de Î£.
Como Pos eÂ´ um arranjo de Ä±Â´ndices de posicÂ¸oËœes em T , um arranjo de sufixos usa espacÂ¸o
n log n bits (Î¸(n) bytes). Tipicamente o espacÂ¸o utilizado por um arranjo de sufixos eÂ´ 4n
41
bytes para um processador de 32-bits (para palavras com comprimento de ateÂ´ 4 bilhoËœes
de caracteres).
O arranjo de sufixos Pos para a palavra T pode ser construÂ´Ä±do em tempo Î¸(n) a partir
da aÂ´rvore de sufixos T para T . Alâ€™em disso existem algoritmos Î¸(n) de construcÂ¸aËœo direta
â€“ que naËœo precisam de construir uma aÂ´rvore de sufixos â€“ como os de Ko e Aluru(19), de
KaÂ¨rkkaÂ¨inen e Sanders(20) e Kim et al.(21). AleÂ´m disso existem algoritmos com pior caso
O(n2) que saËœo mais raÂ´pidos que os algoritmos lineares para praticamente todos os casos1.
Os algoritmos de Ko e Aluru e de KaÂ¨rkkaÂ¨inen e Sanders usam as ideÂ´ias introduzidas
por Farach(23) para chegar num algoritmo recursivo que seja Î¸(n) para a construcÂ¸aËœo de
arranjos de sufixos. A ideÂ´ia baÂ´sica eÂ´ particionar a palavra em dois conjuntos de sufixos
e ordenar um desses subconjuntos recursivamente. Feito isso o subconjunto ordenado eÂ´
combinado com o subconjunto naËœo ordenado usando caracterÂ´Ä±sticas do criteÂ´rio de parti-
cionamento para acelerar a ordenacÂ¸aËœo.
Como Pos eÂ´ ordenado lexicograficamente, para pesquisar o padraËœo P em T usamos o
algoritmo de busca binaÂ´ria e realizamos Î¸(m log2 n) comparacÂ¸oËœes para responder se P eÂ´
subpalavra de T . AleÂ´m disso, em caso afirmativo, a resposta da pesquisa nos daÂ´ todos os
sufixos de T do qual P eÂ´ prefixo.
Acrescentamos ao arranjo de sufixos um arranjo chamado lcp. Dado o arranjo de
sufixos Pos para a palavra T = t1...tn, o arranjo lcp eÂ´ um arranjo de n elementos tal que
lcp(i) eÂ´ o comprimento do maior prefixo comum de TPos(i) e TPos(i+1). O arranjo lcp pode
ser construÂ´Ä±do em tempo linear a partir do arranjo de sufixos como descrito em (24). Um
arranjo de sufixos acompanhado do arranjo lcp correspondente tambeÂ´m eÂ´ conhecido como
arranjo de sufixos melhorado (25). Na figura 8 apresentamos o arranjo de sufixos Pos
para a palavra GATGACCA$, e o arranjo lcp correspondente.
OperacÂ¸oËœes de pesquisa de subpalavras de que podem ser realizadas com aÂ´rvores de
sufixos podem ser realizadas com arranjos de sufixos com a complexidade aumentada por
um fator multiplicativo Î¸(log2 n). A tabela LCP pode transformar esse fator numa soma
de Î¸(log2 n) ao inveÂ´s de uma multiplicacÂ¸aËœo.
1Nas medidas de Manzini e Ferragina (22) os uÂ´nicos casos em que a construcÂ¸aËœo linear no pior caso foi
melhor que a contrucÂ¸aËœo linear no caso meÂ´dio foram casos patoloÂ´gicos onde as palavras eram exclusivamente
repeticÂ¸oËœes de pequenas cadeias de caracteres (ou seja, o LCP meÂ´dio entre dois sufixos adjacentes no arranjo
de sufixos era muito alto).
42
Figura 8: Arranjo de sufixos e LCP
4.2 CaÂ´lculo do Comprimento do Maior Prefixo Co-
mum Usando Arranjos de Sufixos
O que permite o algoritmo de Landau e Vishkin manter a complexidade Î¸(kn) de
tempo e espacÂ¸o eÂ´ o caÂ´lculo em tempo constante do comprimento do maior prefixo co-
mum de sufixos do texto e do padraËœo. Mostramos aqui que eÂ´ possÂ´Ä±vel fazer esse mesmo
caÂ´lculo em tempo constante usando arranjos de sufixos melhorados acrescidos de algumas
estruturas de dados, mantendo a complexidade linear na fase de preÂ´-processamento, e
economizando espacÂ¸o.
Dado o arranjo de sufixos melhorado Pos para a palavra P#T$, noÂ´s podemos proces-
sar o arranjo lcp correspondente e responder consultas do comprimento do maior prefixo
comum de sufixos de P#T$ em tempo constante. A chave para essa operacÂ¸aËœo eÂ´ o teorema
que segue.
Teorema 4.2.1. A maior extensaËœo comum LCES,S(a, b) de dois sufixos Sa e Sb de S pode
ser obtido do arranjo lcp da seguinte forma:
Seja i a posicÂ¸aËœo de Sa entre os sufixos ordenados de S (ou seja, Pos(i) = a). Seja j a
posicÂ¸aËœo de Sb entre os sufixos ordenados de S. Podemos assumir que i < j sem perda de
generalidade. EntaËœo a maior extensaËœo comum de Sa e Sb eÂ´ LCE(a, b) = miniâ‰¤k<jlcp(k).
DemonstracÂ¸aËœo. Sejam Sa = sa...sa+c...sn e Sb = sb...sb+c...sn, e seja c = LCE(a, b).
Se i = j âˆ’ 1 entaËœo k = i e LCE(a, b) = c = lcp(i).
43
Se i < j âˆ’ 1 entaËœo selecionamos k tal que lcp(k) eÂ´ o mÄ±Â´nimo valor no intervalo
lcp(i) . . . lcp(j âˆ’ 1). Temos entaËœo dois casos possÂ´Ä±veis:
â€¢ Se c < lcp(k) temos uma contradicÂ¸aËœo porque sa . . . sa+lcp(k)âˆ’1 = sb . . . sb+lcp(k)âˆ’1 pela
definicÂ¸aËœo do arranjo lcp, e o fato que as entradas de lcp correspondem aos sufixos
ordenados de S.
â€¢ se c > lcp(k), seja j = Pos(k) tal que Sj eÂ´ o sufixo associado a` posicÂ¸aËœo k. Sk eÂ´ tal que
sj . . . sj+lcp(k)âˆ’1 = sa . . . sa+lcp(k)âˆ’1 e sj . . . sj+lcp(k)âˆ’1 = sb . . . sb+lcp(k)âˆ’1, mas como
sa . . . sa+câˆ’1 = sb . . . sb+câˆ’1 temos que o arranjo lcp estaria ordenado erroË†neamente
o que eÂ´ uma contradicÂ¸aËœo.
Logo vale LCE(a, b) = c = lcp(k)
Dessa forma reduzimos a busca da maior extensaËœo comum a uma consulta do valor
mÄ±Â´nimo em um intervalo do arranjo lcp. Essa consulta eÂ´ conhecida por RMQ (Range
Minimum Query).
Para resolver a consulta de valor mÄ±Â´nimo num intervalo utilizaremos um algoritmo
baseado em AÂ´rvores Cartesianas apresentadas em 1984 por Gabow, Bentley e Tarjan(26).
Construiremos em Î¸(n) uma aÂ´rvore cartesiana para o arranjo lcp tal que seja possÂ´Ä±vel fazer
a consulta de valor mÄ±Â´nimo de qualquer intervalo em lcp em tempo constante utilizando
uma consulta ao LCA de dois noÂ´s da aÂ´rvore cartesiana em tempo constante.
DefinicÂ¸aËœo 4.2.1 (AÂ´rvores Cartesianas). Uma aÂ´rvore cartesiana C para a sequÂ¨eË†ncia de
nuÂ´meros inteiros x1 . . . xn eÂ´ a aÂ´rvore binaÂ´ria com noÂ´s rotulados por esses nuÂ´meros tal que
a raiz da aÂ´rvore eÂ´ rotulada por m onde xm = min xi | 1 â‰¤ i â‰¤ n, a sub-aÂ´rvore a` esquerda
eÂ´ a aÂ´rvore cartesiana para x1...xmâˆ’1 e a sub-aÂ´rvore a` direita eÂ´ a aÂ´rvore cartesiana para
xm+1 . . . xn. Na figura 9 apresentamos a aÂ´rvore cartesiana para a sequÂ¨eË†ncia de nuÂ´meros
< 1, 1, 0, 1, 0, 2, 0, 0, 0 > que corresponde ao arranjo lcp na figura 8. Acima de cada noÂ´
apresentamos o seu roÂ´tulo, e abaixo o Ä±Â´ndice em lcp correspondente a esse valor.
ProposicÂ¸aËœo 4.2.1. O menor valor num intervalo xi . . . xj pode ser encontrado por uma
busca do LCAC(i, j) de dois noÂ´s i e j da aÂ´rvore cartesiana C construÂ´Ä±da com os valores
do intervalo.
DemonstracÂ¸aËœo. Dados os noÂ´s i e j na aÂ´rvore cartesiana C, e seja v o LCA de i e j, e
suponha que i < j. A estrutura de C eÂ´ tal que se um noÂ´ v = LCA(i, j), entaËœo i â‰¤ v â‰¤ j,
44
Figura 9: AÂ´rvore cartesiana
pois da construcÂ¸aËœo da aÂ´rvore cartesiana todo outro ancestral de v fica ou a` esquerda de i
e j, ou a` direita de ambos. AleÂ´m disso, da construcÂ¸aËœo da aÂ´rvore, o noÂ´ v eÂ´ o noÂ´ tal que xv
eÂ´ o menor valor de sua subaÂ´rvore, e assim encontrar v, ancenstral comum mais profundo
de i e j tambeÂ´m significa encontrar o menor valor xv no intervalo xi . . . xj.
Como jaÂ´ sabemos processar uma aÂ´rvore qualquer em tempo linear para consultar o
LCA de qualquer par de noÂ´s em tempo constante (ver secÂ¸aËœo 3.1.3), o mesmo vale para
uma aÂ´rvore cartesiana.
Precisamos mostrar entaËœo como construir uma aÂ´rvore cartesiana em Î¸(n). Isso pode
ser feito usando o algoritmo mostrado em (26) e (27).
ConstruÂ´Ä±mos a aÂ´rvore cartesiana Ci para o arranjo x1, . . . , xi da aÂ´rvore cartesiana Ciâˆ’1
para o arranjo x1, . . . , xiâˆ’1 da seguinte forma.
â€¢ se i = 1, entaËœo C1 eÂ´ a aÂ´rvore com um uÂ´nico noÂ´ 1 que eÂ´ rotulado por x1.
â€¢ se i > 1, entaËœo construÂ´Ä±mos Ci seguindo o caminho mais a` direita da aÂ´rvore desde a
folha ateÂ´ a raiz, ateÂ´ encontrarmos um noÂ´ k tal que xi â‰¥ xk.
â€¢ uma vez que encontramos o noÂ´ k, definimos que a sub-aÂ´rvore a` esquerda do noÂ´ i
seraÂ´ a sub-aÂ´rvore a` direita de k, e fazemos o noÂ´ i como sendo a sub-aÂ´rvore a` direita
do noÂ´ k.
Acrescentamos cada valor a` aÂ´rvore um valor de cada vez. A cada iteracÂ¸aËœo acrescenta-
mos o novo noÂ´ ao caminho mais a direita comparando-o com os demais noÂ´s desse caminho
ateÂ´ encontrar um noÂ´ cujo roÂ´tulo seja menor que o seu. Observe que se o caminho mais a`
45
direita possui k noÂ´s e se for preciso realizar kâ€² â‰¤ k comparacÂ¸oËœes para acrescentar um noÂ´ i,
na proÂ´xima iteracÂ¸aËœo seraÂ´ necessaÂ´rio fazer no maÂ´ximo kâˆ’kâ€²+1 comparacÂ¸oËœes porque todos
os noÂ´s que estavam nesse caminho e eram maiores que i foram passados para a sub-aÂ´rvore
a` esquerda de i e naËœo seraËœo feitas novas comparacÂ¸oËœes com eles. Ou seja, sempre que for
preciso fazer n + 1 comparacÂ¸oËœes ao acrescentar um noÂ´ a C (com n > 0)), diminuimos o
caminho mais a direita em n noÂ´s e consequÂ¨entemente o nuÂ´mero maÂ´ximo de comparacÂ¸oËœes
para a insercÂ¸aËœo do proÂ´ximo noÂ´. Cada noÂ´ pode ser adicionado ao caminho mais a` direita
no maÂ´ximo uma vez, e sair desse caminho no maÂ´ximo uma vez, o algoritmo executa em
tempo Î¸(n).
Finalmente, para realizar consultas do comprimento do maior prefixo comum em O(1)
apoÂ´s um preÂ´-processamento em Î¸(n) fazemos:
â€¢ Construimos um arranjo de sufixos em Î¸(n) para o texto concatenado com o padraËœo,
usando caracteres sentinelas.
â€¢ Construimos em Î¸(n) a tabela lcp para o arranjo de sufixos, e uma tabela de Ä±Â´ndices
reversos R tal que Pos(R(i)) = i.
â€¢ Construimos em Î¸(n) a aÂ´rvore cartesiana C para a tabela lcp
â€¢ Processamos C em Î¸(n) para respondermos consultas ao LCA de qualquer par de
noÂ´s de C em O(1).
Dados os sufixos i e j (i < j) da palavra P#T$, o comprimento do seu maior prefixo
comum vai ser o menor valor no intervalo of [lcp(R(i)) . . . lcp(R(j) âˆ’ 1)], que seraÂ´ dado
por uma consulta do ancestral comum mais profundo em O(1) na aÂ´rvore cartesiana C.
4.3 O algoritmo proposto
O algoritmo proposto eÂ´ o mesmo algoritmo de Landau e Vishkin, substituindo a aÂ´rvore
de sufixos por um arranjo de sufixos melhorado, e a consulta do LCA na aÂ´rvore de sufixos
por uma consulta do valor mÄ±Â´nimo num intervalo da tabela LCP por meio de uma consulta
de LCA em uma aÂ´rvore cartesiana, que descrevemos como o Algoritmo 3.
46
Algoritmo 3 Algoritmo de Landau e Vishkin Modificado para pesquisa aproximada de
padroËœes
1. ConstruÄ±Â´mos o arranjo de sufixos melhorado Pos para P#T$.
2. ConstruÄ±Â´mos a aÂ´rvore cartesiana C para o arranjo lcp
3. Processamos C em O(n) de forma a responder consultas LCA em O(1).
4. Para cada diagonal i da tabela de programacÂ¸~ao dina^mica,
encontramos o seu 0-caminho de maior alcance
com uma consulta do menor valor no intervalo
correspondente em lcp.
5. Para d = 1 ...k:
5.1 Para cada diagonal i da tabela de programacÂ¸~ao dina^mica:
5.1.1 Estendemos o (dâˆ’ 1)-caminho de maior alcance na diagonal
iâˆ’ 1 uma ceÂ´lula para a direita para a ceÂ´lula D(r, s) na
diagonal i
5.1.2 Estendemos esse caminho ao longo da diagonal i pela
quantidade de ceÂ´lulas igual ao menor valor no intervalo
correspondente de lcp dado pela consulta do LCA em C.
5.1.3 Estendemos o (dâˆ’ 1)-caminho de maior alcance na diagonal i+ 1
uma ceÂ´lula para a baixo para a ceÂ´lula D(râ€², sâ€²) na diagonal i
5.1.4 Estendemos esse caminho ao longo da diagonal i pela
quantidade de ceÂ´lulas igual ao menor valor no intervalo
correspondente de lcp dado pela consulta do LCA em C.
5.1.5 Estendemos o (dâˆ’ 1)-caminho de maior alcance na diagonal i
uma ceÂ´lula ao longo da diagonal i para a ceÂ´lula D(râ€²â€², sâ€²â€²)
5.1.6 Estendemos esse caminho ao longo da diagonal i pela
quantidade de ceÂ´lulas igual ao menor valor no intervalo
correspondente de lcp dado pela consulta do LCA em C.
5.1.7 Escolhemos o d-caminho de maior alcande dentre os tre^s.
6. Cada caminho que alcancÂ¸ar a linha m eÂ´ uma ocorre^ncia de P em T
com no maÂ´ximo k erros.
47
4.4 AnaÂ´lise do algoritmo proposto
Somente a fase de preÂ´-processamento foi significativamente alterada, jaÂ´ que a consulta
ao valor mÄ±Â´nimo num intervalo de lcp continua sendo dado por uma consulta ao LCA em
O(1), que eÂ´ a mesma operacÂ¸aËœo realizada no algoritmo original, acrescida de duas consultas
diretas na tabela R (que conteÂ´m os Ä±Â´ndices reversos que mapeiam os sufixos de P e T na
suas posicÂ¸oËœes em Pos).
Teorema 4.4.1 (Complexidade de tempo e espacÂ¸o do algoritmo modificado). O algoritmo
modificado de Landau e Vishkin para pesquisa aproximada de padroËœes possui complexidade
de tempo e espacÂ¸o Î¸(nk).
DemonstracÂ¸aËœo. Como comentado acima, a construcÂ¸aËœo e manutencÂ¸aËœo de arranjos de sufixos
pode ser feita em Î¸(n) tempo e espacÂ¸o (19, 20, 21) assim como a construcÂ¸aËœo e manutencÂ¸aËœo
de aÂ´rvores cartesianas. Como o preÂ´-processamento para a consulta de LCA em tempo
constante eÂ´ Î¸(n), entaËœo a complexidade do preÂ´-processamento com respeito ao uso de
tempo e espacÂ¸o tambeÂ´m eÂ´ Î¸(n).
O acreÂ´scimo a` fase de iteracÂ¸aËœo saËœo duas consultas O(1) em uma tabela, de forma que
a complexidade da fase de iteracÂ¸aËœo no algoritmo modificado eÂ´ Î¸(kn) > Î¸(n). Dessa forma,
o algoritmo modificado tambeÂ´m usa tempo e espacÂ¸o da ordem Î¸(kn).
Apesar dos limites teoÂ´ricos do algoritmo modificado coincidirem com os do algoritmo
original, a nossa versaËœo utiliza menos espacÂ¸o durante o preÂ´-processamento das palavras T
e P , e tambeÂ´m na execucÂ¸aËœo completa do algoritmo.
Suponha que a implementacÂ¸aËœo da aÂ´rvore de sufixos seja boa o suficiente, como a
implementacÂ¸aËœo de Kurtz, e utilize 12n bytes para a representacÂ¸aËœo da aÂ´rvore de sufixos,
construÂ´Ä±da com 3
2
n noÂ´s. EntaËœo o espacÂ¸o total para o preÂ´-processamento seraÂ´ 12n + S 3
2
n,
onde S eÂ´ o espacÂ¸o por noÂ´ utilizado no preÂ´-processamento para caÂ´lculo do ancestral comum
mais profundo.
Ora, supondo que a implementacÂ¸aËœo da aÂ´rvore de sufixos contenha toda a informacÂ¸aËœo
necessaÂ´ria para o preÂ´-processamento, entaËœo S = SI+SL+SA+Sid, onde SI , SL e SA saËœo os
espacÂ¸os necessaÂ´rios para as funcÂ¸oËœes A, I e L, e Sid o espacÂ¸o necessaÂ´rio para a numeracÂ¸aËœo
dos noÂ´s de T. Usando um inteiro de 32-bits (4 bytes) por entrada em cada uma dessas
tabelas, temos que S = 16 bytes e o uso de espacÂ¸o do preÂ´-processamento com aÂ´rvores de
48
sufixos seraÂ´ 36n bytes.
Para a versaËœo modificada, uma vez construÂ´Ä±da a aÂ´rvore cartesiana, naËœo eÂ´ mais ne-
cessaÂ´ria a manutencÂ¸aËœo do arranjo de sufixos, mas somente do arranjo lcp que usa 4n
bytes, do Ä±Â´ndice reverso R que tambeÂ´m usa 4n bytes e da aÂ´rvore cartesiana que usa 8n
bytes. Como a aÂ´rvore cartesiana tem exatamente n noÂ´s, entaËœo o uso de espacÂ¸o do preÂ´-
processamento para arranjos de sufixos seraÂ´ 4n+8n+4n+16n = 32n que eÂ´ uma economia
de 4n bytes sobre a versaËœo original.
Quanto ao tempo de execucÂ¸aËœo, em primeiro lugar eÂ´ preciso comparar a construcÂ¸aËœo da
aÂ´rvore de sufixos com a do arranjo de sufixos, porque as construcÂ¸oËœes do arranjo lcp e da
aÂ´rvore cartesiana saËœo muito mais raÂ´pidas que a do arranjo de sufixos. O preÂ´-processamento
da aÂ´rvore cartesiana eÂ´ mais raÂ´pido que o da aÂ´rvore de sufixos, pois haÂ´ menos noÂ´s para
serem processados. Em contrapartida entendemos que a fase iteracÂ¸aËœo execute um pouco
mais raÂ´pido com a versaËœo original porque nesse caso naËœo saËœo necessaÂ´rias as duas consultas
ao Ä±Â´ndice reverso do sufixo de P e do sufixo de T para os quais estamos calculando o
LCE.
49
5 AnaÂ´lise Experimental
Como anaÂ´lise experimental avaliamos o comportamento da versaËœo original e da versaËœo
modificada do algoritmo de Landau e Vishkin.
Os primeiros experimentos foram realizados com dados gerados de forma aleatoÂ´ria.
Geramos vaÂ´rias palavras e padroËœes de tamanhos crescentes com quatros alfabetos de
tamanhos distintos â€” |Î£| = 2, |Î£| = 4, |Î£| = 26 e |Î£| = 93 â€” valores que representam os
tamanhos dos alfabetos binaÂ´rio, quartenaÂ´rio (RNA e DNA), alfabeto da lÂ´Ä±ngua inglesa e
caracteres ASCII que podem ser impressos (que neste trabalho chamamos de ASCII93).
Para os dados reais, dividimos a anaÂ´lise em duas partes. Na primeira parte usamos
textos e sequÂ¨eË†ncias retiradas do projeto Gutenberg (28), do NCBI Genbank (29) e do
corpus de Canterbury (30). Na segunda parte selecionamos sequÂ¨eË†ncias bioloÂ´gicas de
escala cromossoË†mica (por exemplo, todo o cDNA do cromossomo 22 do H. sapiens) e
fizemos pesquisas de porcÂ¸oËœes de cDNA nessas sequÂ¨eË†ncias usando as variantes que usam
espacÂ¸o Î¸(n) dos algoritmos.
5.1 ImplementacÂ¸oËœes utilizadas
Buscamos utilizar implementacÂ¸oËœes eficientes para as estruturas de dados. Em especial,
usamos para a aÂ´rvore de sufixos a implementacÂ¸aËœo na linguagem de programacÂ¸aËœo C de
Kurtz que eÂ´ usada em um programa de alinhamento de genomas, e para arranjos de
sufixos a implementacÂ¸aËœo de Manzini e Ferragina da ordenacÂ¸aËœo de sufixos de uma palavra
(tambeÂ´m escrita na linguagem C). O arranjo lcp foi implementado na linguagem C++ pelo
autor a partir de (24), e as demais estruturas de dados e algoritmos foram implementados
pelo autor em C++.
50
5.1.1 AÂ´rvore de sufixos
A implementacÂ¸aËœo da aÂ´rvore de sufixos utilizada foi a implementacÂ¸aËœo de Kurtz para o
software MUMMER 3.0 (15) (31), que utiliza as teÂ´cnicas descritas em (13) para diminuir
o uso de espacÂ¸o da estrutura de dados. O algoritmo utilizado para a construcÂ¸aËœo de aÂ´rvores
de sufixos eÂ´ o de McCreight (11). O coÂ´digo foi compilado com a opcÂ¸aËœo HUGE que prepara a
aÂ´rvore de sufixos para aceitar palavras maiores que 128 megabytes, ao custo de um espacÂ¸o
adicional, aumentando de cerca de 12 bytes por caractere para 15 bytes por caractere na
construcÂ¸aËœo de aÂ´rvores de sufixos para palavras com |Î£| = 4. Foi preciso realizar algumas
modificacÂ¸oËœes pequenas no coÂ´digo para que a busca em profundidade funcionasse como
esperado, pois a busca em profundidade como estava implementada naËœo fazia a visita
inicial a` raiz da aÂ´rvore.
A implementacÂ¸aËœo eÂ´ bastante eficiente na execucÂ¸aËœo e no uso de espacÂ¸o, mas por isso foi
necessaÂ´rio acrescentar um pouco mais de informacÂ¸oËœes a` estrutura que eÂ´ gerada durante a
fase de preÂ´-processamento do algoritmo de Landau e Vishkin. AleÂ´m das estruturas tÂ´Ä±picas
descritas na secÂ¸aËœo 3.1.3(tabelas I, L, A e de roÂ´tulos dos noÂ´s), foi necessaÂ´rio um arranjo
com os ponteiros para os noÂ´s pais de cada noÂ´ e mais um arranjo com os roÂ´tulos dos noÂ´s
pais, porque o resultado do caÂ´lculo LCA(v, w) eÂ´ o roÂ´tulo na pesquisa em profundidade
do noÂ´ que eÂ´ o LCA de v e w. A implementacÂ¸aËœo utilizada tambeÂ´m naËœo expoËœe diretamente
todos os noÂ´s da aÂ´rvore, mas apenas as folhas. Essa caracterÂ´Ä±stica faz com que o caÂ´lculo
LCA(v, w) em O(1) implementado funcione apenas se tanto v quanto w forem folhas de
T. Como esse eÂ´ exatamente o caso, naËœo causou maiores impactos no algoritmo de Landau
e Vishkin, mas para uma utilizacÂ¸aËœo diferente que precise calcular o LCA de noÂ´s arbitraÂ´rios
seria necessaÂ´rio uma implementacÂ¸aËœo mais complexa e que usasse espacÂ¸o adicional para
mapear os noÂ´s internos da aÂ´rvore. Assim, sendo n o comprimento de T#P$ e v o nuÂ´mero
de noÂ´s de T, o espacÂ¸o total para o preÂ´-processamento foi de 20v + 4n + ST, onde ST eÂ´ o
espacÂ¸o usado pela aÂ´rvore de sufixos em si. Se assumirmos que ST = 12n e v =
3
2
n, entaËœo
o espacÂ¸o usado no preÂ´-processamento seria 46n bytes. Na praÂ´tica o caÂ´lculo exato eÂ´ difÂ´Ä±cil
de determinar, pois a quantidade de noÂ´s da aÂ´rvore depende do alfabeto utilizado e da
estrutura da palavra indexada pela aÂ´rvore de sufixos â€” em especial quando |Î£| eÂ´ grande,
a aÂ´rvore de sufixos tende a precisar de menos noÂ´s. O uso de espacÂ¸o na implementacÂ¸aËœo
utilizada eÂ´ de 14n a 15n para alfabetos pequenos (DNA, RNA) e 10n a 11n para alfabetos
maiores (ASCII). Na secÂ¸aËœo 5.2 seraÂ´ apresentada a avaliacÂ¸aËœo realizada para alguns valores
de v.
51
5.1.2 Arranjos de sufixos
A escolha de implementacÂ¸aËœo da construcÂ¸aËœo arranjo de sufixos vai influenciar a veloci-
dade total do algoritmo, mas naËœo o uso de espacÂ¸o, porque o espacÂ¸o utilizado pelo arranjo
Pos eÂ´ fixo em 4n bytes como descrito na secÂ¸aËœo 4.1, e naËœo eÂ´ influenciado pelo alfabeto ou
a estrutura da palavra. ApoÂ´s a construcÂ¸aËœo do arranjo lcp e do Ä±Â´ndice reverso, o arranjo
Pos naËœo eÂ´ mais necessaÂ´rio e pode ser descartado. A aÂ´rvore cartesiana usa exatamente 8n
bytes e mais 4n bytes para o arranjo lcp. O Ä±Â´ndice reverso â€” necessaÂ´rio para mapear um
sufixo de T#P$ em lcp â€” usa 4n bytes. A estrutura do preÂ´-processamento adiciona um
fator de 20n bytes perfazendo um total de 36n bytes.
5.1.3 Usando algoritmos que melhoram o caso meÂ´dio
Uma avaliacÂ¸aËœo da literatura sobre arranjos de sufixos apresentou alguns resultados
interessantes. Existem meÂ´todos de construcÂ¸aËœo direta dos arranjos de sufixos com com-
plexidade linear para o pior caso, como os algoritmos propostos por Ko e Aluru(19),
KaÂ¨rkkaÂ¨inen e Sanders(20) e Kim et al.(21). Num estudo realizado por Puglisi, Smyth e
Turpin(32) vaÂ´rios algoritmos de construcÂ¸aËœo de arranjos de sufixos de complexidade linear
e linear no caso meÂ´dio foram avaliados e os autores verificaram que, em praticamente
todos os casos, algoritmos cujo pior caso eÂ´ quadraÂ´tico mas que no caso meÂ´dio saËœo lineares
teË†m desempenho bem melhor que os algoritmos lineares no pior caso. Esses algoritmos
costumam se comportar mal em casos patoloÂ´gicos, em que o valor meÂ´dio do arranjo lcp
eÂ´ alto relativo ao texto (ou seja o texto eÂ´ composto por muitas repeticÂ¸oËœes). Dentre esses
algoritmos escolhemos o Deep-Shallow Sort, desenvolvido por Manzini e Ferragina(22).
O algoritmo Deep-Shallow Sort se caracteriza por dividir a ordenacÂ¸aËœo dos sufixos de
T em duas fases. Na primeira fase, chamada de fase rasa (shallow) ordena os sufixos de
T com base nos seus prefixos de ateÂ´ L caracteres usando o algoritmo multikey quicksort
de Bentley e Sedgewick(33). Nesse ponto temos todos os sufixos de T ordenados ateÂ´
o seu L-eÂ´simo caractere. Na segunda fase, chamada de profunda (deep), utiliza-se uma
combinacÂ¸aËœo de dois algoritmos, blind sorting, apresentado por Ferragina e Grossi em (34) e
ternary quicksort apresentado por Bentley e McIlroy em (35), de forma a usar o algoritmo
mais eficiente para as palavras que estaËœo sendo ordenadas em cada passo do algoritmo.
A implementacÂ¸aËœo utilizada eÂ´ a implementacÂ¸aËœo em linguagem C de Manzini e Ferra-
gina(22).
52
5.1.4 Diminuindo mais o uso de espacÂ¸o
Analisando com cuidado a implementacÂ¸aËœo da aÂ´rvore cartesiana, percebemos que apoÂ´s
o preÂ´-processamento a mesma naËœo eÂ´ mais necessaÂ´ria, de forma que o uso de espacÂ¸o cairia
para 28n bytes, usados basicamente para o arranjo lcp, o Ä±Â´ndice reverso (4n cada) e as
estruturas de preÂ´-processamento para a consulta LCA em tempo constante. Acreditamos
ser possÂ´Ä±vel fazer uma economia similar para versaËœo baseada em aÂ´rvores de sufixos para
reduzir o espacÂ¸o final para 30n a 36n bytes, mantendo o pico de uso de espacÂ¸o da ordem
de 41n a 51n bytes. O pico do uso de espacÂ¸o para o preÂ´-processamento de arranjos de
sufixos continua sendo 36n bytes. A implementacÂ¸aËœo baseada em aÂ´rvores de sufixos aqui
descrita naËœo incluiu essa modificacÂ¸aËœo.
5.2 AnaÂ´lise e ComparacÂ¸aËœo de resultados
Para fazer a anaÂ´lise experimental, foram usados dados gerados aleatoriamente e dados
reais retirados do Projeto Gutenberg (28), NCBI Genbank (29) e do corpus de Canterbury
(30). O uso duas massas de dados com caracterÂ´Ä±sticas diferentes quanto a` distribuicÂ¸aËœo dos
caracteres permite uma anaÂ´lise de como o algoritmo tende a se comportar em situacÂ¸oËœes
diversas.
Observe que com relacÂ¸aËœo aos valores percentuais apresentados, o valor de refereË†ncia
(100%) seraÂ´ sempre o valor do algoritmo de Landau e Vishkin original (baseado em aÂ´rvores
de sufixos).
5.2.1 Ambiente computacional
Os testes experimentais foram executados em um computador DELL PowerEdge 1800
com 2 GB de memoÂ´ria RAM e processador Intel Xeon de 3.0 GHz com 2MB de cache L2
e acesso a` memoÂ´ria controlado por um FSB de 800MHz. O sistema operacional utilizado
foi o Red Hat Enterprise Linux usando Linux 2.6.9-5, com compilador gcc versaËœo 3.4.3 e
biblioteca glibc versaËœo 2.3.4-2. AleÂ´m disso, para o gerador de palavras aleatoÂ´rias usamos
um programa python rodando em uma VM Python 2.3.4, usando o dispositivo provedor
de entropia /dev/random e o algoritmo de geracÂ¸aËœo de nuÂ´meros pseudo aleatoÂ´riosMersenne
Twister.
53
5.2.2 Dados aleatoÂ´rios
Optamos por executar 5 seÂ´ries de testes aleatoÂ´rios para quatro tamanhos de alfabeto,
a saber 2 (binaÂ´rio), 4 (DNA), 26 (alfabeto) e 93 (caracteres ASCII93 ). As seÂ´ries saËœo
baseadas no tamanho do texto utilizado na pesquisa aproximada e o nuÂ´mero maÂ´ximo de
erros permitidos. As seÂ´ries utilizadas foram de:
â€¢ 1000 a 10.000 caracteres, em intervalos de 1000 caracteres, usando padraËœo de 100
caracteres.
â€¢ 10.000 a 100.000 caracteres, em intervalos de 10.000 caracteres, usando padraËœo de
100 caracteres.
â€¢ 100.000 a 1.000.000 caracteres, em intervalos de 100.000 caracteres, usando padraËœo
de 1.000 caracteres.
â€¢ 1.000.000 a 10.000.000 caracteres, em intervalos de 1.000.000 caracteres, usando
padraËœo de 1.000 caracteres.
â€¢ 11.000.000 a 20.000.000 caracteres, em intervalos de 1.000.000 caracteres, usando
padraËœo de 10.000 caracteres.
Para cada tamanho de texto de cada seÂ´rie foram gerados 5 arquivos aleatoÂ´rios de
cada alfabeto, e o uso de memoÂ´ria e tempo de execucÂ¸aËœo informados saËœo a meÂ´dia dos dados
recolhidos desses 5 arquivos. Como para palavras de tamanho pequeno as diferencÂ¸as
naËœo saËœo significativas, apresentamos nas tabelas e graÂ´ficos apenas os resultados para n â‰¥
1.000.000. Nas tabelas 1, 2, 3 e 4 temos a comparacÂ¸aËœo com ponto de vista de uso de espacÂ¸o
para o algoritmo que usa a construcÂ¸aËœo de aÂ´rvore de sufixos no seu preÂ´-processamento e o
algoritmo que usa arranjos de sufixos para seu preÂ´-processamento.
A comparacÂ¸aËœo de tempo foi dividida em duas tabelas para cada tamanho de alfabeto,
uma tabela para o tempo de execucÂ¸aËœo, e outra para o tempo do processador. EÂ´ importante
fazer a distincÂ¸aËœo entre essas duas medidas para que os resultados sejam interpretados
corretamente:
â€¢ Por tempo de execucÂ¸aËœo entendemos a medida de tempo total que o algoritmo levou
para ser executado com sucesso no ambiente computacional. O tempo de execucÂ¸aËœo
pode ser afetado por outros programas executando no sistema, pelo uso de memoÂ´ria
virtual, carga de processamento da maÂ´quina e eventos e originados pelo sistema
operacional ou outros programas que interrompam a execucÂ¸aËœo do programa.
54
â€¢ Por tempo do processador entendemos o tempo de uso do processador que o algo-
ritmo usou no seu processamento. O tempo do processador eÂ´ equivalente ao tempo
que o algoritmo total usaria se fosse o uÂ´nico programa em execucÂ¸aËœo no sistema e
todos os dados utilizados coubessem na memoÂ´ria principal, e naËœo sofre influeË†ncia de
eventos externos ao programa que interrompam a sua execucÂ¸aËœo.
Nos experimentos realizados, o computador estava dedicado a` execucÂ¸aËœo de nossos
experimentos, de forma que diferencÂ¸as significativas entre tempo de processador e tempo
de execucÂ¸aËœo coletados dizem respeito ao uso de memoÂ´ria virtual.
As tabelas 6, 8, 10 e 12 apresentam as comparacÂ¸oËœes do ponto de vista do tempo do
processador, enquanto as tabelas 9, 7, 11 e 13 apresentam as comparacÂ¸oËœes do ponto de
vista do tempo de execucÂ¸aËœo.
As tabelas 1, 2, 3 e 4 que descrevem o uso de espacÂ¸o estaËœo estruturadas da seguinte
forma:
â€¢ Uma coluna descrevendo o tamanho do problema â€” N â€” para a execucÂ¸aËœo do algo-
ritmo, contado em milhares de caracteres
â€¢ Quatro colunas descrevendo o uso de espacÂ¸o para a implementacÂ¸aËœo baseada em
arranjos de sufixos e quatro para a baseada em aÂ´rvores de sufixos, nessa ordem,
sendo que essas quatro colunas estaËœo dispostas da seguinte forma:
â€“ Duas colunas descrevendo o espacÂ¸o utilizado apoÂ´s o teÂ´rmino da fase de preÂ´-
processamento, descrevendo a quantidade total de KBytes (KB) e a quantidade
em bytes por caractere (Bpc).
â€“ Duas colunas descrevendo o uso de espacÂ¸o total do algoritmo de Landau e
Vishkin â€“ incluindo o espacÂ¸o utilizado pela fase de preÂ´-processamento â€“ des-
crevendo a quantidade total de KBytes (KB) e a quantidade em bytes por
caractere (Bpc).
â€¢ Quatro colunas descrevendo a diferencÂ¸a no uso de espacÂ¸o, sendo:
â€“ Duas colunas com a diferencÂ¸a do uso de espacÂ¸o da implementacÂ¸aËœo baseada em
aÂ´rvores de sufixos e o uso de espacÂ¸o da implementacÂ¸aËœo baseada em arranjos de
sufixos, em KBytes e bytes por caractere, onde um valor positivo indica que o
uso de espacÂ¸o da versaËœo baseada em aÂ´rvores de sufixos eÂ´ maior.
55
Tabela 1: Uso de espacÂ¸o para |Î£| = 93, k = 20
Arranjo de Sufixos AÂ´rvore de Sufixos Economia de EspacÂ¸o
Pre-proc Total Pre-proc Total bytes Bpc Pre-Proc Total
N (Ã—1000) KB Bpc. KB Bpc KB Bpc KB Bpc
1.000 27.371 28 86.943 89 38.872 40 98.444 101 11.501 12 29,59% 11,68%
2.000 54.715 28 173.858 89 78.402 40 197.545 101 23.687 12 30,21% 11,99%
3.000 82.059 28 260.772 89 112.889 39 291.602 100 30.830 11 27,31% 10,57%
4.000 109.402 28 347.686 89 144.432 37 382.715 98 35.029 9 24,25% 9,15%
5.000 136.746 28 434.600 89 174.889 36 472.742 97 38.143 8 21,81% 8,07%
6.000 164.090 28 521.514 89 205.161 35 562.585 96 41.072 7 20,02% 7,30%
7.000 191.434 28 608.428 89 235.634 34 652.628 95 44.200 6 18,76% 6,77%
8.000 218.777 28 695.342 89 266.429 34 742.993 95 47.651 6 17,89% 6,41%
9.000 246.121 28 782.256 89 297.581 34 833.716 95 51.460 6 17,29% 6,17%
10.000 273.465 28 869.170 89 329.169 34 924.874 95 55.704 6 16,92% 6,02%
11.000 301.055 28 956.330 89 361.381 34 1.016.656 95 60.326 6 16,69% 5,93%
12.000 328.399 28 1.043.244 89 393.703 34 1.108.548 95 65.304 6 16,59% 5,89%
13.000 355.742 28 1.130.158 89 426.370 34 1.200.786 95 70.628 6 16,56% 5,88%
14.000 383.086 28 1.217.072 89 459.403 34 1.293.390 95 76.317 6 16,61% 5,90%
15.000 410.430 28 1.303.986 89 492.793 34 1.386.350 95 82.363 6 16,71% 5,94%
16.000 437.774 28 1.390.900 89 526.522 34 1.479.649 95 88.749 6 16,86% 6,00%
17.000 465.117 28 1.477.815 89 560.489 34 1.573.187 95 95.372 6 17,02% 6,06%
18.000 492.461 28 1.564.729 89 594.882 34 1.667.149 95 102.421 6 17,22% 6,14%
19.000 519.805 28 1.651.643 89 629.554 34 1.761.392 95 109.749 6 17,43% 6,23%
20.000 547.149 28 1.738.557 89 664.506 34 1.855.915 95 117.358 6 17,66% 6,32%
Tabela 2: Uso de espacÂ¸o para |Î£| = 26, k = 20
Arranjo de Sufixos AÂ´rvore de Sufixos Economia de EspacÂ¸o
Pre-proc Total Pre-proc Total bytes Bpc Pre-Proc Total
N (Ã—1000) KB Bpc. KB Bpc KB Bpc KB Bpc
1.000 27.371 28 86.943 89 40.829 42 100.402 103 13.458 14 32,96% 13,40%
2.000 54.715 28 173.858 89 77.724 40 196.867 101 23.009 12 29,60% 11,69%
3.000 82.059 28 260.772 89 112.830 38 291.543 99 30.771 10 27,27% 10,55%
4.000 109.402 28 347.686 89 148.997 38 387.280 99 39.594 10 26,57% 10,22%
5.000 136.746 28 434.600 89 186.654 38 484.508 99 49.908 10 26,74% 10,30%
6.000 164.090 28 521.514 89 225.621 38 583.045 99 61.531 10 27,27% 10,55%
7.000 191.434 28 608.428 89 265.680 39 682.674 100 74.246 11 27,95% 10,88%
8.000 218.777 28 695.342 89 306.579 39 783.144 100 87.802 11 28,64% 11,21%
9.000 246.121 28 782.256 89 348.167 40 884.302 101 102.046 12 29,31% 11,54%
10.000 273.465 28 869.170 89 390.300 40 986.006 101 116.836 12 29,93% 11,85%
11.000 301.055 28 956.330 89 433.174 40 1.088.449 101 132.119 12 30,50% 12,14%
12.000 328.399 28 1.043.244 89 475.847 41 1.190.693 102 147.449 13 30,99% 12,38%
13.000 355.742 28 1.130.158 89 518.654 41 1.293.070 102 162.911 13 31,41% 12,60%
14.000 383.086 28 1.217.072 89 561.515 41 1.395.501 102 178.429 13 31,78% 12,79%
15.000 410.430 28 1.303.986 89 604.317 41 1.497.873 102 193.887 13 32,08% 12,94%
16.000 437.774 28 1.390.900 89 647.032 41 1.600.159 102 209.258 13 32,34% 13,08%
17.000 465.117 28 1.477.815 89 689.596 42 1.702.293 102 224.479 14 32,55% 13,19%
18.000 492.461 28 1.564.729 89 731.948 42 1.804.216 103 239.487 14 32,72% 13,27%
19.000 519.805 28 1.651.643 89 774.101 42 1.905.939 103 254.296 14 32,85% 13,34%
20.000 547.149 28 1.738.557 89 816.031 42 2.007.439 103 268.882 14 32,95% 13,39%
â€“ Duas colunas indicando a porcentagem que espacÂ¸o economizado representa do
espacÂ¸o utilizado pela implementacÂ¸aËœo baseada em aÂ´rvores de sufixos para o preÂ´-
processamento e para o uso total de espacÂ¸o do algoritmo
As figuras 10, 11, 12 e 13 apresentam de forma graÂ´fica a diferencÂ¸a no uso de espacÂ¸o
no preÂ´-processamento e total paras palavras usadas com mais de 1.000.000 de caracteres.
Analisando as tabelas e os graÂ´ficos de uso de espacÂ¸o vemos que consistentemente a
implementacÂ¸aËœo do algoritmo modificado usou menos espacÂ¸o. A diferencÂ¸a eÂ´ maior para
alfabetos pequenos, chegando a ser de 45% para a fase de preÂ´-processamento quando
|Î£| = 4. A economia de espacÂ¸o para o algoritmo completo (preÂ´-processamento e iteracÂ¸aËœo)
eÂ´ menor, e percebe-se que na medida em que o valor do paraË†metro k aumenta, o efeito
dessa economia de espacÂ¸o na execucÂ¸aËœo completa do algoritmo fica menos significativa.
56
Tabela 3: Uso de espacÂ¸o para |Î£| = 4, k = 20
Arranjo de Sufixos AÂ´rvore de Sufixos Economia de EspacÂ¸o
Pre-proc Total Pre-proc Total bytes Bpc Pre-Proc Total
N (Ã—1000) KB Bpc. KB Bpc KB Bpc KB Bpc
1.000 27.371 28 86.943 89 50.381 52 109.953 112 23.010 24 45,67% 20,93%
2.000 54.715 28 173.858 89 100.623 51 219.765 112 45.908 23 45,62% 20,89%
3.000 82.059 28 260.772 89 151.093 52 329.806 113 69.034 24 45,69% 20,93%
4.000 109.402 28 347.686 89 201.362 52 439.646 113 91.960 24 45,67% 20,92%
5.000 136.746 28 434.600 89 251.497 51 549.351 112 114.751 23 45,63% 20,89%
6.000 164.090 28 521.514 89 301.668 51 659.092 112 137.578 23 45,61% 20,87%
7.000 191.434 28 608.428 89 351.953 51 768.947 112 160.519 23 45,61% 20,88%
8.000 218.777 28 695.342 89 402.339 51 878.904 112 183.562 23 45,62% 20,89%
9.000 246.121 28 782.256 89 452.816 52 988.951 113 206.695 24 45,65% 20,90%
10.000 273.465 28 869.170 89 503.337 52 1.099.042 113 229.872 24 45,67% 20,92%
11.000 301.055 28 956.330 89 554.249 52 1.209.524 112 253.194 24 45,68% 20,93%
12.000 328.399 28 1.043.244 89 604.684 52 1.319.530 113 276.285 24 45,69% 20,94%
13.000 355.742 28 1.130.158 89 655.028 52 1.429.444 113 299.286 24 45,69% 20,94%
14.000 383.086 28 1.217.072 89 705.353 52 1.539.339 113 322.267 24 45,69% 20,94%
15.000 410.430 28 1.303.986 89 755.579 52 1.649.135 113 345.149 24 45,68% 20,93%
16.000 437.774 28 1.390.900 89 805.808 52 1.758.935 113 368.034 24 45,67% 20,92%
17.000 465.117 28 1.477.815 89 855.938 52 1.868.636 112 390.821 24 45,66% 20,91%
18.000 492.461 28 1.564.729 89 906.086 52 1.978.353 112 413.625 24 45,65% 20,91%
19.000 519.805 28 1.651.643 89 956.233 52 2.088.071 112 436.429 24 45,64% 20,90%
20.000 547.149 28 1.738.557 89 1.006.329 51 2.197.737 112 459.180 23 45,63% 20,89%
Tabela 4: Uso de espacÂ¸o para |Î£| = 2, k = 20
Arranjo de Sufixos AÂ´rvore de Sufixos Economia de EspacÂ¸o
Pre-proc Total Pre-proc Total bytes Bpc Pre-Proc Total
N (Ã—1000) KB Bpc. KB Bpc KB Bpc KB Bpc
1.000 27.371 28 86.943 89 61.897 63 121.470 124 34.526 35 55,78% 28,42%
2.000 54.715 28 173.858 89 123.733 63 242.876 124 69.018 35 55,78% 28,42%
3.000 82.059 28 260.772 89 185.574 63 364.287 124 103.515 35 55,78% 28,42%
4.000 109.402 28 347.686 89 247.409 63 485.693 124 138.007 35 55,78% 28,41%
5.000 136.746 28 434.600 89 309.242 63 607.096 124 172.496 35 55,78% 28,41%
6.000 164.090 28 521.514 89 371.080 63 728.503 124 206.990 35 55,78% 28,41%
7.000 191.434 28 608.428 89 432.912 63 849.906 124 241.478 35 55,78% 28,41%
8.000 218.777 28 695.342 89 494.749 63 971.313 124 275.972 35 55,78% 28,41%
9.000 246.121 28 782.256 89 556.582 63 1.092.717 124 310.461 35 55,78% 28,41%
10.000 273.465 28 869.170 89 618.427 63 1.214.132 124 344.962 35 55,78% 28,41%
11.000 301.055 28 956.330 89 680.825 63 1.336.100 124 379.770 35 55,78% 28,42%
12.000 328.399 28 1.043.244 89 742.659 63 1.457.504 124 414.260 35 55,78% 28,42%
13.000 355.742 28 1.130.158 89 804.498 63 1.578.914 124 448.756 35 55,78% 28,42%
14.000 383.086 28 1.217.072 89 866.329 63 1.700.316 124 483.243 35 55,78% 28,42%
15.000 410.430 28 1.303.986 89 928.166 63 1.821.723 124 517.737 35 55,78% 28,42%
16.000 437.774 28 1.390.900 89 989.990 63 1.943.117 124 552.216 35 55,78% 28,42%
17.000 465.117 28 1.477.815 89 1.051.840 63 2.064.537 124 586.723 35 55,78% 28,42%
18.000 492.461 28 1.564.729 89 1.113.673 63 2.185.941 124 621.212 35 55,78% 28,42%
19.000 519.805 28 1.651.643 89 1.175.505 63 2.307.343 124 655.700 35 55,78% 28,42%
20.000 547.149 28 1.738.557 89 1.237.345 63 2.428.753 124 690.196 35 55,78% 28,42%
57
Tabela 5: Uso espacÂ¸o nas aÂ´rvores de sufixo
Î£ |Î£| # noÂ´s EspacÂ¸o T EspacÂ¸o PreÂ´-proc T EspacÂ¸o PreÂ´-proc SA
BinaÂ´rio 2 1.8n 19n 63n 28n
DNA 4 1.6n 15n 51n 28n
Alfabeto 26 1.3n 10n 40n 28n
Caracteres ASCII93 93 1.2n 9n 37n 28n
Figura 10: GraÂ´fico de uso de espacÂ¸o |Î£| = 93, k = 20
Observe que o uso de espacÂ¸o da aÂ´rvore de sufixos depende da estrutura da palavra
e do alfabeto utilizado. Compilamos na tabela 5 a relacÂ¸aËœo encontrada entre o alfabeto
utilizado e a estrutura da aÂ´rvore de sufixos construÂ´Ä±da, incluindo nuÂ´mero total de noÂ´s e
espacÂ¸o utilizado por caractere para a aÂ´rvore de sufixos e para a estrutura gerada pelo
preÂ´-processamento para caÂ´lculo do LCA. Os valores foram obtidos a partir dos valores
meÂ´dios para cada alfabeto. A coluna EspacÂ¸o PreÂ´-proc SA descreve o espacÂ¸o utilizado pela
versaËœo baseada em arranjos de sufixos para comparacÂ¸aËœo.
Como descrito na secÂ¸aËœo 5.1.1 a implementacÂ¸aËœo de aÂ´rvore de sufixos utilizada foi a de
Kurtz usada no software MUMMER (15). Os valores apresentados na tabela 5 saËœo os
valores meÂ´dios para o uso de espacÂ¸o, aproximados para o nuÂ´mero inteiro mais proÂ´ximo.
Para alfabetos pequenos, a aÂ´rvore de sufixos usa mais espacÂ¸o. EÂ´ interessante comentar
que para o caso do alfabeto grande (na tabela, os caracteres ASCII93), o uso de espacÂ¸o
eÂ´ tal que, descartada a aÂ´rvore de sufixos, o espacÂ¸o final ficaria praticamente igual ao da
versaËœo baseada em arranjos de sufixos. Entretanto verificamos que para esses casos o
58
Figura 11: GraÂ´fico de uso de espacÂ¸o |Î£| = 26, k = 20
Figura 12: GraÂ´fico de uso de espacÂ¸o |Î£| = 4, k = 20
59
Figura 13: GraÂ´fico de uso de espacÂ¸o |Î£| = 2, k = 20
tempo de preÂ´-processamento eÂ´ bem maior na versaËœo baseada em aÂ´rvores de sufixos que na
versaËœo baseada em arranjos de sufixos, e para k = 20 fez com que o tempo de processador
do algoritmo original fosse maior que o do modificado.
As tabelas 6, 7, 8, 9, 10, 11, 12 e 13 que descrevem o comportamento do algoritmo
com relacÂ¸aËœo a tempo de execucÂ¸aËœo e de processador estaËœo estruturadas da seguinte forma:
â€¢ Uma coluna descrevendo o tamanho do problema (N) para a execucÂ¸aËœo do algoritmo.
â€¢ Duas colunas descrevendo o tempo para a implementacÂ¸aËœo baseada em arranjos de
sufixos e duas para a baseada em aÂ´rvores de sufixos, nessa ordem, sendo uma coluna
para a fase de preÂ´-processamento e uma coluna para a execucÂ¸aËœo total do algoritmo.
â€¢ Duas colunas com a diferencÂ¸a percentual do tempo da implementacÂ¸aËœo baseada em
aÂ´rvores de sufixos e da implementacÂ¸aËœo baseada em arranjos de sufixos, para o preÂ´-
processamento e o algoritmo completo, sendo que um valor positivo em uma linha
indica que o tempo de execucÂ¸aËœo para a versaËœo baseada em aÂ´rvores de sufixos foi
maior.
Analisando as tabelas com os resultados de tempo de execucÂ¸aËœo podemos fazer duas
observacÂ¸oËœes interessantes:
60
Tabela 6: Tempo do Processador para |Î£| = 93, k = 20
Arranjo de Sufixos AÂ´rvore de sufixos DiferencÂ¸a
N (Ã—1000) Pre-Proc Total Pre-Proc Total Pre-Proc Total
1.000 0,606 3,440 4,460 7,246 86% 53%
2.000 1,380 7,132 13,410 19,022 90% 63%
3.000 2,178 10,858 23,066 31,494 91% 66%
4.000 3,010 14,612 32,540 43,790 91% 67%
5.000 3,820 18,394 41,890 55,976 91% 67%
6.000 4,602 22,086 51,134 68,034 91% 68%
7.000 5,410 25,824 60,560 80,248 91% 68%
8.000 6,298 29,714 70,030 92,652 91% 68%
9.000 7,082 33,398 80,020 105,352 91% 68%
10.000 7,928 38,318 89,730 117,806 91% 67%
11.000 10,453 44,127 99,773 131,660 90% 66%
12.000 9,620 45,523 109,787 144,953 91% 69%
13.000 10,567 50,343 119,863 157,993 91% 68%
14.000 11,403 53,230 131,540 172,010 91% 69%
15.000 12,183 56,917 140,597 184,013 91% 69%
16.000 13,080 61,817 151,527 199,650 91% 69%
17.000 14,010 68,957 162,197 217,063 91% 68%
18.000 14,887 75,177 176,477 233,283 92% 68%
19.000 15,653 80,423 184,423 246,800 92% 67%
20.000 16,680 84,923 195,453 260,883 91% 67%
Tabela 7: Tempo de ExecucÂ¸aËœo para |Î£| = 93, k = 20
Arranjo de Sufixos AÂ´rvore de sufixos DiferencÂ¸a
N (Ã—1000) Pre-Proc Total Pre-Proc Total Pre-Proc Total
1.000 0,608 3,442 4,465 7,252 86% 53%
2.000 1,385 7,137 13,412 19,028 90% 62%
3.000 2,183 10,863 23,070 31,499 91% 66%
4.000 3,014 14,616 32,543 43,793 91% 67%
5.000 3,826 18,400 41,896 55,980 91% 67%
6.000 4,604 22,088 51,139 68,040 91% 68%
7.000 5,412 25,826 60,563 80,251 91% 68%
8.000 6,301 29,717 70,032 92,656 91% 68%
9.000 7,084 33,400 80,026 105,354 91% 68%
10.000 7,931 38,321 89,733 117,808 91% 67%
11.000 10,456 44,337 99,785 131,679 90% 66%
12.000 9,628 45,531 109,801 144,968 91% 69%
13.000 10,569 50,352 119,876 158,005 91% 68%
14.000 11,406 53,233 131,553 172,024 91% 69%
15.000 12,181 56,922 140,610 184,027 91% 69%
16.000 13,087 62,257 151,534 205,667 91% 70%
17.000 14,008 93,450 162,391 271,528 91% 66%
18.000 14,892 178,667 176,489 335,989 92% 47%
19.000 15,661 262,197 184,640 414,900 92% 37%
20.000 16,681 424,762 195,468 545,217 91% 22%
Tabela 8: Tempo do Processador para |Î£| = 26, k = 20
Arranjo de Sufixos AÂ´rvore de sufixos DiferencÂ¸a
N (Ã—1000) Pre-Proc Total Pre-Proc Total Pre-Proc Total
1.000 0,636 4,120 2,432 5,678 74% 27%
2.000 1,410 8,570 5,948 12,468 76% 31%
3.000 2,230 13,086 9,542 19,356 77% 32%
4.000 3,120 17,706 13,252 26,402 76% 33%
5.000 3,994 22,274 17,244 33,754 77% 34%
6.000 4,824 26,884 21,292 41,148 77% 35%
7.000 5,740 31,732 25,582 49,062 78% 35%
8.000 6,714 36,484 30,056 56,838 78% 36%
9.000 7,574 41,218 34,610 64,914 78% 37%
10.000 8,512 45,790 39,298 72,932 78% 37%
11.000 11,163 53,497 44,110 82,143 75% 35%
12.000 10,403 55,610 48,980 90,517 79% 39%
13.000 11,497 61,163 53,927 99,307 79% 38%
14.000 12,417 65,897 59,013 107,397 79% 39%
15.000 13,293 70,723 64,090 117,043 79% 40%
16.000 14,277 76,160 69,337 133,700 79% 43%
17.000 15,370 83,627 74,687 146,910 79% 43%
18.000 16,387 105,817 79,923 160,007 79% 34%
19.000 17,190 105,137 85,327 166,317 80% 37%
20.000 18,387 115,130 91,060 184,693 80% 38%
61
Tabela 9: Tempo de ExecucÂ¸aËœo para |Î£| = 26, k = 20
Arranjo de Sufixos AÂ´rvore de sufixos DiferencÂ¸a
N (Ã—1000) Pre-Proc Total Pre-Proc Total Pre-Proc Total
1.000 0,638 4,122 2,435 5,681 74% 27%
2.000 1,414 8,574 5,952 12,472 76% 31%
3.000 2,233 13,089 9,545 19,359 77% 32%
4.000 3,124 17,710 13,256 26,406 76% 33%
5.000 3,998 22,278 17,247 33,757 77% 34%
6.000 4,826 26,886 21,295 41,151 77% 35%
7.000 5,742 31,734 25,584 49,064 78% 35%
8.000 6,717 36,487 30,060 56,842 78% 36%
9.000 7,577 41,221 34,612 64,916 78% 37%
10.000 8,514 45,792 39,301 72,935 78% 37%
11.000 11,164 53,503 44,118 82,156 75% 35%
12.000 10,407 55,616 48,987 90,530 79% 39%
13.000 11,506 61,172 53,936 99,315 79% 38%
14.000 12,421 65,900 59,019 107,409 79% 39%
15.000 13,296 70,728 64,094 119,189 79% 41%
16.000 14,495 76,388 69,343 184,856 79% 59%
17.000 15,381 101,361 74,697 310,134 79% 67%
18.000 16,390 270,983 79,931 409,047 79% 34%
19.000 17,196 641,710 85,333 728,444 80% 12%
20.000 18,388 1.031,485 91,071 1.219,468 80% 15%
Tabela 10: Tempo do Processador para |Î£| = 4, k = 20
Arranjo de Sufixos AÂ´rvore de sufixos DiferencÂ¸a
N (Ã—1000) Pre-Proc Total Pre-Proc Total Pre-Proc Total
1.000 0,652 9,756 1,538 8,638 58% -13%
2.000 1,452 20,344 3,418 17,874 58% -14%
3.000 2,324 30,928 5,398 27,032 57% -14%
4.000 3,274 41,912 7,418 36,430 56% -15%
5.000 4,200 52,774 9,536 46,318 56% -14%
6.000 5,102 63,934 11,512 55,592 56% -15%
7.000 6,038 74,856 13,612 65,850 56% -14%
8.000 7,022 86,926 15,748 75,970 55% -14%
9.000 7,898 98,840 17,906 84,752 56% -17%
10.000 8,834 108,832 20,094 94,704 56% -15%
11.000 11,480 118,933 22,270 101,780 48% -17%
12.000 10,787 124,067 24,513 110,613 56% -12%
13.000 11,843 135,643 26,707 120,673 56% -12%
14.000 12,810 149,580 29,030 130,683 56% -14%
15.000 13,693 157,630 31,240 144,953 56% -9%
16.000 14,650 170,177 33,537 160,777 56% -6%
17.000 15,813 184,343 35,897 175,693 56% -5%
18.000 16,790 208,327 38,360 187,250 56% -11%
19.000 17,603 221,323 40,573 215,793 57% -3%
20.000 18,770 304,000 43,010 309,043 56% 2%
Tabela 11: Tempo de ExecucÂ¸aËœo para |Î£| = 4, k = 20
Arranjo de Sufixos AÂ´rvore de sufixos DiferencÂ¸a
N (Ã—1000) Pre-Proc Total Pre-Proc Total Pre-Proc Total
1.000 0,655 9,759 11,296 18,396 94% 47%
2.000 1,454 20,346 23,764 38,220 94% 47%
3.000 2,327 30,931 36,328 57,962 94% 47%
4.000 3,276 41,914 49,334 78,346 93% 47%
5.000 4,204 52,778 62,312 99,094 93% 47%
6.000 5,104 63,936 75,450 119,530 93% 47%
7.000 6,040 74,858 88,470 140,708 93% 47%
8.000 7,025 86,929 102,676 162,898 93% 47%
9.000 7,900 98,842 116,749 183,595 93% 46%
10.000 8,837 108,835 128,928 203,538 93% 47%
11.000 11,487 118,948 22,279 101,799 48% -17%
12.000 10,786 124,074 24,527 110,624 56% -12%
13.000 11,849 135,655 26,714 120,686 56% -12%
14.000 12,813 149,591 29,041 131,119 56% -14%
15.000 13,701 157,644 31,244 201,778 56% 22%
16.000 14,658 170,194 33,537 345,019 56% 51%
17.000 15,819 200,034 35,899 570,844 56% 65%
18.000 16,797 611,849 38,364 894,459 56% 32%
19.000 17,607 887,734 40,576 1.928,291 57% 54%
20.000 18,772 5.455,711 43,017 11.437,399 56% 52%
62
Tabela 12: Tempo do Processador para |Î£| = 2, k = 20
Arranjo de Sufixos AÂ´rvore de sufixos DiferencÂ¸a
N (Ã—1000) Pre-Proc Total Pre-Proc Total Pre-Proc Total
1.000 0,605 14,629 1,572 12,337 62% -19%
2.000 1,372 30,982 3,352 25,538 59% -21%
3.000 2,176 47,998 5,192 38,682 58% -24%
4.000 3,064 64,056 7,040 52,084 56% -23%
5.000 3,918 80,202 8,932 66,112 56% -21%
6.000 4,728 98,122 10,884 79,478 57% -23%
7.000 5,608 115,474 12,772 94,630 56% -22%
8.000 6,510 132,102 14,752 107,136 56% -23%
9.000 7,314 151,738 16,752 123,754 56% -23%
10.000 8,200 168,560 18,764 139,736 56% -21%
11.000 10,747 194,140 20,877 155,527 49% -25%
12.000 9,953 202,100 22,963 165,077 57% -22%
13.000 10,917 219,023 25,140 181,083 57% -21%
14.000 11,823 239,107 27,220 201,173 57% -19%
15.000 12,630 256,097 29,247 223,907 57% -14%
16.000 13,487 275,207 31,450 244,030 57% -13%
17.000 14,550 299,187 33,657 260,900 57% -15%
18.000 15,477 333,623 35,933 291,047 57% -15%
19.000 16,237 357,973 38,090 367,090 57% 2%
20.000 17,313 452,457 40,257 434,663 57% -4%
Tabela 13: Tempo de ExecucÂ¸aËœo para |Î£| = 2, k = 20
Arranjo de Sufixos AÂ´rvore de sufixos DiferencÂ¸a
N (Ã—1000) Pre-Proc Total Pre-Proc Total Pre-Proc Total
1.000 0,612 14,637 1,577 12,341 61% -19%
2.000 1,376 30,984 3,353 25,543 59% -21%
3.000 2,181 48,003 5,192 38,682 58% -24%
4.000 3,063 64,061 7,042 52,085 57% -23%
5.000 3,917 80,207 8,932 66,238 56% -21%
6.000 4,736 98,134 10,890 79,617 57% -23%
7.000 5,615 115,491 12,780 94,640 56% -22%
8.000 6,514 132,115 14,755 107,146 56% -23%
9.000 7,316 151,747 16,755 123,763 56% -23%
10.000 8,200 168,573 18,765 139,744 56% -21%
11.000 10,748 194,160 20,882 155,547 49% -25%
12.000 9,955 202,315 22,972 165,096 57% -23%
13.000 10,919 219,044 25,146 181,125 57% -21%
14.000 11,826 239,129 27,222 334,518 57% 29%
15.000 12,630 256,298 29,250 347,950 57% 26%
16.000 13,496 275,230 31,454 579,657 57% 53%
17.000 14,550 308,850 33,662 852,980 57% 64%
18.000 15,482 644,768 35,937 1.531,532 57% 58%
19.000 16,238 1.024,395 38,095 7.525,399 57% 86%
20.000 17,314 5.822,213 40,268 13.809,782 57% 58%
63
(i) A fase de iteracÂ¸aËœo da versaËœo baseada em aÂ´rvores de sufixos eÂ´ em geral mais raÂ´pida
que a versaËœo baseada em arranjos de sufixos.
(ii) Quando |Î£| eÂ´ grande o tempo de preÂ´-processamento eÂ´ muito menor na versaËœo
baseada em arranjos de sufixos, e pode influenciar fortemente no tempo total de
execucÂ¸aËœo.
Nossa anaÂ´lise indica que a observacÂ¸aËœo (i) acima eÂ´ causada pela necessidade de fazer
consultas ao Ä±Â´ndice reverso (que mapeia os sufixos Pj e Tk na sua posicÂ¸aËœo no arranjo Pos),
para podermos identificar os noÂ´s da aÂ´rvore cartesiana cujo LCA seraÂ´ consultado. Esta
uma operacÂ¸aËœo naËœo eÂ´ necessaÂ´ria na versaËœo baseada em aÂ´rvores de sufixos, e, aleÂ´m disso,
como as posicÂ¸oËœes de Pos que seraËœo consultadas naËœo saËœo facilmente previstas a partir de j
e k, e provavelmente causam erros na consulta a` memoÂ´ria cache e uma busca da memoÂ´ria
RAM.
A observacÂ¸aËœo (ii) acima eÂ´ consequÂ¨eË†ncia direta da implementacÂ¸aËœo de aÂ´rvore de sufixos
utilizada e da frequÂ¨eË†ncia de distribuicÂ¸aËœo aleatoÂ´ria dos caracteres, pois o tipo de aÂ´rvore de
sufixos construÂ´Ä±da eÂ´ a variante ILLI descrita em (13), que usa uma lista ligada para guardar
as arestas dos filhos de cada noÂ´. Como |Î£| eÂ´ grande, as buscas nas arestas para identificar
se jaÂ´ existe uma aresta cujo roÂ´tulo comecÂ¸a com determinado caractere geram uma busca
linear O(|Î£|). Para resolver isso, seria necessaÂ´rio usar a variante IHTI (13) baseada em
tabelas de hash, mas a implementacÂ¸aËœo que obtivemos suporta apenas a construcÂ¸aËœo de
aÂ´rvores do tipo ILLI. De qualquer forma, o nosso foco eÂ´ a economia de espacÂ¸o e segundo
Kurtz(13) a versaËœo IHTI usa mais espacÂ¸o que a versaËœo ILLI. Por exemplo, para o genoma
da bacteÂ´ria E. coli a versaËœo ILLI usa 12,56 bytes por caractere, enquanto a versaËœo IHTI
usa 17,14 bytes por caractere.
Percebemos que aumentar a quantidade de diferencÂ¸as permitidas aumenta o custo da
fase de iteracÂ¸aËœo, o que diminui a vantagem que o algoritmo modificado poderia ter por uma
fase de preÂ´-processamento mais raÂ´pida. Assim, na medida em que k aumente, a tendeË†ncia
eÂ´ que o custo da fase de iteracÂ¸aËœo domine a execucÂ¸aËœo total do algoritmo, minimizando a
vantagem que o algoritmo modificado tem na fase de preÂ´-processamento.
Com respeito ao uso de espacÂ¸o, o algoritmo modificado usa menos espacÂ¸o em todos
os casos. Na versaËœo com espacÂ¸o Î¸(kn) do algoritmo, se aumentamos o valor de k tambeÂ´m
aumentamos o uso de espacÂ¸o da fase de iteracÂ¸aËœo e isso diminui a vantagem de uso de
espacÂ¸o do algoritmo modificado, pois para k grande o espacÂ¸o utilizado na fase de iteracÂ¸aËœo
seraÂ´ bem maior que o utilizado na fase de preÂ´-processamento. A versaËœo com espacÂ¸o Î¸(n)
64
Figura 14: GraÂ´fico de uso de processador |Î£| = 93, k = 20
Figura 15: GraÂ´fico de tempo de execucÂ¸aËœo |Î£| = 93, k = 20
65
Figura 16: GraÂ´fico de uso de processador |Î£| = 26, k = 20
Figura 17: GraÂ´fico de tempo de execucÂ¸aËœo |Î£| = 26, k = 20
66
Figura 18: GraÂ´fico de uso de processador |Î£| = 4, k = 20
Figura 19: GraÂ´fico de tempo de execucÂ¸aËœo |Î£| = 4, k = 20
67
Figura 20: GraÂ´fico de uso de processador |Î£| = 2, k = 20
Figura 21: GraÂ´fico de tempo de execucÂ¸aËœo |Î£| = 2, k = 20
68
do algoritmo modificado sempre usaraÂ´ menos espacÂ¸o independente de k, mas necessitaraÂ´
de uma fase adicional para construir os alinhamentos das palavras.
5.2.3 Dados reais
Para a avaliacÂ¸aËœo do comportamento do algoritmo com dados reais, usamos sequÂ¨eË†ncias
do Genbank e textos do projeto Gutenberg, acessÂ´Ä±veis pela internet. Dividimos a avaliacÂ¸aËœo
em duas partes.
Na primeira parte avaliamos o comportamento das variacÂ¸oËœes do algoritmo com aÂ´rvores
e arranjos de sufixos, utilizando dados reais retirados do Genbank e do projeto Gutenberg.
SaËœo palavras que cabem completamente na memoÂ´ria principal do computador utilizado
nos experimentos e servem somente para validar as observacÂ¸oËœes de uso de espacÂ¸o e tempo
feitas sobre os experimentos com dados aleatoÂ´rios.
Na segunda parte avaliamos o uso do algoritmo com problemas de dimensoËœes maiores,
que precisam ser tratados pela variante que usa espacÂ¸o Î¸(n) por usarem massas de dados
muito grandes e exigirem valores grandes para k.
Como dados reais utilizamos as seguinte sequÂ¨eË†ncias do Genbank:
â€¢ Halo. â€“ Halobacterium NRC-1 plasmÄ±Â´deo pNRC100, sequÂ¨eË†ncia completa.
â€¢ E. rumin. â€“ Ehrlichia ruminantium str. Welgevonden, genoma completo.
â€¢ Influenza C, vÂ´Ä±rus, segmento 5, sequÂ¨eË†ncia completa (usado como padraËœo).
â€¢ Coliphage phiX174, vÂ´Ä±rus, genoma completa (usado como padraËœo).
AleÂ´m disso, usamos os seguintes textos retirados do projeto Gutenberg e do corpus
de Canterbury:
â€¢ Fifteen â€“ Fifteen Thousand Useful Phrases, por Greenville Kleiser ( EBook #18362
do Projeto Gutenberg).
â€¢ Moby Dick â€“ Moby Dick, por Herman Melville ( Etext #2701 do Projeto Gutenberg)
â€¢ Shakespeare â€“ CompilacÂ¸aËœo de obras de William Shakespeare (Etexts #2253, #1103,
#1107, #1113, #1114, #1127, #1794, #1129, #1135, #1522 e #1524 do Projeto
Gutenberg)
69
Tabela 14: Uso de espacÂ¸o para dados reais
Arranjo de Sufixos AÂ´rvore de Sufixos Economia de EspacÂ¸o
PP Total PP Total MB Bpc PP Total
|Î£| N (KB) MB Bpc. MB Bpc MB Bpc MB Bpc
Halo. 4 191 5 29 15 79 10 53 19 104 5 25 46,38% 23,68%
E. rumin. 4 1.516 42 28 117 79 78 53 154 104 36 25 46,70% 23,72%
E. coli 4 4.639 127 28 358 79 236 52 467 103 109 24 46,13% 23,29%
Biblia 62 4.047 111 28 312 79 185 47 387 98 75 19 40,32% 19,32%
Fifteen 85 589 16 28 45 79 27 46 56 97 10 18 39,33% 18,69%
Moby Dick 90 1.256 34 28 97 79 56 46 119 97 22 18 38,88% 18,40%
Shakespeare 93 1.875 51 28 145 79 84 46 178 97 33 18 39,10% 18,54%
world192 93 2.473 68 28 191 79 112 46 235 97 44 18 39,36% 18,70%
Tabela 15: Tempo de execucÂ¸aËœo para dados reais
Arranjo de Sufixos AÂ´rvore de sufixos DiferencÂ¸a
|Î£| N (KB) Pre-Proc Total Pre-Proc Total Pre-Proc Total
Halo. 4 191 0,080 0,753 0,185 0,790 57% 4,7%
E. rumin. 4 1.516 1,030 7,820 2,438 7,810 58% -0,1%
E. coli 4 4.639 3,875 25,605 8,595 25,340 55% -1,0%
Biblia 62 4.047 3,070 13,000 6,847 15,503 55% 16,1%
Fifteen 85 589 0,310 1,480 0,713 1,823 57% 18,8%
Moby Dick 90 1.256 0,830 3,370 2,167 4,550 62% 25,9%
Shakespeare 93 1.875 1,310 5,137 3,227 6,767 59% 24,1%
world192 93 2.473 1,790 7,277 3,677 8,570 51% 15,1%
â€¢ BÄ±Â´blia â€“ BÂ´Ä±blia do Rei Jaime (do arquivo large do corpus de Canterbury).
â€¢ E.coli â€“ Genoma da E. coli (do arquivo large do corpus de Canterbury).
â€¢ world192 â€“ CIA World Factbook de 1992 (do arquivo large do corpus de Canterbury).
Nas tabela 14 temos a comparacÂ¸aËœo do uso de espacÂ¸o para o algoritmo que usa a
construcÂ¸aËœo de aÂ´rvore de sufixos no seu preÂ´-processamento e o algoritmo que usa arranjos
de sufixos para seu preÂ´-processamento, e na tabela 15 temos a comparacÂ¸aËœo do tempo de
execucÂ¸aËœo. Como em todos os casos as informacÂ¸oËœes cabiam completamente na memoÂ´ria
principal, naËœo houve diferencÂ¸a significativa entre tempo de execucÂ¸aËœo e tempo de processa-
dor e apresentamos apenas o tempo de processador. Essas tabelas teË†m estrutura similar a
das tabelas de resultados para dados aleatoÂ´rios (apenas acrescentamos uma identificacÂ¸aËœo
da sequÂ¨eË†ncia e o tamanho de Î£ para cada experimento).
Verificamos que o comportamento eÂ´ similar ao dos dados gerados de forma aleatoÂ´ria,
e as mesmas consideracÂ¸oËœes se aplicam. Em todos os casos, o preÂ´-processamento eÂ´ mais
raÂ´pido no algoritmo modificado, e a fase de iteracÂ¸aËœo do algoritmo original eÂ´ mais raÂ´pida.
Para alfabetos pequenos (DNA), a vantagem no preÂ´-processamento do algoritmo modifi-
cado eÂ´ pequena o suficiente para naËœo se converter em vantagem no tempo total de execucÂ¸aËœo
do algoritmo, mas para os casos de alfabetos grandes, a diferencÂ¸a foi suficiente para que
o desempenho total do algoritmo modificado fosse superior. Em todos os casos, o uso
de espacÂ¸o da versaËœo baseada em arranjos de sufixos foi menor, sendo que quando |Î£| eÂ´
70
grande, a diferencÂ¸a de uso de espacÂ¸o eÂ´ menor e o tempo de execucÂ¸aËœo eÂ´ maior.
Observe que mesmo para alfabetos grandes a diferencÂ¸a no uso de espacÂ¸o continua
significativa, e maior que no caso dos dados aleatoÂ´rios. Isso ocorre porque tanto textos
de literatura quanto sequÂ¨eË†ncias bioloÂ´gicas possuem uma certa estrutura, e a frequÂ¨eË†ncia de
cada caractere (ou de codons) naËœo eÂ´ uniforme, o que gera uma quantidade maior de noÂ´s
na aÂ´rvore de sufixos que no caso aleatoÂ´rio. Isso aumenta o espacÂ¸o utilizado tanto para a
proÂ´pria aÂ´rvore de sufixos como para a estrutura usada para o caÂ´lculo do LCA.
Sabemos que no computador utilizado para a anaÂ´lise experimental rapidamente chega-
mos ao ponto em que naËœo eÂ´ possÂ´Ä±vel processar de forma realista palavras grandes, como as
palavras que formariam todas as regioËœes codificadoras de um cromossomo. Isso acontece
em parte porque qualquer resultado significativo exigiria um valor alto para k.
Ora, para realizar buscas exatas nessas palavras o caminho usual seria realizar o
algoritmo de programacÂ¸aËœo dinaË†mica em tempo linear, que marcaria todas as posicÂ¸oËœes em
T onde encontramos uma ocorreË†ncia de P compatÂ´Ä±veis com o criteÂ´rio de busca, e entaËœo
posteriormente construirÂ´Ä±amos os respectivos alinhamentos usando tempo Î¸(m2) e espacÂ¸o
Î¸(m), sendo que m eÂ´ muito menor que n.
Vamos usar a mesma abordagem para estender o limite das palavras que podemos
processar independente da quantidade de diferencÂ¸as admitidas. Dessa forma o valor de
k somente interferiraÂ´ no tempo de execucÂ¸aËœo do algoritmo, mas naËœo no uso de espacÂ¸o que
seraÂ´ Î¸(n).
Para esse esperimento escolhemos como padraËœo regioËœes de cDNA do ser humano re-
tirado do NCBI Genbank de comprimentos da ordem de 8, 9, e 11 mil caracteres (H.
sapiens adenomatosis polyposis coli, H. sapiens dystrophin e H. sapiens talin 1).
Para texto usamos:
â€¢ Drosophila melanogaster, cDNA release 5 de 17 de Abril de 2006, eucromatina e
heterocroma:
â€“ BracÂ¸o 2R (21 milhoËœes de caracteres).
â€“ BracÂ¸o 2L (23 milhoËœes de caracteres).
â€“ BracÂ¸o 3L (25 milhoËœes de caracteres).
â€“ BracÂ¸o 3R (28 milhoËœes de caracteres).
â€“ BracÂ¸o U Extra, (29 milhoËœes de caracteres).
71
Tabela 16: Dados reais - uso de espacÂ¸o para pesquisa em DNA
Arranjo de Sufixos (MB) AÂ´rvore de Sufixos (MB) Economia de EspacÂ¸o
M (KB) N (MB) Pre-Proc Total Pre-Proc Total MB Bpc %
8 21 592 1.438 1.102 1.948 510 24 26%
9 21 592 1.438 1.102 1.948 510 24 26%
9 21 592 1.438 1.102 1.948 510 24 26%
11 21 592 1.438 1.102 1.948 510 24 26%
8 23 645 1.565 1.200 2.121 556 24 26%
9 23 645 1.565 1.200 2.121 556 24 26%
9 23 645 1.565 1.200 2.121 556 24 26%
11 23 645 1.565 1.200 2.121 556 24 26%
8 25 687 1.669 1.280 2.262 593 24 26%
9 25 687 1.669 1.280 2.262 593 24 26%
9 25 687 1.669 1.280 2.262 593 24 26%
11 25 688 1.669 1.280 2.262 593 24 26%
8 28 782 1.898 1.451 2.567 669 24 26%
9 28 782 1.898 1.451 2.567 669 24 26%
9 28 782 1.898 1.451 2.567 669 24 26%
11 28 782 1.898 1.451 2.567 669 24 26%
8 29 812 1.973 1.637 2.797 825 28 29%
9 29 812 1.973 1.637 2.797 825 28 29%
9 29 812 1.973 1.637 2.797 825 28 29%
11 29 812 1.973 1.637 2.797 825 28 29%
8 35 968 2.350 1.818 - - - -
9 35 968 2.350 1.818 - - - -
9 35 968 2.350 1.818 - - - -
11 35 968 2.350 1.818 - - - -
â€¢ Homo sapiens, cDNA do cromossomo 22 (34,5 milhoËœes de caracteres)
Observe que a avaliacÂ¸aËœo feita aqui eÂ´ de caraÂ´ter estritamente algorÂ´Ä±tmico, naËœo tendo
sido realizada buscando um significacÂ¸aËœo bioloÂ´gica real. O alinhamento de sequÂ¨eË†ncias
bioloÂ´gicas se beneficia mais de um algoritmo de maximizacÂ¸aËœo de uma medida de simila-
ridade, que leve em conta fatores como a probabilidade de mutacÂ¸aËœo de uma base para
outra, enquanto o algoritmo que estamos avaliando eÂ´ um algoritmo de minimizacÂ¸aËœo cujo
criteÂ´rio eÂ´ a distaË†ncia de edicÂ¸aËœo.
Na tabela 16 apresentamos os resultados com relacÂ¸aËœo ao uso de espacÂ¸o e nas tabelas
17 e 18 os resultados com relacÂ¸aËœo ao tempo de execucÂ¸aËœo para k = 50 e k = 100, respec-
tivamente (como usamos a variante com espacÂ¸o linear do algoritmo, naËœo haÂ´ diferencÂ¸a no
uso de espacÂ¸o para diferentes valores de k).
Na figura 22 apresentamos um graÂ´fico comparativo do uso de espacÂ¸o dos algoritmos,
baseado na tabela 16. Nas figuras 23 e 24 apresentamos de forma graÂ´fica a comparacÂ¸aËœo
do tempo de processador para cada algoritmo, para k = 50 e k = 100, respectivamente.
Nas figuras 25 e 26 apresentamos de forma graÂ´fica a comparacÂ¸aËœo do tempo de execucÂ¸aËœo
para cada algoritmo, para k = 50 e k = 100, respectivamente.
Note que o texto de 34,5 milhoËœes de caracteres (cromossomo 22 do H. sapiens) naËœo
poË†de ser processado pelo algoritmo original. O espacÂ¸o adicional de 845 MB usado no preÂ´-
processamento do algoritmo foi decisivo para que a memoÂ´ria total utilizada superasse a
capacidade de memoÂ´ria virtual do computador utilizado. Para o experimento de pesquisa
72
Figura 22: GraÂ´fico de uso de espacÂ¸o para pesquisa em DNA
Tabela 17: Dados reais â€“ tempo de execucÂ¸aËœo para pesquisa em DNA â€” k = 50
Arranjo de Sufixos (seg) AÂ´rvore de Sufixos (seg) %
M (KB) N (MB) PP CPU Total Total CPU PP CPU Total Total CPU Total CPU
8 21 19,7350 428 428,4000 45,1400 360 359,9100 -19,0% -19,0%
9 21 19,6350 508 507,5450 45,1100 408 408,3300 -24,3% -24,3%
9 21 19,6300 506 505,8350 45,0100 408 407,7800 -24,0% -24,0%
11 21 19,7000 476 476,3100 45,0050 387 386,9400 -23,1% -23,1%
8 23 21,2300 458 458,2500 49,0550 428 389,8900 -7,2% -17,5%
9 23 21,1550 557 556,7300 49,2300 485 446,5800 -14,7% -24,7%
9 23 21,1850 555 554,8300 49,1600 484 445,9900 -14,7% -24,4%
11 23 21,3900 525 525,0500 49,0400 466 425,2600 -12,6% -23,5%
8 25 23,0900 504 504,4050 52,8950 509 421,6750 0,9% -19,6%
9 25 23,0250 610 610,0750 52,7050 563 488,6500 -8,4% -24,8%
9 25 23,0800 608 607,1250 52,7850 576 481,9650 -5,5% -26,0%
11 25 23,3350 561 561,0250 52,8250 539 455,2300 -4,1% -23,2%
8 28 26,3950 598 590,2850 61,1900 648 482,2800 7,7% -22,4%
9 28 26,4900 732 696,1950 61,2850 767 558,8350 4,5% -24,6%
9 28 26,4550 701 693,6900 61,2950 814 565,2350 13,9% -22,7%
11 28 26,4250 659 649,6550 61,1850 797 539,9100 17,3% -20,3%
8 29 27,2950 597 541,7650 47,1750 613 454,3500 2,6% -19,2%
9 29 27,6300 723 641,4150 47,2800 907 523,7300 20,3% -22,5%
9 29 27,5250 750 652,6300 47,0350 719 538,5300 -4,2% -21,2%
11 29 28,0350 673 605,9550 47,3250 663 499,4850 -1,4% -21,3%
8 35 32,5450 1.894 798,6850 72,7300 - - - -
9 35 32,1750 1.772 895,3400 72,7750 - - - -
9 35 31,9550 1.680 875,1150 72,6750 - - - -
11 35 31,9500 1.983 824,2750 72,9100 - - - -
73
Tabela 18: Dados reais â€“ tempo de execucÂ¸aËœo para pesquisa em DNA â€” k = 100
Arranjo de Sufixos (seg) AÂ´rvore de Sufixos (seg) %
M (KB) N (MB) PP CPU Total Total CPU PP CPU Total Total CPU Total CPU
8 21 19,6600 913 912,5000 45,2250 717 716,7350 -27,3% -27,3%
9 21 19,6300 1.008 1.008,0200 44,9550 782 782,0000 -28,9% -28,9%
9 21 19,6450 1.007 1.007,1350 45,0800 778 778,0500 -29,4% -29,4%
11 21 19,6300 960 960,3950 45,0050 750 750,1250 -28,0% -28,0%
8 23 21,2800 991 991,1750 49,0400 826 776,9900 -19,9% -27,6%
9 23 21,1850 1.103 1.102,2950 49,2050 913 852,5700 -20,8% -29,3%
9 23 21,2000 1.104 1.104,0250 49,1900 905 853,3050 -22,0% -29,4%
11 23 21,3900 1.068 1.068,0450 49,1450 876 825,0950 -21,9% -29,4%
8 25 23,1100 1.075 1.074,7000 52,7550 1.018 839,6100 -5,6% -28,0%
9 25 23,0750 1.201 1.201,3150 52,7200 1.082 922,3450 -11,1% -30,2%
9 25 23,0500 1.201 1.200,2350 52,7400 1.097 920,8450 -9,5% -30,3%
11 25 23,2900 1.134 1.134,1700 52,9200 1.068 891,3500 -6,2% -27,2%
8 28 26,4150 1.275 1.261,4500 61,3100 1.209 978,6850 -5,4% -28,9%
9 28 26,4800 1.415 1.398,1900 61,2600 1.299 1.073,7400 -9,0% -30,2%
9 28 26,3900 1.398 1.379,8300 61,2850 1.262 1.057,6400 -10,7% -30,5%
11 28 26,4150 1.316 1.310,7350 61,2300 1.277 1.031,5550 -3,1% -27,1%
8 29 27,3050 1.185 1.119,4400 47,2400 1.446 887,8850 18,1% -26,1%
9 29 27,5500 1.404 1.260,3400 47,0800 1.199 988,0650 -17,0% -27,6%
9 29 27,5450 1.319 1.256,0500 47,2800 1.325 988,6050 0,4% -27,1%
11 29 28,0600 1.272 1.201,1700 47,2200 1.241 952,5350 -2,5% -26,1%
8 35 32,6500 2.512 1.588,9400 72,8300 - - - -
9 35 31,9050 2.516 1.691,7050 73,1050 - - - -
9 35 31,8950 2.696 1.705,4500 72,7450 - - - -
11 35 31,9300 2.568 1.629,1200 72,7450 - - - -
Figura 23: GraÂ´fico de tempo de processador para pesquisa em DNA â€“ k = 50
74
Figura 24: GraÂ´fico de tempo de processador para pesquisa em DNA â€“ k = 100
Figura 25: GraÂ´fico de tempo de execucÂ¸aËœo para pesquisa em DNA â€“ k = 50
75
Figura 26: GraÂ´fico de tempo de execucÂ¸aËœo para pesquisa em DNA â€“ k = 100
em DNA a economia meÂ´dia de espacÂ¸o foi de 27%.
Com respeito ao tempo de execucÂ¸aËœo, ao eliminarmos a tabela para manter a in-
formacÂ¸aËœo de construcÂ¸aËœo dos alinhamentos (mantendo somente as posicÂ¸oËœes iniciais e finais)
ambas as versoËœes do algoritmo se comportaram melhor na presencÂ¸a da memoÂ´ria virtual.
JaÂ´ comentamos na secÂ¸aËœo 5.2.2 que a fase de iteracÂ¸aËœo baseada em aÂ´rvore de sufixos eÂ´ mais
raÂ´pida. Essa diferencÂ¸a fica mais expressiva na medida em que aumentamos k, como po-
demos ver nas coluna que descrevem o tempo de processador utilizado (CPU). Apesar
disso, quando a versaËœo baseada em aÂ´rvore de sufixos comecÂ¸a a usar a memoÂ´ria virtual a
diferencÂ¸a de tempo real de execucÂ¸aËœo passa a ser menor que a diferencÂ¸a do tempo de pro-
cessador. Quando ambas as implementacÂ¸oËœes estaËœo usando memoÂ´ria virtual, as diferencÂ¸as
saËœo mÄ±Â´nimas e em vaÂ´rios casos a implementacÂ¸aËœo baseada em arranjos de sufixos foi mais
raÂ´pida.
5.2.4 AvaliacÂ¸aËœo dos resultados
A partir dos experimentos relatados nas secÂ¸oËœes 5.2.2 e 5.2.3 podemos fazer algumas
observacÂ¸oËœes comparando o algoritmo de Landau e Vishkin original e o algoritmo modifi-
cado.
â€¢ A fase de iteracÂ¸aËœo do algoritmo original eÂ´ mais raÂ´pida que a do algoritmo modificado.
76
â€¢ O preÂ´-processamento do algoritmo modificado eÂ´ mais raÂ´pido que o do original.
â€¢ Para alfabetos grandes, a diferencÂ¸a no tempo de preÂ´-processamento eÂ´ ainda maior,
embora a economia de espacÂ¸o seja reduzida.
â€¢ O algoritmo modificado usa menos espacÂ¸o que o algoritmo original. Em especial, ao
usarmos a versaËœo com espacÂ¸o linear, a diferencÂ¸a eÂ´ maÂ´xima.
Em todos os casos o algoritmo modificado usou menos espacÂ¸o que o algoritmo ori-
ginal, e pudemos apresentar dados reais que puderam ser processados com o algoritmo
modificado que naËœo puderam ser processados com o algoritmo original no ambiente com-
putacional utilizado para os experimentos.
Em geral, se k for grande e toda a informacÂ¸aËœo usada pelo algoritmo couber na memoÂ´ria
principal do computador, a versaËœo original do algoritmo teraÂ´ desempenho melhor que
a versaËœo modificada. Em contrapartida, quando o uso de espacÂ¸o passar do limite da
memoÂ´ria principal do computador e comecÂ¸ar a fazer uso de memoÂ´ria virtual, a vantagem
de processamento do algoritmo original tende a diminuir, ateÂ´ efetivamente desaparecer
quando houver palavras que naËœo podem ser processadas pelo algoritmo original e que
puderem ser processadas pelo algoritmo modificado.
77
6 ConclusaËœo e caminhos futuros
Estudamos o algoritmo de Landau e Vishkin e identificamos uma oportunidade de
melhorar o seu uso de espacÂ¸o ao substituir as aÂ´rvores de sufixos utilizadas no algoritmo
original por arranjos de sufixos, que saËœo estruturas de dados mais compactas. Para isso
foi necessaÂ´rio um estudo que nos permitiu chegar a um caÂ´lculo em tempo constante do
menor valor em um intervalo de um arranjo (tambeÂ´m conhecido como RMQ â€” range
minimum query), e verificar que esse caÂ´lculo seria suficiente para que a nossa proposta
fosse viaÂ´vel.
Desenvolvemos nossa proposta e apresentamos neste trabalho um algoritmo para o
problema de pesquisa aproximada de padroËœes em palavras baseado no algoritmo de Landau
e Vishkin(4) de complexidades Î¸(kn) para execucÂ¸aËœo e Î¸(kn) ou Î¸(n) para uso de espacÂ¸o.
O algoritmo de Landau e Vishkin usa uma consulta em tempo constante do LCA de pares
de folhas de uma aÂ´rvore de sufixos para calcular saltos em tempo constante ao longo das
diagonais da tabela de programacÂ¸aËœo dinaË†mica.
Em primeiro lugar verificamos que a informacÂ¸aËœo essencial para esses saltos eÂ´ o com-
primento do maior prefixo comum de um sufixo do texto e um sufixo do padraËœo. Seguindo
as ideÂ´ias expostas por Abouelhoda, Kurtz e Ohlebusch(25), pudemos verificar que esse
comprimento seria igual ao valor mÄ±Â´nimo em um intervalo do arranjo lcp construÂ´Ä±do a
partir do arranjo de sufixos. A chave para realizarmos esse caÂ´lculo em tempo constante
foram as aÂ´rvores cartesianas (26), apoÂ´s serem processadas para responder consultas de
LCA em tempo constante.
O nosso objetivo foi diminuir o uso de espacÂ¸o do algoritmo de Landau e Vishkin.
Apesar de aumentarmos a quantidade de passos na fase de preÂ´-processamento, e introdu-
zirmos uma quantidade maior de estruturas de dados, verificamos que a versaËœo modificada
do algoritmo usava menos espacÂ¸o que a original, mantendo a complexidade linear para a
fase de preÂ´-processamento e Î¸(kn) para a fase de iteracÂ¸aËœo.
Em (5) apresentamos uma previsaËœo teoÂ´rica de economia de espacÂ¸o da ordem de 4n
78
bytes â€” que neste trabalho modificamos para 12n bytes â€” sobre uma implementacÂ¸aËœo
de aÂ´rvores de sufixos que utilizasse 12n bytes. Na praÂ´tica essa medida naËœo eÂ´ exata por-
que o uso exato de espacÂ¸o de uma aÂ´rvore de sufixos depende do alfabeto utilizado e da
sua estrutura (frequÂ¨eË†ncia de cada caractere, quantidade e tamanho de repeticÂ¸oËœes). Nos
experimentos realizados, o uso de espacÂ¸o da aÂ´rvore de sufixos ficou entre 10n e 19N , de
acordo com o alfabeto utilizado, e a economia meÂ´dia de espacÂ¸o no preÂ´-processamento
variou de 8n a 35n (para caracteres ASCII que podem ser impressos e alfabeto binaÂ´rio,
respectivamente).
Fizemos uma avaliacÂ¸aËœo experimental com dados gerados aleatoÂ´riamente para vaÂ´rios
tamanhos e alfabetos e para dados reais, disponÂ´Ä±veis publicamente e retirados dos projetos
NCBI Genbank, Projeto Gutenberg e Corpus de Canterbury.
A avaliacÂ¸aËœo experimental foi satisfatoÂ´ria, pois comprovou o ganho de espacÂ¸o esperado.
O uso de alfabetos maiores diminui o espacÂ¸o utilizado pela aÂ´rvore de sufixos do algoritmo
original e diminui a economia obtida, ao passo que alfabetos pequenos (como o alfabeto
binaÂ´rio e DNA) aumentam o uso de espacÂ¸o da aÂ´rvore de sufixos e fazem com que a
economia de espacÂ¸o do algoritmo modificado seja mais expressiva.
Em especial para alfabetos de 4 sÂ´Ä±mbolos (sequÂ¨eË†ncias de DNA) o ganho foi em meÂ´dia
27% no caÂ´lculo com espacÂ¸o linear para dados reais, e em meÂ´dia 20,9% para palavras
aleatoÂ´rias no algoritmo com espacÂ¸o Î¸(kn) quando k = 20. A economia meÂ´dia para alfa-
betos de tamanho 4 foi de 24n bytes. AleÂ´m disso o algoritmo original naËœo foi capaz de
processar uma sequÂ¨eË†ncia baseada no cromossomo 22 do H. sapiens porque precisou de
mais espacÂ¸o que a memoÂ´ria virtual do computador utilizado foi capaz de prover, enquanto
a mesma sequÂ¨eË†ncia poË†de ser processada pelo algoritmo modificado.
Quanto ao tempo de execucÂ¸aËœo, o algoritmo modificado eÂ´ mais lento que o original na
fase de iteracÂ¸aËœo e mais raÂ´pido na fase de preÂ´-processamento. Isso faz com que o algoritmo
modificado seja competitivo principalmente quando k eÂ´ pequeno e |Î£| eÂ´ grande. Nos
demais casos ainda assim a diferencÂ¸a de uso do processador foi de 22% e 28% para k = 50
e k = 100 no experimento com sequÂ¨eË†ncias de DNA. Apesar disso a diferencÂ¸a do tempo
real de execucÂ¸aËœo diminuiu na medida em que o algoritmo original usava mais espacÂ¸o e
comecÂ¸ou a demandar memoÂ´ria virtual do computador utilizado.
Do ponto de vista teoÂ´rico, entendemos que o estudo desse algoritmo e a sua imple-
mentacÂ¸aËœo saËœo de grande utilidade para dominar as ferramentas complexas que ele utiliza,
como o processamento de aÂ´rvores para consultas de LCA em tempo constante. AleÂ´m
disso, ao implementar uma teÂ´cnica nova para alguns dos componentes utilizados por esse
79
algoritmo foi possÂ´Ä±vel testar essa teÂ´cnica e comparar com a teÂ´cnica original, e entender as
vantagens e desvantagens que cada teÂ´cnica apresenta ao ser utilizada num problema real.
Entendemos que a maior contribuicÂ¸aËœo deste trabalho eÂ´ justamente a implementacÂ¸aËœo e
avaliacÂ¸aËœo da teÂ´cnica para caÂ´lculo do LCE de dois sufixos de uma palavra usando arranjos
de sufixos ao inveÂ´s de aÂ´rvores de sufixos, e uma ferramenta para avaliar empiricamente
outras teÂ´cnicas para o caÂ´lculo do LCE de dois sufixos de uma palavra que possam vir a
serem desenvolvidos.
Recentemente foi publicado na confereË†ncia Combinatorial Pattern Matching 2006 um
artigo de Fischer e Heun(36) que descreve um algoritmo para calcular o LCE de dois
sufixos de uma palavra em tempo constante, apoÂ´s preÂ´-processamento linear que naËœo ne-
cessita da construcÂ¸aËœo de uma aÂ´rvore cartesiana e do caÂ´lculo de LCA. O primeiro trabalho
futuro que enxergamos seria atualizar a nossa versaËœo do algoritmo de Landau e Vishkin
para utilizar essa teÂ´cnica e comparar o uso de espacÂ¸o e o tempo de execucÂ¸aËœo com a versaËœo
original e com a que desenvolvemos.
Outro caminho futuro que visualizamos seria tentar adaptar o algoritmo de Landau
e Vishkin para a utilizacÂ¸aËœo em alinhamento de sequÂ¨eË†ncias bioloÂ´gicas, transformando-o
num algoritmo de maximizacÂ¸aËœo exato baseado em similaridade, que utilize matrizes de
pontuacÂ¸aËœo como eÂ´ possÂ´Ä±vel fazer com os algoritmos FASTA, BLAST e de programacÂ¸aËœo
dinaË†mica.
Se pudermos estabeler a aplicabilidade do algoritmo de Landau e Vishkin para dados
bioloÂ´gicos, a sua utilizacÂ¸aËœo de forma paralela seria uma consequÂ¨eË†ncia imediata. O ano de
2006 foi marcado pela proliferacÂ¸aËœo de processadores com muÂ´ltiplos nuÂ´cleos (multi-core)
disponÂ´Ä±veis jaÂ´ em precÂ¸os acessÂ´Ä±veis para computadores pessoais de mesas e portaÂ´teis. Ao
quebrar o texto sendo pesquisado em palavras com alguma sobreposicÂ¸aËœo eÂ´ possÂ´Ä±vel realizar
o preÂ´-processamento e a iteracÂ¸aËœo de cada uma dessas partes em paralelo, e a comunicacÂ¸aËœo
entre cada uma dessas execucÂ¸oËœes seria mÄ±Â´nima, o que resultaria em um speed-up expressivo.
No caso distribuÂ´Ä±do, a memoÂ´ria adicional presente em cada noÂ´ do sistema seria melhor
aproveitada pelo nosso algoritmo, permitindo aumentar o tamanho da massa de dados
processada por cada componente do sistema. Uma aplicacÂ¸aËœo possÂ´Ä±vel para isso seria a
pesquisa de uma sequÂ¨eË†ncia em bases de dados de proteÂ´Ä±nas como o Swissprot.
80
RefereË†ncias
1 NEEDLEMAN, S. B.; WUNSCH, C. D. A general method applicable to the search
for similarities in the amino acid sequence of two proteins. J Mol Biol, v. 48, n. 3, p.
443â€“453, March 1970. ISSN 0022-2836.
2 SMITH, T. F.; WATERMAN, M. S. Identification of common molecular subsequences.
J Mol Biol, v. 147, n. 1, p. 195â€“197, March 1981. ISSN 0022-2836.
3 HIRSCHBERG, D. A linear space algorithm for computing the maximal common
subsequences. Communications of the ACM, v. 18, p. 341â€“343, 1975.
4 LANDAU, G.; VISHKIN, U. Introducing efficient parallelism into approximate string
matching and a new serial algorithm. In: STOC â€™86: Proceedings of the eighteenth
annual ACM symposium on Theory of computing. New York, NY, USA: ACM Press,
1986. p. 220â€“230. ISBN 0-89791-193-8.
5 MIRANDA, R. de C.; AYALA-RINCOÂ´N, M. A Modification of the Landau-Vishkin
Algorithm Computing Longest Common Extensions via Suffix Arrays (resumo estendido
â€“ publicada como artigo completo no XXXI CLEI). In: Brazilian Symposium on
Bioinformatics. SaËœo Leopoldo, RS, Brasil: Springer Verlag, 2005. (Lecture Notes in
Bioinformatics, v. 3594), p. 210â€“213.
6 KNUTH, D. E. The art of computer programming, volume 1 (3rd ed.): fundamental
algorithms. Redwood City, CA, USA: Addison Wesley Longman Publishing Co., Inc.,
1997. ISBN 0-201-89683-4.
7 DURBIN, R. et al. Biological Sequence Analysis. Cambridge, UK: Cambridge
University Press, 1998.
8 PEVZNER, P. A. Computational Molecular Biology: An Algorithmic Approach.
Cambridge, MA, USA: The MIT Press, 2000. ISBN 0262161974.
9 GUSFIELD, D. Algorithms on Strings, Trees and Sequences: Computer Science and
Computational Biology. New York, NY, USA: Cambridge University Press, 1997.
10 WEINER, P. Linear pattern matching algorithm. In: 14th Annual Symposium on
Switching and Automata Theory. [S.l.: s.n.], 1973. p. 1â€“11.
11 MCCREIGHT, E. M. A Space-Economical Suffix Tree Construction Algorithm.
Journal of the Association for Computing Machinery, v. 23, n. 2, p. 262â€“272, abr. 1976.
12 UKKONEN, E. On-line Construction of Suffix-Trees. Algorithmica, v. 14, p. 249â€“260,
1995.
81
13 KURTZ, S. Reducing the space requirement of suffix trees. Softw., Pract. Exper.,
v. 29, n. 13, p. 1149â€“1171, 1999.
14 KURTZ, S.; GIEGERICH, R. From Ukkonen to McCreight and Weiner: A unifying
view of linear-time suffix tree construction. Algorithmica, p. 331â€“353, 1997.
15 MUMMER Home Page. DisponÂ´Ä±vel em: <http://mummer.sourceforge.net/>. Acesso
em: 11/2006.
16 KURTZ, S. et al. Reputer: The manifold applications of repeat analysis on a genomic
scale. Nucleic Acids Research, v. 29, n. 22, p. 4633â€“4642, 2001.
17 SEDGEWICK, R. Algorithms in Java, 3rd Edition, parts 1â€“4. USA: Addison-Wesley,
2003.
18 MANBER, U.; MYERS, G. Suffix arrays: A new method for on-line string searches.
[S.l.], 1989.
19 KO, P.; ALURU, S. Space-Efficient Linear Time Construction of Suffix Arrays.
Journal of Discrete Algorithms, v. 3, n. 2-4, p. 143â€“156, 2005.
20 KaÂ¨RKKaÂ¨INEN, J.; SANDERS, P. Simpler linear work suffix array construction.
In: Int. Colloquium on Automata, Languages and Programming. [S.l.]: Springer Verlag,
2003. (Lecture Notes in Computer Science, v. 2719), p. 943â€“955.
21 KIM, D. K. et al. Linear-time construction of suffix arrays. In: 14th Annual
Symposium on Combinatorial Pattern Matching. [S.l.]: Springer Verlag, 2003. (Lecture
Notes in Computer Science, v. 2676), p. 186â€“199.
22 MANZINI, G.; FERRAGINA, P. Engineering a lightweight suffix array construction
algorithm. Algorithmica, v. 23, n. 40, p. 33â€“50, 2004.
23 FARACH, M. Optimal suffix tree construction with large alphabets. In: . [S.l.: s.n.],
1997. p. 137â€“143.
24 KASAI, T. et al. Linear-Time Longest-Common-Prefix Computation in Suffix Arrays
and Its Applications. In: 12th Annual Symposium on Combinatorial Pattern Matching.
[S.l.]: Springer Verlag, 2001. (Lecture Notes in Computer Science, v. 2089), p. 181â€“192.
25 ABOUELHODA, M.; KURTZ, S.; OHLEBUSCH, E. The enhanced suffix array
and its applications to genome analysis. In: Workshop on Algorithms in Bioinformatics.
[S.l.]: Springer Verlag, 2002. (Lecture Notes in Computer Science, v. 2452).
26 GABOW, H. N.; BENTLEY, J. L.; TARJAN, R. E. Scaling and related techniques
for geometry problems. In: 16th ACM STOC. [S.l.: s.n.], 1984. p. 135â€“143.
27 BENDER, M.; FARACH-COLTON, M. The LCA Problem Revisited. In: LATIN
2000. London, UK: Springer Verlag, 2000. (Lecture Notes in Computer Science, v. 1776),
p. 88â€“94.
28 PROJECT Gutenberg. DisponÂ´Ä±vel em: <http://www.gutenberg.org/>. Acesso em:
11/2006.
82
29 NCBI Genbank. DisponÂ´Ä±vel em: <http://ncbi.nlm.nih.gov/Genbank/index.html>.
Acesso em: 11/2006.
30 CANTERBURY Corpus. DisponÂ´Ä±vel em: <http://corpus.canterbury.ac.nz/>.
Acesso em: 11/2006.
31 KURTZ, K. et al. Versatile and open software for comparing large genomes. Genome
Biology, v. 5, p. R12, 2004.
32 PUGLISI, S. J.; SMYTH, W. F.; TURPIN, A. The Performance of Linear
Time Suffix Sorting Algorithms. In: DCC â€™05: Proceedings of the Data Compression
Conference. Washington, DC, USA: IEEE Computer Society, 2005. p. 358â€“367.
33 BENTLEY, J.; SEDGEWICK, R. Fast Algorithms for Sorting and Searching Strings.
In: SODA â€™97: Proceedings of the eighth annual ACM-SIAM symposium on Discrete
algorithms. Philadelphia, PA, USA: Society for Industrial and Applied Mathematics,
1997. p. 360â€“369.
34 FERRAGINA, P.; GROSSI, R. The string b-tree: A new data structure for string
search in external memory and its applications. Journal of the ACM, v. 46, n. 2, p.
236â€“280, 1999.
35 BENTLEY, J.; MCILROY, M. D. Engineering a sort function. Software, Practice
and Experience, v. 23, n. 11, p. 1249â€“1265, 1993.
36 FISCHER, J.; HEUN, V. Theoretical and Practical Improvements on the RMQ-
Problem, with Applications to LCA and LCE. In: Combinatorial Pattern Matching.
[S.l.]: Springer Verlag, 2006. (Lecture Notes in Computer Science, v. 4009), p. 36â€“48.
